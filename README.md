# 2cornot2c
It's a 101 C course for my students.
Sorry, only italian version so far.

## Indice
  * [Introduzione](#introduzione)
  * [Installare l'ambiente di sviluppo](#installare-l-ambiente-di-sviluppo)
    + [Guest Additions](#guest-additions)
  * [Laboratori](#laboratori)
  * [Il processo di compilazione](#il-processo-di-compilazione)
  * [Introduzione](#introduzione-1)
  * [Il primo programma in C](#il-primo-programma-in-c)
  * [Funzioni](#funzioni)
  * [Variabili](#variabili)
  * [Classi di memorizzazione](#classi-di-memorizzazione)
  * [Block scope](#block-scope)
  * [File scope](#file-scope)
  * [Linkage](#linkage)
  * [Storage duration](#storage-duration)
  * [Static storage duration](#static-storage-duration)
  * [Auto storage duration](#auto-storage-duration)
  * [Classi di memorizzazione](#classi-di-memorizzazione-1)
  * [Variabili automatiche (automatic class)](#variabili-automatiche--automatic-class-)
  * [Variabili register (regiter class)](#variabili-register--regiter-class-)
  * [Varabili statiche locali (static variables with block scope)](#varabili-statiche-locali--static-variables-with-block-scope-)
  * [Differenza tra definzione e dichiarazione di variabile](#differenza-tra-definzione-e-dichiarazione-di-variabile)
  * [Variabili globali con External Linkage (Static variables with External Linkage)](#variabili-globali-con-external-linkage--static-variables-with-external-linkage-)
  * [Variabili globali con Internal Linkage (Static variables with Internal Linkage)](#variabili-globali-con-internal-linkage--static-variables-with-internal-linkage-)
  * [Sintassi dichiarazione variabili](#sintassi-dichiarazione-variabili)
    + [Classi di memorizzazione per le funzioni](#classi-di-memorizzazione-per-le-funzioni)
    + [Classi memorizzazione riassunto](#classi-memorizzazione-riassunto)
    + [Suddivisione in moduli di un programma](#suddivisione-in-moduli-di-un-programma)
    + [Il preprocessore](#il-preprocessore)
      - [La direttiva #define](#la-direttiva--define)
      - [La direttiva #include](#la-direttiva--include)
      - [Le direttive #if #ifdef #ifndef](#le-direttive--if--ifdef--ifndef)
    + [Eliminazione temporanea di codice](#eliminazione-temporanea-di-codice)
    + [Protezione del contenuto dei file d'intestazione](#protezione-del-contenuto-dei-file-d-intestazione)
  * [Rappresentazione delle informazioni](#rappresentazione-delle-informazioni)
    + [Big & Little endian](#big---little-endian)
    + [Codifica numeri decimali](#codifica-numeri-decimali)
      - [Codifica interi senza segno](#codifica-interi-senza-segno)
      - [Condifica interi con segno (complemento a due)](#condifica-interi-con-segno--complemento-a-due-)
    + [Mapping signed - unsigned](#mapping-signed---unsigned)
    + [Estensione rappresentazione binaria di un numero intero](#estensione-rappresentazione-binaria-di-un-numero-intero)
    + [Troncamento rappresentazione binaria di un numero](#troncamento-rappresentazione-binaria-di-un-numero)
    + [Addizione senza segno](#addizione-senza-segno)
    + [Addizione con segno](#addizione-con-segno)
    + [Tipi di dato](#tipi-di-dato)
    + [`int`](#-int-)
      - [Stampare `int`](#stampare--int-)
      - [Altri tipi interi](#altri-tipi-interi)
      - [Stampare altri tipi di interi](#stampare-altri-tipi-di-interi)
      - [Overflow `int`](#overflow--int-)
- [Rappresentazione binaria `int`](#rappresentazione-binaria--int-)
    + [Cast](#cast)
      - [Cast tra `signed` e `unsigned`](#cast-tra--signed--e--unsigned-)
    + [Estensione della rappresentazione binario di un numero](#estensione-della-rappresentazione-binario-di-un-numero)
    + [Troncamento rappresentazione binaria](#troncamento-rappresentazione-binaria)
    + [`char`](#-char-)
    + [Stampare un `char`](#stampare-un--char-)
    + [Costanti](#costanti)
    + [Operatori](#operatori)
      - [Operatore di assegnamento: =](#operatore-di-assegnamento---)
    + [Operatore somma: +](#operatore-somma---)
    + [Operatore differenza: -](#operatore-differenza---)
    + [Operatore segno: - e +](#operatore-segno----e--)
    + [Operatore moltiplicazione: *](#operatore-moltiplicazione---)
    + [Operatore divisione: /](#operatore-divisione---)
    + [Operatore `sizeof`](#operatore--sizeof-)
    + [Operatore %](#operatore--)
    + [Operatore incremento/decremento ++ --](#operatore-incremento-decremento------)
    + [Controllo del flusso](#controllo-del-flusso)
      - [if o if-else](#if-o-if-else)
      - [Condizioni complesse con l'uso di operatori logici e condizionali](#condizioni-complesse-con-l-uso-di-operatori-logici-e-condizionali)
      - [for](#for)
      - [while](#while)
      - [do-while](#do-while)
      - [switch](#switch)
      - [break e continue](#break-e-continue)
  * [I puntatori](#i-puntatori)
    + [Puntatori non inizializzati](#puntatori-non-inizializzati)
    + [Il puntatore nullo (NULL)](#il-puntatore-nullo--null-)
      - [Aritmetica puntatori](#aritmetica-puntatori)
    + [Vettori](#vettori)
      - [Inizializzare un vettore](#inizializzare-un-vettore)
      - [Dimensione vettore (`sizeof`)](#dimensione-vettore---sizeof--)
    + [Relazione tra array e puntatori](#relazione-tra-array-e-puntatori)
    + [Differenza tra puntatori](#differenza-tra-puntatori)
    + [Le stringhe](#le-stringhe)
    + [Dettagli sull'inizializzazione](#dettagli-sull-inizializzazione)
    + [Stampare una stringa](#stampare-una-stringa)
    + [Funzioni](#funzioni-1)
    + [Dichiarazione di funzione](#dichiarazione-di-funzione)
    + [Uso di void nelle funzioni](#uso-di-void-nelle-funzioni)
    + [Definizione di funzione](#definizione-di-funzione)
    + [Chiamata di funzione](#chiamata-di-funzione)
    + [Passaggio di parametri per valore](#passaggio-di-parametri-per-valore)
    + [Passaggio di parametri per indirizzo](#passaggio-di-parametri-per-indirizzo)
    + [Passaggio di puntatori const](#passaggio-di-puntatori-const)
    + [Array come parametri a funzioni](#array-come-parametri-a-funzioni)
    + [Allocazione dinamica della memoria](#allocazione-dinamica-della-memoria)
    + [Array bidimensionali](#array-bidimensionali)
    + [Array di puntatori](#array-di-puntatori)
    + [Differenza tra array bidimensionali ed array di puntatori](#differenza-tra-array-bidimensionali-ed-array-di-puntatori)
    + [Sezioni di memoria di un programma C](#sezioni-di-memoria-di-un-programma-c)
    + [L'inizializzazioni delle variabili](#l-inizializzazioni-delle-variabili)
    + [Allocazione dinamica di matrici](#allocazione-dinamica-di-matrici)
    + [Le strutrure](#le-strutrure)
      - [Passaggio di strutture a funzioni](#passaggio-di-strutture-a-funzioni)
  * [Sistema Operativo](#sistema-operativo)
    + [I modelli di memoria](#i-modelli-di-memoria)
    + [I Segmenti](#i-segmenti)
    + [I Registri](#i-registri)
    + [I registri di segmento](#i-registri-di-segmento)
    + [I registri di segmento in x64](#i-registri-di-segmento-in-x64)
    + [I registri General-Purpose](#i-registri-general-purpose)
    + [Instruction Pointer](#instruction-pointer)
    + [Flags Register](#flags-register)
    + [Math Coprocessors and Registers](#math-coprocessors-and-registers)
    + [I quattro principali modelli di programmazione per x86](#i-quattro-principali-modelli-di-programmazione-per-x86)
  * [Real Mode Flat Model (modello piatto in modalità reale)](#real-mode-flat-model--modello-piatto-in-modalit--reale-)
  * [Real Mode Segmented Model (modello segmentato in modalità reale)](#real-mode-segmented-model--modello-segmentato-in-modalit--reale-)
    + [32-Bit Protected Mode Flat Model](#32-bit-protected-mode-flat-model)
    + [Memory Mapped Video](#memory-mapped-video)
    + [Accesso diretto alle porte hardware](#accesso-diretto-alle-porte-hardware)
    + [Chiamate dirette al BIOS](#chiamate-dirette-al-bios)
    + [64bit Long Mode](#64bit-long-mode)
  * [Il primo programmma assembly (eatsyscall.asm)](#il-primo-programmma-assembly--eatsyscallasm-)
  * [Il primo programmma assembly in SASM (eatsyscallgcc.asm)](#il-primo-programmma-assembly-in-sasm--eatsyscallgccasm-)
    + [Template per nasm](#template-per-nasm)
    + [Template per sasm](#template-per-sasm)
    + [Le Istruzione ed i loro operandi](#le-istruzione-ed-i-loro-operandi)
    + [Operandi Sorgente e Destinazione](#operandi-sorgente-e-destinazione)
    + [Dati Immediati](#dati-immediati)
    + [Dati di Registro](#dati-di-registro)
    + [Dati di Memoria ed Effective Addresses](#dati-di-memoria-ed-effective-addresses)
    + [Il dato ed il suo indirizzo](#il-dato-ed-il-suo-indirizzo)
    + [La dimensione dei dati di memoria](#la-dimensione-dei-dati-di-memoria)
    + [Il registro RFLAGS](#il-registro-rflags)
    + [Aggiungere e Sottrarre 1 con INC e DEC](#aggiungere-e-sottrarre-1-con-inc-e-dec)
    + [Come i Flags cambiano l'esecuzione del programma](#come-i-flags-cambiano-l-esecuzione-del-programma)
    + [Valori Signed ed Unsigned](#valori-signed-ed-unsigned)
    + [Complemento a due e NEG](#complemento-a-due-e-neg)
    + [Estensione del segno e MOVSX](#estensione-del-segno-e-movsx)
    + [Operandi impliciti e MUL](#operandi-impliciti-e-mul)
    + [MUL ed il Carry Flag](#mul-ed-il-carry-flag)
    + [Divisione senza segno con DIV](#divisione-senza-segno-con-div)
    + [MUL e DIV sono dei ritardatari](#mul-e-div-sono-dei-ritardatari)
    + [Leggere ed Usare una guida all'assembly](#leggere-ed-usare-una-guida-all-assembly)
    + [Legal Forms](#legal-forms)
    + [Operand Symbols](#operand-symbols)
    + [Examples](#examples)
    + [Notes](#notes)
    + [Cosa manca](#cosa-manca)
    + [Esaminiamo `EASTSYSCALL.ASM`](#esaminiamo--eastsyscallasm-)
    + [Sezione .data](#sezione-data)
    + [Sezione .bss](#sezione-bss)
    + [Sezione .text](#sezione-text)
    + [Labels (Etichette)](#labels--etichette-)
    + [Variabili per i dati inizializzati](#variabili-per-i-dati-inizializzati)
    + [Variabili Stringa](#variabili-stringa)
    + [Derivare la lunghezza della stringa con EQU e $](#derivare-la-lunghezza-della-stringa-con-equ-e--)
    + [Lo Stack (LIFO: Last in, First out)](#lo-stack--lifo--last-in--first-out-)
    + [Istruzione Push](#istruzione-push)
    + [Istruzione Pop](#istruzione-pop)
    + [PUSHA E POPA sono stati rimossi](#pusha-e-popa-sono-stati-rimossi)
    + [Push e Pop in dettaglio](#push-e-pop-in-dettaglio)
    + [Syscall del kernel](#syscall-del-kernel)
    + [ABI (Application Binary Interface)](#abi--application-binary-interface-)
    + [Lo Schema dei Parametri del Registro ABI](#lo-schema-dei-parametri-del-registro-abi)
    + [Terminare un programma via SYSCALL](#terminare-un-programma-via-syscall)
    + [Registri sporcati da una SYSCALL](#registri-sporcati-da-una-syscall)
    + [Progettare un programma](#progettare-un-programma)
    + [Scansionare un Buffer](#scansionare-un-buffer)
    + [Dallo Pseudocodice al codice Assembly](#dallo-pseudocodice-al-codice-assembly)
    + [Operazioni sui Bit](#operazioni-sui-bit)
    + [Bit Numbering](#bit-numbering)
    + [Operazioni Binarie](#operazioni-binarie)
    + [Istruzione AND](#istruzione-and)
    + [Mascherare i Bit](#mascherare-i-bit)
    + [Istruzione OR](#istruzione-or)
    + [Istruzione XOR](#istruzione-xor)
    + [Istruzione NOT](#istruzione-not)
    + [I segmenti di registro non rispondono alla logica](#i-segmenti-di-registro-non-rispondono-alla-logica)
    + [Shiftare i Bit](#shiftare-i-bit)
    + [Come funziona lo shifting dei bit](#come-funziona-lo-shifting-dei-bit)
    + [Colpire i Bit nel Carry Flag](#colpire-i-bit-nel-carry-flag)
    + [L'istruzione Rotate](#l-istruzione-rotate)
    + [Ruotare i Bit attraverso il Carry Flag](#ruotare-i-bit-attraverso-il-carry-flag)
    + [Settare un valore conosciuto nel Carry Flag](#settare-un-valore-conosciuto-nel-carry-flag)
    + [Bit-Bashing](#bit-bashing)
    + [Dividere un Byte in due Nibble](#dividere-un-byte-in-due-nibble)
    + [Shiftare il nibble alto nel nibble basso](#shiftare-il-nibble-alto-nel-nibble-basso)
    + [Usare una Lookup Table](#usare-una-lookup-table)
    + [Moltiplicare attraverso Shifting e Somme](#moltiplicare-attraverso-shifting-e-somme)
    + [Flags, Tests e Branches](#flags--tests-e-branches)
    + [Salti Incondizionati](#salti-incondizionati)
    + [Salti Condizionati](#salti-condizionati)
    + [Saltare sull'assenza di una condizione](#saltare-sull-assenza-di-una-condizione)
    + [Flags](#flags)
    + [Confronti con CMP](#confronti-con-cmp)
    + [Una giungla di istruzioni JUMP](#una-giungla-di-istruzioni-jump)
    + [Cercare un bit a 1 con TEST](#cercare-un-bit-a-1-con-test)
    + [Cercare un bit a 0 con  BT](#cercare-un-bit-a-0-con--bt)
    + [X64 Long Mode Memory Addressing](#x64-long-mode-memory-addressing)
    + [Calcolo dell' Effective Address](#calcolo-dell--effective-address)
    + [Displacements (Scostamento)](#displacements--scostamento-)
    + [Il problema della dimensione dello scostamento in x64](#il-problema-della-dimensione-dello-scostamento-in-x64)
    + [Base Addressing (indirizzamento di base)](#base-addressing--indirizzamento-di-base-)
    + [Base + Displacement Addressing](#base---displacement-addressing)
    + [Base + Index Addressing](#base---index-addressing)
    + [Index X Scale + Displacement Addressing](#index-x-scale---displacement-addressing)
    + [Altri Schemi d'Indirizzamento](#altri-schemi-d-indirizzamento)
    + [Istruzione LEA](#istruzione-lea)
    + [Tabella di traduzione caratteri](#tabella-di-traduzione-caratteri)
    + [Tabella di traduzione](#tabella-di-traduzione)
    + [Tradurre con MOV o XLAT](#tradurre-con-mov-o-xlat)
    + [Tabelle al posto di calcoli](#tabelle-al-posto-di-calcoli)
    + [Procedure](#procedure)
    + [Chiamare e Ritornare](#chiamare-e-ritornare)
    + [Chiamate all'interno di chiamate](#chiamate-all-interno-di-chiamate)
    + [Il pericolo della ricorsione accidentale](#il-pericolo-della-ricorsione-accidentale)
    + [Un errore di etichetta sul flag di cui fare attenzione](#un-errore-di-etichetta-sul-flag-di-cui-fare-attenzione)
    + [Le Procedure ed i dati di cui hanno bisogno](#le-procedure-ed-i-dati-di-cui-hanno-bisogno)
    + [Salvare i registri del chiamante](#salvare-i-registri-del-chiamante)
    + [Preservare i registri attraverso le chiamate di sistema Linux](#preservare-i-registri-attraverso-le-chiamate-di-sistema-linux)
    + [PUSHAD e POPAD sono spariti](#pushad-e-popad-sono-spariti)
    + [Dati Locali](#dati-locali)
    + [Inserire Dati Costanti nelle Definizioni delle Procedure](#inserire-dati-costanti-nelle-definizioni-delle-procedure)
    + [Alcuni trucchi per le Tabelle](#alcuni-trucchi-per-le-tabelle)
    + [Etichette locali e lunghezze dei salti](#etichette-locali-e-lunghezze-dei-salti)
    + [Accesso forzato all'etichetta locale](#accesso-forzato-all-etichetta-locale)
    + [Salti Corti, Vicini e Lontani](#salti-corti--vicini-e-lontani)
    + [Costruzione di librerie di procedure esterne](#costruzione-di-librerie-di-procedure-esterne)
    + [Quando i Tool raggiungono i loro limiti](#quando-i-tool-raggiungono-i-loro-limiti)
    + [Utilizzare gli include file in SASM](#utilizzare-gli-include-file-in-sasm)
    + [Dove devono essere memorizzati i file di inclusione di SASM](#dove-devono-essere-memorizzati-i-file-di-inclusione-di-sasm)
    + [Il modo migliore per creare una libreria di file di inclusione](#il-modo-migliore-per-creare-una-libreria-di-file-di-inclusione)
    + [Assemblaggio e moduli separati](#assemblaggio-e-moduli-separati)
    + [Dichiarazioni Globali ed Esterne](#dichiarazioni-globali-ed-esterne)
- [Il meccanismo dei Globals e Externals](#il-meccanismo-dei-globals-e-externals)
    + [Linkare le librerie nei tuoi programmi](#linkare-le-librerie-nei-tuoi-programmi)
    + [I pericoli di troppe procedure e tropte librerie](#i-pericoli-di-troppe-procedure-e-tropte-librerie)
    + [L'arte di creare procedure](#l-arte-di-creare-procedure)
    + [Manutenibilità e Riutilizzo](#manutenibilit--e-riutilizzo)
    + [Decidere cosa dovrebbe essere una procedura](#decidere-cosa-dovrebbe-essere-una-procedura)
    + [Usare i commenti!](#usare-i-commenti-)
    + [Controllo semplice del cursore nella console di Linux](#controllo-semplice-del-cursore-nella-console-di-linux)
    + [Avvertenze per il controllo della console](#avvertenze-per-il-controllo-della-console)
    + [Creare ed Usare Macro](#creare-ed-usare-macro)
    + [Il Meccanisco della definizione di Macro](#il-meccanisco-della-definizione-di-macro)
    + [Definire Macron con parametri](#definire-macron-con-parametri)
    + [Il Meccanismo d'invocazione delle Macro](#il-meccanismo-d-invocazione-delle-macro)
    + [Etichette Locali all'interno di macro](#etichette-locali-all-interno-di-macro)
    + [Librerie Macro come File di Inclusione](#librerie-macro-come-file-di-inclusione)
    + [Macro contro Procedure: Pro e Contro](#macro-contro-procedure--pro-e-contro)
    + [Le stringhe in lunguaggio Assembly](#le-stringhe-in-lunguaggio-assembly)
    + [Stringa Sorgente e stringa Destinazione](#stringa-sorgente-e-stringa-destinazione)
    + [Uno schermo virtuale di visualizzazione del testo](#uno-schermo-virtuale-di-visualizzazione-del-testo)
    + [REP STOSB, la mitragliatrice software](#rep-stosb--la-mitragliatrice-software)
    + [Mitragliatrice sul display virtuale](#mitragliatrice-sul-display-virtuale)
    + [Esecuzione dell'istruzione STOSB](#esecuzione-dell-istruzione-stosb)
    + [STOSB e il Flag di Direzione DF](#stosb-e-il-flag-di-direzione-df)
    + [Definire le linee nel buffer di visualizzazione](#definire-le-linee-nel-buffer-di-visualizzazione)
    + [Invio del Buffer alla Console di Linux](#invio-del-buffer-alla-console-di-linux)
    + [L'Arma Semiautomatica: STOSB Senza REP](#l-arma-semiautomatica--stosb-senza-rep)
    + [Chi Decrementa RCX?](#chi-decrementa-rcx-)
    + [L'Istruzione LOOP](#l-istruzione-loop)
    + [Visualizzare un righello sullo schermo](#visualizzare-un-righello-sullo-schermo)
    + [MUL non è IMUL](#mul-non---imul)
    + [Le quattro dimensioni di STOS](#le-quattro-dimensioni-di-stos)
    + [Addio Matematica BCD](#addio-matematica-bcd)
    + [MOVSB: Copie di blocco veloci](#movsb--copie-di-blocco-veloci)
    + [DF e Mosse di Blocco Sovrapposte](#df-e-mosse-di-blocco-sovrapposte)
    + [Istruzioni di stringa REP con passo singolo](#istruzioni-di-stringa-rep-con-passo-singolo)
    + [Memorizzare dati in stringhe discontinue](#memorizzare-dati-in-stringhe-discontinue)
    + [Visualizzazione di una tabella ASCII](#visualizzazione-di-una-tabella-ascii)
    + [Cicli di istruzioni annidati](#cicli-di-istruzioni-annidati)
    + [Salto quando RCX arriva a 0](#salto-quando-rcx-arriva-a-0)
    + [Chiusura del ciclo interno](#chiusura-del-ciclo-interno)
    + [Chiusura del ciclo esterno](#chiusura-del-ciclo-esterno)
    + [Showchar Recap](#showchar-recap)
    + [Argomenti da linea di comando, ricerche di stringhe e lo stack di Linux](#argomenti-da-linea-di-comando--ricerche-di-stringhe-e-lo-stack-di-linux)
    + [Visualizzazione degli argomenti della riga di comando da SASM](#visualizzazione-degli-argomenti-della-riga-di-comando-da-sasm)
    + [Ricerche di stringhe con SCASB](#ricerche-di-stringhe-con-scasb)
    + [REPNE vs. REPE](#repne-vs-repe)
    + [Non puoi passare argomenti da linea di comando ai programmi all'interno di SASM](#non-puoi-passare-argomenti-da-linea-di-comando-ai-programmi-all-interno-di-sasm)
    + [Lo Stack, la sua struttura e come usarlo](#lo-stack--la-sua-struttura-e-come-usarlo)
    + [Accedere allo Stack direttamente](#accedere-allo-stack-direttamente)
    + [Stack Alignment Prolog](#stack-alignment-prolog)
    + [Indirizzamento dei dati nello Stack](#indirizzamento-dei-dati-nello-stack)
    + [Usare gcc per l'assembly](#usare-gcc-per-l-assembly)
    + [SAMSusa GCC](#samsusa-gcc)
    + [Come usare GCC in assembly](#come-usare-gcc-in-assembly)
    + [Perchè no GAS?](#perch--no-gas-)
    + [Linking alla libreria standand del C](#linking-alla-libreria-standand-del-c)
    + [Convensioni di chiamata C](#convensioni-di-chiamata-c)
    + [Chiamanti, Chiamati e Sovrascrittori](#chiamanti--chiamati-e-sovrascrittori)
    + [Impostare lo Stack Frame](#impostare-lo-stack-frame)
    + [Distruggere lo Stack Frame (in the Epilog - epilogo)](#distruggere-lo-stack-frame--in-the-epilog---epilogo-)
    + [Allineamento dello Stack](#allineamento-dello-stack)
    + [Caratteri via Puts()](#caratteri-via-puts--)
    + [Testo formattato con printf()](#testo-formattato-con-printf--)
    + [Passaggio di parametri a printf()](#passaggio-di-parametri-a-printf--)
    + [Printf() necessita di uno 0 precedente in RAX](#printf---necessita-di-uno-0-precedente-in-rax)
    + [Gcc --no-pie](#gcc---no-pie)
    + [Dati in con fgets() e scanf()](#dati-in-con-fgets---e-scanf--)
    + [Utilizzando scanf() per l'inserimento di valori numerici](#utilizzando-scanf---per-l-inserimento-di-valori-numerici)
    + [Essere un Signore del Tempo Linux](#essere-un-signore-del-tempo-linux)
    + [La macchina del tempo della libreria C](#la-macchina-del-tempo-della-libreria-c)
    + [Recupero valori time_t dall'orologio di sistema](#recupero-valori-time-t-dall-orologio-di-sistema)
    + [Convertire un valore time_t in una stringa formattata](#convertire-un-valore-time-t-in-una-stringa-formattata)
    + [Generazione di valori locali di tempo separati](#generazione-di-valori-locali-di-tempo-separati)
    + [Creare una copia della struttura tm di glibc con MOVSD](#creare-una-copia-della-struttura-tm-di-glibc-con-movsd)
    + [Comprendere i mnemonici di istruzione AT&T](#comprendere-i-mnemonici-di-istruzione-at-t)
    + [Convezioni mnemoniche di AT&T](#convezioni-mnemoniche-di-at-t)
    + [Sintassi di riferimento della memoria AT&T](#sintassi-di-riferimento-della-memoria-at-t)
    + [Generazione di numeri casuali](#generazione-di-numeri-casuali)
    + [Inizializzare il generatore con srand()](#inizializzare-il-generatore-con-srand--)
    + [Generazione di numeri pseudocasuali](#generazione-di-numeri-pseudocasuali)
    + [Alcuni bit sono più casuali di altri](#alcuni-bit-sono-pi--casuali-di-altri)
    + [Chiamate a indirizzi nei registri](#chiamate-a-indirizzi-nei-registri)
    + [Usare puts() per inviare una linea vuota alla console](#usare-puts---per-inviare-una-linea-vuota-alla-console)
    + [Come passare più di sei parametri a una funzione libc](#come-passare-pi--di-sei-parametri-a-una-funzione-libc)
    + [Come C vede gli argomenti della riga di comando](#come-c-vede-gli-argomenti-della-riga-di-comando)
    + [Semplici operazioni di I/O sui file](#semplici-operazioni-di-i-o-sui-file)
    + [Convertire le stringhe in numeri con sscanf()](#convertire-le-stringhe-in-numeri-con-sscanf--)
    + [Creare ed Aprire i File](#creare-ed-aprire-i-file)
    + [Leggere testo dai file con fgets()](#leggere-testo-dai-file-con-fgets--)
    + [Scrivere testo su file con fprintf()](#scrivere-testo-su-file-con-fprintf--)
    + [Note sulla raccolta delle procedure in librerie](#note-sulla-raccolta-delle-procedure-in-librerie)
  * [Controllo dei processi](#controllo-dei-processi)
  * [Linux Programming](#linux-programming)
    + [Processi](#processi)
      - [Process IDs](#process-ids)
    + [Vedere i processi attivi](#vedere-i-processi-attivi)
    + [Uccidere un processo](#uccidere-un-processo)
    + [Creare un processo](#creare-un-processo)
      - [`system()`](#-system---)
    + [`fork()` `exec()`](#-fork-----exec---)
      - [Segnali](#segnali)
      - [sigaction](#sigaction)
      - [Terminare un processo](#terminare-un-processo)
      - [Aspettare la terminazione di un processo](#aspettare-la-terminazione-di-un-processo)
      - [wait()](#wait--)
      - [Processi zombie](#processi-zombie)
    + [Ripulire il figlio in modo asincrono](#ripulire-il-figlio-in-modo-asincrono)
    + [I Thread](#i-thread)
      - [Creazione di un thread](#creazione-di-un-thread)
      - [Passare dati ad un thread](#passare-dati-ad-un-thread)
      - [Attendere la terminazione dei thread](#attendere-la-terminazione-dei-thread)
      - [Il valore di ritorno dei thread](#il-valore-di-ritorno-dei-thread)
      - [`pthread_self()` e `pthread_equal()`](#-pthread-self----e--pthread-equal---)
      - [Gli attributi dei thread](#gli-attributi-dei-thread)
      - [Cancellazione del thread](#cancellazione-del-thread)
      - [Thread sincroni ed asincroni](#thread-sincroni-ed-asincroni)
      - [Sezioni critiche non cancellabili](#sezioni-critiche-non-cancellabili)
      - [Quando usare la cancellazione del thread](#quando-usare-la-cancellazione-del-thread)
    + [Dati specifici del thread](#dati-specifici-del-thread)
    + [Gestori di pulizia (Cleanup Handler)](#gestori-di-pulizia--cleanup-handler-)
    + [Sincronizzazione e Sezioni Critiche](#sincronizzazione-e-sezioni-critiche)
      - [Race Conditions](#race-conditions)
    + [Mutex](#mutex)
    + [Mutex Deadlocks](#mutex-deadlocks)
    + [Test Mutex non bloccanti](#test-mutex-non-bloccanti)
    + [Semafori](#semafori)
    + [Variabili di condizione](#variabili-di-condizione)
    + [Deadlocks con due o più Thread](#deadlocks-con-due-o-pi--thread)
    + [Implementazione dei Thread in GNU/Linux](#implementazione-dei-thread-in-gnu-linux)
    + [Signal Handling](#signal-handling)
    + [La chiamata di sistema Clone()](#la-chiamata-di-sistema-clone--)
    + [Processi vs Thread](#processi-vs-thread)

<small><i><a href='http://ecotrust-canada.github.io/markdown-toc/'>Table of contents generated with markdown-toc</a></i></small>



## 

## Introduzione

<p align=justify>
Il corso è fondamentalmente pratico, non è richiesto alcun prerequisito e nulla è dato per scontato.
</p>

<p align=justify>
Prima di iniziare è giusto ricordare che per svolgere i laboratori richiesti è necessaria la conoscenza di alcuni strumenti, in particolare:
</p>

* [git](https://git-scm.com/download/win)
* [virtualbox](https://www.virtualbox.org/wiki/Downloads) Installa la versione 7.0 che è la più recente compatibile con vagrant. Leggi [qui](https://developer.hashicorp.com/vagrant/docs/providers/virtualbox) per maggiori info
  * [Microsoft Visual C++](https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170) Solo in caso ti venga richiesto durante l'installaizone di VBox (dovrebbe andare in errore)
* [vagrant](https://developer.hashicorp.com/vagrant/install?ajs_aid=e022a39f-7694-4bed-a4cd-f721f515b885&product_intent=vagrant#windows)

<p align=justify>
I link forniti sopra portano alle versioni dei software per architettura `amd64` in ambiente `windows`, questo a causa dell'assenza di macchine linux nei lab scolastici.
</p>

<p align="justify">
 <b>GIT</b> e <b>VAGRANT</b> ci serviranno per ottenere un ambiente di sviluppo identico per tutti e per un provisioning automatico; in altre parole git ci permetterà di condividere il codice dei laboratori e vagrant di condividere la stessa macchina virtuale (<code>ubuntu-22.04</code>) con l'ambiente di sviluppo preinstallato.
</p>

 ## Installare l'ambiente di sviluppo

<p align="justify">
Guarda il <a href="https://drive.google.com/file/d/1WkLleojruhYkJ31kiY00jUknGVAGrHiR/view?usp=sharing">video</a> se i passaggi elencati sotto non ti sono chiari. Il video è senza tagli in modo da mostrare l'intero processo di installazione.
</p>

<p align="justify">
I passi seguenti permettono di duplicare sulla tua macchina locale l'ambiente di sviluppo (codice e vm).
Nella directory radice del progetto (<code>2cornot2c</code> che otterrai clonando il repository nei passi seguenti) troverai una directory <code>lab</code>con il codice c per tutti laboratori. 
Questa cartella <code>2cornot2c\lab</code> è montata automaticamente sul file system della macchina virtuale nella cartella <code>/lab</code>. 
Tutto quello che verrà modificato sulla macchina linux in <code>/lab</code>( vm o macchina guest) verrà visto sulla macchina windows (host) in <code>2cornot2c\lab</code>. 
</p>

1) Clona il repository con il codice ed il Vagrantfile

 ```bash
git clone https://github.com/kinderp/2cornot2c.git
```

2) Entra dentro la directory root del repository
   
```bash
cd 2cornot2c
```

3) Avvia la macchina virtuale

```bash
vagrant up
```

4) Apri una sessione ssh sulla macchina appena avviata

```bash
vagrant ssh
```

### Guest Additions

1. Installa il plugin `vagrant-vbguest`:

<p align="justify">	
Apri il terminale o il prompt dei comandi, vai alla directory del progetto Vagrant ed esegui il seguente comando.
</p>

```
     vagrant plugin install vagrant-vbguest
```

2. Configura il Guest Additions nel tuo Vagrantfile:

<p align="justify">	
Apri il tuo Vagrantfile.<br>
Aggiungi le seguenti line all'interno del blocco `config.vm.provision` (o in cima se lo vuoi applicare a tutte le VMs)
</p>

```
     config.vbguest.auto_update = false
```

<p align="justify">	
La riga di sopra disabilita gli aggiornamenti automatici delle Guest Additions, il che può essere utile se preferisci gestirli manualmente o se riscontri problemi con il processo di aggiornamento automatico. In alternativa, puoi abilitarlo in base alla presenza o meno del plugin:
</p>

```
     if Vagrant.has_plugin?("vagrant-vbguest")
       config.vbguest.auto_update = false
     end
```

<p align="justify">	
Questo assicura che l'impostazione è applicata solamente se il plugin è installato
</p>

3. Gestisci i Guest Additions (Opzionale):

<p align=justify>
Se vuoi in maggiore controllo sull'installazione dei Guest Additions, tu puoi usare i seguenti comandi:
</p>

* `vagrant vbguest`: Questo comando controlla lo stato delle Guest Additions e tenta di installarle o aggiornarle se necessario.
* `vagrant vbguest --do install`: Questo forza l'installazione delle Guest Additions.
* `vagrant vbguest --do rebuild`: Questo ricostruisce i moduli del kernel del Guest Additions, il che può essere utile se hai aggiornato il tuo kernel.
* `vagrant vbguest --status`: Questo mostra lo stato attuale delle aggiunte degli ospiti.

<p align=justify>
Tu puoi anche scaricare il file ISO dei Guest Additions e montarlo manualmente all'interno della VM se secessario
</p>

4. Starta or Ricarica la tua macchina: 

<p align="justify">	
Dopo aver apportato modifiche al tuo Vagrantfile, esegui <code>vagrant up</code> per avviare il computer o <code>vagrant reload</code> per applicare le modifiche. Il plugin <code>vagrant-vbguest</code> gestirà l'installazione o l'aggiornamento delle Guest Additions in base alla tua configurazione. Seguendo questi passaggi, puoi gestire efficacemente l'installazione e l'aggiornamento delle Guest Additions di VirtualBox all'interno del tuo ambiente Vagrant.
</p>

## Laboratori

<div align="justify">	
All'interno della cartella <code>/lab</code> nella macchian Linux troverai il codice su cui lavorare.
Ogni lab ha un numero ed un nome ad esso associato, ad esempio al primo laboratorio è assegnato il numero <code>0</code> ed il nome <code>intro</code>; questo significa che per questo lab esisterà una cartella <code>lab/0_intro</code> che conterrà tutto il codice del lab. All'interno della cartella del laboratorio troverai dei file sorgente con estensione <code>.c</code> o <code>.h</code> anche questi con un numero ed un nome; ad esempio il primo sorgente del lab <code>0_intro</code> è <code>0_hello.c</code>.
Ogni lab al suo interno contiene una cartella <code>bin</code> destinata ad ospitare i file eseguibili ottenuti al termine del processo di compilazione.
</div>

## Il processo di compilazione

<p align="justify">
I programmi sono scriti in un qualche linguaggio di programmazione, il programmatore scrive il codice sorgente; nel caso del linguaggio C i file sorgente hanno estensione <code>.c</code> o <code>.h</code>. Il codice sorgente contiene tutte le istruzioni che il programma dovrà eseguire. Le istruzioni all'interno del codice sorgente scritte in un qualsiasi linguaggio di programmazione devono essere tradotte in una sequenza di bit (in altri termini nel linguaggio macchina) perchè la cpu è in grado di comprendere solo il linguaggio macchina, esclusivamente sequenze di bit e nient'altro. In sintesi si dice che il programma sorgente deve essere trasformato in un file eseguibile (file binario) che contiene le istruzioni (sequenze di bit) per la specifica architettura del nostro processore.
Questo processo di trasformazione del sorgente in binario è detto processo di compilazione ed è svolto dal compilatore. In realtà queto processo è articolato in vari step e non coinvolge solo il compilatore. Vediamo brevemente di studiarne le fasi.
Se non lo hai già fatto avvia la macchina virtuale con <code>vagrant up</code> ed al termine del boot avvia una sessione ssh con il comando <code>vagrant ssh</code>.
Una volta dentro, nella tua home directory (utente vagrant) usa vim per creare un nuovo file in questo modo: <code>vim hello.c</code> e copia il codice mostrato sotto:
</p>

```c
#include <stdio.h>

int main(void){
    printf("Hello World");
}
```

Salva il contenuto premendo la combinazione: `Esc` + `:wq`.

<p align="justify">
Compila il sorgente <code>hello.c</code> lanciando il seguente comando: <code>gcc -o hello hello.c</code>; gcc è il compilatore che useremo in questo corso, lo trovi già installato sulla vm. In questo caso l'opzione <code>-o</code> specifica il nome del file oggetto (il file binario eseguibile) che vogliamo creare; ovviamente dobbiamo specificare successivamente il sorgente da cui partire per la generazione dell'eseguibile (<code>hello.c</code>). Se tutto ha funzionato puoi lanciare il programma appena compilato in questo modo: <code>./hello</code>. Come avrai avuto modo di constatare, il programma ha stampato a schermo la frase <code>Hello World</code>; per fare ciò il programmatore si è servito di un pezzo di codice già pronto (in sostenza la funzione <code>printf()</code>). Per informare il compilatore circa il corretto uso di questo pezzo di codice (la funzione <code>printf()</code>) è stata inserita nella prima riga del programma la direttiva al preprocessore <code>#include <stdio.h></code>. Vedremo in dettaglio cosa vuol dire usare una funzione esterna e come includere con le direttive il suo prototipo, per adesso ci basta sapere che per stampare è stata usata una funzione già pronta ed è stato necessario informare il compilatore di questo.
</p>

<p align="center">
<img src="https://github.com/kinderp/2cornot2c/blob/main/images/processo_di_compilazione.png" align="center">
</p>

<p align="justify">
Nella figura di sopra è mostato l'intero processo di compilazione che è composto da almeno quattro fasi; come puoi vedere i due parametri passati al compilatore con: <code>gcc -o hello hello.c</code> sono ripsettivamente il nome del file di input del processo (<code>hello.c</code>) cioè il sorgente di partenza ed il file di output (<code>hello</code>) cioè l'eseguibile che vogliamo generare al termine del processo.
Volendo è possibile richiedere al compilatore di fermarsi ad uno specifico step senza produrre l'output finale. Le quattro fasi del processo di compilazione sono rispettivamente:
</p>

1. **Preprocessamento** (_Preprocessing_):
<p align="justify">il preprocessore (<code>cpp</code>) esegue sostituzioni di testo, disabilita/abilita condizionalmente parti di codice in fase di compilazione. Il risultato della sua elaborazione è un file con estensione <code>.i</code>: nel nostro caso quindi <code>hello.i</code>. Per bloccare il processo di compilazione alla fase di preprocessamento puoi eseguire questo comando: <code>gcc -E hello.c > hello.i</code>. Il file <code>hello.i</code> conterrà tutte le sostituzioni effettuate dal preprocessore e come puoi vedere da solo, ha molto più contenuto del file di partenza <code>hello.c</code>, spiegheremo le chiamate al preprocessore nei prossimi paragrafi.</p>

2. **Compilazione** (_Compilation_):
<p align="justify">il compilatore (<code>cc</code>) trasforma il contenuto testuale del file <code>hello.i</code> (che è scritto in codice c) nel corrispettivo codice assembly (<code>hello.s</code>) specifico per l'architettura del processore target. Puoi bloccare il processo alla fase di compilazione producendo il corrispettivo codice assembly in questo modo: <code>gcc -S -masm=intel hello.c</code>
</p>

3. **Assemblaggio** (_Assembly_):
<p align="justify">
l'assemblatore <code>as</code> trasforma il codice assembly contenuto in <code>hello.s</code> nelle istruzioni macchina dell'architettura della cpu, il risultato è il file oggetto rilocabile <code>hello.o</code>. Puoi bloccare il processo in questa fase con il comando: <code>gcc -c hello.c</code>
</p>

4. **Linkaggio** (_Linking_):
<p align="justify">
il linker (<code>ld</code>) ha il compito di aggreggare in un unico file oggetto (il file eseguibile) eventuali altri file oggetto di librerie esterne o del linguaggio. Nel nostro esempio il programmatore ha fatto uso di una funzione del linguaggio (<code>printf()</code>) quindi il linker aggregerà nel file eseguibile (<code>hello</code>) il file oggetto <code>hello.o</code> ed il file oggetto relativo al codice della funzione printf: <code>printf.o</code>. Puoi generare il file eseguibile in questo modo: <code>gcc -o hello hello.c</code>
</p>

## Introduzione

<p align=justify>
Un programma C è di fatto una collezione di:
</p>

<ul>
	<li>Variabili</li>
	<li>Costanti</li>
	<li>Funzioni</li>
	<li>Chiamate al preprocessore</li>
</ul>

<p align=justify>
Di seguito provvederemo a dare una definizione sommaria per ogni componente sopra citato, rimandiamo ai singoli paragrafi per una trattazione completa.
</p>

<table align="center">
	<td>:exclamation: <b>Importante</b>
	<p align=justify>
 Una <b>variabile</b> è una locazione di memoria a cui è stato associato un <b>identificatore</b> cioè un nome per referenziare nel codice quella cella di memoria
	</p>
	</td>
</table>

<p align="justify">
Una variabile ha un <b>tipo</b>; il tipo associato ad una variabile definisce appunto che genere di dato essa può contenere (un numero intero, un numero reale, un carattere etc.) in altre parole il tipo della variabile definisce il numero di byte occupati dalla locazione di memoria referenziata dall'identificatore.
Una variabile può cambiare il valore in essa contenuto durante il ciclo di vita del programma. L'operazione mediante la quale si assegna un valore iniziale ad una variabile è detto <b>inizializzazione</b>, l'operazione attraverso cui si associa un nuovo valore ad una variabile già inizializzata è detta <b>assegnamento</b>
Prima di usare una variabile è necessario prima dichiararla cioè assegnarle un tipo ed un identificatore. Non è obbligatorio invece assegnare un valore iniziale ad una variabile in fase di dichiarazione. Una variabile dichiarata ma non inizializzata conterrà un valore assolutamente casuale, in pratica il valore che era precedentemente contenuto nella locazione di memoria che è stata associata alla varabile (o meglio al suo identificatore).
</p>

```c
int var_intera; // dichiarazione di variabile senza inizializzazione
var_intera = 5; // assegnamento di varabile precedentemente non inizializzata
int var_intera_inizializzata = 3; // dichirazione di variabile con inizializzazione
var_intera_inizializzata = 9; // assegnamento
```

<table align="center">
	<td>⚠️: <b>Attenzione</b>
	<p align=justify>
Le variabili possono essere sia dichiarate che definite e spesso due termini sono usati per esprimere la stessa cosa. E' prematuro spiegarne la lieve differenza ma tieni a mente per adesso i due termini non sono la stessa cosa.
	</p>
	</td>
</table>

<table align="center">
	<td>❗: <b>Importante</b>
	<p align=justify>
Per la <b>costante</b> valgono le stesse considerazioni fatte per le variabili con l'eccezione che per le costanti non è possibile assegnare un nuovo valore una volta che questa è stata inizializzata
	</p>
	</td>
</table>

```c
const double pi = 3.14; // costante pi greco
```

<table align="center">
	<td>❗: <b>Importante</b>
	<p align=justify>
<b>Una funzione</b> è una collezione di istruzioni che svolgono uno specifico compito
	</p>
	</td>
</table>

<p align="justify">
una funzione ha un nome (<code>differenza</code> nel codice sottostante), un valore di ritorno, dei parametri di input (<code>minuendo</code> e <code>sottraendo</code> nel codice d'esempio) ed un corpo che è delimitato da una parentesi graffa aperta <code>{</code> ed una chiusa <code>}</code>.
I parametri d'ingresso detti anche parametri formali sono racchiusi tra una coppia di parentesi tonde: <code>(</code>, <code>)</code>.
</p>

```c
int differenza(int minuendo, int sottraendo){
    return minuendo - sottraendo;
}
```

<table align="center">
	<td>❗: <b>Importante</b>
	<p align=justify>
Il preprocessore viene richiamato dal compilatore come primo step nel processo di generazione del file eseguibile. Il preprocessore ha il compito di effettuare delle semplici sostituzioni di testo; esistono diverse sostituzioni che il preprocessore può effettuare per conto nostro. L'insieme di queste operazioni sono dette <b>chiamate al preprocessore</b>.
	</p>
	</td>
</table>

## Il primo programma in C

<p align="justify">
Come da tradizione, il primo esempio di codice è il classico <code>Hello World</code>.
Il programma di sotto stampa a schermo una semplice frase: <code>Ciao Mondo</code> in inglese.
</p>

<details>
<summary>lab/0_intro/0_hello.c</summary>
[/lab/0_intro/0_hello.c](https://github.com/kinderp/2cornot2c/blob/18b60e866c1e0e22c59835fe953cbe3c534e7422/lab/0_intro/0_hello.c)
</details>

```c {.line-numbers}
#include <stdio.h>

int main(void){
        printf("Hello World\n");
        return 0;
}
```

<p align="justify">
Compila il sorgente con: <code>gcc -o 0_hello bin/0_hello</code> e poi esegui il programma con: <code>bin/0_hello</code>.
Riconosciamo subito una funzione: <code>main()</code>. Questa è una funzione speciale, tutti i programmi C devono averne una in quanto rappresenta il punto di partenza per l'esecuzione di ogni programma. Sei libero di chiamare tutte le altre funzioni a tuo piacimento ma la funzione da cui parte l'esecuzione si deve chiamare <code>main()</code>. Come qualsiasi funzione, <code>main()</code> ha un tipo di ritorno <code>int</code> e dei parametri in ingresso opzionali, in questo caso la funzione <code>main()</code> non si aspetta nessun parametro in ingresso dal chiamante (il sistema operativo) e per esprimere che questa non accetta alcun valore in ingresso si usa la parola riservata <code>void</code>.
Ti potrebbe capitare di vedere la funzione <code>main()</code> in queste versioni:
</p>

```c
main()
```

```c
void main()
```

<p align="justify">
La prima forma è tollerata da vecchia versioni del C (C90) o pre ANSI C ma non è accettata da quelle successive (C99, C11); la seconda potrebbe essere tollerata da alcuni compilatori ma se il tuo codice deve funzionare anche su altre macchine è meglio usare qualcosa che funzioni sempre: dunque evitala.
</p>

<table align="center">
	<td>❗: <b>Importante</b>
	<p align=justify>
<b>Dichiarazione di funzione</b> (o <b>prototipo</b>): il tipo di ritorno, i tipi dei parametri in ingresso ed il nome della funzione rappresentano il prototipo della funzione. Quando si fornisce il prototipo di una funzione si usa dire che si effettua la dichiarazione della funzione
	</p>
	</td>
</table>

<table align="center">
	<td>❗: <b>Importante</b>
	<p align=justify>
<b>Definizione di funzione</b>: quando si fornisce l'implementazione della funzione (il corpo: cioè le istruzioni contenute tra la coppia di graffe <code>{</code> <code>}</code>) allora si dice che la funzione è definita. La definizione implica anche la dichiarazione
	</p>
	</td>
</table>

<p align=justify>
Riprendendo la funzione <code>differenza</code> usata precedentemente avremo rispettivamente: la definizione in basso
</p>

```c
/* definizione della funzione differenza */
int differenza(int minuendo, int sottraendo){
    return minuendo - sottraendo;
}
```
<p align=justify>
e la dichiarazione o prototipo di seguito:
</p>

```c
int differenza(int, int);  // prototipo della funzione differenza
```

<p align=justify>
volendo è possibile fornire anche i nomi dei parametri in ingresso ma nulla cambia ai fini della dichiarazione.
</p>

```c
int differenza(int minuendo, int sottraendo);  // prototipo della funzione differenza
```

<table align="center">
	<td>❗: <b>Importante</b>
	<p align=justify>
Il compilatore quando incontra una chiamata a funzione deve conoscerne almeno il prototipo per verificare che questa stia venendo usata correttamente (il corretto numero e tipo per i parametri di ingresso e che il valore di ritorno sia assegnato ad una variabile compatibile, dello stesso tipo). E' necessario dunque, prima di usare una qualsiasi funzione, aver fornito nelle righe precedenti l'uso della funzione almeno il suo prototipo o la definizione completa. 
	</p>
	</td>
</table>

<p align="justify">
La funzione <code>main()</code> fa uso di un'altra funzione: <code>printf()</code> che viene usata per stampare su schermo. Questa funzione è fornita (la sua implementazione) dal linguaggio C stesso, quindi non viene definita (non si fornisce l'implementazione nel nostro file). L'implementazione della <code>printf()</code> sarà fornita sotto forma di file oggetto <code>.o</code> che verrà assemblato dal linker assieme al nostro .o: <code>hello.o</code> all'interno del file eseguibile finale. Il compilatore, come anticipato, ha però bisogno di conoscere almeno il prototipo della funzione <code>printf()</code> per verificarne l'uso corretto. Il prototipo della funzione <code>printf()</code> è fornito all'interno del file <code>stdio.h</code>; risulta necessario copiare il contenuto di questo file nel nostro esempio nelle righe precedenti a quella dove la funzione <code>printf()</code> è effettivamente usata (chiamata a funzione). Non c'è bisogno di copiare ed incollare il file <code>stdio.h</code> ma è possibile usare una direttiva del preprocessore <code>#include<stdio.h></code> che sostuisce il contenuto del file <code>stdio.h</code> a partire dalla riga di codice dove è inserita.
Per verificare l'effettiva aggiunta del prototipo di <code>printf()</code> da parte del preprocessore puoi lanciare:
</p>

```bash
 gcc -E 0_hello.c |grep 'printf'
```

<p align="justify">
questo l'output sulla mia macchina:
</p>

```bash
      1 extern int fprintf (FILE *__restrict __stream,
      2 extern int printf (const char *__restrict __format, ...);
      3 extern int sprintf (char *__restrict __s,
      4 extern int vfprintf (FILE *__restrict __s, const char *__restrict __format,
      5 extern int vprintf (const char *__restrict __format, __gnuc_va_list __arg);
      6 extern int vsprintf (char *__restrict __s, const char *__restrict __format,
      7 extern int snprintf (char *__restrict __s, size_t __maxlen,
      8      __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 3, 4)));
      9 extern int vsnprintf (char *__restrict __s, size_t __maxlen,
     10      __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 3, 0)));
     11 extern int vdprintf (int __fd, const char *__restrict __fmt,
     12      __attribute__ ((__format__ (__printf__, 2, 0)));
     13 extern int dprintf (int __fd, const char *__restrict __fmt, ...)
     14      __attribute__ ((__format__ (__printf__, 2, 3)));
     15  printf("Hello World\n");
```

<p align="justify">
Alla riga 2 il prototipo di <code>printf()</code>.
</p>

<p align="justify">
Infine, terminata la propria computazione il nostro programma ritorna 0 per informare il sistema operativo che ha terminato la propria esecuzione senza errori.
</p>

Riassumendo:

<details>
<summary>lab/0_intro/0_hello.c</summary>
[/lab/0_intro/0_hello.c](https://github.com/kinderp/2cornot2c/blob/18b60e866c1e0e22c59835fe953cbe3c534e7422/lab/0_intro/0_hello.c)
</details>

<ul>
	<li>
		<p align="justify">
riga 14: inclusione del file d'intestazione <code>stdio.h</code> contenente il prototipo della funzione <code>printf()</code>. Il prototipo serve al compilatore per verificare che il programmatore utilizzi correttamente la funzione, in questo caso la <code>printf()</code>
  		</p>
	</li>
 	<li>
		<p align="justify">
riga 16-19: definizione della funzione <code>main()</code>
  		</p>
	</li>
</ul>

## Funzioni

<p align="justify">
Le funzioni sono un blocco di codice, un insieme di istruzioni che vengono raggruppate e possono essere richiamate in qualsiasi momento all'interno di un programma. Per intenderci, se nel nostro programma calcoliamo più volte la media pesata dei nostri voti, è consigliabile racchiudere tutte le istruzioni all'interno di una funzione e richiamarla ogni volta che ne abbiamo bisogno piuttosto che riscrivere più volte lo stesso identico codice in punti diversi. Le funzioni possono ritornare un valore come risultato della loro elaborazione (possono anche non ritornare nulla al chiamante) e possono ricevere in ingresso un certo numero di parameti.
Una funzione ha un'intestazione ed un corpo, usando sempre la solita funzione <code>differenza</code> vista in precedenza avremo:
</p>

```c
int differenza(int minuendo, int sottraendo){
    return minuendo - sottraendo;
}
```

<p align="justify">
la prima riga rappresenta l'intestazione della funzione (esclusa la parentesi graffa), tutto il codice compreso da <code>{</code> e <code>}</code> è il corpo. Il corpo di una funzione è dunque rappresentato da tutte le istruzioni comprese dalla coppia di graffe, tutto ciò che precede è l'intestazione.
Come anticipato, quando viene fornita sia l'intestazione che il corpo (l'implementazione) si parla di <b>definizione di funzione</b>, se viene fornita solo l'intestazione (anche detta <b>prototipo</b>) si parla di <b>dichiarazione di funzione</b>.
Il prototipo della funzione <code>sottrazione</code> è dunque il seguente:
</p>

```c
int differenza(int minuendo, int sottraendo);
```

Volendo è possibile omettere il nome dei parametri in ingresso lasciando solo il tipo, in questo modo:

```c
int differenza(int, int);
```

<p align="justify">
Per il compilatore non cambia nulla ma può aiutare un altro programmatore a comprendere il significato e l'uso dei parametri in ingresso.
Di sotto è riportato un esempio completo che fa uso della funzione <code>sottrazione</code>, come è possibile vedere questa è richiamata all'interno del <code>main()</code> alla riga 8 fornendo in ingresso i due parametri previsti durante le definzione. Se avessimo fornito un numero diverso (sia inferiore che superiore) di parametri o di tipo diverso rispetto al tipo intero il compilatore ci avrebbe dato errore (o forse nel secondo caso no...?!?)
</p>

<details>
<summary>lab/0_intro/1_funzioni.c</summary>
[/lab/0_intro/1_funzioni.c](https://github.com/kinderp/2cornot2c/blob/849c8731e84196bab6b5a17aed9e983d045cb025/lab/0_intro/1_funzioni.c)
</details>

```c
#include<stdio.h>

int sottrazione(int, int);

int main(void){
        int minuendo = 10;
        int sottraendo = 3;
        int risultato = sottrazione(minuendo, sottraendo);
        printf("%d - %d = %d", minuendo, sottraendo, risultato);
}

int sottrazione(int minuendo, int sottraendo){
        return minuendo - sottraendo;
}
```

<p align="justify">
A causa del fatto che la definzione della funzione <code>sottrazione</code> è stata fornita successivamente (riga 12-14) al punto in cui questa è richiamata (riga 8) per permettere al compilatore di controllare il corretto uso da parte del programmatore è stato necessario fornire prima della riga 8 il prototipo della funzione (riga 3). Commentando la riga 3 il compilatore darebbe errore o almeno rileverebbe un warning circa una dichiarazione implicita che non è in grado di verificare.
Come spiegato ampiamente in precedenza, facciamo uso anche della funzione <code>printf()</code> ed in questo caso per fornirne il prototipo sfruttiamo la direttiva al preprocessore <code>#include <stdio.h></code>
</p>

## Variabili

<p align="justify">
Abbiamo precedentemente detto che una variabile è semplicemente una locazione di memoria a cui è associato un identificatore ed un tipo.
L'identificatore è un nome mnemonico che ci permette, all'interno del codice, di accedere al valore contenuto nella locazione di memoria corrispondente. Il tipo definisce lo spazio (in terminit di byte) che la locazione di memoria può contenere.
<b>Una variabile prima di essere usata deve esssere sempre dichiarata</b>. Come anticipato, **l'operazione di dichiarazione consiste nell'allocare spazio di memoria per la variabile ed associargli l'identificatore**; lo spazio riservato viene dedotto dal tipo della variabile.
I diversi tipi privisti del C hanno un numero di byte prefissati dipendenti dall'architettura; per esempio <code>int</code> di solito occupa 32 o 64 bit, <code>char</code> 8 bit etc.
Se ti può aiutare puoi pensare ad una variabile come ad una scatola, vedi immagine di sotto.
</p>

```c
int answer;
```


<p align="center">
<img src="https://github.com/kinderp/2cornot2c/blob/main/images/dichiarazione_variabile.png">
</p>

<p align="center">
Una volta dichiarata la variabile è pronta ad ospitare un valore del tipo corrispondente a quello scelto nella dichiarazione; questa operazione è detta <b>assegnamento</b>
</p>

```c
int answer;   // dichiarazione di variabile, tipo intero
answer = 12;  // assegnamento del valore 12 alla variabile sopra dichiarata
```

<p align="center">
<img src="https://github.com/kinderp/2cornot2c/blob/main/images/assegnamento_variabile.png">
</p>

<p align="center">
E' possible associare un valore ad una variabile direttamente nella dichiarazione, questa operazione è detta <b>inizializzazione</b>
</p>

```c
int answer = 12; // dichiarazione con inizializzazione
```

<p align="center">
E' possibile dichiarare più variabile nella stessa riga, purchè esse siano dello stesso tipo. In questo modo:
</p>

```c
int question, answer;
```

<p align="center">
Oltre al tipo ed all'identificatore una variabile è caratterizzata dalla <b>visibilità</b> (<code>scope</code> in inglese) ed il <b>tempo di vita</b> (<code>lifetime</code> o <code>storage duration</code>)
</p>

> [!IMPORTANT]
> **Visibilità**: porzioni di codice nel programma in cui la variabile (il suo identificatore) è visibile e quindi è possibile fare riferimento alla variabile. Se in un dato punto del programma la variabile non è visibile, anche se effettivamente allocata in memoria (ha associata una locazine di memoria), è inutilizzabile o comunque non è possibile accedere al suo contenuto.

> [!IMPORTANT]
> **Tempo di vita**: porzione di tempo all'interno del ciclo di esecuzione del programma durante il quale alla variabile è associata una locazione di  memoria

Sulla base del tempo di vita e della visibilità possiamo classificare le variabili in due grandi categorie: **variabili globali** e **variabili locali**.


<p align="justify">
<b>Le variabili locali</b> sono definite all'interno delle funzioni e hanno una visibilità limitata: dal punto in cui sono dichiarate fino al termine del corpo della funzione (ti ricordo che il corpo è compreso tra <code>{</code> e <code>}</code>); il loro tempo di vita è anche limitato: la locazione di memoria ad esse associata è allocata quando la funzione viene invocata ed è liberata quando l'esecuzione dell'intero corpo della funzione termina.
</p>

<p align="justify">
<b>Le variabili globali</b> sono definite fuori dalle funzioni, di solito dopo le direttive <code>#include</code> nelle righe iniziali. 
Hanno visibilità globale appunto, cioè sono visibili a tutte le funzioni nel file in cui sono dichiarate (e potenzialmente anche alle funzioni in altri file del programma, ma questo lo vedremo in seguito); il loro tempo di vita coincide con quello globale di esecuzione del programma.
</p>

<p align="justify">
<b>Le variabili globali</b> se non inizializzate vengono poste a zero automaticamente, al contrario <b>le variabili locali</b> se non inizializzate contengono semplicemente un valore sporco ed assolutamente non prevedibile (il valore che era precedentemente contenuto nella locazione di memoria che è stata associata alla variabile, al suo identificatore).
</p>

<p align="justify">
Il programma di sotto fa uso di variabili globali e locali; semplicemente sono definite tre funzioni: <code>somma()</code>, <code>differenza()</code> e <code>moltiplicazione()</code>. I due operandi su cui le funzioni devono lavorare (<code>primo</code> e <code>secondo</code>) vengono definiti coeme variabili globali; essendo globali queste variabili sono visibili da tutte le funzioni nel file. 
</p>

```c
int primo, secondo; /* variabili globali */
```

Il risultato dell'operazione ed il tipo di operazione da svolgere sono definiti come variabili locali (dentro la funzione `main()`)

```c
int risultato; 	 // variabile locale
char operazione; // variabile locale
```

Queste due variabili sono visibili solo all'interno della funzione `main()` (dove sono effettivamente dichiarate come variabili locali) e non dalle altre funzioni.

<p align="justify">
Inoltre, siccome facciamo uso della funzione <code>printf()</code> e <code>scanf()</code> dobbiamo includere attraverso la direttiva al preprocessore (<code>#include<stdio.h></code>) i rispettivi prototipi contenuti nel file header: <code>stdio.h</code>.
Mentre <code>printf()</code> serve per stampare a schermo il contenuto di una variabile, <code>scanf()</code> viene usata per leggere un valore da tastiera e memorizzarlo in una variabile.
</p>

Le definizioni della funzioni `somma()`, `differenza()` e `moltiplicazione()` sono fornite dopo la loro effettiva chiamata nel `main()` e quindi per permettere al compilatore di controllare l'uso corretto di queste funzioni da parte del programmatore è stato necessario, prima del `main()`, fornire i prototipoi.

[/lab/0_intro/2_variabili.c](https://github.com/kinderp/2cornot2c/blob/8fcadf5f8a958f9b6194c4dac724d5a21ecef717/lab/0_intro/2_variabili.c)

```c
#include <stdio.h>

int primo, secondo; /* variabili globali */

int somma();
int differenza();
int moltiplicazione();

int main(void){
        int risultato;   // variabile locale
        char operazione; // variabile locale
        printf("Inserisci il primo operando\n");
        scanf("%d", &primo);
        printf("Inserisci il secondo operando\n");
        scanf("%d", &secondo);
        printf("s)Somma d)Differenza m)Moltiplicazine\n");
        scanf(" %c", &operazione);
        if (operazione == 's'){
                risultato = somma();
        } else if(operazione == 'd') {
                risultato = differenza();
        } else if(operazione == 'm') {
                risultato = moltiplicazione();
        } else {
                printf("Operazione non riconosciuta");
        }
        printf("Il risultato e': %d\n", risultato);
        return 0;
}

int somma(){
        return primo + secondo;
}

int differenza(){
        return primo - secondo;
}

int moltiplicazione(){
        return primo * secondo;
}
```

<p align="justify">
Inoltre nel codice incontriamo il primo costrutto per il controllo del flusso e precisamente <code>if-else</code>.
Vedremo in dettaglio la sintassi più avanti, ora forniamo solo una breve spiegazione.
Il costrutto <code>if</code> serve per realizzare l'istruzione di salto condizionale ed assume questa forma:
</p>

`if (espr) istr`

<p align="justify">
Se la condizione specificata dall'espressione <code>espr</code> è vera (cioè diversa da zero) viene eseguito il blocco di istruzioni <code>istr</code> alrimenti si prosegue con l'elaborazione
</p>

Il costrutto `if` ammette l'enunciato opzionale `else`. Il costrutto `if-else` assume questa forma:

`if (espr) istr1 else istr2`

<p align="justify">
I blocchi di istrzioni <code>istr1</code> e <code>istr2</code> vengono eseguiti a seconda se l'espressione <code>espr</code> sia vera o falsa. Se è vera si esegue <code>espr1</code> se è falsa <code>espr2</code>
Nel nostro codice abbiamo qualcosa di un po' più complesso, analizziamolo assieme:
</p>

```c
scanf(" %c", &operazione);
if (operazione == 's'){
	risultato = somma();
} else if(operazione == 'd') {
	 risultato = differenza();
} else if(operazione == 'm') {
	 risultato = moltiplicazione();
} else {
	 printf("Operazione non riconosciuta");
}
```

<p align="justify">
La funzione <code>scanf()</code> legge un carattere da tastiera ed inserisce il valore all'interno della variabile <code>operazione</code>, il costrutto <code>if-else</code> ci serve per eseguire la funzione corrispondente all'operazione richiesta dall'utente attraverso la digitazione di un carattere della tastiera.
Se <code>operazione</code> contiene il carattere <code>s</code> allora si eseguirà la funzione <code>somma()</code> (solo quella e nessun'altra) altrimenti se il carattere è <code>d</code> si esegue la funzione <code>differenza()</code> e così via. Se il carattere contenuto in <code>operazione</code> non è tra i tre attesi <code>s</code> <code>d</code> <code>m</code> allora (ultimo <code>else</code>) si stampa un messaggio che informa l'utente che l'operazione non è stata riconosciuta.
</p>

Tornando alle variabili possiamo riassumere quanto segue:

**Variabili globali**: 
* visibili in tutto il file da ogni funzione
* se non inizializzate ad un valore sono settate a zero automaticamente
* il loro ciclo di vita coincide con quello del programma, la memoria è allocata prima dell'esecuzione e deallocata al termine dell'esecuzione
  
**Variabili locali**:
* visibili solo nel blocco dove sono state dichiarate
* se non inizializzate settate ad un valore assolutamente casuale
* il loro ciclo di vita è limitato all'esecuzione del blocco dove sono dichiarate

<p align="justify">
L'uso di variabili globali per comunicare con le funzioni è scorretto ed è stato mostrato solo come esempio per introdurre le variabili globali. Meno uso facciamo delle variabili globali e meglio è.
Per comunicare con le funzioni e scambiare valori col chiamante è sempre preferibile usare i parametri in ingresso ed i valori di ritorno, quindi le variabili locali.
Di sotto è riportato il codice corretto che elimina l'uso improprio delle variabili globali:
</p>

[/lab/0_intro/3_variabili.c](https://github.com/kinderp/2cornot2c/blob/9c77cc456006b9edb0dddea96eaf5860037e7b8c/lab/0_intro/3_variabili.c)

```c
#include<stdio.h>

int somma(int, int);
int differenza(int, int);
int moltiplicazione(int, int);

int main(void){
        int risultato = 0;
        int primo, secondo;
        char operazione;

        printf("Inserisci il primo operando\n");
        scanf("%d", &primo);
        printf("Insesci il secondo operando\n");
        scanf("%d", &secondo);
        printf("s)Somma d)Differenza m)Moltiplicazione\n");
        getchar();
        operazione = getchar();
        switch(operazione){
                case 's':
                        risultato = somma(primo, secondo);
                        break;
                case 'd':
                        risultato = differenza(primo, secondo);
                        break;
                case 'm':
                        risultato = moltiplicazione(primo, secondo);
                        break;
                default:
                        printf("Operazione non riconosciuta\n");

        }
        printf("Il risultato e': %d\n", risultato);
        return 0;
}

int somma(int primo_addendo, int secondo_addendo){
        return primo_addendo + secondo_addendo;
}

int differenza(int minuendo, int sottraendo){
        return minuendo - sottraendo;
}

int moltiplicazione(int primo_fattore, int secondo_fattore){
        return primo_fattore * secondo_fattore;
}
```

<p align="justify">
come puoi vedere le variabili <code>primo</code> e <code>secondo</code> sono state dichiarate dentro la funzione <code>main()</code> e quindi sono locali (sono visibili solo all'interno di questa funzione), esattamente come <code>risultato</code> ed <code>operazione</code>. Solo <code>risultato</code> è inizializzato a zero, le altre variabili conterranno all'inizio un valore casuale (le variabili locali non sono inizializzate automaticamente)
</p>

```c
int risultato = 0;
int primo, secondo;
char operazione;
```

## Classi di memorizzazione

Conoscere la differenza tra variabili globali e locali è un buon punto di partenza, le cose sono però più complesse.
Agli identificatori è associato uno **scope** (**visibilità**), alle variabili invece uno **storage duration** (**tempo di vita**) ed il **linkage** (**collegamento**).

Lo **scope** può essere di quattro tipi:

* **block scope**
* **file scope**
* **function scope**
* **function prototype scope**

Ricordiamo che lo **scope** di un identificatore è la regione di codice in cui l'identificatore è visibile (quindi la variabile accessibile da parte del programmatore).

Lo **storage duration** può essere di quattro tipi:

* **static**
* **thread**
* **auto**
* **allocated**

Ricordiamo che lo **storage duration** rappresenta il tempo di vita della variabile ovvero per quanto tempo questa rimane allocata in memoria

Il **linkage** può essere di tre tipi:

* **no linkage**
* **internal**
* **external**

Il **linkage** definisce se una variabile può essere condivisa dal codice dello stesso file o di file diversi. 

## Block scope

Un blocco è un insieme di istruzioni comprese tra `{` e `}`.
Esempi di blocchi (alcuni li abbbimao già incontrati) sono:

* il corpo nella definzione di una funzione

  ```c
  int differenza(int minuendo, int sottraendo){
      // tutte le istruzioni comprese tra le due graffe rappresentano il corpo
  }
  ```

* il corpo nei costrutti di controllo del flusso `if-else`, `for`, `while` etc

  ```c
  if(operazione == 's'){
	risultato = somma(primo, secondo);
  } else {

  }
  ```
* un blocco innestato:
  ```c
  for(int i=0; i<N; i++){
	{
		int i = N; // questa i nasconde l'indice i del for
  	}
  }
  ```

  Una variabile all'interno di un blocco ha un **block scope** ed è quindi visibile (**scope**) dal punto in cui è definita fino alla fine del blocco che contiene la sua definizione.
  Le variabili locali sono di tipo **block scope**.

> [!IMPORTANT]
> I parametri formali di una funzione, anche se dichiarati fuori del corpo della funzione (dal blocco) appartengono al corpo e quindi hanno anch'essi un **block scope**

> [!NOTE]  
> Storicamente le variabili con **block scope** dovevano essere dichiarate all'inizio del blocco.
> 
> Dal C99 è possibile dichiarare le variabili all'interno del blocco in qualsiasi posizione al suo interno.
> Questo è utile soprattutto per le variabili indici di un ciclo o per documentare meglio il proprio codice dichiarando le variabili il più vicino possibile alla riga che fa   uso effettivamente della stessa.
 
## File scope

Una variabile definita al di fuori di qualsiasi funzione in un file `.c` o `.h` ha un **file scope** ed è visibile dal punto in cui è definita fino alla fine del file che la contiene.
Questo è il caso delle variabili globali che abbiamo trattato, esse infatti hanno un **file scope**.

```c
#include<stdio.h>
	     
int N = 100 /* N è globale: ha un file scope, è definita fuori da qualsiasi funzione, è visibile
	     * al main() ed alla funzione uno()
             */

int main(){

}

int uno(){

}
```

## Linkage

Il **linkage** definisce se una variabile è visibile in più file diversi o solo nel file in cui è definita.

Esistono tre tipi di **linkage**: `no linkage` `external` ed `internal`.

<p align=justify>
Le variabili con un <b>block scope</b> (quelle locali) sono <b>no linkage</b>: cioè non sono visibili nell'intero file in cui sono definite ma la loro visibilità è limitata al blocco che le ospita.
</p>

<p align="justify">
Le variabili con un <b>file scope</b>  (quelle globali) sono o <b>external linkage</b> o <b>interanl</b>: se <code>external</code> la variabile può essere vista anche in altri file del programma.
Se <code>internal</code> la variabile è visibile in tutto il file (quindi a tutte le funzione del file) in cui è stata definita ma non in altri file del programma.
</p>

<p align="justify">
Le variabili globali hanno automaticamente un <b>external linkage</b> quindi potenzialmente possono essere viste in altri file sorgente del programma. Per restringere il linkage da <b>external</b> ad <b>internal</b> si usa la <i>keyword</i> <b>static</b> al momento della definizione della variabile, vediamo un esempio
</p>

```c
int globale_esterna = 10; /* variabile globale, file scope, external linkage.
                           * E' visibile all'interno del file sorgente corrente e potenzialmente
			   * anche in tutti gli altri sorgenti del programma
                           */

int static globale_interna = 100; /* variabile globale, file scope, internal linkage in  quanto usa
                                   * keyword static. E' visibile solo all'interno del file sorgente
				   * corrente
                                   */

int main(void) {

}
```
<p align="justify">
E' buona norma, soprattutto se il tuo programma ha grosse dimensioni in termini di file, dichiarare <b>static</b> le tue variabili globali se queste servono solo all'interno del file corrente. Questo previene il problema di uno spazio di nomi globale pieno di identificatori già utilizzati.
</p>

> [!CAUTION]
> La parola chiave **static** non ha nulla a che vedere con lo **storage duration** di tipo static. Tutte le variabili globali (sia di tipo **external** che **internal** linkage) hanno uno **storage durantion** di tipo _static_ cioè esistono in memoria per tutto il tempo di esecuzione del programma. Affronteremo nel dettaglio lo storage duration nei paragrafi successivi.

## Storage duration

Esistono quattro tipi diversi di **storage duration**: `static` `thread` `auto` `allocated`.

Per il momento affrontiamo solamente i tipi: `static` ed `auto`.

## Static storage duration

Variabili che esistono in memoria per l'intero tempo di esecuzione del programma: sono le variabili con **file scope** (variabili globali sia di tipo `external` che `internal` **linkage**)

```c
int file_scope_extenal_linkage;         /* variabile globale con file scope ed external linkage */
static int file_scope_internal_linkage; /* variabile globale con file scope ma internal linkage:
                                         * è usata la keyword static che limita la visibilità al
					 * solo file corrente
                                         */

int main(void){

}
```

## Auto storage duration

<p align="justify">
Variabili che hanno un tempo di vita limitato che non coincide che il tempo di esecuzione del programma: sono le variabili con <b>block scope</b> che vengono allocate quando il programma entra nel blocco nel quale queste sono definite e poi deallocate quando si esce dallo stesso.
</p>

> [!IMPORTANT]  
> E' possibile per una variabile con **block scope** avere uno **storage duration** non **auto** ma **static**. Per farlo basta dichiarare la variabile all'interno del blocco usando la _keyword_ **static** come mostrato sotto:

```c
int main(void){
	uno();
}

int uno(void){
	static int variabile_statica = 0; /* variabile statica anche se dichiarata all' interno di
  					   * un blocco (dovrebbe essere di tipo auto senza la paro
					   * -la chiave static).
                                           * La  memoria per la  variabile è  allocata all' inizio
					   * del  programma e deallocata al termine del programma.
 					   * Se fosse rimasta auto la memoria sarebbe stata alloca
					   * ta solo all' entrata  del flusso nella  funzione e ri
					   * -mossa all'uscita
                                           */
}
```


## Classi di memorizzazione

Scope, linkage e storage duration sono combinati assieme per definire le **classi di memorizzazione**

<div align=center>
	
| Class                 | Storage Duration | Scope | Linkage   | Come dichiarare |
|----------------------:|------------------|-------|-----------|-----------------|
|automatic              |Automatic         |Block  | No linkage| Dentro un blocco|        
|register               |Automatic         |Block  | No linkage| Dentro un blocco con _keyword_ **register**|
|static external linkage|Static            |File   | External  | Fuori dalle funzioni|
|static internal linkage|Static            |File   | Internal  | Fuori dalle funzione con _keyword_ **static**|
|static no linkagge     |Static            |Block  | No linkage| Dentro un blocco con _keyword_ **static**|

</div>

## Variabili automatiche (automatic class)

Una variabile appartenente alla **classe di memorizzazione automatica** (`auto`) ha:

* automatic storage duration
* block scope
* no linkage

Qualsiasi variabile dichiarata all'interno di un blocco (`{` e `}`) è di tipo `auto`, in pratica è la classe di memorizzazione per tutte le variabili locali.
Le variabili di classe `auto` non sono inizializzate automaticamente, questo è il motivo per cui le variabili locali devono essere inizializzate esplicitamente altrimenti ospitano un valore assolutamente casuale, sporco.

```c
int main(void){
  int a; /* variabile di classe auto: il suo storage duration è limitato all'esecuzione del  blocco
   	  * cioè viene allocata quando il flusso di esecuzione entra nel blocco e deallocata quando
	  * si esce dal blocco;  quindi quando si esce dal blocco il valore in essa contenuto viene
	  * perso,quando si rientrerà nel blocco la volta successiva verrà allocato nuovo spazio in
	  * memoria completamente diverso rispetto a quello precedente.
	  * Lo scope è  limitato al  blocco: cioè il suo identificatore è visibile solo all'interno
	  * del blocco e in ultimo non ha linkage in quanto ovviamente non è visibile alle funzioni
	  * nel file corrente e nei restanti file del programma.
	  * Inoltre la variabile non è inizializzata ad alcuno valore, non possiamo prevedere quale
	  * sia il valore iniziale che troveremo al suo interno.
	  * /
}
```

<p align="justify">
E' possibile dichiarare la variabile usando esplicitamente la parola chiave `auto` anche se `auto` per le variabili dichiarate dentro un blocco è il default.
Di solito questo ha senso quando all'interno del blocco si sta offuscando una variabile esterna e si vuole esplicitare questo evento avvertendo chi legge il 
codice di questo o per specificare che non si vuole che si cambi la classe di memorizzazione per quella variabile. Sotto un esempio:
</p>

```c
int a; /* variabile esterna visibile da tutte le funzioni, compreso il main() */

int main(void){
	auto int a; /* la dichiarazine di una variabile  automatica di nome a nel main() determina
                     * l'offuscamento (uscita di scope) della variabile esterna con lo stesso nome.
                     * Per informare chi legge il codice di fare attenzione a questo evento si può
                     * esplicitare la classe di memorizzazione auto nella dichiarazione 
                     */
}
```

<p align="justify">
Ricordati quindi che all'uscita del blocco il valore contenuto nella variabile viene perso perchè viene deallocata e non puoi accederci perchè fuori dal blocco l'identificatore non è visibile.
</p>

## Variabili register (regiter class)

<p align="justify">
Le variabili <code>register</code> sono delle variabili di tipo <code>auto</code> (block scope, no linkage, automatic storage duration). Dichiarando una variabile di classe register, il programmatore richiede al compilatore di memorizzarla nella memoria più veloce a disposizione che dovrebbe essere rappresentata dai registri della cpu; questi come noto sono molto più veloci della normale ram.
Questa è una richiesta che può anche non essere soddisfatta del compilatore se i registri sono occupati o la dimensione del dato è troppo grando rispetto alla capacità dei registri della cpu. Si dichiarano <code>register</code> le variabili che devono essere accedute spesso e con grande velocità: ad esempio gli indici dei cicli. L'uso di variabili <code>register</code> ha perso la sua importanza in quanto i moderni compilatori sono in grado di effettuare queste considerazioni per l'ottimizzazione del codice da soli anche se usare variabili `register` potrebbe aiutare a capire quali variabili ricihedono velocità di accesso.
Da ricordare è che una volta che una variabili è dichiarata <code>register</code> non è possbile recuperare l'indirizzo della variabile. Si possono dichiarare di classe <code>register</code> anche i parametri formali delle funzioni.
</p>

```c
int main(void){
	register int a; /* variabile register, non è possibile fare &a ERRORE */
}
```

```c
int uno(register int a);
```

## Varabili statiche locali (static variables with block scope)

<p align="justify">
Una variabile con block scope ha visibilità limitata all'interno del blocco in cui è dichiarata ed ovviamente nessun linkage (non è visibile alle altre funzioni nel file corrente e negli altri file). Lo storage duration è limitato al tempo di esecuzione del blocco in cui è dichiarata; la variabile è allocata in memoria appena si entra nel blocco e deallocata all'uscita. Queste variabili sono le variaili locali. Rendere statica una variabile locale significa modificare il suo storage duration in modo da farlo coincidere con il tempo di esecuzione del programma e non più con il tempo di esecuzione del blocco; in altre parole la variabile sarà allocata quando il programma verrà eseguito e deallocata alla sua terminazione. Ovviamente lo scope resta di tipo block quindi anche se la variabile non viene deallocata all'uscita del blocco il suo identificatore non è più visibile e quindi non è possibile accedere alla locazione di memoria. Quando il flusso di esecuzione rientrerà nel blocco il valore precedetemente conservato sarà disponibile attraverso l'identificatore. Per dichiarare statica una variabile locale si usa la <i>keyword</i> <b>static</b>, vediamo un esempio:
</p>

La funzione `example_static_var` dichiara due variabili: `a` di tipo automatica e `b` statica (con block scope). Vediamo le differenze pratiche:

```c
#include<stdio.h>

void example_static_var(void);

int main(void){
        /* Richiamiamo cinque volte la funzione example_static_var: la variabile a ad ogni
	 * nuova chiamata verrà prima allocata poi inizializzata a zero, incrementata di 1
	 * e poi deallocata. una successiva chiamata alla funzione example_static_var rial
	 * -locherà spazio in memoria per la variabile e la inizializzerà a 0 e  così via.
	 * Al  massimo  la variabile a potrà valere 1. Al contrario la variabile di nome b
	 * viene allocata una sola volta all' esecuzione e deallocata  alla  terminazione,
	 * quindi il suo valore sarà conservato  tra due chiamate successive alla funzione
	 * example_static_var, il valore di b infatti  sarà incrementato cinque volte,  un
	 * valore pari al numero di chiamate alla funzione example_static_var   
         
        example_static_var();
        example_static_var();
        example_static_var();
        example_static_var();
        example_static_var();

}

void example_static_var(void){
        int a = 0;     /* variabile automatica: viene allocata all' entrata del  blocco e
			* deallocata  all' uscita perdendo il  valore  in  esso contenuto
			*/
        static int b;  /* variabile locale statica: viene  allocata  una  sola volta all'
			* esecuzione del programma e deallocata alla terminazione, mantie
			* -ne il valore  in essa contenuto  anche  se  si esce dal blocco
			* Non abbiamo  inizializzato la  variabile  esplicitamente a zero
			* in quanto è statica: le variabili  statiche  non  inizializzate
			* esplicitamente sono poste a zero dal compilatore.
 			*/

        a = a + 1;     // a ora vale 1
        b = b + 1;     // b ora  vale b + 1, il valore di b  dipende  da quante volte  la
		       // funzione è stata richiamata nel programma fino a questo momento
        printf("a=%d, b=%d\n", a, b);
}
```

Come puoi vedere dall'output del programma compilato

```bash
vagrant@ubuntu2204:~$ ./static_variable
a=1, b=1
a=1, b=2
a=1, b=3
a=1, b=4
a=1, b=5
```

Infine, i parametri formali di una funzione non posso essere dichiarati static, non puoi fare questo:

```c
int no_possible_static_parameter(static int a); /* ERRORE */
```

## Differenza tra definzione e dichiarazione di variabile

<p align=justify>
Fino a questo punto abbiamo usato i termini dichiarazione e definizione in modo intercambiabile come se fossero la stessa cosa. In realtà esiste una differenza ed è arrivato il momento di affrontarla.
La definizione di una variabile coincide con l'istruzione per cui avviene l'allocazione di spazio in memoria per la variabile. La dichiarazione invece consiste nel dichiarare al compilatore che si farà uso di una variabile già allocata nel file corrente o in un altro file.
Per le variabili locali (<code>auto</code>) la definizione coincide con la dichiarazione, per le variabili globali ha senso conoscere questa leggera differenza.
Una variabile globale ha file scope ed external linkage, per questo viene anche detta variabile esterna (visibile anche all'esterno del file, negli altri file del programma).
Ricordiamo che una variabile esterna (globale) è <b>DEFINITA</b> fuori dalle funzioni all'inizio del file, in questo modo:
</p>

```c
#include<stdio.h>

int extern_global_var; /* variabile globale,  è esterna ( external linkage, visibile agli altri
			*  file ) inizializzata a zero dal compilatore perchè statica  ( static
			* storage duration) questa è una DEFINIONE, questa istruzione determina
			* l'allocazione di spazio in memoria per la variabile. La variabile può
			* essere vista anche dagli altri file del programma.
			*/

extern int global_var_somewhere_in_other_file; /* questa è una DICHIARAZIONE di variabile ester
						* na che è stata DEFINITA in qualche altro file
						* per renderla visibile anche in questo  file è
						* OBBLIGATORIA la dichiazione attraverso la key
						* -word extern
						*/

int main(void){
	extern int extern_global_var;  /* questa è una DICHIARAZIONE opzionale, NON OBBLIGATORIA
 					* basta usare la keyword extern.Serve esclusivamente per
					* documentare che nella funzione verrà usata una variabi
					* le globale (non locale automatica)e di stare attenti a
					* come questa viene valorizzata e  manipolata in  quanto
					* ha visibilità in tutto il file e potenzialmente in tut
					* -ti i file dell'intero programma
					*/
}
```

<p align="justify">
E' possibile dopo aver DEFINITO la variabile esterna, a scopo di documentazione, DICHIARARLA all'interno delle funzioni che la useranno attraverso le <i>keyword</i> <code>extern</code> come fatto sopra nel <code>main()</code>.
Infine per rendere visibile in un file una variabile esterna (globale) che è stata DEFINITA in un altro file è OBBLIGATORIA la DICHIARAZIONE con <i>keyword</i> <code>extern</code> nel secondo file come è stato fatto sopra per la variabile <code>global_var_somewhere_in_other_file</code>
</p>

> [!CAUTION]
> Se togliessimo la _keyword_ `extern` nella DICHIARAZIONE della variabile `global_var_somewhere_in_other_file` questa si traformerebbe in una DEFINIZIONE
>  di nuova variabile e causerebbe un errore in quanto (in qualche altro file) già esiste una variabile globale esterna con queste nome ed ovviamente non
>  possono esistere due variabili (due locazione di memoria diverse) con lo stesso nome nel medesimo spazio di nomi.

```c
#include<stdio.h>

int extern_global_var;  /* DEFINZIONE di variabile esterna (globale)

int global_var_somewhere_in_other_file; /* togliendo la keyword extern questa non è più una DICHIA
					 * RAZIONE di variabile esterna  definita in un altro file
					 * ma una DEFINIZIONE di nuova variabile esterna,una varia
					 * -bile esterna con lo stessso nome già esiste ed il com-
					 * pilatore tornerà errore.
					 */

int main(void){
	extern int extern_global_var;   /* DICHIARAZIONE opzionale della variabile esterna DEFINITA
					 * sopra
					 */
}
```

## Variabili globali con External Linkage (Static variables with External Linkage)

<p align="justify">
Le variabili globali sono DEFINITE all'esterno delle funzioni, di solito all'inizio del file sorgente dopo le direttive al preprocessore (<code>#include</code>). Come anticipato queste variabili hanno: file scope (sono visibili a tutte le funzioni del file che contiene la loro definizione) static storage duration (tempo di vita in memoria coincidente con l'esecuzione del programma) ed external linkage (sono potenzialmente visibili anche in tutti i file sorgente del programma). Quindi le variabili globali sono variabili statiche con external linkage. Nella definizione non si usa la <i>keyword</i> <code>extern</code>, invece questa può essere usata (opzionale) nella dichiarazione della variabile all'interno delle funzioni che la useranno, l'uso di <code>extern</code> è invece obbligatorio quando si vuole usare una variabile globale definita in un altro file del programma, in questo caso è necessario dichiarare (nel file che vuole usare la variabile definita in altro file) esplicitamente la variabile usando la <i>keyword</i> <code>extern</code>. In soldoni <code>extern</code> non viene usata nella DEFINIZIONE (quando si crea per la prima volta la variabile globale e viene allocata la memoria) bensì è usata nelle DICHIARAZIONI per informare il compilatore che la variabile è definita da qualche altra parte e nel file si vuole solo fare uso della varabile esterna già allocata.
Infine è importante ricordare che <b>le variabili esterne possono essere inizializzate solo una volta</b> e </b>nella DEFINIZIONE</b>, inizializzare una variabile esterna nella DICHIARAZIONE è un ERRORE:
</p>

```c
// file uno.c

int esterna = 10; /* DEFINIZIONE CON INIZIALIZZAZIONE ESPLICITA, OK */
```

```c
// file due.c
extern int esterna = 2; // DICHIARAZIONE ERRORE
```

<p align="justify">
Alla luce di queste nuove conoscenze modifichiamo il programma visto in <code>3_variabili.c</code> spostando i prototipi della funzioni e la DEFINIZIONE delle variabili globali in un file <code>header</code> (estensione <code>.h</code>). Abbiamo già incontrato questi file quando abbiamo introdotto la funzione <code>printf()</code> ed avevamo detto che era necessario includere il file header <code>stdio.h</code> che conteneva il prototipo della <code>printf()</code>. I file header o d'intestazione contengono sia i prototipi delle funzioni sia le strutture dati (quindi anche le variabili globali) che saranno utili nel corrispondente file sorgente (estensione <code>.c</code>).
I file d'intestazione possono essere sia di sistema (cioè forniti dal linguaggio stesso) e, come detto, vengono inclusi con la direttiva <code>#include</code> usando le parentesi angolari <code><</code> <code>></code>, in questo modo:
</p>

```c
#include <stdio.h>
```

<p align="justify">
i file d'instestazione definiti dal programmatore vengono inclusi usando i doppi apici <code>"</code> in questo modo:
</p>

```c
#include "4_varibili.h"
```

<p align="justify">
Il nostro compito è allora spostare tutti i prototipi e le variabili globali di <code>3_variabili.c</code> in un file d'instazione (<code>4_variabili.h</code>) ed includere il file header nel corrispondente file sorgente (<code>4_variabili.c</code>).
Ovviamente faremo anche qualche piccola modifica e miglioramento al programma precedente, nello specifico:

<ul>
	<li>
	Nel file <code>4_variabili.h</code> oltre che dichiarare i prototipi delle funzioni, definiamo una nuova variabile esterna (costante) <code>NUM_ITERATIONS</code> che rappresenta il numero di volte che il programma richiederà all'utente di eseguire un'operazione prima di terminare autonomamente.
	</li>	
</ul>
</p>


```c
const int NUM_ITERATIONS = 2;
```

<p>
<ul>
	<li align="justify">
		Per iterare più volte il processo di calcolo (richiesta di inserimento operandi ed operazione) usiamo un nuovo costrutto di controllo del flusso: il <code>for</code>. Anche questo verrà trattato in dettaglio in un altro paragrafo ma brevemente possiamo anticipare che il costrutto <code>for</code> serve per realizzare un clico (o loop), permette di eseguire un insieme di istruzioni un certo numero di volte. Ha questa forma: <code>for ( espr1 ; espr2 ; espr3 ) istr</code>. Prima di iniziare il ciclo viene valutata <b>una volta sola</b> <code>espr1</code> che viene tipicamente usata per inizalizzare le variabili che controllano il ciclo (dette indici del ciclo). Poi viene valutata l'espressione <code>espr2</code> che, se vera, determina l'esecuzione del corpo del ciclo costituito dal blocco di istruzioni <code>istr</code>, in caso contrario (<code>espr2</code> è falsa) il ciclo termina. Prima di valutare nuovamente (passo successivo) <code>espr2</code>, viene valutata l'espressione <code>espr3</code> che tipicamente viene usata per incrementare o decrementare la variabile (indice) che controlla il ciclo (in <code>espr2</code>).	
	</li>
</ul>
</p>

Ecco un sempio di un ciclo che stampa i numeri da 0 a 9:

```c
#include <stdio.h>

int main(void){
   /* i è la variabile indice del ciclo, viene inizializzata a zero in espr1
    * se espr2 è vera:cioè se i < 0 si esegue il blocco (funzione printf() )
    * al termine delle istruzioni del blocco (comprese tra { e } ) si esegue
    * espr3 (i++) cioè si incrementa di uno la variabile indice i. Ii ciclo
    * terminerà quando i = 10 cioè quando espr2 sarà falsa
    */
   for (int i=0; i<10; i++){
	printf("%d\n", i);
   }
}
```

Quando il blocco del ciclo è composto da una sola istruzione è possibile omettere la coppia di parentesi graffe (`{` `}`) come nel nostro caso e riscrivere il ciclo in questo modo:

```c
for (int i=0; i<10; i++)
	printf("%d", i);
```

*  Aggiungiamo l'operazione di divisione che mancava nella versione precedente

<p align="justify">
Il codice del fle header <code>4_variabili.h</code> ed il sorgente <code>4_variabili.c</code> è mostrato di sotto, la cosa da far notare è la variabile esterna <code>NUM_ITERATIONS</code> che è DICHIARATA nel <code>.h`</code>; il file d'intestazoine verrà, attraverso la direttiva include incluso nel <code>.c</code> dal prepocessore e sarà poi effettivamente parte integrante del file <code>.i</code>. Per esplicitare che si sta usando una variabile DEFINITA in un altro file, nel <code>.c</code> si effettua una DICHIARAZIONE della variabile usando la <i>keyword</i> <code>extern</code>.
</p>

[/lab/0_intro/4_variabili.h](https://github.com/TheBitPoets/2cornot2c/blob/main/lab/0_intro/4_variabili.h)

```c
const int NUM_ITERATIONS = 2; 

int somma(int, int);
int differenza(int, int);
int moltiplicazione(int, int);
int divisione(int, int);
```

[/lab/0_intro/4_variabili.c](https://github.com/TheBitPoets/2cornot2c/commit/8fcadf5f8a958f9b6194c4dac724d5a21ecef717)

```c
#include <stdio.h>
#include "4_variabili.h"

extern const int NUM_ITERATIONS;

int main(void){
	int risultato = 0;
	int primo, secondo;
	char operazione;
	for(int i = 0; i < NUM_ITERATIONS; i++){
		printf("Inserisci il primo operando\n");
		scanf("%d", &primo);
		printf("Inserisci il secondo operando\n");
		scanf("%d", &secondo);
		printf("s)Somma d)Differenza m)Moltiplicazione D)Divisione\n");
		scanf(" %c", &operazione);
		switch(operazione){
			case 's':
				risultato = somma(primo, secondo);
				break;
			case 'd':
				risultato = differenza(primo, secondo);
				break;
			case 'm':
				risultato = moltiplicazione(primo, secondo);
				break;
			case 'D':
				risultato = divisione(primo, secondo);
				break;
			default:
				printf("Operazione non riconosciuta\n");
		
		}
		printf("Il risultato e': %d\n", risultato);
	}	
}

int somma(int primo_operando, int secondo_operando){
	return primo_operando + secondo_operando;
}

int differenza(int minuendo, int sottraendo){
	return minuendo - sottraendo;
}

int moltiplicazione(int primo_fattore, int secondo_fattore){
	return primo_fattore * secondo_fattore;
}

int divisione(int dividendo, int divisore){
	return dividendo / divisore;
}
```

## Variabili globali con Internal Linkage (Static variables with Internal Linkage)

<p align="justify">
Queste variabili sono globali ed hanno file scope, static storage duration ma internal linkage: questo vuol dire che la loro visibilità è limitata al file che le contiene. La loro DEFINIZIONE è: come tutte le variabili globali effettuata fuori da tutte le funzioni di solito all'inizio del file con l'aggiunta della parola chiave <b>static</b>.
</p>

```c
int global_external; /* DEFINIZIONE di variabile globale esterna, visibile nel file ed in tutti gli altri file del programma */
static int global_internal; /* DEFINIZIONE di variabile globale interna, non è visibile agli altri file del programma */

int main(void){
	extern int global_external;  /* DICHIARAZIONE opzionale di variabile globale esterna */
	extern int global_internal;  /* DICHIARAZIONE opzionale di variabile globale interna */
}
```

## Sintassi dichiarazione variabili

Una dichiarazine di variabile ha questa forma:

```
specificatori-dichiarazione dichiaratori
```

Gli specificatori di dichiarazione descrivono le proprietà della variabile o della funzione oggetto della dichiarazione.

Gli specificatori di dichiarazione sono raggruppabili in tre categorie:

* classi di memorizzazione (storage classes): sono quattro `auto`, `static`, `extern` e `register`. Al massimo una di queste può presentarsi in una dichiarazione e se presente deve essere la prima _keyword_ nella dichiarazione
* qualificarori di tipo (type qualifiers): sono tre `const`, `volatile` e `restrict`. Una dichiarazione puà contenere zero, uno o più di un qualificatori di tipo
* specificatori di tipo (type specifiers): `void` `char` `short` `int` `long` `float` `double` `signed` `unsigned`. Queste _keyword_ possono essere combinate assieme (`unsigned long int``) l'ordine con cui compaiono non ha importanza

Vediamo alcuni esempi:

```c
   +--------------classe di memorizzazione
   |
static float x, y, *p;
	 |  |   |   |
	 |  +---+---+---dichiaratori
	 |
	 +---specificatore di tipo
```

```c
  +---qualificatore di tipo
  |
  |	     +----dichiaratore
  |	     |
const char month[] = "July";
	|		|
	|		+----inizializzatore
	|
	+----specificatore di tipo

```

```c
  +--classe di memorizzazione
  |
  |		+-------+---+-------specificatori di tipo
  |		|	|   |
extern const unsigned long int a[10];
	 |			  |
	 |			  +-----dichiaratore
	 + qualificatore di tipo
```
### Classi di memorizzazione per le funzioni

<p align="justify">
La definizione (e dichiarazione) di funzione, come per le variabili, può contenere una classe di memorizzazione. Per le funzioni abbiamo solo due classi di memorizzazione: <code>extern</code> e <code>static</code>. La <i>keyword</i> <code>extern</code> all'inizio della dichiarazione o definizione di funzioni specifica che la funzione ha <b>external linkage</b>: può essere chiamata da funzioni in altri file del programma. La parola chiave <code>static</code> invece indica <b>internal linkage</b> e quindi limita l'uso della funzione all'interno del file in cui è definita. <b>Se non viene specificata una classe di memorizzazione per la funzione questa assume la classe <code>extern</code></b>.
</p>

```c
extern int f(int i);
static int g(int i);
int h(int i); /* default extern */
```

### Classi memorizzazione riassunto

```c
int a;
extern int b;
static int c;

void f(int d, register int e){
	auto int g;
	int h;
	static int i;
	extern int j;
	register int k;
}
```

<div align=center>
	
| Name  | Storage Duration | Scope     | Linkage  |
| :---: |     :---:        | :---:     | :---:    |
| a     | static           | file      | external |
| b     | static           | file      |**Nota**  |
| c     | static           | file      | internal |
| d     | automatic        | block     | none     |
| e     | automatic        | block     | none     |
| g     | automatic        | block     | none     |
| h     | automatic        | block     | none     |
| i     | static           | block     | none     |
| j     | static           | block     |**Nota**  |
| k     | automatic        | block     | none     |

</div>

**Nota**: La definizione di  `b` e di `j` non sono mostrate, quindi non è possibile determinare il **linkage** di queste variabili. Nella maggior parte dei casi le variabili saranno definite in un altro file ed avranno quindi **external linkage**

### Suddivisione in moduli di un programma

<p align="justify">
La capacità di separare l'implementazione delle funzioni dai loro prototipi attraverso l'uso dei file header e la possibilità di poter condividere variabili tra file diversi del programma ci permettono ora di fare un uleriore passo nel miglioamento della nostra calcolatrice. Vogliamo riorganizzare il codice in modo da ottenere dei moduli separati, ora vedremo cosa significa e quali sono i vantaggi nel fare ciò. Pensare di realizzare programmi di grandi dimensioni usando un unico grande file sorgente è una cattiva idea per tante ragioni, le principali sono:
</p>

* una modifica anche piccola al codice richiede la ricompilazione dell'intero file sorgente che essendo molto esteso può richiedere tanto tempo
* in un unico file sorgente può risultare difficile trovare la porzione di codice su cui dobbiamo lavorare o da correggere, al contrario usando un approccio modulare la ricerca di una certa funzionalità richiede di analizzare solo il file sorgente e d'intestazione corrispondente
* non è possibile fare _information hiding_ rendendo nascosti i dettagli alle porzioni di codice che non hanno alcun ruolo in un certo compito

Vantaggi di un approccio modulare sono:

* in progetti di grosse dimensioni, i programmatori possono lavorare su moduli diversi
* i moduli di un programma possono essere riutilizzati in altri progetti
* ogni modulo contiene il codice relativo ad una singola funzionalità isolando al suo interno tutto il codice necessario
  
Abbiamo già detto che i file che compongono un programma sono:

* file sorgenti: (_source files_) con estensione `.c`
* file d'intestazione (_header files_) con estensione `.h`

<p align="justify">
Di solito si raggruppano tutte le funzioni ed i dati relativi ad una certa funzionalità in un unico file sorgente (<code>.c</code>) e si crea un corrispondente file header <code>.h</code> (con lo stesso nome del file sorgente a cui si riferisce ma con ovviamente estensione diversa) che contiene i prototipi delle funzioni (implementate nel file sorgente) e la definizione dei tipi di dato usati dal modulo (se è richiesto).
</p>

> [!CAUTION]
> Nei file header `.h` devono essere inseriti solo le definizioni dei tipi ed i prototipi (le dichiarazioni) della funzioni. L'implementazione delle funzioni risiede nel file sorgente `.c` 

<p align="justify">
Brevemete, in <code>5_variabili_main.c</code> inseriamo la logica di interazione con l'utente, l'implementazione delle funzioni matematiche viene spostata in un file sorgnete separato: <code>5_variabili.c</code> ed i prototipi nel corrispondente file header <code>5_variabili.h</code>
</p>

> [!NOTE]
> Il file sorgente che contiene le funzioni matematiche ed il suo corrispettivo file d'intestazione hanno stesso nome ma estensioni differenti: `5_variabili.c` e `5_variabili.h`

<p align="justify">
Nel file <code>5_varibili_main.c</code> facciamo uso delle funzioni matematiche, quindi, prima del loro utilizzo all'interno dello <code>switch</code>, importiamo il file header contenente i prototipi; ovvviamente facciamo lo stesso anche per la funzione <code>printf()</code>.
</p>

> [!WARNING]
> Fai attenzione che per includere il file header per la funzione `printf()` si usano le parentesi angolari `<` `>` in quanto si tratta di funzioni del linguaggio, per includere file d'intestazione definiti dal programmatore si usano i doppi apici `"`

```c
#include <stdio.h> // header della libreria c
#include "5_variabili.h" // header definito dal programmatore
```

<p align="justify">
In aggiunta, sostituaimo il costrutto <code>if-else</code> con lo <code>switch</code>. Lo <code>switch</code> è assolutamente equivalente ad un <code>if-else</code> e serve a scegliere tra diversi blocchi di istruzioni in base al valore di una espressione intera. La sintassi è la seguente:
</p>

```c
switch ( espressione-intera ) {
	case espressione-costante :
	  [ istr ]
	  [ ... ]
	  [ break ; ]
	case espressine-costante :
	  [ istr ]
	  [ ... ]
	  [ break ; ]
	[ default: ]
	  [ istr ]
	  [ ... ]
	  [ break ; ]
} 
```

<details>
<summary>lab/0_intro/5_variabili_main.c#L1-L34</summary>
https://github.com/kinderp/2cornot2c/blob/23edeb0541fb524a4389e3728b72eec3df1da49e/lab/0_intro/5_variabili_main.c#L1-L34
</details>

<details>
<summary>lab/0_intro/5_variabili.h#L1-L6</summary>
https://github.com/kinderp/2cornot2c/blob/23edeb0541fb524a4389e3728b72eec3df1da49e/lab/0_intro/5_variabili.h#L1-L6
</details>

<details>
<summary>lab/0_intro/5_variabili.c#L1-L15</summary>
https://github.com/kinderp/2cornot2c/blob/23edeb0541fb524a4389e3728b72eec3df1da49e/lab/0_intro/5_variabili.c#L1-L15
</details>

### Il preprocessore

<p align="justify">
Il preprocessore elabora il contenuto di un file sorgente <b>prima della compilazione</b> ed opera delle sostituzioni di testo: la sostituzione di parti del codice sorgente originale con altro testo.
Il preprocessamento è il primo step del processo che porta alla generazione del file eseguibile. Il preprocessore può svolgere differenti sostituzioni, tutte le chiamate al preprocessore sono dette <b>direttive al preprocessore</b>, le più famose sono:
</p>

* `#define`
* `#include`
* `#if` `#ifdef`

> [!IMPORTANT]
> Tutte le righe nel codice che iniziano con il carattere `#` sono direttive al preprocessore

Queste direttiva permettono di:

* includere il cotenuto di altri file all'interno del sorgente
* ridefinire il significato degli identificatori
* disabilitare condizionalmente parti di codice in fase di compilazione, eliminando il testo prima che il compilatore lo elabori

> [!TIP]
> E' il preprocessore che elimina tutti i commenti presenti nel codice sorgente in modo che sia compilato solo il codice vero e proprio


#### La direttiva #define 

<p align="justify">
La direttiva <code>#define</code> viene usata per creare le <b>macro</b>. Le <b>macro</b> sono utilizzate per effettuare sostituzioni tipografiche nel codice sorgente prima della compilazione. 
Ha questa forma:
</p>

```c
#define nome nuovo-nome
```

<p align="justify">
A seguito della riga sopra, tutte le successive occorrenze dell'identificatore <code>nome</code> presenti nel codice saranno sostituite con <code>nuovo-nome</code> (non viene considerato lo spazio tra <code>nome</code> e <code>nuovo-nome</code>).
Il testo da sostituire può estendersi su più di una riga se l'ultimo carattere della linea è <code>\</code> che fa ignorare il carattere di nuova riga <code>\n</code> al preprocessore.
</p>

Ecco alcuni esempi di uso di `#define`:


```c
#define NUM_ITERATIONS 10

for(int i=0; i < NUM_ITERATIONS; i++)
	printf("%d\n", i);
```

```c
#define DIM_BUFFER 100

int array[DIM_BUFFER];
```

Le **macro** possono ricevere parametri in ingresso, vengono realizzate per realizzare piccole pseudo-funzioni:

```c
#define QUADRATO(x) x*x

int main(void){
	int lunghezza_lato = 10;
	int area_quadrato = QUADRATO(lunghezza_lato);
}
```

La **macro** `QUADRATO` determina la sostituzione del testo `QUADRATO(lunghezza_lato)` col testo `lunghezza_lato*lunghezza_lato` prima della compilazione, quindi il codice visto dal compilatore è:

```c
int main(void){
	int lunghezza_lato = 10;
	int area_quadrato = lunghezza_lato*lunghezza_lato;
}
```

Si usa dire che la **macro** è stata espansa.

<p align="justify">
Le <b>macro</b> sono molto più veloci delle funzioni ma usandole è più facile inserire nel codice errori difficilmente identificabili. Inoltre i moderni compilatori sono in grado di effetturare ottimizzazioni sul codice e capire autonomamente quando evitare una chiamata a funzione espandendo il codice in essa contenuta. In generale quindi l'uso eccessivo di <b>macro</b> o l'utilizzo di <b>macro complesse</b> non porta a miglioramenti delle prestazioni ma può comportare l'insorgere di bug difficili da risolvere. Vediamo un esempio:
</p>

```c
#define QUADRATO(x) x*x

int main(void){
	int area_quadrato = QUADRATO(1+2);
}
```

Il codice di sopra viene in espanso in questo modo:

```c
#define QUADRATO(x) x*x

int main(void){
	int area_quadrato = 1+2*1+2;
}
```

Per evitare errori sarebbe stato giusto definire la **macro** in questo modo:

```c
#define QUADRATO(x) ((x)*(x))
```

> [!CAUTION]
> L'uso di macro con parametri senza l'uso di parentesi tonde porta ad errori difficili da identificare

#### La direttiva #include

Abbiamo accennato a questa direttiva nei paragrafi introduttivi spiegando che serviva ad includere, nel file sorgente, il file header `stdio.h` che conteneva il prototipo della funzione `printf()`.

La direttiva `#include` sostituisce il contenuto di un intero file nella riga di codice dove è inserita.

Esiste in due forme: con parentesi angolari o con doppi apici:

```c
#include <stdio.h>
```

```c
#include "file.h"
```

La prima forma (parentesi angoli `<` `>`) è usata per includere il contenuto di file d'intestazione del linguaggio, la seconda forma invece permette di includere i file header definiti dal programmatore.

#### Le direttive #if #ifdef #ifndef 

Con queste direttive si possono escludere porzioni di codice in base al verificarsi o meno di certe condizioni.

La direttiva `#if` valuta **un'espressione intera costante** il cui **valore deve essere noto all'atto della compilazione**.

```c
#if espressione-intera-costante
	/*
	 * questo  codice  viene  compilato  solo se
	 * l'espressione risulta (vera) diversa da 0
	 *
	 * #endif  termina  la  sezione condizionale
	 */
#endif
```

Tutte le righe comprese tra `#if` e `#endif` vengono incluse nel file header solo se l'espressione è diversa da 0 altrimenti vengono rimosse.

La direttiva `#ifdef` è molto simile, non valuta un'espressione costante ma la definizione o meno di una macro;  vedi codice sottostoante:

```c
#ifdef macro
	/*
	 * questo  codice  viene  considerato
	 * solo se macro è già stata definita
	 */
#endif
```

`#ifdef `include il codice tra se stessa e la direttiva `#endif` solo se la macro è definita.

E' possibile ottenere il comportamento opposto con `#ifndef`, come segue:

```c
#ifndef macro
	/*
	 * questo  codice  viene  considerato
	 * solo se macro non è stata definita
	 */
```

> [!IMPORTANT]
> La definizione del simbolo macro deve essere effettuata con la direttiva `#define`


### Eliminazione temporanea di codice

<p align="justify">
In fase di debugging può essere utile eliminare temporaneamente porzioni di codice senza cancellarle, oppure al contrario far eseguire certi pezzi di codice (<code>printf()</code> di variabili per valutarne il valore) solo in fase di debug/testing. A questi scopi possiamo usare le direttive mostrate sopra, vediamo come:
</p>

```c
#if 0
	/* pezzzo di codice da non considerare */
#endif
```

Una volta eliminati i problemi si può rispristinare il codice rimuovendo le righe contenenti <code>#if</code> <code>#endif</code> oppure cambiando il valore zero con il valore uno come mostrato sotto:

```c
#if 1
	/* codice ripristinato */
#endif
```

oppure più elgantemente usando `#define` e `#if` assieme:

```c
#define SWITCH 0

#if SWITCH
	/*
	 * Se l'interruttore è chiuso (SWITCH 0) il codice non è considerato
	 * Se l'interruttore è aperto (SWITCH 1) il codice è considerato
	 */
#endif
```

Si può ottenere lo stesso risultato con la direttiva `#ifdef` in questo modo:

```c
#ifdef UNDEF
	/* pezzo di codice non è incluso perchè UNDEF non è definita */
#endif
```

<p align="justify">
Questa seconda soluzione, più elegante, può essere utilizzata anche per includere dei pezzi di codice in fase di testing/debugging (per esempio uan serie di stampe su schermo dei valori della variabili). Per farlo basta definire una macro <code>DEBUG</code> con la direttiva <code>#define</code> ed usare <code>#ifdef</code> o <code>#ifndef</code> per includere il codice di test in questo modo:
</p>

```c
#define DEBUG

#ifdef DEBUG
	/*
	 * questo codice viene considerato perchè  DEBUG
	 * è definito, per escludere questo codice  devi
	 * usare la direttiva #undef o eliminare la dire-
	 * ttiva '#define DEGUB'
	 * /
#endif
```

<p align="justify">
Per non considerare il codice basta rimuovere la prima riga <code>#define DEBUG</code> ma, per rendere esplicito che DEBUG è usato per una compilazione condizionale del codice attraverso il preprocessore e che questo è stato disattivato, è meglio usare la direttiva <code>#undef</code> in questo modo:
</p>

```c
#undef DEBUG

#ifdef DEBUG
	/*
	 * questo codice non viene considerato
	 * perchè   DEBUG   non   è   definito
	 * /
#endif
```

Ovviamente con `#ifndef` otteniamo il comportamento opposto, vediamo un esempio che usa `#ifdef` e `#ifndef` per includere e/o escludere porzioni di codice a seconda se è attivato il DEBUG o meno:

```c
#undef DEBUG /* We are in production */

#ifdef DEBUG
	printf("Staging code, debugging is enabled");
#endif

#ifndef DEBUG
	printf("Production code, no debugging enabled");
#endif
```

Esiste anche la possibilità di usare `#else` in questo modo:

```c
#define DEBUG /* We are in staging */

#ifdef DEBUG
	printf("Staging code, debugging is enabled");
#else
	printf("Production code, no debugging enabled");
#endif
```

Esiste anche la possibilità di usare `#if` `#elif` `#else` per condizioni più complesse:

```c
#include<stdio.h>
int main(void){
#ifdef IA32
        #define CPU_FILE "ia32.h"
#elif MAC_OS
        #define CPU_FILE "arm.h"
#else
        #define CPU_FILE "amd64.h"
#endif
printf("CPU_FILE = %s\n", CPU_FILE);
return 0;
}
```

```bash
vagrant@ubuntu2204:~$ gcc -DMAC_OS -o test test.c
vagrant@ubuntu2204:~$ ./test
CPU_FILE = arm.h
 ```

La cosa interessante di questo approccio è il fatto che è possibile definire simboli passando direttamente un opzione al compilatore, se ho ad esempio il file `conditional_compilation.c` con questo contenuto:

```bash
#include<stdio.h>

int main(void){
	#ifdef DEBUG
		printf("Staging code, debugging is enabled");
	#else
		printf("Production code, no debugging enabled");
	#endif
	return 0;
}
```

Posso definire il simbolo `DEBUG` da riga di comando a tempo di compilazione passando a `gcc` l'opzione `-D` in questo modo:

```bash
gcc -DDEBUG -o conditional_compilation conditional_compilation.c
```
Anche se nel file non è presente alcuna riga `#define DEBUG` il simbolo è stato definito a tempo di compilazione quindi siamo in staging è l'output del programma sarà:

```bash
vagrant@ubuntu2204:~$ ./conditional_compilation
Staging code, debugging is enabled
```

Ovviamente è possibile all'interno del codice annullare la dichiarazione del simbolo con `#undef DEBUG` in questo modo:

```c
#include<stdio.h>
#undef DEBUG

int main(void){
	#ifdef DEBUG
		printf("Staging code, debugging is enabled");
	#else
		printf("Production code, no debugging enabled");
	#endif
	return 0;
}
```

anche definendo il simbolo attraverso `gcc`, a tempo di compilazoine, questo verrà annullato dalla direttiva `#undef` e l'output del programma sarà:

```bash
vagrant@ubuntu2204:~$ gcc -o conditional_compilation -DDEBUG conditional_compilation.c
vagrant@ubuntu2204:~$ ./conditional_compilation
Production code, no debugging enabled
```

### Protezione del contenuto dei file d'intestazione

<p align="justify">
I file d'intestazione contengono dichiarazioni sia di funzioni (prototipi) ma anche di dati (strutture, definizione di tipo, variabili e costanti); questi file possono essere inclusi in più sorgenti correndo il rischio di avere una situazione in cui lo stesso file d'intestazione è incluso due volte nello stesso sorgente; in queste situzioni il preprocessore copierà due volte il contenuto del file d'intestazione.
Non è un grosso problema, all'interno di un file <code>.c</code>, avere due o più dichiarazioni (prototipi) della stessa funzione; il compilatore invece darà errore se trova due dichiarazioni di tipo identiche. Dobbiamo quindi trovare un modo di evitare inclusioni multiple dello stesso file d'intestazione in un file sorgente.
Per capire meglio facciamo un esempio: supponiamo di avere tre file header: <code>file1.h</code> <code>file2.h</code> <code>file3.h</code> ed un file sorgente <code>prog.c</code>. La situazione, mostrata nella figura di sotto, è la seguente: sia <code>file1.h</code> che <code>file2.h</code> includono <code>file3.h</code> mentre <code>prog.c</code> include <code>file1.h</code> e <code>file2.h</code>. In <code>prog.c</code> <code>file3.h</code> verrà incluso due volte: la prima volta a seguito dell'inclusione di <code>file1.h</code> e la seconda per l'inclusione di <code>file2.h</code> 
</p>

![](https://github.com/kinderp/2cornot2c/blob/main/images/inclusione_multipla.png)

```c
/* file1.h */

#include "file3.h"
```

```c
/* file2.h */

#include "file3.h"
```

```c
/* file3.h */

#define TRUE 1
#define FALSE 0
typedef int Bool;
```

```c
/* prog.c */

#include "file1.h"
#include "file2.h"

int main(void){
        return 0;
}
```

Mostrando l'output prodotto dal preprocessore vediamo che effettivamente `file3.h` è stato incluso due volte in `prog.c`

```bash
vagrant@ubuntu2204:~$ gcc -E prog.c
# 0 "prog.c"
# 0 "<built-in>"
# 0 "<command-line>"
# 1 "/usr/include/stdc-predef.h" 1 3 4
# 0 "<command-line>" 2
# 1 "prog.c"
# 1 "file1.h" 1
# 1 "file3.h" 1


typedef int Bool;
# 2 "file1.h" 2
# 2 "prog.c" 2
# 1 "file2.h" 1
# 1 "file3.h" 1


typedef int Bool;
# 2 "file2.h" 2
# 3 "prog.c" 2

int main(void){
 return 0;
}
```

Per risolvere il problema basta fare uso della direttiva `#ifndef` in questo modo all'interno di `file3.h`:

```c
#ifndef __FILE3_H__
#define __FILE3_H__

#define TRUE 1
#define FALSE 0
typedef int Bool;

#endif
```

<p align="justify">
Al momento dell'inclusione se il simbolo <code>__FILE3_H__</code> non è stato ancora definito questo verrà definito e verrà anche incluso il contenuto del file d'intestazione altrimenti se <code>file3.h</code> è stato già incluso una prima volta il simbolo <code>__FILE3_H__</code> sarà già definito ed il contenuto del file d'intestazione fino ad <code>#endif</code> verrà ignorato evitando così una seconda inutile inclusione. Verifichiamo di aver risolto rilanciando lo step di preprocessamento:
</p>

```bash
vagrant@ubuntu2204:~$ gcc -E prog.c
# 0 "prog.c"
# 0 "<built-in>"
# 0 "<command-line>"
# 1 "/usr/include/stdc-predef.h" 1 3 4
# 0 "<command-line>" 2
# 1 "prog.c"
# 1 "file1.h" 1
# 1 "file3.h" 1





typedef int Bool;
# 2 "file1.h" 2
# 2 "prog.c" 2
# 1 "file2.h" 1
# 3 "prog.c" 2

int main(void){
 return 0;
}
```
## Rappresentazione delle informazioni

<p align="justify">
<b>Le informazioni di seguito riportate sono solo un aiuto per fissare i concetti e vedere un'applicazione pratica in un linguaggio di programmazione dei contenuti teorici presentati a lezione e non sostituiscono in alcun modo lo studio del materiale teorico</b>
</p>

<p align="justify">
Il computer rappresenta le informazioni attraverso sequenze di bit. Qualsiasi tipo di dato sia esso un documento, un video, audio etc viene memorizzato come una lunga successione di bit . 
Il bit è l'unità atomica, l'elemento minimo, per rappresentare informazioni. Il bit può essumere solamente due valori <code>0</code> (falso/basso) <code>1</code> (vero/falso). Dati $N$ bit è possible costruire $2^N$ diverse combinazioni di queste sequenze. Per intenderci facciamo un esempio con $N = 4$ abbiamo $2^4=16$ diverse sequenze di bit (sotto riportate).
</p>

<p align="center">
<img src="https://github.com/kinderp/2cornot2c/blob/main/images/sequenza_binaria.jpg">
</p>

Queste sequenze di bit possono essere difficili da interpretare e lunghe da stampare su shermo per questo si fa uso della loro rappresentazione in esadecimale di seguito riportata

<p align="center">
<img src="https://github.com/kinderp/2cornot2c/blob/main/images/tabella_binario_esadecimale_decimale.png">
</p>

In esadecimale usiamo 16 simboli da 0 a F per rappresentare tutti i possibili valori. 
Ogni simbolo esadecimale (da 0 a F) può rappresentare 4 bit ($2^4=16$).
La seguente sequenza di bit: 

<p align="center">
$0001 0111 0011 1010 0100 1100$
</p>

diventa in esacimale:

<p align="center">
$1 7 3 A 4 C$
</p>

### Big & Little endian

<p align=justify>
La memoria è una sequenza di byte (8 bit), dette celle. Ad ogni cella è associato un indirizzo per leggere e scrivere da e su di essa. La dimensione (in bit) degli indirizzi di un sistema è detta <b>word size</b>. Se la word size è $N$ si potreanno indirizzare $2^N$ celle diverse di memoria. Il numero totale di celle di memoria indirizzabili è detto spazio degli indirizzi virtuale. Quindi la differenza tra una macchina a 32 bit ed a 64 bit è la dimensione in bit degli indirizzi (e probabilmente dei registri interni della CPU).
</p>

<p align=justify>
Visto che le informazioni sono lunghe più di un byte (più di una cella) bisogna decidere come ordinare i singoli byte dell'informazione nelle celle. Il byte più a sinistra è detto MSB (most significant byte) il byte più a destra è detto LSB (least significant byte). 
</p>

```
10110011 00010111 00111010 01001100
<  MSB >                   <  LSB >
```

L'indirizzo di partenza dell'informazione è sempre quello del primo byte (della prima cella).

Abbiamo due possibilità per sistemare i byte nelle celle:

* **big endian**: MSB nell'indirizzo più basso
* **little endian**: LSB nell'indirizzo più basso

Per esempio: la seguente sequenza di bit $0x01234567$ scritta in esadecimale (ogni due cifre abbiamo un byte) verrà memorizzata in memoria a partire dall'indirizzo $0x100$

<p align="center">
<img src="https://github.com/kinderp/2cornot2c/blob/main/images/big_little_endian.png">
</p>

### Codifica numeri decimali

Esistono tre diversi modi per codificare i numeri:

* **Binaria tradizionale** per i **numeri interi senza segno**
* **Complemento a due** per i **numeri interi con segno**
* **Floating point**  per i **numeri interi con parte decimale**

#### Codifica interi senza segno

<p align=justify>
Per i numeri interi senza segno si usa la tradizionale codifica binaria tradizionale.
Dati $W$ bit per rappresentare un numero intero senza segno (positivo), possiamo esprimere $2^W$ numeri in un range $[0, 2^W-1]$
$0$ è  l'estremo negativo $U_{min}$ , $2^W-1$ è l'estremo positivo: $U_{max}$

Il valore decimale corrispondente alla sequenza di bit ad esso associata è ricavabile attraverso la seguente formula:
</p>

$$
\sum_{i=0}^{W-1} x_i*2^i
$$

dove $x_i$ è il simbolo in posizione $i$ all'interno della sequenza

<p align=justify>
La proprietà di questa codifica ($W$ bit per la codifica) è che ciascun valore rappresentato nel range: $[0, 2^W-1]$ ha un'unica codica ad esso associato, non abbiamo due sequenze associate ad uno stesso valore.
</p>

Alcuni esempi:


```math
0001 = 0*2^3 + 0*2^2 + 0*2^1 + 1*2^0 = 1
```

```math
0101 = 0*2^3 + 1*2^2 + 0*2^1 + 1*2^0 = 4 + 1 = 5
```

```math
1011 = 1*2^3 + 0*2^2 + 1*2^1 + 1*2^0 = 8 + 2 + 1 = 11
```

```math
1111 = 1*2^3 + 1*2^2 + 1*2^1 + 1*2^0 = 8 + 4 + 2 + 1 = 15
```

#### Condifica interi con segno (complemento a due)

<p align=justify>
La codifica in complmento a due è la più utilizzata per i numeri interi con segno (positivi e negativi). Il motivo principale è che ci permette per svolgere le operazione aritmetiche gli stessi circuiti usati per i numeri senza segno ed inoltre anche in questo caso ogni valore ha associato una sola rappresentazione (come nel caso dei numer senza segno).
Per rappresentare il segno usiamo il bit più a sinistra (MSB) il più significativo. Se MSB è alto (1) il numero sarà negativo, se MSB è basso (0) il numero è positivo. 
Data una sequenza di $W$ bit codificata in complemento a due, il valore associato alla sequenza è ricavabile dalla formula:
</p>

```math
-x_{W-1}*2^{W-1} + \sum_{i=0}^{W-2} x_i*2^i
```

dove $x_i$ è il simbolo in posizione $i$ all'interno della sequenza e $x^W-1$ (bit MSB) è detto **bit di segno**

Alcuni esempi:

```math
0001 = -0*2^3 + 0*2^2 + 0*2^1 + 1*2^0 = 1
```

```math
0101 = -0*2^3 + 1*2^2 + 0*2^1 + 1*2^0 = 4 + 1 = 5
```

```math
1011 = -1*2^3 + 0*2^2 + 1*2^1 + 1*2^0 = -8 + 2 + 1 = -5
```

```math
1111 = -1*2^3 + 1*2^2 + 1*2^1 + 1*2^0 = -8 + 4 + 2 + 1 = -1
```

<p align=justify>
Se noti abbiamo usato le stesse quattro sequenze degli esempi per la codifica dei numeri senza segno. Anche se le sequenze di bit sono le stesse le codifiche (come i bit vengono interpretati) sono diverse ed i valori ottenuti a seguito del processo di codifica può essere diverso. Da notare come i valori positivi coincidono in entrambe le codifiche (il bit di segno è 0 e le due codifiche coincidono) mentre quando il bit di segno è alto il valore rappresentato è diverso (è negativo).
</p>

<p align=justify>
Anche in questo caso ogni valore ha associata una sola sequenza di bit, non ci sono due sequenze o più associate allo stesso valore. Il range di valori rappresentabili con $W$ bit è $[-2^{W-1}:-1, 0:2^{W-1}-1]$
In quanto con $W$ bit ho $2^W$ sequenze possibili da distribuire metà ai numeri positivi $\frac{2^{W}}{2} = 2^W*2^{-1} = 2^{W-1}$ e metà ai negativi $2^{W-1}$ ma nei numeri positivi abbiamo lo zero a cui associare una sequenze delle $2^{W-1}$ quindi il valore massimo (estremo superiore) per i numeri positivi sarà appunto $2^{W-1}-1$ (-1 perchè appunto devo considerare lo zero che non ho invece nei numeri negativi). **Il range dei numeri rappresentabili è dunque asimmetrico** maggiore per i negativi di uno.
</p>

<p align=justify>
<b>Lo standard C non richiede che i numeri interi con segno siano rappresentati con codifica in complemento a due</b> ma quasi tutti i sistemi fanno questo. <b>L'unica cosa prevista dallo standard sono gli intervalli</b> (tutti simmetrici) per i tipi di dati predefiniti mostrati nell'immagine di sotto
</p>

<p align=center>
<img src="https://github.com/kinderp/2cornot2c/blob/main/images/c_datatype_ranges.png">
</p>

<p align=justify>
Il file d'intestazione <code>limits.h</code> contiene informazioni circa gli intervalli (costanti per estremo superiore ed inferiore: <code>INT_MAX</code>, <code>INT_MIN</code>, <code>U_INT_MAX</code>) per i diversi tipi di interi relativi all'architettura di default del compilatore.

Nella figura di sotto sono invece riportati i range reali per i vari tipi che le implementazioni del C hanno rispettivamente per macchine a 32 e 64 bit
</p>

<p align=center>
<img src="https://github.com/kinderp/2cornot2c/blob/main/images/c_32_64_bit_datatype_ranges.png">
</p>

### Mapping signed - unsigned

$UMax$ : Estremo superiore intervallo codifica senza segno
$TMax$ : Estremo superiore intervallo codifica   con segno
$TMin$ : Estremo inferiore intervallo codifica   con segno

U = Unsigned
T = Two's complement

<div align=center>

| Codifica         | Intervallo valori |  Caso generale (W bit)       | W = 4
| -------------    | -------------     | -------------                | -------------
| Senza segno      | $[0, UMax]$       | $[0, 2^W -1]$                | $[0, 16]$ 
| Complemento a 2  | $[TMin, TMax]$    | $[-2^{W-1}:-1, 0:2^{W-1}-1]$ | $[-8:-1, 0:7]$

</div>

<p align=justify>
Come anticipato le sequenze di bit sono le stesse, le due codifiche si sovrappongono (una sequenza di bit ha lo stesso valore associato in entrambe le codifiche) solo nel range dei numeri positivi da $0$ a $UMax$, poi oltre questo valore, le stesse sequenze rappresentano rispettivamente valori positivi per la unsigned e negativi per la signed (fondamentalmente le sequenze di bit con MSB=1 saranno quelle per cui la codifica è differente). 
</p>

<p align=center>
<img src=https://github.com/kinderp/2cornot2c/blob/main/images/mappa_signed_unsigned.png>
</p>

<p align=justify>
Data una sequenza di bit e conosciuto il valore in una codifica è possibile passare al valore nell'altra codifica aggiungendo o togliendo a quest'ultimo una valore pari a: $UMax+1=2^W$. 
Per esempio con $W=4$ $UMax+1=2^W=16$ data la sequenza $1110$ nella codifica senza segno:
</p>

```math
1110 = 1*2^3 + 1*2^2 + 1*2^1 + 0*2^0 = 8 + 4 + 2 = 14
```

Per ottenere il valore della stessa sequenza nella codifica in complemento (con segno) basta sommare a 14 il valore 16 ($UMax+1$ o anche $2^W$)

```math
1110 = 14 - 16 = -2
```

Allo stesso modo se calcolassimo il valore della sequenza nella codifica in complemento:

```math
1110 = -1*2^3 + 1*2^2 + 1*2^1 + 0*2^0 = -8 + 4 + 2 = -2
```

Per ottnere il valore nella rappresentazione senza segno dovremmo sommare a 2 il valore 16 ($UMax+1$ o anche $2^W$)

```math
1110 = -2 + 14
```

![](https://github.com/kinderp/2cornot2c/blob/main/images/conversione_signed_unsigned.png)

### Estensione rappresentazione binaria di un numero intero

<p align=justify>
Può capitare di dover convertire una rappresentazione binaria (una sequenza binaria) di un numero intero in un'altra con capacità (numero di bit per rappresentare i diversi valori) maggiore.
Consideriamo il caso di una rappresentazione di un numero intero di $W$ bit da convertire (estendere) nella rappresentazione di $W+k$ bit, senza alterare il valore dell'intero rappresentato. 
</p>

<p align=justify>
Per i numeri senza segno (positivi) basterà effettuare una <b>zero extension</b>: cioè porre a zero i $k$ bit (che sono sempre i MSB rispetto ai $W$ bit di partenza).  
</p>

<p align=justify>
Per i numeri con segno (complemneto a 2) basterà effetturare una <b>sign extension</b>: cioè copiare nei nuovi $k$ bit il valore contenuto nel MSB dei $W$ bit di partenza.
La figura di sotto ti aiuterà a capire meglio
</p>

<p align=center>
<img src=https://github.com/kinderp/2cornot2c/blob/main/images/estensione_segno_unsigned.png>
</p>

Per esempio:

<p align=center>
<img src=https://github.com/kinderp/2cornot2c/blob/main/images/esempio_estensione_segno.png>
</p>

### Troncamento rappresentazione binaria di un numero

<p align=justify>
Data una rappresentazione di un numero intero (con o senza segno) di $W+k$ per convertirla in una rappresentazione di $W$ bit che rappresenti lo stesso intero dovremmo eliminare i $k$ bit più significativi in questo modo:
</p>

<p align=center>
<img src=https://github.com/kinderp/2cornot2c/blob/main/images/troncamento_signed_unsigned.png>
</p>

<p align=justify>
Da un punto di vista matematico dobbiamo distinguere i casi di troncamento di numero con o senza segno.
</p>

<p align=justify>
<b>Nel caso di numero senza segno</b> possiamo dire che:
Data una rappresentazione $X$ di $W+k$ bit un troncamento di $k$ bit determina una nuova rappresentazione $X^1$ il cui valore intero è:
</p>

```math
X^1 = X mod 2^k 
```

<p align=justify>
Detto in altri termini, troncare k bit da una sequenza di $W+k$ bit comporta la creazione di una nuova sequenza di $W$ bit il cui valore intero è pari al valore intero della prima rappresentazione modulo $2^k$
</p>

<p align=justify>
<b>Nel caso di numero con segno</b> possiamo dire che:
Data una rappresentazione $X$ di $W+k$ bit un troncamento di $k$ bit determina una nuova rappresentazione $X^1$ il cui valore intero è:
</p>

```math
X^1 = X_{unsigned} mod 2^k 
```

<p align=justify>
Detto in altri termini, troncare k bit da una sequenza di $W+k$ bit comporta la creazione di una nuova sequenza di $W$ bit il cui valore intero è pari al valore <b>senza segno</b> intero della prima rappresentazione modulo $2^k$
</p>

Per esempio:

<p align=center>
<img src=https://github.com/kinderp/2cornot2c/blob/main/images/esempio_troncamento.png>
</p>

### Addizione senza segno

<p align=center>
<img src=https://github.com/kinderp/2cornot2c/blob/main/images/unsigned_addition.png>
</p>

### Addizione con segno

<p align=center>
<img src=https://github.com/kinderp/2cornot2c/blob/main/images/two_complement_addition.png>
</p>

### Tipi di dato

```c
int main(void){
	const float gold_value = 70.57;
	float your_weight;
	float your_value;

	printf("Please, insert your weight in kg\n");
	scanf("%f", &your_weight);

	your_value = yout_weight*gold_value*1000;
	printf("Your weight in gold is: %2.f\n");
}
```

Il linguaggio C riconosce differenti tipi di dato predefiniti. Fino ad ora abbiamo visto solo il tipo `int`, di seguito riportiamo tutto le _keyword_ riconosciute dal C per gli specificatori di tipo:

| Keyowrd       | 
| ------------- |
| `int`         |
| `long`        |
| `short`       |
| `unsigned`    |
| `signed`	|
| `char`        |
| `float`       |
| `double`	|
| `void`	|

`int` permette di rappresentare in memoria i tipi interi (senza parte decimale), le successive quattro _keyword_ in tabella: `long` `short` `unsigned` e `signed` son usate per ottenere variazioni del tipo base (es: `unsigned short int` o `long long int`). `char` è usato per rappresentare i singoli caratteri, simboli d'interpuzione etc; `char` può essere utilizzato anche per esprimere `int` di piccole dimensioni. `float` `double` e `long double` sono usati per i numeri reali, numeri con parte decimale.

### `int`

Il tipo `int` è `signed` questo vuol dire che possiamo esprimere sia numeri positivi (segno +) sia numeri negativa (segno -). La dimensione in bit usata per rappresentare un `int` (e quindi anche il valore intero massimo esprimibile) dipende dall'architettura. Tipicamente un `int` utilizza una word nell'architettura target: quindi nei sistemi con word a 16 bit (IBM compatibile) `int` occuperà 16 bit. Quale sarà il valore massimo e minimo rappresentabili con un `int` a 16 bit? Semplice:

Con 16 bit possono esprimere 65536 diverse combinazioni di bit (65536 diversi valori):

$2^{16} = 65536$

Questi 65536 valori devono essere assegnati metà ai i numeri negativi e metà ai positivi  

$\frac{65536}{2} = 32768$

Per i numeri positivi le diverse 32768 combinazioni devono essere assegnate a partire dallo zero, quindi i numeri positivi andranno da 0 fino a 32767. Per i numeri negativi (non avendo lo zero) i valori andranno da -1 a -32768.

Le stesse considerazioni valgono per macchina con word a 32 o 64 bit. In questi sistemi `int` sarà rispettivamente a 32 e 64 bit.
Quindi, **lo spazio occupato in memoria da un `int` dipende dalla dimensione della word della macchina** che può essere 16,32 o 64 bit a seconda del tipo di architettura. **Lo standard ISO C specifica solo la dimensione minima di `int`: 16 bit** con range [-32767, +32767]

```c
int a; /* dichirazione di intero, non inizializzato */
int b, c, d; /* dichiarazione di interi nella stessa riga */

a = 10; /* assegnamento */

int x = 100; /* dichiarazione di intero con inizializzazione */
int y = 101, z = 102; /* dichiarazione di interi nella stessa riga con inizializzazione */
int q, w = 200 /* q non è inizializzata, w è inizializzata. scarso stile di  programmazione */
```

#### Stampare `int`

Usa `%d` (decimal int) per stampare una variabile di tipo `int` **in base 10**.

```c
#include<stdio.h>

int main(void){
	int ten = 10;
	int two = 2;

	printf("%d - %d = %d\n", ten, 2, ten - two);
}
```

Usa `%o` per stampare una variabile di tipo `int` **in base 8**.
Usa `%x` per stampare una variabile di tipo `int` **in base 16**

Se vuoi stampare il prefisso per la base aggiungi il `#`: `%#o`, `%#x`
```c
include<stdio.h>

int main(void){
	int x = 100;

	printf("decimale = %d, ottale = %o, esadecimale = %x\n", x, x, x);
	printf("decimale = %d, ottale = %#o, esadecimale = %#x\n", x, x, x);
}
```

#### Altri tipi interi

Il linguaggio offre le _keyword_ `short` `long` `unsigned` per modificare il tipo `int` di default.


| Tipo                                            | Descrizione   |
| ----------------------------------------------  | ------------- |
| `int`						  | **Deve essere almeno di 16 bit**. E' `signed` |
| `short int` o `short`                           | **non può essere più grande di `int`**, potrebbe usare meno memoria di `int` salvando spazio quando si rappresentano interi piccoli. Come `int` è `signed` di default |
| `long int`  o `long`                            | **non può essere più piccolo di `int`**, potrebbe usare più memoria di `int`, utile per rappresentare interi molti grandi. Come `int` è `signed` di default |
| `long long int` o `long long`                   | **Deve essere almeno di 64 bit**. Potrebbe usare più  memoria di `long`. Come `int` è `signed` di default |
| `unsigned int` o `unsigned`                     | Usato per valori solo positivi. Il tipo shifta a destra il range di rappresentazione, esempio con 16 bit avendo 65736 possibili rappresentazioni ed escludendo i valori negativi il range passa da [-32768, 32767] a [0, 65735] |
| `unsigend long int` o `unsigned long`           | Previsto da C90 |
| `unsigend long int` o `unsigned long`           | Previsto da C90 |
| `unsigend long long int` o `unsigned long long` | Previsto da C99 |

Lo standard quindi non specifica la dimensione precisa dei diversi interi, l'idea è che il tipo si adatterà alla dimensione della word dell'architettura di riferimento. Lo standard richiede solamente che:

* `int` deve essere almeno 16 bit
* `short` non può essere più grande di `int`
* `long` non può essere più piccolo di `int`
* `long long` deve essere almeno 64 bit

| 16 bit        | 32 bit        | 64 bit        |
| ------------- | ------------- | ------------- |
| `short` 16    | `short` 16    | `short` 16    |
| `int`   16    | `int`   32    | `int` 16 o 32 (dipende dalla word dell'architettura)|
| `long`  32    | `long`  32    | `long` 32     |
| `long long`   | `long long`   | `long long` 64|

Quando allora usare i diversi tipi di interi? Dipenda dalla situazione.

* `unsigned` è usato per contare perchè non rappresenta i numeri negativi e `unsigned` shiftando a destra il range rappresentabile può raggiungere valori maggiori di un `signed`
* `long` è usato per rappresentare valori che `int` non riesce a rappresentare. Tieni conto che nei sistemi in cui `long` è maggiore di `int` usare `long` rallenta i calcoli, quindi usalo solo ne necessario. Altre considerazioni possono essere fatte sulla portabilità: se hai bisogno di interi a 32 e stai scrivendo codice su una macchina dove `int` e `long` sono a 32 bit dovresti scegliere `long` in modo tale che se il programma viene portato su macchine a 16 bit dove `int` è 16 il tuo intero sarà sempre a 32 bit perchè `long` su sistema a 16 bit è lungo 32 bit
* `long long` è usato solo quando gli interi devono essere lunghi 64 bit
* `short` è usato per risparmiare spazio, nel senso se i tuoi interi possono essere lunghi solo 16 bit usare `int` potrebbe renderli lunghi 32 bit (in macchine a 32 bit e superiori).

#### Stampare altri tipi di interi

| Tipo        		| 10	| 16	| 8	
| ----------		| ------|------ |-------	
| `int`			| `%d`	| `%x`	| `%o`
| `unsigned`		| `%u`	| `%ux`	| `%uo`
| `short`		| `%h`	| `%hx`	| `%ho`
| `unsigned short` 	| `%hu` | `%hux`| `%huo`
| `long`		| `%ld` | `%lx` | `%lo`
| `unsigned long`	| `%lu	| `%lux`| `%luo`
| `long long`		| `%lld`| `%llx`| `%llo`

```c
#include<stdio.h>

int main(void){
        unsigned int un = 300000000;
        short end = 200;
        long big = 65537;
        long long verybig = 12345678908642;
        /* Udasa un segnaposto errara nella printf() porta a
         * risultati strani */
        printf("un  = %u  and not %d\n", un, un);
        printf("end = %hd and not %d\n", end, end);
        printf("big = %ld and not %hd\n", big, big);
        printf("verybig = %lld and not %ld\n", verybig, verybig);
        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/3_datatype$ bin/print_others_ints
un  = 300000000  and not 300000000
end = 200 and not 200
big = 65537 and not 1
verybig = 12345678908642 and not 12345678908642
```

#### Overflow `int`

Cosa accade quando si cerca di rappresentare un numero intero più grande del massimo valore rappresentabile: quando si esce fuori dal range massimo. Vediamo in questo esempio.
Consideriamo un sistema a 32 bit quindi `int` 32.

$2^{32} = 4.294.967.296$

$\frac{4.294.967.296}{2} = 2.147.483.648$

```
Per gli `unsigned` avremo un range:
[0, 4294967295]

Per i `signed` avremo un range:
[-2147483648:-1 , 0: 2147483647]
|<--negativi--->|<--postivi--->|
```
	  
```c
#include<stdio.h>

int main(void){
	int i = 2147483647;
	unsigned int j = 4294967295;

	printf("Signed: %d %d %d\n", i, i+1, i+2);
	printf("Unsigned: %u %u %u\n", j, j+1, j+2); /* we need to use %u for unsigned int */

	return 0;
}
```

```bash
vagrant@ubuntu2204:~$ ./int_overflow
Signed: 2147483647 -2147483648 -2147483647
Unsigned: 4294967295 0 1
```

La rappresentazione dei numeri interi si comporta come un odometro (vedi figura di sotto).

Ricordiamo che dati $W$ bit per la rappresentazione i range rappresentabili sono
* con segno: $[-2^{W-1}:-1, 0:2^{W-1}-1]$
* senza segno: $[0, 2^{W}-1]$
  
Per i numeri con segno, abbiamo due casi.
* **un intero positivo, raggiunto il valore massimo** ($+2^{W-1}-1$), **se incrementato** di un'altra unità **assume il valore minimo negativo** rappresentabile($-2^{W-1}$). In figura $W=4$, il valore massimo positivo è $2^3-1=+7$ che ha codifica $0111$ se sommiamo 1 otteniamo un effetto a cascata del riporto $1000$ che in complento a due (siamo con numeri con segno) vale:
```math
-1*2^3+0*2^2+0*2^1+0*2^0=-8
```
che è appunto il valore minimo rappresentabile
* **un intero negativo, raggiunto il valore massimo** ($-1$), **se incrementato** di un'altra unità **assume il valore minimo positivo** rappresentabile ($0$). In figura In figura $W=4$, il valore massimo negativo è $-1$ che ha codifica in complemento a due $1111$
```math
-1*2^3+1*2^2+1*2^0=-8+4+2+1=-1
```
se sommiamo 1 otteniamo $10000$ ma la rappresentazione è a 4 bit ed il primo bit ad uno deve essere scartato con risultato $0000$ che è appunto il valore minimo positivo rappresentabile.

Per i numeri senza segno abbiamo:
* **un intero senza segno, raggiunto il valore massimo** ($2^{W}-1$), **se incrementato** di un'altra unità **assume il valore minimo** rappresentabile($0$). Per esempio sempre con $W=4$ il valore massimo rappresentabile è $2^4-1=15$ che ha una codifica $1111$
```math
1*2^3+1*2^2+1*2^1+1*2^0=8+4+2+1=15
```
se sommiamo 1 otteniamo $10000$ ma la rappresentazione è a 4 bit ed il primo bit ad uno deve essere scartato con risultato $0000$ che è appunto il valore minimo rappresentabile.

![](https://github.com/kinderp/2cornot2c/blob/main/images/odometro_con_segno.png)


> [!IMPORTANT]
> Una qualunque operazione aritmetica su interi si dice in **overflow** quando l'intero risultante dall'operazione ha una dimensione in bit superiore alla dimensione massima (in bit) del tipo di dato. I bit eccedenti sono semplicemente scartati.

# Rappresentazione binaria `int`

La rappresentazione dei numeri interi con segno (`signed`, di default per la _keyword_ `int`) è in **complemento a due**, per gli interi senza senzo (`unsigned int`) si usa una normale rappresentazione binaria del valore intero.
Nel codice di sotto proviamo a predire la sequenza binaria di un valore decimale scelto arbitrariamente. Per comprendere il codice è necessaria una conoscenza del processo di conversione da decimale a binario oltre che ovvia
mente alle basi relative sia al sistema numerico posizionale binari che esadecimale. Trovi la teoria trattata a lezione [qui](https://github.com/kinderp/2cornot2c/tree/main/lab/lessons/UDA_1) 

```c
#include<stdio.h>

/*
 * Calcoliamo la rappresentazione binaria del valore 27:
 *
 *  valore       resto
 *      27 | 2 | 1
 *      13 | 2 | 1
 *       6 | 2 | 0
 *       3 | 2 | 1
 *       1 | 2 | 1
 *       0 |
 *
 *    7   6   5   4   3   2   1   0
 *  +---+---+---+---+---+---+---+---+
 *  | 0 | 0 | 0 | 1 | 1 | 0 | 1 | 1 |
 *  +---+---+---+---+---+---+---+---+
 *               16 + 8 +   + 2 + 1 = 27
 *
 *  Calcoliamo la rappresentazione esadecimale del valore 27:
 *  0001 1011
 *  \  / \  /
 *    1    B
 *
 * Gli interi signed sono rappresentati in questo modo, quindi
 * il valore 27 unsigned stampandolo in esacimale con printf()
 * deve restituire 0x1B
 *
 * Per gli interi con segno si usa la rappresentazione in comp
 * lemento a due, per trovare la sequenza di bit del valore ne
 * tivo dobbbiamo calcolare il complemento a 2 del valore posi
 * tivo ( nega tutti i bit ed aggiungi uno)
 *
 * signed: 00011011
 * negato: 11100100
 * +1    : 11100101
 *
 * 1110 0101
 * \  / \  /
 *   E    5
 *
 * Gli interi su questa architettura sono a 32  bit ( 4 byte )
 * Per gli altri byte estendiamo il bit di segno (MSB) del pri
 * mo byte
 *
 * 00000000 00000000 00000000 00011011
 * 11111111 11111111 11111111 11100101
 *
 */

int main(void){
        int positive = 27;
        int negative = -27;
        unsigned u_positive = 27;

        /*
         * stamperemo gli interi in esadecimale (base 16) per
         * verificare la diversa rappresentazione degli interi
         * di tipo signed ed unsigned
         */
        printf("signed positive: %#x\n", positive);    /* mi aspetto 0x00-00-00-1B */
        printf("signed negative: %#x\n", negative);    /* mi aspetto 0xff-ff-ff-E5 */
        printf("       unsigned: %#x\n", u_positive);

        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/3_datatype$ bin/print_int
signed positive: 0x1b
signed negative: 0xffffffe5
       unsigned: 0x1b
```

### Cast

Il cast è una conversione esplicita di tipo e prevede un proprio operatore. Esistono altri tipi di **conversioni di tipo**: conversione automatica e conversione per assegnamento.

> [!IMPORTANT]
> **Conversione automatica**
> Le conversioni automatiche prevedono che nelle espressioni che coinvolgoo costanti o variabili di tipo diverso il tipo del risultato è pari a quello dell'operando più capiente in termini di bit

Nel codice di sotto il valore che viene stampato è 1, la divisione è tra due interi quindi il risultato anche se è un numero reale (con parte decimale) sarà di tipo intero e la parte decimale verrà troncata.

```c
int x = 8, y=5;
printf("%i\n", x/y);
```

Nel secondo caso (codice sottostante) invece la divisione coinvolge un intero (`int`) ed un numero reale (`double`) ed il risultato sarà dunque un `double`, Il tipo del risulato è uguale a quello dell'operando con maggiore capacità in termini di bit.

```c
int x = 8;
double y = 5;
printf("%lf\n", x/y);
```

> [!IMPORTANT]
> **Conversione per assegnamento**
> il valore assegnato viene convertito nel tipo dell'espressione a sinistra dell'operatore di assegnamento (detto **lvalue**)

```c
int n1, n2;
double a = 1.6, b= -1.6
n1 = a;
n2 = b;
```

Nell'esempio di sopra vengono assegnati dei valori `double` a degli `int`, il risultato è che a seguito del troncamento della parte decimale ad `n1` viene assegnato il valore 1 ed a `n2` -1
Nel caso di sotto invece, si ha un assegnamento da un tipo più capiente (`int`) ad uno meno (`char`). Il valore che viene assegnato ad `n` è 3. La rappresentazinoe binaria di 259 è:

```
259 | 2 | 1
129 | 2 | 1
 64 | 2 | 0
 32 | 2 | 0
 16 | 2 | 0
  8 | 2 | 0
  4 | 2 | 0
  2 | 2 | 0
  1 | 2 | 1
  0

int è a 32 bit quindi:
00000000 00000000 0000001 00000011
```

assegnando questa configurazione di bit ad un char che occupata solo 8 bit i primi 3 ottetti andranno persi e la configurazione binaria copiata nella variabile `n` sarà

```
00000011
```

che corrisponde al valore 3 in deciimale

```c
unsigned char n;
int a = 259;
n = a;
```

> [!IMPORTANT]
> **Conversione esplicita: CAST**
> Le conversioni esplicite vengono effettuate usando l'operatore di cast. L'operatore di cast è costituito dalla parentesi tonde `(` `)` e questa è la sua sintassi

```(nome_del_tipo) espr_da_castare```

In questo modo si forza la conversione del valore restituito dall'espressione (`espr_da_castare`) nel tipo specificato da `nome_tipo`, esempio:

```c
int x = 8, y = 5;
printf("%lf\n", x / (double) y);
```

Il codice di sopra stampa 1.6 in quanto prima di effettuare la divisione il valore di `y` viene convertito in `double` e quindi viene svolta una divisione tra `int` e `double`, per le regole della conversione automatica il valore della divisione sarà quello del tipo più capiente: `double`.
Se invece il cast venisse fatto  in questo modo:

```c
printf("%lf\n", (double)(x/y));
```

il valore stampato sarebbe 1.0 perchè prima vine effettuata la divisione tra `int` ed il risultato è un `int` pari ad 1 e poi questo intero viene trasformato in `double`.

> [!NOTE]
> Quando si effettua il cast di una variabile i bit memorizzati non vengono alterati in alcun modo


#### Cast tra `signed` e `unsigned`

In C, il cast in entrambi i versi: da signed ad unsigned e viceversa, non cambia mai la configurazione dei bit ma soltanto l'interpretazione che viene data alla sequenza di bit.
Vediamo un esempio:

```c
#include<stdio.h>
/*
 * Usiamo la rappresentazione in complemento a due del valore 27
 * che abbiamo calcolato nell'esercizio precedente e che è: 0xE5
 *
 * shoirt int v = -27
 * è un numero con segno (complento a due) ma short (16 bit) la
 * rappresentazione in esadecimale (complemento a 2) è: 0xff-ff
 * ff-E5
 *
 * Cosa accade se facciamo un cast da unsigned a signed? Per se
 * mplicita stiamo consideriamo short int per avere solo 16 bit.
 *
 *  0XFF-FF-FF-E5 in binario è:
 *  +---+---+---+---+---+---+---+---+
 *  | 1 | 1 | 1 | 0 | 0 | 1 | 0 | 1 |
 *  +---+---+---+---+---+---+---+---+
 *
 * Castando il tipo (short int) al tipo (unsigned int) la rap-
 * presentazione (la seuqenza di bit)  rimarrà la stessa ma l'
 * interpretazione  che il  sistema darà  ai bit sarà diversa.
 * Nel caso di (short int) sarà interpretato in complemento a
 * due, nel caso di  (unsigned int) come una sequenza binaria
 * il cui valore è:
 *
 *  +---+---+---+---+---+---+---+---+
 *  | 1 | 1 | 1 | 0 | 0 | 1 | 0 | 1 |
 *  +---+---+---+---+---+---+---+---+
 *  128 + 64+ 32+         4     + 1 = 229
 *
 *  Gli altri 8 bit  (dal 15-esimo all'ottavo) sono tutti a uno
 *  otto bit ad uno (0xff) 255 shiftati di otto 255*(2^8)=65280
 *  65280+229 = 65509
 *  Mi aspetto che il sistema a seguito del cast stamperà 65509
 */
int main(void){
        short int v = -27;
        unsigned int u_v = (unsigned short) v;
        printf("v = %d,  u_v = %u\n", v, u_v);   /* mi aspetto 0xFF-E5 */
        printf("v = %#x, u_v = %#x\n", v, u_v);  /* mi aspetto sempre 0xff-e5 ma valore decimale 65509 */
        return 0;
}
```

Lo stesso discorso vale nel caso di cast nel verso opposto:

```c
#include<stdio.h>
/*
 * Anche nel  caso di cast  da unsigned a signed
 * la sequenza di bit rimane invariata ma cambia
 * solo l'interpretazione data alla sequenza.
 * Scegliendo  come valore senza segno l'estremo
 * superiore  della  rappresentazione (UMax) che
 * nel caso di  (unsigned short) e' 65536 (2^16)
 * per conoscere  il valore  con segno basta sot
 * trarre (UMax + 1) o 2^W
 */

int main(void){
        unsigned short u = 65535; /* UMax */
        short int tu = (short int) u;
        printf("u = %u, tu=%d\n", u, tu);
        printf("u = %#x, tu=%#x\n", u, tu);
        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/3_datatype$ bin/cast_tra_unsigned_signed
u = 65535, tu=-1
u = 0xffff, tu=0xffffffff
```

Il cast può avvenire sia eslicitamente con l'operatore di cast o anche implicitamente in un assegnmento:

```c
#include<stdio.h>

int main(void){
        int tx, ty;
        unsigned ux, uy;
        ux = 4294967295; /* il cast cambia il valore */
        ty = 2147483647; /* il cast non cambia il valore */
        int tx_, ty_;
        unsigned ux_, uy_;

        ux_ = ux;
        ty_ = ty;
        /* cast esplicito */
        tx = (int) ux;
        uy = (unsigned) ty;

        /* cast implicito */
        tx_ = ux_;
        uy_ = ty_;

        printf("unsigned = %ld byte\n", sizeof(unsigned int));
        printf("     int = %ld byte\n", sizeof(int));
        printf("\n");

        printf("ux = %u, tx = %d\n", ux, tx);
        printf("ux_ = %u, tx_ = %d\n", ux_, tx_);
        printf("\n");

        printf("uy = %u, ty = %d\n", uy, ty);
        printf("uy_ = %u, ty_ = %d\n", uy_, ty_);
        printf("\n");

        /* se prendo un valore intero negativo allora cambia il valore castando verso unsigned */
        int cast_me = -2147483648; /* TMin */
        int u_cast_me = (unsigned) cast_me; /* Tmax+1 = (unsigned) TMin */
        printf("cast_me = %d, u_cast_me = %u\n", cast_me, u_cast_me);

}
```

> [!CAUTION]
> **Gestione delle espressioni contenenti combinazioni di valori signed ed unsigned**: quando un'operazione è calcolata e un operando è signed e l'altro unsigned, C implicitamente casta il valore signed ad unsigned e solo dopo calcola l'operazione

Le costanti unsigned si specificano la lettera U, nell'esempio di sotto i due operandi dell'espressioni sono diversi (signed ed unsigned): prima -1 (valore signed) viene trasformato in signed ($-1{unsigned} = -1 + (UMax + 1) = -1 + (4294967295 + 1) = 4294967295 = UMax$  

```c
-1 < 0U
```

Sotto altri esempi 

![](https://github.com/kinderp/2cornot2c/blob/main/images/cast_implicito_valutazione_espressioni.png)

### Estensione della rappresentazione binario di un numero

Come anticipato nella teoria quando si estende la rappresentazione binaria di un numero abbiamo due casi:

* Se il numero è unsigned si effettua **zero extension**: si copia nei nuovi bit il valore 0
* Se il numero è signed si effettua **sign extension**: si copia il valore contenuto nel bit più significativo (MSB) della vecchia rappresentazione nei nuovi bit della nuova rappresentazione
  
```c
#include<stdio.h>

int main(void){
        short sx = -12345;
        unsigned short usx = sx; /* short: 16 bit,    UMax = 2^16 -1 = 65535
                                  * per passare da valore signed ad unsigned
                                  * basta sommare Umax + 1 quindi:
                                  * usx = -12345 + 65536 = 53191
                                  */

        int x = sx;              /* int: 32 bit, verranno aggiunti 16 bit al
                                  * la sequenza di 16 bit che rappresenta sx
                                  * siccoma int è signed sarà effettuata una
                                  * sign extension e non  una zero extension
                                  * nei  sedici bit MSB aggiunti verrà copia
                                  * to 1 e non 0 perchè sx era negativo ed è
                                  * rappresentato  in complemento a due dove
                                  * MSB è il bit di segno (0=+, 1=-)
                                  * x = -12345 (ma con 32 e non 16 bi)
                                  */

        unsigned ux = usx;       /* usx è unsigned short,  aumentando  i bit
                                  * della sequenza da 16 a 32 (  con il cast
                                  * da  (unsigned short)  a  (unsigned) sarà
                                  * effettuata una zero extension.
                                  * ux = 53191 (ma con 32 e non 16 bit)
                                  */
        printf("sx  = %d \t %#hx\n", sx, sx);
        printf("usx = %u \t %#hx\n", usx, usx);
        printf("x   = %d \t %#x\n", x, x);
        printf("ux  = %u \t %#x\n", ux, ux);
        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/3_datatype$ bin/estensione_della_rappresentazione_binaria
sx  = -12345     0xcfc7
usx = 53191      0xcfc7
x   = -12345     0xffffcfc7
ux  = 53191      0xcfc7
```

Come puoi notare `sx` e `usx` sono entrambi `short` il primo con segno ed il secondo senza segno ma hanno la stessa rappresentazione binaria (il cast non cambia la configurazione dei bit ma solo l'interpretazione). Invece `x` ed `ux` sono a 32 bit rispettivamente con segno e senza segno ed hanno sequenze di bit diverse (`x` `0xffffcfc7`, `ux` `0xcfc7`) questo perchè `x` è con segno e quindi si effettua **sign extension** cioè MSB di `sx` è 1 e quindi vengono copiati nei nouvi 16 MSB tutti valori posti ad 1. Invece `ux` è unsigned ed anche se `usx` ha MSB alto (c esadecimale in binario è 1100) viene effettuato uno **zero extension**

In una situazione in cui si effettua un cast da un tipo meno capiente con segno ad uno più capiente senza segno il C deve svolgere due operazioni: l'estensione dei bit ed il cast (cioè interpretare la sequenza di bit secondo il nuovo tipo). Non è difficile comprendere che il risultato finale (il valore) dipende dall'ordine di esecuzione di queste due operaizioni, vediamo un esempio:

```c
#include<stdio.h>

int main(void){
        short sx = -12345;
        unsigned uy = sx;

        printf("sx = %hd \t\t %hx\n", sx, sx);
        printf("uy = %u  \t %x\n", uy, uy);
}
```

`sx` vale `0xcfc7` MSB = 1 (c = 1100) se viene effettuato prima il cast la sequenza di bit viene considerata unsigned e si effettua **zero extension** ed `uy` vale `0x0000cfc7`; se poi si effettua il cast ad unsigned, la sequenza ottenuta vale +12345
Se invece viene effettuato prima l'estensione dei bit `sx` è ancora signed e viene eseguita una **sign extension** in questo modo `0xffffcfc7`; successivamente si effettua il cast ad unsigned e la sequenza varrà $uy{unsigned} = sx + (UMax + 1) = -12345 + 4294967296 = 4294954951$

```bash
vagrant@ubuntu2204:/lab/3_datatype$ bin/mistero
sx = -12345              cfc7
uy = 4294954951          ffffcfc7
```

### Troncamento rappresentazione binaria

```c
#include<stdio.h>

int main(void){
        int x = 53191;
        /* castando int x a short avremo il trocamento dei 16 bit (MSB) */
        short sx = (short) x; /* -12345 */
        int y = sx;           /* -12345 signed short 2 signed con sign extension */
        printf("x  = %d \t %x\n", x, x);
        printf("sx = %hd \t %hx\n", sx, sx);
        printf("y  = %d \t %x\n", y, y);
        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/3_datatype$ bin/troncamento_bit
x  = 53191       cfc7
sx = -12345      cfc7
y  = -12345      ffffcfc7
```

### `char`

Il tipo `char` è usato per memorizzare caratteri, la dichiarazione di una variabile di tipo `char` è fatta in questo modo:

```c
char letter;
char one, two;
```

Per inizializzare un variabile di tipo `char` ad uno specifico carattere è necessario usare il singolo apice: `'` in questo modo:

```c
char lettera_a = 'A';
char lettera_b = 'B';
```

Inizializzare le variabili `char` come nel codice di sotto è un grave errore:

```c
char errore = "T"; /* i doppi apici sono usati per le stringhe, non per i caratteri */
char altro_errore = T /* T senza apici singoli è interpretata come una variabile */
```

Il tipo `char` è lungo 1 byte (8 bit) e in verità è un tipo intero: nel senso che il carattere viene memorizzato come un intero senza sengo e poi attraverso una tabella di codifica/decondifica (ASCII) il valore numerico viene convertito nel carattere corrispondente.

### Stampare un `char`

Per stamapre su schermo il contenuto di una variabile di tipo `char` si usa `%c`

```c
#include<stdio.h>

int main(void){
        char lettera_a = 'A';
        printf("%c\n", lettera_a);  /* stampa il carattere A */
        printf("%d\n", lettera_a);  /* stampa il valore intero usato per codificare il carattere A */
        printf("%u\n", lettera_a);  /* stampa il valore senza segno, dovrebbe essere lo stesso */
        printf("%#x\n", lettera_a); /* stampa la rappresentazione esadecimale */
}
```

```bash
vagrant@ubuntu2204:/lab/3_datatype$ bin/print_char
A
65
65
0x41
```

```math
4 = 0100
```

```math
$1 = 0001
```

```math
0X41 = 0100 0001 = 1*2 + 1*2^0 = 64 + 1 = 65
```

Il valore decimale per rappreentare il carattere `A` è 65, in memoria vengono salvati valori binali che poi attraversi il sistema di codifica **ASCII** vengono convertiti in caratteri


### Costanti

**TODO**

### Operatori

Gli operatori sono usati nelle operazione aritmetiche.

#### Operatore di assegnamento: =

Il simbolo di uguale `=` come abbiamo già visto viene usato per assegnare il valore ad una variabile e non rappresenta l'uguaglianza come invece siamo abitutati a pensarlo.

Il codice di sotto usa l'operatore `=` per assegnare il valore `1234` alla variabile `mio_intero`

```c
mio_intero = 1234;
```

`mio_intero` è l'identificatore attraverso cui il programmatore può accedere alla locazione di memoria corrispondente. 
`mio_intero` è anche detto **lvalue** mentre `1234` è detto **rvalue**

Un **lvalue** identifica appunto una locazione di memoria (referenzia un indirizzo di memoria) e può essere usato a sinistra di un operatore di assegnamento (`l` in `lvalue` sta per **left** in inglese). Per la verità `mio_intero` è detto **modifiable lvalue** perchè è modificabile (non è una costante).

Un **rvalue** può essere usato a destra di un operatore di assegnamento (quantità che possono essere assegnati ad un **modifiable lvalue**) questo può essere un: una costante, una variabile o un'espressione che ritorna un valore (es. una chiamata a funzione).


```c
int main(void){
        int uno;
        int due;
        const int tre = 3;

        uno = 1;
        due = (uno + 1);
        tre = due + 1;  /* ERRORE!
                         * tre è una costante (non è modificabile) non può essere usato come lvalue
                         * di un opeatore di assegnamento.
                         */
        due = tre - 1;
}
```

### Operatore somma: +

L'operatore di somma `+` somma tra loro il valore dei suoi operandi


```c
int main(void){
	int uno = 1;
	int due = 2
	int quattro = uno + due + 1
}
```

### Operatore differenza: -

L'operatore differenza `-` sottrae il valore dell'operando di destra al valore dell'operando di sinistra

### Operatore segno: - e +

L'operatore segno permette di specificare o alterare il segno di un valore.
Questo è un **operatore unario** perchè agisce su un singolo operando al contrario degli operatore che abbiamo vista fino ad ora.

```c
int main(void){
	int uno = +1;
	int meno_uno = -1;
}
```

### Operatore moltiplicazione: *

Questo operatore effettua il prodotto del valore dei due operandi

```c
int main(void){
	int prodotto = 3 * 2;
}
```

### Operatore divisione: /

L'operatore `/` effettua la divisione del valore dei due operandi. Il risultato dipende dal tipo degli operandi come si vede nel codice di sotto.

```c
#include<stdio.h>

int main(void){
        printf("5/4=%d\n",5/4);
        printf("6/3=%d\n",6/3);
        printf("5.0/4.0=%1.2f\n",5.0/4.0);
        printf("6.0/3.0=%1.2f\n",6.0/3.0);

        printf("5.0/4=%1.2f\n",5.0/4);
        printf("6/3.0=%1.2f\n",6/3.0);
}
```

### Operatore `sizeof`

L'operatore ritorna il numero di byte occupati dal suo operando. L'operatore può essere sia una variabile sia il nome di un tipo. Il valore tornato da `sizeof` è di tipo `size_t` che è semplicemente un `unsigned int` o un `unsigned long` che è stato ridefinito con `typedef`.

> [!NOTE]
> **typedef** permette di definire un alias per un tipo di dato, per esempio `typedef unsigned int positivo` associa l'alias `positivo` al tipo `unsigned int` in moda da poter dichiarare varaibili intere positive in entramvi i seguenti modi: `unsigned int a`, `positivo a`. 


```c
#include<stdio.h>

int main(void){
        int n = 0;
        size_t int_in_byte;

        int_in_byte = sizeof(int);
        printf("n = %d, n occupa %zd bytes\n", n, sizeof n);
        printf("Gli interi occupano %zd bytes\n", int_in_byte);
        return 0;
}
```

Come avrai notato `sizeof` può essere usato con o senza parentesi tonde. L'uso delle parentesi è obbligatorio solo quando l'operando è un tipo ma è meglio usarle sempre. Per stampare un tipo `size_t` puoi usare `%zd` o in alternativa `%u` o `%lu`.

### Operatore %

L'operatore modulo ritorna il resto della divisione dei suoi due operandi

```c
#include<stdio.h>

int main(void){
        int n;
        printf("Inserisci un numero tra 1 e 10\n");
        scanf("%d", &n);
        int pari_o_dispari = n % 2;
        if(pari_o_dispari == 0){
                printf("%d e' pari\n", n);
        } else{
                printf("%d e' dispari\n", n);
        }
        return 0;
}
```

### Operatore incremento/decremento ++ --

Questi operatori incrementano o decrementano il proprio operando di un'unità.
Possono essere usati in due versioni prima dell'operando o dopo l'operando in questo modo:

```c
int i = 0;
i++; /* dopo l'operando i */
++i; /* prima dell'operando i */

i--; /* dopo l'operando i */
--i; /* prima dell'operando i */
```

Il risultato è equivalente ad un normale incremento e decremento

```c
i = i + 1;
i = i - 1;
```

Perchè due versioni dello stesso operatore?

```c
#include<stdio.h>

int main(void){
	int i = 0;
	int j = 0;
	int z = 0;
	i++;
	++j;
	z = z + 1;

	i++;
	++j;
	z = z + 1;

	i++;
	++j;
	z = z + 1;

	i++;
	++j;
	z = z + 1;

	printf("i=%d, j=%d, z=%d\n", i, j, z);
	return 0;	
}
```

```bash
vagrant@ubuntu2204:/lab/4_operators$ bin/op_incremento_decremento
i=4, j=4, z=4
```

Sembra che il risultato sia lo stesso ma esiste una sottile differenza tra l'uso dell'operatore nella versione pre e post. Quando l'operatore precede l'operando (versione pre) prima viene incrementato il valore dell'operando di un'unità e poi viene valutato l'operando, diversamente quando l'operatore segue l'operando (versione post) prima viene valutato il valore dell'operando e successivamento lo si incrementa di uno. 

```c
#include<stdio.h>

int main(void){

        int i = 0;
        int j = 0;

        int ii = i++; /* prima viene valutato i ( assegnato il suo valore ad ii )
                       * successivamente i viene incrementato di uno ma ii rimane
                       * al valore precedente di i, cioè 0
                       */

        int jj = ++j; /* prima j viene incrementato di uno e poi viene valutato il
                       * il suo valore (assegnato alla variabile jj). In questo ca
                       * jj vale 1
                       */

        printf("i=%d, ii=%d\n", i, ii);
        printf("j=%d, jj=%d\n", j, jj);
        return 0;
}
```

Quindi quando l'operatore è usato singolarmente non c'è differenza nell'usare la versione pre o post ma quando questo si trova all'interno di un'espressione (assegnamento, test di un loop) allora dobbiamo tenere in considerazione questa lieve differenza tra i due.



### Controllo del flusso

Operatori Logici

| Operatore  | Significato |
| ---------- | ------------- |
| `&&`  | and  |
| `\|\|`  |  or  |
| `!`   | not  |

Operatori Relazionali

| Operatore  | Significato |
|----- | ------------- |
| `<`  | minore di         |
| `>`  | maggiore di       |
| `<=` | minore o uguale   |
| `>=` | maggiore o uguale |
| `==` | uguale uguale     |
| `!=` | diverso           |

#### if o if-else

Il costrutto `if` serve per realizzare l'istruzione di salta condizionale ed ha questa forma:

```c
if ( espr ) istr
```

Se la condizione è vera (cioè diversa da zero) viene esguito il blocco di istruzioni `istr`, altrimenti si prosegue con l'elaborazione.

> [!NOTE]
> Come tutti gli altri costrutti, il blocco `istr` può rappresentare una singola istruzione, un altro costrutto di controllo, oppure un blocco di itruzioni racchiuse tra parentesi graffe

il costrutto `if` ammette l'enunciato opzionale `else` in questa forma:

```c
if ( espr ) istr1 else istr2
```

I blocchi di istruzioni `istr1` e `istr2` vengono eseguiti a seconda che l'espressione `espr` sia rispettivamente vera o falsa.


```c
#include<stdio.h>

int main(void){
        int n;
        printf("Inserisci un numero tra 1 e 10\n");
        scanf("%d", &n);
        int pari_o_dispari = n % 2;
        if(pari_o_dispari == 0){  /* Se la condizione  e' vera (diversa da zero)
                                   * il  flusso   entra in questo blocco, stampa
                                   * "n e' pari" ed il blocco else viene saltato
                                   */
                printf("%d e' pari\n", n);
        } else{                   /* Se la condizione e' falsa ( uguale a zero )
                                   * il blocco if viene saltato e si  entra  nel
                                   * blocco else e  viene  stampata  la  stringa
                                   * "n è dispari"
                                   */
                printf("%d e' dispari\n", n);
        }
        return 0;
}
```

#### Condizioni complesse con l'uso di operatori logici e condizionali

```c
#include<stdio.h>

int main(void){
        int stipendio_base = 1000;
        int stipendio_medio = 3000;
        int stipendio_alto = 5000;

        int eta;
        char laurea = 0;
        printf("Inserisci la tua eta'\n");
        scanf("%d", &eta);
        printf("Hai la laurea?\n");
        printf("[S]ì \t [N]o\n");
        scanf(" %c", &laurea);
        if(laurea == 'S' || laurea == 'N') {
                if(eta < 30){
                        printf("Sei giovane, il tuo stipendio e' %d\n", stipendio_base);
                } else if (eta > 30 && eta < 50 && laurea == 'N'){
                        printf("Non hai la laurea, il tuo stipendio e' %d\n", stipendio_base);
                } else if (eta > 30 && eta < 50 && laurea == 'S'){
                        printf("Hai la laurea, il tuo stipendio e' %d\n", stipendio_medio);
                } else {
                        printf("Hai esperienza, il tuo stipendio e' %d\n", stipendio_alto);
                }
        } else {
                printf("Digita S per sì o N per no\n");
                return 1;
        }
        return 0;
}
```

#### for

Il costrutto `for` serve per realizzare un ciclo (**loop**) permette di eseguire un'istruzione (o un insieme di istruzioni) per un certo numero di volte consecutivamente. Ha questa forma:

```c
for ( espr1; espr2; espr3 ) istr 
```

Prima di iniziare il ciclo viene valutata **una volta sola** `espr1` che viene tipicamente utilizzata  per inizializzare le variabili  che controllano il ciclo, poi viene valutata l'espressoine `espr2`. Se `espr2` è vera (diversa da zero) venogono eseguite le istruzioni del corpo del ciclo rappresentate da `istr`. Quando `espr2` è falsa (uguale a zero) il ciclo termina. Prima di valutare `espr2` una seconda volta viene prima eseguita `espr3` che viene usata per incrementare o decrementare la variabile che controlla il ciclo

```c
#include<stdio.h>

int main(void){
        for(int i = 0; i < 10; i++){
                printf("%d ", i);
        }
        printf("\n");
        return 0;
}
```

#### while

Il costrutto `while` serve (come il `for`) per realizzare un ciclo. Ha questa forma:

```c
while ( espr ) istr
```

Il ciclo `while` continua ad eseguire il ciclo finzh+ la condizione indicata da `espr` risulta vera. Il ciclo termina quando la condizione è falsa. Se la condizione è inizialmente falsa il blocco non viene mai eseguito. I costrutti `while` e `for` sono equivalenti: ogni `for` può essere eseguito con un `while` e viceversa.

```c
#include<stdio.h>

int main(void){
        int i = 0;
        while(i < 10){
                printf("%d ", i);
                i++;
        }
        printf("\n");
        return 0;
}
```

#### do-while

Il costrutto `do-while` serve per realizzare un ciclo ed assume questa forma:

```c
do instr while ( espr )
```

A differenza del costrutto `while`, il blocco  di istruzioni nel ciclo viene eseguito almeno una volta infatti la condizione che controlla l'esecuzione del ciclo viene valutata alla fine del ciclo.

```c
#include<stdio.h>

int main(void){
        int i = 0;
        /* i++ prima viene valutato il  valore di i  (si stampa il suo valore)
         * dopo i viene incrementata  di 1 ,  poi  si controlla  che  sia < 10
         * cosa accade se uso ++i?Invece di stampare da 0 a 9 stampo da 1 a 10
         */
        do {
                printf("%d ", i++);
        } while(i < 10);
        printf("\n");
        return 0;
}
```

#### switch

 Lo `switch` è assolutamente equivalente ad un `if-esle` e serve a scegliere tra diversi blocchi di istruzioni in base al valore di una espressione intera. La sintassi è la seguente:

```c
switch ( espressione-intera ) {
	case espressione-costante :
	  [ istr ]
	  [ ... ]
	  [ break ; ]
	case espressine-costante :
	  [ istr ]
	  [ ... ]
	  [ break ; ]
	[ default: ]
	  [ istr ]
	  [ ... ]
	  [ break ; ]
} 
```

Le parentesi quadre `[`, `]` indicano parti del costrutto opzionali. Le **parentesi graffe sono obbligatorie**, `case` e `default` sono parole chiave.
Il costrutto permette di eseguire un'istruzione o una serie di istruzioni sulla base del valore di `espressione-intera`, l'esecuzione salta al case corrispondente al valore di `espressione-intera`. Se nessun `case` corrisponde ad `espressione-intera` viene eseguita la clausola `default` (se presente).

> [!NOTE]
> Le espressioni di ogni `case` devono essere **espressioni intere e costanti**

* La presenza di istruzioni dopo il `case` è facoltativa per permeettere di ragruppare lo stesso codice in relazione a diversi casi
* la presenza di `break` alla fine di un `case` è facoltativa e quindi la mancanza di `break` determina il continuamento dell'esecuzione del codice associato al `case` successivo
* `default` è facoltativo
* non è obbligatorio che `default` sia l'ultimo caso del costrutto

```c
#include<stdio.h>

int main(void){
        char scelta;
        int a, b, c, other;
        printf("a=%d \t b=%d \t c=%d \t other=%d\n", a, b, c, other);
        printf("Quale variabile vuoi incrementare?\n");
        printf("[a-A]\t[b-B]\t[c-C]\n");
        scanf(" %c", &scelta);
        switch(scelta){
                case 'a':
                case 'A':
                        a++;
                        break;
                case 'b':
                case 'B':
                        b++;
                        break;
                case 'c':
                case 'C':
                        c++;
                        break;
                default:
                        other++;
                        /* non ho bisogno del break perchè è l'ultimo case se lo avessi messo sopra dovevo mettere il break altrimenti
                         * l'esecuzione  del  flusso  sarebbe  passata  al  codice  relativo  al  case sottostante la clausola default
                         */
        }
        printf("a=%d \t b=%d \t c=%d \t other=%d\n", a, b, c, other);
        return 0;
}
```

#### break e continue

Le istruzioni `break` e `continue` sono utilizzate per controllare il flusso di esecuzione nei cicli `while`, `do-while` e `for` in particolare:

* `break` termina immediatamente il ciclo più interno nel quale è contenuta
* `continue` passa immediatamente all'interazione successiva

```c
#include<stdio.h>

int main(void){
        int i = 0;
        while(1){
                if(i == 10){
                        printf("\n");
                        break;
                }
                if(i % 2 == 0){
                        ++i;
                        continue;
                }
                printf("%d ", i);
                i++;
        }


        for(int j=0; ; j++){
                if(j == 10){
                        printf("\n");
                        break;
                }
                if(j % 2 == 0)
                        continue;
                printf("%d ", j);
        }
        return 0;
}
```

## I puntatori

Un puntatore è una variabile che contiene un indirizzo di memoria (di un'altra cella di memoria). 

Un puntatore è un intero positivo (`unsigned int`). Di solito nelle macchine UNIX è di tipo `unsigned long` dato che deve contenere indirizzi da 64 bit.

Per dichiarare un puntatore è necessario specificare il tipo della locazione di memoria a cui esso dovrà puntare. Un puntatore che ospita l'indirizzo di una variabile `int` è di tipo diverso rispetto ad un puntatore che ospita l'indirizzo di una variabile di tipo `char`. Per dichiarare il tipo del puntatore si utilizza il simbolo `*` insieme al tipo della variabile a cui esso dovrà puntare. Per esempio nel codice di sotto dichiariamo una variabile intera `thing` che viene inizializzata al valore 6, nella riga di sotto dichiariamo un puntatore (variabile `thing_ptr`) di tipo (`int *`) che conterrà l'indirizzo di memoria della variabile `int` di nome `thing`.

```c
int thing = 6;
int *thing_ptr;
```

per un `char` avremmo fatto

```
char thing = 'A';
char *thing_prt;
```

Quando un putatore è dichiarato il suo contenuto (come ogni variabile locale automatica) contiene un valore sporco assolutamente casuale. Come per tutte le altre variabili è necessario quindi inizializzare una variabile puntatore ad un indirizzo di memoria valido, per fare questo si usa l'operatore unario `&` (**operatore di indirizzamento**) che permette di ottenere l'indirizzo di memoria di una qualsiasi variabile.

Tornando al nostro esempio se volessimo inizializzare il puntatore ad intero `thing_ptr` all'indirizzo di memoria della variabile intera `thing` dovremmo usare l'operatore `&` in questo modo:

```c
int thing = 6;  /* ipotizziamo che l'indirizzo della variabile thing sia 0x1000 */
int *thing_ptr; /* la variabile puntatore thing_ptr punta ad un indirizzo casuale
                 * DEVE ESSERE INIZIALIZZATA ad un indirizzo valido
                 */

thing_ptr = &thing; /* ora  nella  locazione di  memoria rappresentata da thing_ptr
		     * c'è il valore 0x1000, cioè l'indirizzo della variabile thing
		     * ora thing_ptr è inizializzata correttamente,può essere usata
		     */
```

![](https://github.com/kinderp/2cornot2c/blob/main/images/puntatore.png)

Una volta che abbiamo inizializzato `thing_ptr` all'indirizzo di memoria di `thing` possiamo accedere (leggere e modificare) il contenuto di `thing` attraverso `thing_ptr` usando l'operatore `*` (**operatore di deferenziazione**)

> [!NOTE]
> L'operazione di accesso alla locazione di memoria di una variabile è detta **deferenziazione** per questo motivo `&` è detto **operatore di deferenziazione**

Una variabile puntatore può essere pensata come ad una freccia che punta ad una cella di memoria (ad un'altra variabile).

```c
int thing = 5;  /* ipotizziamo che l'indirizzo della variabile thing sia 0x1000 */
int *thing_ptr; /* la variabile puntatore thing_ptr punta ad un indirizzo casuale
                 * DEVE ESSERE INIZIALIZZATA ad un indirizzo valido
                 */

thing_ptr = &thing; /* ora  nella  locazione di  memoria rappresentata da thing_ptr
		     * c'è il valore 0x1000, cioè l'indirizzo della variabile thing
		     * ora thing_ptr è inizializzata correttamente,può essere usata
		     */

int other = *thing_ptr /* accedo al contenuto della variabile puntata da thing_prt cioè
			* thing (il suo contenuto è il valore 5 ) e lo copio nella varia
			* bile other
			* /

*thing_ptr = 6;    /* copio il valore 6 nella variabile puntata da thing_ptr (thing) */
```

![](https://github.com/kinderp/2cornot2c/blob/main/images/deferenziazione.png)


```c
#include<stdio.h>

int main(void){
        int i = 42, j = 107;
        printf("i = %d, &i = %p\n", i, &i);
        printf("j = %d, &j = %p\n", j, &j);
        getchar();
        int *p = &i;
        int *q = &j;
        printf("*p = %d, p = %p\n", *p, p);
        printf("*q = %d, p = %p\n", *q, q);
}
```

![](https://github.com/kinderp/2cornot2c/blob/main/images/0_pointers.png)

***

```c
#include<stdio.h>

int main(void){
        int i = 42, j = 107;
        printf("i = %d, &i = %p\n", i, &i);
        printf("j = %d, &j = %p\n", j, &j);

        getchar();

        int *p = &i;
        int *q = &j;

        printf("*p = %d, p = %p\n", *p, p);
        printf("*q = %d, p = %p\n", *q, q);

        // p = q;  // (1)
        // *p = *q;// (2)
        // *p = q; // (3)
        // p = *q; // (4)

}
```

***

![](https://github.com/kinderp/2cornot2c/blob/main/images/1_1_pointers.png)

***

![](https://github.com/kinderp/2cornot2c/blob/main/images/1_2_pointers.png)

***

![](https://github.com/kinderp/2cornot2c/blob/main/images/1_3_pointers.png)

***

![](https://github.com/kinderp/2cornot2c/blob/main/images/1_4_pointers.png)

***


### Puntatori non inizializzati

Abbiamo detto che **prima di essere usati** (deferenziazione) per accedere alla memoria **i puntatori devono essere inizializzati** ad un indirizzo valido altrimenti il programma potrebbe crashare o avere comportamenti imprevisti e difficili da indiduare. Vediamo un esempio

```c
#include<stdio.h>

int main(void){
        int i;  /* i non è inizializzata, è locale quindi avrà un valore sporco (casuale) */
        int *p; /* anche  p  non è inizializzato,  punta ad una cella a caso, deve essere
                 * inizializzato prima di essere usato con l'operatore di deferenziazione
                 * *p
                 */

        printf("i  = %d\n", i); /* non possiamo prevedere che valore stamperà */
        printf("&i = %p\n", &i);
        printf("p  = %p\n", p); /* cella  di memoria casuale forse appartenete
                                 * ad un altro processo a cui non possiamo mai
                                 * accedere
                                 */
        printf("*p = %d\n", *p); /* accediamo ad una cella di memoria sconosciuta */
}
```

![](https://github.com/kinderp/2cornot2c/blob/main/images/2_pointers.png)

***

### Il puntatore nullo (NULL)

Il puntatore nullo vale zero e non è un puntatore valido, non può essere utilizzato per un'operazione di derenziazione.
Il valore `NULL` è definito tramite macro al preprocessore (`#define`) in questo modo:

```c
#define NULL 0
```

Sfruttando il valore `NULL` è possibile identificare un puntatore nullo, `NULL` è confrontabile con qualsiasi puntatore.
E' buona norma inizializzare una variabile puntatore a `NULL` se la sua inizializzazione valida avverrà successivamente nel codice e controllare se il puntatore è nullo prima di effettuare operazioni di deferenziazione. Vediamo un esempio

```c
#include<stdio.h>

int main(void){
        int *p = NULL; /* inizializzo il puntatore p a NULL */
        if (p != NULL)  /* prima di deferenziare controllo se p e' diverso da NULL */
                printf("*p = %d", *p);

}
```

![](https://github.com/kinderp/2cornot2c/blob/main/images/3_pointers.png)

***

#### Aritmetica puntatori

I puntatori sono variabili che hanno tutte la stessa lunghezza (`unsigned long` di solito nelle architetture a 64 bit) fissata dall'architettura (32, 64 bit). Però abbiamo detto che quando dichiariamo una variabile puntatore dobbiamo specificare anche il suo tipo che rappresenta il tipo della variabile puntata.
Questo serve al compilatore per effettuare i calcoli quando si usa **l'artimetica dei puntatori**. L'aritmetica dei puntatori ci permette di spostarci, usando l'operatore `+`, nelle celle di memoria adiacenti a quella puntata dal puntatore.
Vediamo un esempio, se ho tre variabili intere (`a`, `b`, `c`) contingue in memoria (`int` occupa 4 byte) ed ho un puntatore (`ptr_a`) che punta alla prima variabile (`a`) posso accedere ai due interi successivi (`b`, `c`) rispettiva con `ptr_a + 1` (accedo a `b`) e `ptr_a + 2` (accedo a c). 
La sintassi `ptr_a + 1` o `ptr_a + 2` indica che ci vogliamo spostare dall'indirizzo puntato da `ptr_a` di un numero di byte pari alla dimensione di un intero (`ptr_a + 1`) o di due interi (`ptr_a + 2`) quindi nel nostro caso di interi a 4 byte il compilatore calcola per noi i byte dello scostamento in questo modo $ptr_a + 1*(4)$ e $ptr_a + 2*(4)$
Ecco perchè è necessario specificare il tipo del puntatore (il tipo della variabile puntata).

```c
#include<stdio.h>

int main(void){
        int a = 1;
        int b = 2;
        int c = 3;

        int *ptr_a = &a;

        printf("a = %d\n", *ptr_a);
        printf("b = %d\n", *(ptr_a + 1));
        printf("a = %d\n", *(ptr_a + 2));

        return 0;
}
```

Come puoi vedere dall'output del programma usando l'artimetica dei puntatori riusciamo ad accedere agli interi (`b` e `c`) adiacenti alla variabile puntata da `ptr_a` (variabile `a`)

```bash
vagrant@ubuntu2204:/lab/6_pointers$ bin/33_pointers
a = 1
b = 2
a = 3
```

L'aritmetica dei puntatoti è potentissima, ipotizziamo ora di avere un intero il cui valore sia posto a $16909060$ (variabile `magic`)
Il numero decimale $16909060$ ha una codifica binaria (32 bit, 4 byte) pari a:

```math
00000001 00000010 00000011 00000100
```

Lo stesso valore in esadecimale vale

```math
0x 01 02 03 04
```

Il primo byte vale 01, il secondo 02, il terzo 03, quarto 04.
Ora se recupero l'indirizzo di questa variabile e la assegno ad un puntatore ad intero cosa accade se faccio un cast da puntatore ad intero ad un puntaore a carattere? Nulla, il valore dell'indirizzo non cambia ma quando uso l'artimetica dei puntatori per spostarmi con `+1` `+2` non aumento di 4byte (dimensione di un intero) ma di 1byte (dimensione di un carattere) perchè il tipo del puntatore è cambiato (da `int *` a `char *)`. Questo mi permettere di spostarmi attraverso i quattro byte del mio intero e di stamparne il valore, come mostrato nel codice di sotto.

```c
#include<stdio.h>

int main(void){o 
        int magic = 16909060;
        int after_magic = 123456789;
        printf("magic        = %#x\n", magic);
        printf("after_magic  = %#x\n", after_magic);

        int *ptr_magic = &magic;
        printf("&magic       = %p\n", ptr_magic);
        printf("&after_magic = %p\n", &after_magic);

        char *ptr_byte1 = (char *)ptr_magic;
        char *ptr_byte2 = ptr_byte1 + 1;
        char *ptr_byte3 = ptr_byte1 + 2;
        char *ptr_byte4 = ptr_byte1 + 3;

        printf("ptr_byte1    = %d\n", *ptr_byte1);
        printf("ptr_byte2    = %d\n", *ptr_byte2);
        printf("ptr_byte3    = %d\n", *ptr_byte3);
        printf("ptr_byte4    = %d\n", *ptr_byte4);
        return 0;
}
```

Nell'output del programma, mostrato sotto, è interessante notare come siamo in configurazione **big endian** perchè l'indirizzo più alto (`ptr_a + 4`) è assegnato al byte MSB (quello più a sinistra, che contiene il valore 01)

```bash
vagrant@ubuntu2204:/lab/6_pointers$ bin/4_pointers
magic        = 0x1020304
after_magic  = 0x75bcd15
&magic       = 0x7fff5ff87eb8
&after_magic = 0x7fff5ff87ebc
ptr_byte1    = 4
ptr_byte2    = 3
ptr_byte3    = 2
ptr_byte4    = 1
```

L'artimetica dei puntatori ci sarà molto utile quando lavoreremo con i vettori (array).

### Vettori

I vettori (o array) permettono di allocare un insieme di elementi **dello stesso tipo** in una zona contingua di memoria.
La sintassi per dichiarare un array è la seguente:

```c
nome-tipo identificatore[cardinalità];
```

* `nome-tipo` è un tipo di dato predefinito o derivato
* `identificatore` è il nome del vettore con cui si accede ai suoi elementi
* `cardinalità` è **una costante** che indica il numero degli elementi
  
Per esempio, per dichiarare un vettore di interi di dieci elemetni

```c
int vettore[10];
```

Per accedere ai singoli elmenti di un vettore (operazione di **indicizzazione**) basta indicare tra le parentesi quadre (`[` `]`) l'indice del vettore a cui si vuole accedere.
**Il primo elemento di un vettore ha indice zero** quindi nel nostro esempio avremo:

```c
vettore[0] = 1 // il primo elemento di un vettore ha indice 0, lo inizializzo al valore 1
vettore[1] = 2 // secondo elemento (indice 1), inizializzato al valore 2
vettore[2] = 3
vettore[9] = 10 // ultimo elemento del vettore, assume valore 10
```

> [!IMPORTANT]
> **Limiti indicizzazione di un vettore**
> Dato un vettore di cardinalità N (N elementi contigui in memoria) il primo elemento avrà indice **0**, l'ultimo elemento avrà indice **N - 1**. Se si accede oltre il limite massimo il comportamento del programma è indefinito quindi non bisogna mai accedere un cella di memoria oltre il limite dell'indice massimo.

> [!IMPORTANT]
> ** Nome del vettore
> Il nome (identificatore) di un vettore contiene l'indirizzo del primo elemento del vettore, in particolare è un **puntatore costante** al **primo elemento del vettore**. Questo vuol dire che per accedere all'elemento i-esimo entrambe le sintassi di sotto sono lecite

```c
#include<stdio.h>

int main(void){
        int vettore[5];

        /* inizializzo gli elementi del vettore con un ciclo */
        for(int i=0; i < 5; i++)
                vettore[i] = i;

        /* accedo agli elementi del vettore tramite [] */
        for(int i=0; i < 5; i++)
                printf("%d ", vettore[i]);
        printf("\n");

        /* accedo agli elementi del vettore tramite aritemetica puntatori */
        for(int j=0; j < 5; j++)
                printf("%d ", *(vettore + j));
        printf("\n");

}
```

#### Inizializzare un vettore

Possiamo inizializzare esplicitamente tutti gli elementi di un vettore in questo modo:

```c
#include<stdio.h>

int main(void){
        int vettore[5];
        vettore[0] = 1;
        vettore[1] = 2;
        vettore[2] = 3;
        vettore[3] = 4;
        vettore[4] = 5;

        for(int i=0; i < 5; i++)
                printf("%d ", vettore[i]);

        printf("\n");
        return 0;
}
```

possiamo anche non esplicitare la cardinalità (parentesi quadre vuote) nella dichiarazione che verrà allora dedotta dal numero dei valori specificati nell'inizializzazione

```c
#include<stdio.h>

int main(void){
        int vettore[] = {1, 2, 3, 4, 5};

        for(int i=0; i < 5; i++)
                printf("%d ", vettore[i]);

        printf("\n");
        return 0;
}
```

Se vogliamo inizializzare tutti gli elementi del vettore allo stesso valore possiamo usare questa sintassi

```c
#include<stdio.h>

int main(void){
	int vettore[5] = {0};

        for(int i=0; i < 5; i++)
                printf("%d ", vettore[i]);

        printf("\n");
        return 0;
}
```

Spesso nella dichiarazione di un vettore si usa la direttiva `#define` per specificare la cardinalità del vettore come mostrato nel codice di sotto.
Come puoi vedere se dovessi cambiare la cardinalità non dovrei modidificare la riga della dichiarazione e quella del ciclo ma solamente la riga con la direttiva `#define`

```c
#include<stdio.h>

#define N 5

int main(void){
	int vettore[N] = {0};

        for(int i=0; i < N; i++)
                printf("%d ", vettore[i]);

        printf("\n");
        return 0;
}
```

Verifichiamo che gli elementi di un vettore siano effettivamente contigui stampando gli indirizzi dei singoli elementi. Per farlo sfruttiamo il fatto che il nome (identificatore) del vettore rappresenta l'indirizzo del primo elemento del vettore.

```c
#include<stdio.h>

#define N 5

int main(void){
        int vettore[N] = {0, 1, 2, 3, 4};

        for(int i=0; i < N; i++)
                printf("%d\t\t\t", vettore[i]);
        printf("\n");

        for(int j=0; j < N; j++)
                printf("%p\t\t", vettore + j);
        printf("\n");

        return 0;
}
```

Questo è l'output prodotto dal codice di sopra:

```bash
vagrant@ubuntu2204:/lab/7_array$ bin/4_array
0                       1                       2                       3                       4
0x7fff64c62430          0x7fff64c62434          0x7fff64c62438          0x7fff64c6243c          0x7fff64c62440
```

Un intero occupa quattro byte sulla mia macchina (ricorda che puoi sempre usare `sizeof(int)`).

```math
vettore + 0 = 0x7fff64c62430
```

```math
vettore + 1 = 0x7fff64c62430 + 4 = 0x7fff64c62434
```

```math
vettore + 2 = 0x7fff64c62434 + 4 = 0x7fff64c62438
```

```math
vettore + 3 = 0x7fff64c62438 + 4 = 0x7fff64c6243c
```

```math
vettore + 4 = 0x7fff64c6243c + 4 = 0x7fff64c62440
```

#### Dimensione vettore (`sizeof`)

Abbiamo visto come l'operatore `sizeof` ci permetta di conoscere il numero di byte occupati da una variabile o di un tipo di dato. Possiamo sfruttare questo operatore per conoscere il numero di elementi di un vettore a tempo di esecuzione svolgendo semplicemente la divisione tra il numero di byte totali occupati dal vettore ed il numero di byte occupati dal singolo elemento del vettore (ricordiamo che gli elementi di un vettore sono tutti dello stesso tipo ed allocati in celle contigue in memoria).

```c
#include<stdio.h>

#define NUM_ELEM 100
int main(void){
        int array[NUM_ELEM] = {0};

        unsigned int num_byte_array = sizeof(array); /* n. di byte occupati dall'intero verrore (100*4) */
        unsigned int num_byte_int   = sizeof(int);   /* n. di byte occupati da un intero in questa arch */

        unsigned int n_elem = num_byte_array / num_byte_int;
        printf("Il vettore di interi occupa %d byte\n", num_byte_array);
        printf("Un singolo intero occupa %d byte\n", num_byte_int);
        printf("Il vettore ha %d(byte)/%d(byte) = %d elementi\n", num_byte_array, num_byte_int, num_byte_array/num_byte_int);
        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/7_array$ bin/5_array
Il vettore di interi occupa 400 byte
Un singolo intero occupa 4 byte
Il vettore ha 400(byte)/4(byte) = 100 elementi
```

Volendo è possibile definire una macro da usare ogni volta che è necessario calcolare il numero di elementi di un array, sfruttando il fatto che il nome del vettore è un **puntatore costante** al primo elemento del vettore:

```c
#define ARRAY_SIZE(x) sizeof(x)/sizeof(*x)
```

```c
#include<stdio.h>

#define NUM_ELEM 100

#define ARRAY_SIZE(x) sizeof(x)/sizeof(*x)

int main(void){
        int array[NUM_ELEM] = {0};

        unsigned int num_byte_array = sizeof(array); /* n. di byte occupati dall'intero verrore (100*4) */
        unsigned int num_byte_int   = sizeof(int);   /* n. di byte occupati da un intero in questa arch */

        unsigned int n_elem = ARRAY_SIZE(array);
        printf("Il vettore di interi occupa %d byte\n", num_byte_array);
        printf("Un singolo intero occupa %d byte\n", num_byte_int);
        printf("Il vettore ha %d(byte)/%d(byte) = %d elementi\n", num_byte_array, num_byte_int, num_byte_array/num_byte_int);
        return 0;
}
```

### Relazione tra array e puntatori

Abbiamo detto che il nome di un array è un puntatore costante al primo elemento del vettore.
Quello che non abbiamo detto che i puntatori come gli array possono essere indicizzati con le parentesi `[` `]` esattamente come i vettori.
La differenza tra nome di un array e puntatori è che il primo è un puntatore costante quindi non è possibile fare le operazione seguenti:

```c
#define N 300

int main(void){
        int a[N] = {1};
        int *p;

        a = p;   // errore: a è un puntaore costante, non lo posso cambiare assegnando un altro indirizzo
        p = a++; // errore: a è un puntaore costante, non lo posso incrementare con operatore ++ ma (a+1) ok
        p = &a;  // errore: a è un puntaore costante, non posso accedere al suo indirizzo
}
```

```c
#include<stdio.h>

#define N 300

int main(void){
        int a[N];
        for(int j=0; j < N; j++)
                a[j] = 1;
        int *p = NULL;
        int i = 0;
        p = a; // equivalente a: p = &a[0]

        /*
         * array e puntatori sono simili:
         * - posso usare aritmetica puntatori con nome array
         * - posso usare indicizzazione array con puntatori
         * quindi le espressioni di sotto sono tutte lecite
         *   *(a + 1) // aritmetica puntatori con nome array
         *   a[i]     // indicizzazione array con nome array
         *   p[i]     // indicizzazione array con  puntatore
         *   *(p +1)  // aritemetica puntatori con puntatore
         */

        int risultato = 0;
        /* ciclo il vettore usando l'indicizzazione dei vettore sul nome del vettore */
        for(i = 0; i < N; i++)
                risultato += a[i];
        printf("%d\n", risultato);

        /* ciclo il vettore uando l'artmetica dei puntatori sul puntatore*/
        risultato = 0;
        for(p = a; p < &a[N]; p++)
                risultato += *p;
        printf("%d\n", risultato);

        /* ciclo il vettore usando l'aritmetica dei puntatori sul nome del vettore */
        risultato = 0;
        for(i=0; i < N; i++)
                risultato += *(a + i);
        printf("%d\n", risultato);

        /* ciclo il vettore usando l'indicizzazione dei vettori sul puntatore */
        risultato = 0;
        p = a;
        for(i=0; i < N; i++)
                risultato += p[i];
        printf("%d\n", risultato);

        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/6_pointers$ bin/7_pointers
300
300
300
300
```

### Differenza tra puntatori

```c
#include<stdio.h>

int main(void){
        int a[2], *p, *q;
        printf("(int  ) %ld bytes\n", sizeof(int));
        printf("(long ) %ld bytes\n", sizeof(long));
        printf("(int *) %ld bytes\n", sizeof(int *));
        printf("\n");

        /* La differenza  tra due puntatori ritorna  il numero di elementi
         * che li separa e NON il numero di byte  come ci si  aspetterebbe
         * devi fare  un  cast  per  ottenere  il risultato atteso
         */
        p = a;
        q = a + 1; // equivalente a: q = p + 1, q = &a[1]
        printf("%ld\n", q - p); // %ld -> long int, un puntatore è di tipo long int (arch a 64 bit)
        printf("%ld\n", (long)q - (long)p);
        printf("\n");

        /* questi vale anche se le variabili puntate non sono elementi di un array */
        int b = 2;
        int c = 1;
        int d = 3;
        q = &d;
        p = &b;
        printf("&b = %p\n", p);
        printf("&c = %p\n", &c);
        printf("&d = %p\n", q);
        printf("%ld\n", q - p); // distanza in elementi in memoria
        printf("%ld\n", (long)q - (long)p); // distanza in termini di byte
}
```

```bash
vagrant@ubuntu2204:/lab/6_pointers$ bin/8_pointers
(int  ) 4 bytes
(long ) 8 bytes
(int *) 8 bytes

1
4

&b = 0x7fff570affa4
&c = 0x7fff570affa8
&d = 0x7fff570affac
2
8
```

### Le stringhe

Il linguaggio C non ha un tipo predefinito per le stringhe, queste vengono implementate come array di caratteri.
Una stringa in C deve essere racchiusa tra **doppi apici**: `"` in questo modo

```c
"Questa è una stringa"
```

**Una costante stringa come quella di sopra è tratta dal compilatore come un puntatore a carattere** quindi per assegnare una costante stringa ad una variabile abbiamo due possibilità. La prima è dichiarare un array di catteri sufficientemente capiente per contenere tutti i caratteri della stringa. Tutte le stringhe vengono terminate (ultimo elemento della stringa) dal carattere `\0` detto di fine stringa che ovviamente non è stampabile ma serve per delimitare la fine della stringa. Nel calcolo della dimensione del vettore di carattere che conterrà la stringa dobbiamo quindi tenere conto del `\0` ed aumentare la dimenisone di 1 per esempio: la stringa "ciao" è composta da quattro caratteri, dobbiamo dichiarare un array di 5 caratteri per ospitare anche il carattere `\0`, in questo modo:

> [!NOTE]
> Il carattere di fine stringa `\0` è diverso dal catattere '0' (il valore in ACII del carattere '0' è 48). `\0` in ASCII ha valore 0.

```c
#include<stdio.h>

int main(void){
        char ciao[5] = "ciao";
        for(int i=0; i < 5; i++)
                printf("%c \t", ciao[i]);
        printf("\n");

        for(int i=0; i < 5; i++)
                printf("%d \t", ciao[i]);
        printf("\n");
        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/8_strings$ bin/0_strings
c       i       a       o
99      105     97      111     0
```

> [!CAUTION]
> I doppi apici `"` devono essere utilizzati per le stringhe, i singoli apici `'` per i caratteri. Fai attenzione a non scambiare i simboli tra loro.

Un altra possibilità per assegnare una costante stringa ad una variabile è quella di utilizzare una variabile di tipo puntatore a carattere `char *` in questo modo:

```c
#include<stdio.h>

int main(void){
        char *ciao = "ciao";
        for(int i=0; i < 5; i++)
                printf("%c \t", ciao[i]);
        printf("\n");

        for(int i=0; i < 5; i++)
                printf("%d \t", ciao[i]);
        printf("\n");
        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/8_strings$ bin/1_strings
c       i       a       o
99      105     97      111     0
```
In questo modo non ci dobbiamo preoccupare di tenere conto del carattere di fine stringa `\0`.

Abbiamo visto che c'è una relazione tra array e puntatori, il compilatore infatti ci permette di dichiarare una stringa anche usando un array con le parentesi quadre vuote in questo modo:

```c
#include<stdio.h>

int main(void){
        char ciao[] = "ciao";
        for(int i=0; i < 5; i++)
                printf("%c \t", ciao[i]);
        printf("\n");

        for(int i=0; i < 5; i++)
                printf("%d \t", ciao[i]);
        printf("\n");
        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/8_strings$ bin/2_strings
c       i       a       o
99      105     97      111     0
```
Anche in questo caso possiamo scordarci di `\0`.

### Dettagli sull'inizializzazione

Anche se esistono due modi diversi per dichiarare una stringa (il primo pensandola come un array di carattere e il secondo pensandola come un literals puntato da un puntatore a carattere) esistono delle differenza sottili tra i due metodi che vanno oltre il non doversi preoccupare di allocare spazio per '\0'.
Vediamole in questo esempio:

```c
#include<stdio.h>
#include<string.h>

int main(void){
        char ciao[] = "ciao";
        /*  Il nome di un array e' un putatore costante al primo elemento del vettore
         *  non posso farlo puntatore ad un'altro indirizzo, si ottiene un errore:
         *  error: assignment to expression with array type
         */
        //ciao = "miao";/* errore: ciao e' puntaore costante */

        /* Il puntatore non può essere modificato ma i caratteri ovviamente si come
         * singoli elementi del vettore oppure usando la strcpy()
         */
        ciao[0] = 'm'; // corretto
        printf("%s\n", ciao); // (1) miao
        strcpy(ciao, "ciao");
        printf("%s\n", ciao); // (2) ciao

        printf("\n");

        /* Se assegno la stringa ad un puntatore a carattere posso far puntare ciao_
         * ad un' altra  cella di memoria senza problemi perche' il puntatore non e'
         * const
         */
        char *ciao_ = "ciao";
        printf("%s\n", ciao_); // (3) ciao
        ciao_ = "miao";
        printf("%s\n", ciao_); // (4) miao
        /* In questo caso *ciao_ punta alla stringa "ciao" e di solito il compilatore
         * inserisce le stringhe in un'area di memoria a sola lettura quindi probabil
         * mente tentare di modificare la stringa con indicizzazione  o strcpy  porta
         * al crash del programma (segmentation fault)
         */
        strcpy(ciao_, "ciao");
        printf("%s\n", ciao_); // (5) ciao
        ciao_[0] = 's';
        printf("%s\n", ciao_); // (6) siao

}
```

```bash
vagrant@ubuntu2204:/lab/8_strings$ bin/5_strings
miao
ciao

ciao
miao
Segmentation fault (core dumped)
```

### Stampare una stringa

Fare un ciclo `for` per stampare carattere dopo carattere tutti gli elementi della stringa (come fatto sopra) non è una grande idea, per stampare una stringa basta usare `%s` con la funzione `printf()` passando l'indirizzo base della stringa (l'indirizzo del primo carattere).


```c
#include<stdio.h>

int main(void){
        char ciao_v1[5] = "ciao"; // vettore dimensione fissa (+1 per '\0')
        char *ciao_v2 = "ciao";   // puntatore a carattere
        char ciao_v3[] = "ciao";  // vettore dimensine dedotta dal numero di caratteri

        printf("%s\n", ciao_v1);
        printf("%s\n", ciao_v2);
        printf("%s\n", ciao_v3);
        printf("%s\n", "ciao");
        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/8_strings$ bin/4_strings
ciao
ciao
ciao
ciao
```

### Funzioni

Quando un certo numero di istruzioni vengono usate più volte nel codice, piuttosto che copiarle ed incollarle in tutte le parti dove ne abbiamo bisogno, è preferibile raggrupparle in una funzione.
Una funzione è una porzione di codice che può essere richiamata in qualsiasi parte del programma e di solito raggruppa le istruzioni che cooperano per svolgere un certo compito. Ogni funzione ritorna uno ed un solo valore (di solito un intero che informa circa il successo o meno delle operazioni svolte oppure direttamente il risultato dell'operazione) e riceve una serie di parametri in ingresso (può anche non accettare alcun parametro in ingresso se non ne ha bisogno).
Una funzione ha questa forma:

```c
tipo-valore-ritorno nome-funzione(tipo-parametro-1 nome-parametro-1, ..., tipo-parametro-N nome-parametro-N){
	istruzione1;
 	...
  	return valore-di-ritorno;
}
```

La prima riga esclusa la parentesi graffa aperta `{` è detta **prototipo** della funzione

```c
tipo-valore-ritorno nome-funzione(tipo-parametro-1 nome-parametro-1, ..., tipo-parametro-N nome-parametro-N)
```

In realtà il nome dei paraemtri in ingresso è opzionale, quindi il prototipo di sotto (più compatto) è comunque corretto

```c
tipo-valore-ritorno nome-funzione(tipo-parametro-1, ..., tipo-parametro-N)
```

Specificare i nomi dei parametri aiuta chi legge il codice a comprendere il tipo di operazioni che la funzione svolge, è cosa buona e giusta aggiugerli nella dichiarazione della funzione (nel prototipo)

> [!IMPORTANT]
> **Prototipo** di funzione: consiste nel tipo di ritorno, nel nome della funzione e nella lista dei tipi dei parametri in ingresso (se presenti)

tutto il codice compreso tra le parentesi graffe `{` `}` è il **corpo** (body) della funzione:

```c
{
	istruzione1;
 	...
  	return valore-di-ritorno;
}
```

Quindi se ho questa funzione

```c
int differenza(int minuendo, int sottraendo)
{
	return minuendo - sottraendo;
}
```

questo è il suo prototipo

```c
int differenza(int minuendo, int sottraendo)
```

o in forma compatta

```c
int differenza(int, int)
```

questo è il suo corpo

```c
{
	return minuendo - sottraendo;
}
```

Le funzioni possono essere dichiarate e definite. 

### Dichiarazione di funzione
**La dichiarazione è opzionale** e non prevede che si specifichino le istruzioni che compongono la funzione ma **solo il suo prototipo**. La dichiarazione serve solo per informare il compilatore circa l'esistenza di una certa funzione da qualche altra parte nel codice sorgente. In questo modo quando il compilatore incontrerà una chiamata alla funzione avrà (grazie alla dichiarazione che precede la cihamata) le informazioni necessaria per verificare la correttezza della chiamata (i parametri sono dei tipi attesi, nel numero corretto, il valore di ritorno coincide con quello nel prototipo, etc). Ovviamente **la dichiarazione della funzione deve sempre precedere la prima invocazione della funzione stessa**. La definizione (che vedremo sotto) può essere inserita in qualunque punto del codice sorgente. **La dichiarazione è il prototipo della funzione**.

### Uso di void nelle funzioni

Le funzioni possono non accettare al parametro in ingresso o non restituire alcun valore di ritorno. Per informare di questo il compilatore si uso il tipo `void`. Per esempio

Questa funzione non ritorna nulla:

```c
void stampa(char *stringa){
	pritnf("%s\n", stringa);
}
```

Questa non accetta alcun parametro in ingresso

```c
char *saluta(void){
	return "ciao"
}
```

### Definizione di funzione

La definizione di funzone include il prototipo  e le istruzioni che formano il corpo della funzione. Una definizione di funzione può comparire solo una volta nel codice sorgente. La definizione di funzione termina quando viene eseguita l'ultima istruzione o quando viene incontrata l'istruzione `return`. Quando l'istruzione termina, il programma prosegue dall'istruzione successiva alla chiamata della funzione appena terminata. Lo scopo dell'istruzione `return` è quella di specificare il valore di ritorno della funzione.
Una funzione può anche avere un corpo vuoto:

```c
void do_nothing(void){

}
```

> [!CAUTION]
> Un programma in linguaggio C deve almeno contenere la definizione della funzione main() da cui inizia l'esecuzione del programma

### Chiamata di funzione

La chiamata di una funzione (invocazione di funzione) è l'operazione con lal quale si richiama l'esecuzione della funzione stessa. E' possibile richiamare 0 o N volte una funzione in un qualunque punto del programma. Ogni volta che la funzione viene invocata, l'esecuzione del programma si sposta dal punto di invocaione alla prima istruzione del corpo della funzione. Quando una funzione termina la propria esecuzione, il flusso di esecuzione ritorna al punto in cui la funzione era stata invocata e continua ed eseguire l'istruzione successiva.
Vediamo un esempio:

```c
#include<stdio.h>

#define ESPONENTE 16

int potenza_di_due(int esponente); /* prototipo o dichiarazione di funzione */

int main(void){
        /* stampo potenze del 2 con esponente da 0 a 16 */
        for(int i=0; i < ESPONENTE + 1; i++){
                int risultato = potenza_di_due(i); /* invocazione funzione */
                printf("2^(%d)\t = %d\n", i, risultato);
        }
        return 0;

}

/* definizione di funzione */
int potenza_di_due(int esponente){
        int risultato = 1;
        for(int i=1; i <= esponente; i++)
                risultato *= 2;
        return risultato;
}
```

```bash
vagrant@ubuntu2204:/lab/9_functions$ bin/0_functions
2^(0)    = 1
2^(1)    = 2
2^(2)    = 4
2^(3)    = 8
2^(4)    = 16
2^(5)    = 32
2^(6)    = 64
2^(7)    = 128
2^(8)    = 256
2^(9)    = 512
2^(10)   = 1024
2^(11)   = 2048
2^(12)   = 4096
2^(13)   = 8192
2^(14)   = 16384
2^(15)   = 32768
2^(16)   = 65536
```

### Passaggio di parametri per valore

I parametri di ingresso di una funzione sono **passati sempre per valore**: la funzione utilizza **una nuova variabile** (nello stack della funzione) per immagazzinare **una copia del valore** contenuto nella variabile passata come parametro in ingresso alla funzione dal chiamante. Anche se dentro la funzione il valore passato in ingresso alla funzione viene alterato (incremento/decremento etc) siccome questo valore è stato copiato in una variabile diversa rispetto a quella passata come in ingresso dal chiamante, il valore nella variabile del chiamante rimane inalterato; sarà modificato il valore nella variabile (nuova) allocata nello stack della funzione quando questa è stata invocata.

> [!IMPORTANT]
> Le variabili allocate all'interno di una funzione sono **locali** alla funzione. La memoria per queste variabili viene allocata solo al momento dell'invocazione della funzione e questa memoria è accessibile solo all'interno della funzione. Quando la funzione termina la memoria viene completamente deallocata. Questa porzione di memria usata per variabili locali delle funzioni è detta **stack**. Lo **stack** cresce verso il basso: l'allocazione della memoria sullo stack avviene partendo dagli indirizzi più alti verso gli indirizzi più bassi. La deallocazione della memoria sullo stack avviene partendo dall'ultimo elemento allocato fino al primo procedendo quindi in ordine inverso rispetto all'ordine di allocazione. Lo stack viene utilizzato per memorizzare l'indirizzo di ritorno della funzione (l'indirizzo dell'istruzione successiva del chiamante), il valore dei parametri di ritorno e dei parametri in ingresso alla funzione e per allocare la memoria per tutte le variabili locali della funzione stessa. Lo spazio sullo stack per la funzione viene allocato al momento dell'invocazione della fuznione e deallocata al termine della sua esecuzione (ultima istruzione della funzione o chiamata a `return`).
		
Cechiamo di capire con un esempio:

```c
#include<stdio.h>

int incrementa(int, int); /* prototipo */

int main(void){
        int valore = 100;   /* valore iniziale di partenza */
        printf("valore = %d, &valore = %p\n\n", valore, &valore);

        printf("valore prima dell'invocazione: %d\n\n", valore);
        /* quando la funzoine incremanta() viene invocata, il contenuto della variabile di nome valore
         * viene copiato all'interno della variabile valore_f ( primo parametro in input nel prototipo
         * della funzione). Il valore contenuto in questa nuova variabile puo' essere modificato ma è
         * una copia del valore della variabile orginale nel chiamante. Quest'ultimo dunque non subisce
         * alcuna variazione perchè si trova in un'altra variabile in memoria.
         */
        int risultato = incrementa(valore, 3); /* incremento il valore di iniziale di 3 */
        printf("\n");
        printf("valore dopo     l'invocazione: %d\n", valore);
        printf("risultato                    : %d\n", risultato);
}

int incrementa(int valore_f, int iterazioni){
        printf("************incrementa****************\n");
        for(int i=0; i<iterazioni; i++){
                valore_f++;
                printf("i=%d valore_f = %d, &valore_f = %p\n", i, valore_f, &valore_f);
        }
        printf("************incrementa****************\n");
        return valore_f;
}
```

```bash
vagrant@ubuntu2204:/lab/9_functions$ bin/1_functions
valore = 100, &valore = 0x7ffef9659030

valore prima dell'invocazione: 100

************incrementa****************
i=0 valore_f = 101, &valore_f = 0x7ffef965900c
i=1 valore_f = 102, &valore_f = 0x7ffef965900c
i=2 valore_f = 103, &valore_f = 0x7ffef965900c
************incrementa****************

valore dopo     l'invocazione: 100
risultato                    : 103
```

### Passaggio di parametri per indirizzo

Se si vuole modificare il valore della variabile del chiamante, bisogna passare alla funzione l'indirizzo della variabile (usando una variabile puntatore) del chiamante da modificare. Ovviamente il passaggio dell'indirizzo dal chiamante alla funzione è fatto per copia: cioè l'indirizzo della variabile del chiamante è copiato all'interno una nuova variabile di tipo puntatore ma avendo a disposizione l'indirizzo della variabile del chiamante la funzione potrà (attraverso la deferenziazione) acccedere al reale valore della variabile originale.
Per ottenere un passaggio per indirizzo nel codice precedente dobbiamo trasformare il primo parametro della funzione (variabile `valore_f`) da `int` a `int *` rendondola un puntatore pronta ad aspitare l'indirizzo della variabile `valore` (la variabile del chiamante da modificare). Per modificare all'interno della funzione il valore della variabile `valore` basterà usare la deferenziazione sul puntatore `valore_f` in questo modo `*valore_f` di fatto accedendo alla locazione di memoria riservata alla variabile `valore`.
Sotto il codice modificato:

```c
#include<stdio.h>

int incrementa(int *, int); /* prototipo */

int main(void){
        int valore = 100;   /* valore iniziale di partenza */
        printf("valore = %d, &valore = %p\n\n", valore, &valore);

        printf("valore prima dell'invocazione: %d\n\n", valore);
        /* In questo passiamo l'indirizzo della variabile valore  e lo capiamo dentro
         * una  variabile puntatore ad intero locale alla funzione  ( primo parametro
         * in  ingresso della funzione incrementa). Dentro la funzione dereferenziamo
         * il puntatore accedendo effettivamente alla locazione di memoria della vari
         * abile valore del chiamante modificando di fatto il valore originale.
         */
        int risultato = incrementa(&valore, 3); /* incremento il valore di iniziale di 3 */
        printf("\n");
        printf("valore dopo     l'invocazione: %d\n", valore);
        printf("risultato                    : %d\n", risultato);
}

int incrementa(int *valore_f, int iterazioni){
        printf("************incrementa****************\n");
        for(int i=0; i<iterazioni; i++){
                (*valore_f)++;
                printf("i=%d valore_f = %d, &valore_f = %p\n", i, *valore_f, valore_f);
        }
        printf("************incrementa****************\n");
        return *valore_f; /* superfluo */
}
```

```bash
vagrant@ubuntu2204:/lab/9_functions$ bin/2_functions
valore = 100, &valore = 0x7ffef6f854a0

valore prima dell'invocazione: 100

************incrementa****************
i=0 valore_f = 101, &valore_f = 0x7ffef6f854a0
i=1 valore_f = 102, &valore_f = 0x7ffef6f854a0
i=2 valore_f = 103, &valore_f = 0x7ffef6f854a0
************incrementa****************

valore dopo     l'invocazione: 103
risultato                    : 103
```

> [!IMPORTANT]
> L'utilizzo della tecnica del passaggio di parametri per indirizzo permette al programmatore di:
* ritornare più di una valore da una funzione
* evitare di perdere tempo nella copia di dati di grandi dimensioni passando solo l'indirizzo e non il dato completo


### Passaggio di puntatori const

Quando è necessario passare dati di grandi dimensioni ad una funzione è quindi cosa buona e giusta passare solo il puntatore al dato (tramite variabile puntatore: passaggio per indirizzo). Abbiamo visto che passando il puntatore di una variabile ad una funzione applichiamo un passaggio per indirizzo ed il dato originale nel chiamante è di fatto modificabile dalla funzione che lo riceve. Se non vogliamo che la funzione sia in grado di modificare il dato passato per indirizzo attraverso la deferenziazione del puntatore possiamo dichiarare il puntatore const nel prototipo della funzione rendendo di fatto il dato a sola lettura dentro la funzione. Vediamo un esempio:

```c
#include<stdio.h>

void leggi(const char *);

int main(void){
        char qualcosa[30] = "Non voglio essere modificata";
        qualcosa[0] = 'x';
        qualcosa[1] = 'x';
        qualcosa[2] = 'x';
        leggi(qualcosa);
}

void leggi(const char *qualcosa){
        // qualcosa[0] = '\0';
        /* Se decommenti la riga sopra e provi a ricompilare ottineni errore
         * error: assignment of read-only location *qualcosa
         * perchè stai provando a modificare una locazione di memoria in sola
         * lettura (puntatore costante)
         */
        printf("%s\n",qualcosa);
}
```

```bash
vagrant@ubuntu2204:/lab/6_pointers$ bin/5_pointers
xxx voglio essere modificata
```

### Array come parametri a funzioni

In una definizione di funzione, un parametro in ingresso dichiarato come array è in realtà un puntatore. Quindi, quando un array viene passato ad una funzione, viene fatto un passaggio per valore dell'indirizzo del primo elemento dell'array; gli elementi degli array non vengono mai copiati. Per convenienza notaionale, il compilatore permette l'utilizzo della notazione con le parentesi quadre (vuote) degli array per dichiarare parametri di tipo puntatore. Vediamo un esempio:

```c
#include<stdio.h>
#define N 100

int sum(int a[], int dim);
int somma(int *, int dim);

int main(void){
        int vettore[N];
        for(int i=0; i < N; i++)
                vettore[i] = 1;

        printf("%d\n", sum(vettore, N));
        printf("%d\n", somma(vettore, N));
        return 0;
}

int sum(int a[], int dim){
        int risultato = 0;
        for(int i=0; i < dim; i++)
                risultato += a[i];
        return risultato;
}

int somma(int *a, int dim){
        int risultato = 0;
        for(int i=0; i < dim; i++)
                risultato += a[i];
        return risultato;
}
```

```bash
vagrant@ubuntu2204:/lab/9_functions$ bin/3_functions
100
100
```

### Allocazione dinamica della memoria

Quando si dichiara una variabile, il compilatore alloca automaticamente lo spazio in memoria necessario per memorizzare la variabile. La quantità di spazio allocato dipende dal tipo della variabile. Quando si dichiara un puntatore ad un determinato tipo, viene allocato spazio in memoria per il puntatore soltanto (che è sempre la stessa `unsisgned long` 8byte) indipendentemente dalla dimensione del tipo puntato. Il puntatore potrà successivamente essere assegnato per contenere l'indirizzo di una variabile dello stesso tipo del puntatore e da quel momento si potrà utilizzare il puntatore per accedere al contenuto della variabile passando per il suo indirizzo (usando l'operazione di derenziazione dei puntatori che abbiamo studiato).
Questo tipo di allocazione della memoria avviene a tempo di compilazione ed è spesso detta **allocazione statica della memoria**. L'allocazione statica può risultare inutile soprattutto nel caso dei vettori se la dimensione (il numero di elementi del vettore) non è noto a tempo di compilazione ma solo durante l'esecuzione del programma (ad esempio il numero degli elementi è scelto dall'utente ad ogni nuova esecuzione). Il linguaggio C permette di effettuare l'allocazione di memoria a tempo di esecuzione; questo tipo di allcoazione è detta: **allocazione dinamica della memmoria**.
Esistono diverse funzioni offerte dal libreria standard del C, per allocare dinamicamente la memoria a tempo di esecuzione. Per adesso vediamo la più comune: la funzione **malloc()**.
Questo è il suo prototipo:

```c
void * malloc(size_t n);
```

La funzione `malloc()` alloca n byte contigui in memoria e ritorna in caso di successo il puntatore al primo elemento della memoria allocata o in caso di errore `NULL`.

* `size_t n`: n è il numero di byte da allocare contigui in memoria
* `void *`: ritorna un puntatore a void (che può essere trasformato in un puntatore di qualsiasi tipo) che punta al primo elemento della memoria contigua allocata

Tornando `NULL` in caso di errore è cosa buona e giusta, prima di usare la memoria allocata, effettuare un controllo sul puntatore tornato da `malloc()` in questo modo:

```c
	int *ptr = (int *)malloc(sizeof(int));
	if (ptr) {
		/* codice che usa ptr ed accede alla memoria allocata*/
	}
```

o anche esplicitamente

```c
	int *ptr = (int *)malloc(sizeof(int));
	if (ptr != NULL) {
		/* codice che usa ptr ed accede alla memoria allocata*/
	}

```

> [!CAUTION]
> Tutta la memoria allocata dinamicamente deve essere rilasciata quando non più necessaria. A questo scopo si richiama la funzione free() che accetta come parametro un puntatore contenente la memoria da deallocara
> Chiamare free() su un puntatore non allocato o precedentemente deallocato può portare a comportamenti del programma imprevedibili. Chiamare free() su un puntatore nullo (`NULL`) non ha alcun effetto.

```c
#include<stdio.h>
#include<stdlib.h>

#define N 10

int main(void){
        /* allocazione statica a tempo di compilazione, la dimensione del vettore
         * deve essere nota a tempo di compilazione e non puo' essere modificata
         * successivamente durante l'esecuzione del programma.
         */
        int statico[N];
        for(int i=0; i<N; i++)
                statico[i] = i;

        /* allocazione dinamica a tempo di esecuzione, possiamo definire la dimen
         * sione del vettore a durante l'esecuzione del programma ad esempio chie
         * dendo all'utente il numero di elementi del vettore
         */
        int M = 0;
        printf("Quanti elementi per il vettore?\n");
        scanf("%d", &M);
        /* malloc alloca n byte contigui in memoria e ritorna l'indirizzo del primo
         * byte relativo allo spazio allocato.Nota come la variabile dinamico e' un
         * puntaore ma nel ciclo posso usare l'indicizzazione come fosse un vettore
         */
        int *dinamico = (int *) malloc(M * sizeof(int));
        /* dinamico e' un puntatore*/
        for(int j=0; j<M; j++)
                dinamico[j] = j;

        int k;
        printf("statico : ");
        for(k=0; k<N; k++)
                printf("%d ", statico[k]);
        printf("\n");

        printf("dinamico: ");
        for(k=0; k<M; k++)
                printf("%d ", dinamico[k]);
        printf("\n");
        /* dealloco la memoria con free() */
        free(dinamico);
        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/10_dynamic_memory$ bin/0_malloc
Quanti elementi per il vettore?
15
statico : 0 1 2 3 4 5 6 7 8 9
dinamico: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
```

### Array bidimensionali

Gli array sono memorizzati in modo contiguo (linearmente) in memoria ma spesso è utile pensare a vettori a due dimensioni (detti anche matrici) in cui un elmento del vettore a due dimensioni è indentificato da due indici: **indice di riga** e **indice di colonna**.
La dichiarazione di una matrice prevede quindi due cardinalità per il numero delle righe e per il numero delle colonne.

```c
nome-tipo identificatore [ cardinalita-riga] [cardinalita-colonna]
```

Per esempio per allocare spazio per una matrice con 6 righe e 7 colonne dovremmo fare:

```c
int mat[6][7];
```

![](https://github.com/kinderp/2cornot2c/blob/main/images/matrici.png)

Come puoi vedere nella figura di sopra anche se da un punto di vista di indicizzazione `mat` ha due indici quindi è bidimensionale in memoria lo spazio allocato è lineare e continguo (la RAM ha una struttura monodimensionale): viene allocato spazio contiguo per 42 interi.
Rimane la relazione tra array e puntatori, il nome della matrice è un puntatore doppio (punta ad un puntatore) cioè se faccio la deferenziazione `*mat` non ottengo il valore del primo elemento del vettore contingue di 42 elementi ma l'indirizzo del primo elemento del vettore contiguo in RAM; usando l'aritmetica dei puntatori a partire da questo indirizzo mi sposto tra i vari elementi.
Per esempio data una matrice di `N_RIGHE=6` e `N_COLONNE=7`: `mat[6][7]` sia `i` l'indice di riga e `j` l'indice colonna, per accedere al 21° elemento (ultimo elemento della terza riga) quindi `i=2` (gli indici partono sempre da zero, i=0 prima riga, i=2 terza riga) `j=6` (settima ed ultima colonna) possiamo usare: 

* l'accesso ad indice degli array
  ```c
	mat[i][j]
  ```
* l'artimetica dei puntaori
  ```c
  	/*
  	 * mat è un puntatore doppio: contiene l'indirizzo di una variabile puntatore che continene
  	 * a suo volta l'indirizzo del primo elemento del vettore contiguo di 42 elementi.
  	 * 1. deferenziazione sul doppio puntatore mat:
  	 *           *mat 
  	 * ottengo l'indirizzo del primo elemento del vettore
  	 * 2. mi sposto con aritmetica puntatori all'indirizzo del 21 elemento con la formula
  	 *           *mat + ( (i*N_COLONNE) + j) )
  	 * 3. deferenziazione del puntatore che punta al 21 elemento
  	 *           *(*mat + ( (i*N_COLONNE) + j) ) )
  	 * e finalmente ottengo il valore del 21 elemento
  	 */
  ```

```c
#include<stdio.h>

#define N_RIGHE 6
#define N_COLONNE 7

int main(void){
        int mat[N_RIGHE][N_COLONNE];

        int i; // indice riga
        int j; // indice colonna
        for(i=0; i<N_RIGHE; i++)
                for(j=0; j<N_COLONNE; j++)
                        mat[i][j] = (i*N_COLONNE) + j;

        for(i=0; i<N_RIGHE; i++){
                for(j=0; j<N_COLONNE; j++)
                        printf("%2d ", mat[i][j]);
                printf("\n");
        }

        printf("\n");
        /* Gli elementi della matrice sono  contigui in memoria e
         * posso accedervi senza la notazione  ad indici del vett
         * ore ma usando l' artimetica dei  puntatori, se i e' l'
         * indice di riga  e j l' indice  colonna per accedere al
         * k-esimo elemento contigue in  memoria  basta  usare la
         * formula k = (i*N_COLONNE) + j
         * Per accedere ad esempio all' ultimo  elemento della 3°
         * riga: k = 20, i=2 (3° riga), j=6 (7° colonna) (ricorda
         * che gli indici partono da 0) k=2*7+6=20
         */
        for(i=0; i<N_RIGHE; i++)
                for(j=0; j<N_COLONNE; j++)
                        printf("%d ", *(*mat + ( (i*N_COLONNE) + j) ) );
        printf("\n");
        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/7_array$ bin/7_array
 0  1  2  3  4  5  6
 7  8  9 10 11 12 13
14 15 16 17 18 19 20
21 22 23 24 25 26 27
28 29 30 31 32 33 34
35 36 37 38 39 40 41

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41
```



### Array di puntatori

I puntatori sono variabili come tutte le altre e quindi è possibile dichiare un vettore di puntatori. 

```c
#include<stdio.h>

int main(void){
        char *mesi_anno[12] = {"Gennaio", "Febbraio", "Marzo", "Aprile", "Maggio", "Giugno", "Luglio",
                              "Agosto", "Settembre", "Ottobre", "Novembre", "Dicembre"};

        int mese;
        printf("Inserisci un numero da 1 a 12\n");
        scanf("%d", &mese);

        printf("%d -> %s\n", mese, mesi_anno[mese-1]);
        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/6_pointers$ bin/9_pointers
Inserisci un numero da 1 a 12
10
10 -> Ottobre
```

### Differenza tra array bidimensionali ed array di puntatori

Benchè simili i vettori bidimensionali (matrici) e gli array di puntatori sono diversi.
Riprendendo l'esempio dei mesi dell'anno le due variabili: `array_di_puntatori` e `matrice` svolono lo stesso identico ruolo: contenere la lista ordinata dei mesi dell'anno

```c
#include<stdio.h>

int main(void){
        char *array_di_puntatori[12] = {"Gennaio", "Febbraio", "Marzo", "Aprile", "Maggio", "Giugno", "Luglio",
                                        "Agosto", "Settembre", "Ottobre", "Novembre", "Dicembre"};

        char matrice[12][10] =  {"Gennaio", "Febbraio", "Marzo", "Aprile", "Maggio", "Giugno", "Luglio",
                                 "Agosto", "Settembre", "Ottobre", "Novembre", "Dicembre"};

        int mese;
        printf("Inserisci un numero da 1 a 12\n");
        scanf("%d", &mese);

        printf("%d -> %s\n", mese, array_di_puntatori[mese-1]);
        printf("%d -> %s\n", mese, matrice[mese-1]);
        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/6_pointers$ bin/10_pointers
Inserisci un numero da 1 a 12
6
6 -> Giugno
6 -> Giugno
```

e l'accesso indicizzato `array_di_puntatori[5][0]` o `matrici[5][0]` è equivalente e permette di leggere la lettera `G` (il primo carattere del mese di giugno, primo elemento dell'array in sesta posizione).
Da un punto di vista di allocazione di memoria ci sono delle sottili differenze.
Nel caso di vettore bidimensionale abbiamo allocato una quantità di memoria fissa pari a 12*10=120 byte (12 ovviamente sono i mesi, il 10 è dato dalla lunghezza della stringa più lunga: Settembre che misura 9 caratteri più il carattere di fine stringa `\0`) quindi abbiamo 12 righe tutte con una lunghezza di 10 colonne. C'è un certo spreco di memoria perchè non tutti i mesi sono lunghi 9 caratteri ed i byte resteranno non utlizzati.
Nel caso di vettori di puntaori invece abbiamo una quantità di memoria allocata pari a 12 puntatori a carattere quindi 12*8=96 byte, un puntatore doppio che punta al primo elemento del vettore di puntatori quindi 8 byte e più la memoria allocata per ogni singola stringa rappresentante i mesi dell'anno. Questa volta però le stringhe occupano lo spazio strettamente necessario a contenere i loro caratteri senza spreco di spazio e qualche elemento del vettore di puntatori potrebbe anche non contenere alcun indirizzo quindi non puntatore a nulla se fosse necessario.
La differenza sostanziale però tra i due metodi è che nel caso delle matrici gli elementi sono allocati in modo contiguo in memoria mentre in un array di puntatori solo le variabili di tipo puntatorw sono contigue in memoria mentre le variabili puntate sono sparse in memoria; questo secondo approccio si traduce in un grosso vantaggio quando si devono svolgere operazioni di ordinamento e/o spostamento tra i vari elementi se questi ultimo occupano grandi quanità di memoria.
Il vantaggio di un array di puntaori non è tanto il risparmio di memoria nella rappresentazione degli elmenti ma piuttosto il fatto che ordinamenti e spostamenti degli elementi del vettore sono molto più facili e veloci da fare perchè lo scambio di posizione tra due elementi del vettore si traduce nello scrivere dei nuovi indirizzi nelle variabili puntatori mentre nel caso delle matrice dobbiamo spostare tutti gli elementi compresi tra i due elementi interessati.

Nulla vieta di provare ad allocare un array bidimensionale dinamicamente con la funzione `malloc()` anche in questo caso avremmo la possibilità di scegliere esattamente la dimensoine dei byte da allocare per ogni singolo elemento come nel caso degli array di vettori, ma non è questo il caso d'uso dell'allocazione dinamica. Vediamo un esempio:

```c
#include<stdio.h>  // printf()
#include<stdlib.h> // malloc(), free()
#include<string.h> // strcpy()

int main(void){
        char *array_di_puntatori[12] = {"Gennaio", "Febbraio", "Marzo", "Aprile", "Maggio", "Giugno", "Luglio",
                                        "Agosto", "Settembre", "Ottobre", "Novembre", "Dicembre"};

        char matrice[12][10] =  {"Gennaio", "Febbraio", "Marzo", "Aprile", "Maggio", "Giugno", "Luglio",
                                 "Agosto", "Settembre", "Ottobre", "Novembre", "Dicembre"};

        /* array di puntatore a char allocato dinamicamente */
        char **matrice_dinamica = (char **) malloc(12*sizeof(char*)); // alloca spazio contiguo per 12 puntatori a char
        for(int k=0; k<12; k++)
                matrice_dinamica[k] = (char *)malloc(10*sizeof(char));   // alloca spazio contiguoper 10 caretteri

        /* Ho allocato spazio per 10 caratteri per tutti i mesi e sto sprecando spazio ma nulla mi impedisce di allocare
         * il numero di caratteri strettamente necessario per ogni singolo mese, non avevo voglia di perdere tempo ma e'
         * una cosa fattibile ovviamente ed avremmo avuto lo stesso risultato degli array di puntatori solo che l'alloca
         * zione in questo caso è dinamica cioe' e' avvenuto a tempo di esecuzione e non statico cioe' a tempo di compil
         * azione. Usa l'allocazione dinamica solo quando la dimensine del vettore o della matrice non e' nota se non du
         * rante l'esecuzione; in questo caso e' inutile usare l'allocazione dinamica perche' sia la dimensione delle ri
         * ghe che delle colonne e' nota prima dell'esecuzione.
         */

        /* Questo metodo per inizializzare i vettori di caratteri non va bene se
         * e' prevista la deallocazione con free() in quanto gli string literals
         * sono allocati nel DATA segment che e' a sola lettura quindi non potra
         * nno e non dovranno mai essere deallocate, provare a fare una free() su
         * queste variabili e' inutile (non stanno nello stack) e porta ad un seg
         * mentation fault in quanto free() provera' ad scrivere in memoria a so
         * la lettura
         */

        /* decommanta le righe di sotto e commaenta le righe con strcpy() per pro
         * vare l'errore di segmentation fault spiegato sopra
         */

        /*
        matrice_dinamica[0]  = "Gennaio";
        matrice_dinamica[1]  = "Febbraio";
        matrice_dinamica[2]  = "Marzo";
        matrice_dinamica[3]  = "Aprile";
        matrice_dinamica[4]  = "Maggio";
        matrice_dinamica[5]  = "Giugno";
        matrice_dinamica[6]  = "Luglio";
        matrice_dinamica[7]  = "Agosto";
        matrice_dinamica[8]  = "Settembre";
        matrice_dinamica[9]  = "Ottobre";
        matrice_dinamica[10] = "Novembre";
        matrice_dinamica[11] = "Dicembre";
        */

        strcpy(matrice_dinamica[0] , "Gennaio");
        strcpy(matrice_dinamica[1] , "Febbraio");
        strcpy(matrice_dinamica[2] , "Marzo");
        strcpy(matrice_dinamica[3] , "Aprile");
        strcpy(matrice_dinamica[4] , "Maggio");
        strcpy(matrice_dinamica[5] , "Giugno");
        strcpy(matrice_dinamica[6] , "Luglio");
        strcpy(matrice_dinamica[7] , "Agosto");
        strcpy(matrice_dinamica[8] , "Settembre");
        strcpy(matrice_dinamica[9] , "Ottobre");
        strcpy(matrice_dinamica[10], "Novembre");
        strcpy(matrice_dinamica[11], "Dicembre");

        int mese;
        printf("Inserisci un numero da 1 a 12\n");
        scanf("%d", &mese);

        printf("%d -> %s\n", mese, array_di_puntatori[mese-1]);
        printf("%d -> %s\n", mese, matrice[mese-1]);
        printf("%d -> %s\n", mese, matrice_dinamica[mese-1]);

        /* con l'allocazione dinamica e' compito del programmatore deallocare la memoria quando non serve piu'*/

        /* prima dealloco i 12 array di caratteri di lunghezza 10 contenenti i mesi */
        for(int k=0; k<12; k++)
                free(matrice_dinamica[k]);
        /* infine dealloco i 12 puntatori a caratteri che puntavano ai 12 vettori di caratteri prima deallocati */
        free(matrice_dinamica);
        return 0;
}
```

```bash
vagrant@ubuntu2204:/lab/6_pointers$ bin/11_pointers
Inserisci un numero da 1 a 12
6
6 -> Giugno
6 -> Giugno
6 -> Giugno
```

### Sezioni di memoria di un programma C

Quando un programma viene caricato in memoria per la sua esecuzione, al programma vengono assegnate delle porzioni di memoria dette **sezioni** o **segmenti**, ciscuna delle quali è deputata ad una funzione specifica. La memoria di un programma C consiste nelle seguenti sezioni:

* **text segment** (anche detto **code segment**)
* **data segment** (che si divide in tre zone: data, BSS e heap)
* **stack segment**

Il **text segment** (o anche **code segment**) è la parte della memoria che contiene le **istruzioni eseguibili** del programma. Per questioni di sicurezza (accidentali o malefiche modifiche del codice del programma), questa zona di memoria è in **sola lettura** (read-only)
Il **data segment** è la parte di memoria che contiene: **variabili globali**, **variabili statiche**. Esso si divide in tre zone: **data**, **BSS** e **heap**
* Il segmento **data** contiene
  * le variabili inizializzate dal programmatore nella dichiarazione (es: `static int i = 10`)
* Il segmento **BSS** (*Block Started by Symbol) contiene
  * le variabili non inizializzate dal programmatore (es: `int vet[100]`), queste variabili vengono inizializzate dal sistema oprativo al valore 0 prima dell'esecuzione del programma
* Il segmento **heap** è destinato ad ospitare la memoria allocata dinamicamente tramite funzioni come `malloc()`. Quando il programmatore allora o dealloca memoria dinamicamente la dimensione di questo segmento cresce o diminuisce. Questo segmento inizia dopo il **BSS** e cresce verso l'alto occupando indirizzi crescenti
* Il segmento **stack** gestisce la chiamata a funzione ed ospita le variabili automatiche della funzione chiamata (variabil locali, classe memorizzazione `auto`) i parametri passati in ingresso alla funzione, l'indirizzo di ritorno al chiamante da cui riprendere l'esecuzine al termine dell'esecuzione della funzione ed il contenuto di alcuni registri della CPU. Lo stack cresce verso il basso dagli indirizzi più alti verso indirizzi più bassi e confina con il segmento **heap**

Lo **stack** è un'area di memoria contigua all'heap e cresce in direzione opposta a quest'utlimo, quando il puntatore allo stack incontra il puntatore all'heap, lo spazio di memoria libera per il programma è esautito.

![](https://github.com/kinderp/2cornot2c/blob/main/images/memoria_programma_c.png)

### L'inizializzazioni delle variabili

**In assenza di inizializzazioni esplicite**, l'inizializzazione di una variabile segue alcune regole che dipendono dalla classe di memorizzazione alla quale la variabile appartiene. In particolare:

* le **variabili globali** vengono **inizializzate a zero** (si trovano nel **BSS**, se fossero state inizializzate esplictiamente sarebbero state nella sezione **data** del **data segment**)
* le **variabili statiche** vengono **inizializzate a zero** (si trovano nel **BSS**, se fossero state inizializzate esplictiamente sarebbero state nella sezione **data** del **data segment**)
* le **variabili statiche e globali** possono essere **inizializzate solo tramite espresioni costanti** (quindi non con valori di altre variabili non statiche o globali o valori restituiti da funzioni)
* le **variabili locali** possono essere inizializzate anche con valori di altre variabili o restituiti da funzione e se non inizializzate esplicitamente **non vengono poste a zero ma contengono un valore casuale e non prevedibile** a priori.

### Allocazione dinamica di matrici


![](https://github.com/kinderp/2cornot2c/blob/main/images/pianeti_matrice.png)

```c
#include<stdio.h>  // printf()
#include<stdlib.h> // malloc(), free()
#include<string.h> // strcpy()

#define N_ROWS 9
#define N_COLS 8

char **alloc_planets_mat_dyn(int n_rows, int n_cols);
void initialize_planets_mat_dyn(char **matrix);
void print_all_chars(char **array_of_pointers, char static_matrix[][N_COLS], char **dynamic_matrix);
void print_just_strings(char **array_of_pointers, char static_matrix[][N_COLS], char **dynamic_matrix);
void dealloc_planets_mat_dyn(char **matrix, int n_rows);

int main(void){
        char *planets[] = {"Mercury", "Venus", "Earth", "Mars", "Jupiter", "Saturn", "Uranus", "Neptune", "Pluto"};
        char planets_mat[N_ROWS][N_COLS] = {"Mercury", "Venus", "Earth", "Mars", "Jupiter", "Saturn", "Uranus", "Neptune", "Pluto"};
        char **planets_mat_dyn = alloc_planets_mat_dyn(N_ROWS, N_COLS);
        initialize_planets_mat_dyn(planets_mat_dyn);

        print_all_chars(planets, planets_mat, planets_mat_dyn);

        printf("\n\n");
        print_just_strings(planets, planets_mat, planets_mat_dyn);

        dealloc_planets_mat_dyn(planets_mat_dyn, N_ROWS);
        return 0;
}

char **alloc_planets_mat_dyn(int n_rows, int n_cols){
        char **matrix = (char **)malloc(n_rows*sizeof(char *)); /* alloco un vettore di puntatori a char (le righe) */
        for(int i=0; i<n_rows; i++)
                matrix[i] = (char *)malloc(n_cols*sizeof(char)); /* alloco un vettore di caratteri (le collonne di una riga) */
        return matrix;
}


void dealloc_planets_mat_dyn(char **matrix, int n_rows){
        /* prima dealloco le righe */
        for(int i=0; i<n_rows; i++)
                free(matrix[i]);
        /* poi il vettore di puntatori a char */
        free(matrix);
}
void initialize_planets_mat_dyn(char **matrix){

        /*
        matrix[0] = "Mercury";
        matrix[1] = "Venus";
        matrix[2] = "Earth";
        matrix[3] = "Mars";
        matrix[4] = "Jupiter";
        matrix[5] = "Saturn";
        matrix[6] = "Uranus";
        matrix[7] = "Neptune";
        matrix[8] = "Pluto";
        */

        strcpy(matrix[0], "Mercury");
        strcpy(matrix[1], "Venus");
        strcpy(matrix[2], "Earth");
        strcpy(matrix[3], "Mars");
        strcpy(matrix[4], "Jupiter");
        strcpy(matrix[5], "Saturn");
        strcpy(matrix[6], "Uranus");
        strcpy(matrix[7], "Neptune");
        strcpy(matrix[8],"Pluto");

}

void print_all_chars(char **array_of_pointers, char static_matrix[][N_COLS], char **dynamic_matrix){
        for(int i=0; i<N_ROWS; i++){
                for(int j=0; j<N_COLS; j++){
                        printf("%c ", array_of_pointers[i][j]);
                        if(array_of_pointers[i][j] == '\0') break;
                }
                printf("\n");
        }

        printf("\n");


        for(int i=0; i<N_ROWS; i++){
                for(int j=0; j<N_COLS; j++){
                        printf("%c ", static_matrix[i][j]);
                        if(static_matrix[i][j] == '\0') break;
                }
                printf("\n");
        }

        printf("\n");


        for(int i=0; i<N_ROWS; i++){
                for(int j=0; j<N_COLS; j++){
                        printf("%c ", dynamic_matrix[i][j]);
                        if(dynamic_matrix[i][j] == '\0') break;
                }
                printf("\n");
        }

        printf("\n");
}


void print_just_strings(char **array_of_pointers, char static_matrix[][N_COLS], char **dynamic_matrix){
        for(int i=0; i<N_ROWS; i++)
                printf("%s\n", array_of_pointers[i]);

        printf("\n");


        for(int i=0; i<N_ROWS; i++)
                printf("%s\n", static_matrix[i]);

        printf("\n");

        for(int i=0; i<N_ROWS; i++)
                printf("%s\n", dynamic_matrix[i]);

        printf("\n");

}
```

```bash
vagrant@ubuntu2204:/lab/6_pointers$ bin/12_pointers
M e r c u r y
V e n u s
E a r t h
M a r s
J u p i t e r
S a t u r n
U r a n u s
N e p t u n e
P l u t o

M e r c u r y
V e n u s
E a r t h
M a r s
J u p i t e r
S a t u r n
U r a n u s
N e p t u n e
P l u t o

M e r c u r y
V e n u s
E a r t h
M a r s
J u p i t e r
S a t u r n
U r a n u s
N e p t u n e
P l u t o



Mercury
Venus
Earth
Mars
Jupiter
Saturn
Uranus
Neptune
Pluto

Mercury
Venus
Earth
Mars
Jupiter
Saturn
Uranus
Neptune
Pluto

Mercury
Venus
Earth
Mars
Jupiter
Saturn
Uranus
Neptune
Pluto
```

### Le strutrure

Una struttura o **struct** è un tipo di dato derivato che permette di raggruppare un insieme di elementi di tipo diverso con una qualche forte correlazione tra loro, detti **campi** della struttura, in un'area contigua in memoria.  
I campi della struttura possono essere semplici (predefiniti dal linguaggio) o derivari (anche altre sterutture stesse) e come detto possono essere di tipo diverso tra loro (al contrario degli array).
La sintassi per dichiarare una struttura è la seguente:

```c
struct nome-struttura {
	tipo-campo1 nome-campo1;
	[tipo-campo2 nome-campo2;]
	[...]
} ;
```

Per esempio per dichiarare un tipo che rappresenti un punto nello spazio bidimensionale:

```c
/* dichiaro il nuovo tipo che si chiama: struct punto_2d */
struct punto_2d {
	int x;
	int y;
};
```

Una volta che il nuovo tipo è stata dichiarato è possibile dichiarare variabili o puntatori del nuovo tipo, in questo modo:

```c
/* dichiaro una variabile ed un puntatore del tipo struct punto_2d
 * fai attenzione che il nuovo tipo è "struct punto_2s" e non sola
 * mente "punto_2d", non ti scordare "struct" nel nome del tipo.
 */
struct punto_2d i;
struct punto_2d *ptr
```

Per accedere ai singoli campi di una struttura attraverso una variabile basta usare il `.` in questo modo: `nome_variabile.nome_campo`, se si accede ai campi attraverso un puntatore si usa `->` in questo modo `nome_variabile_puntatore->nome_campo`. Per esempio:

```c
#include<stdio.h>

/* dichiaro il nuovo tipo che si chiama: struct punto_2d */
struct punto_2d {
        int x;
        int y;
};

int main(void){
        /* dichiaro una variabile ed un puntatore del tipo struct punto_2d
         * fai attenzione che il nuovo tipo è "struct punto_2s" e non sola
         * mente "punto_2d", non ti scordare "struct" nel nome del tipo.
         */
        struct punto_2d i;
        struct punto_2d *ptr = NULL; /* alloco spazio per il puntatore */

        /* il puntaore deve essere inizializzato all'indirizzo della struttura
         * altrimenti non punta ad una locazione di memoria valida per noi
         */
        ptr = &i;
        /* inizializzo la struttura accedendo ai campi con la notazione puntata
          * attraverso una variabile di tipo "struct punto_2d"
          */
        i.x = 0;
        i.y = 0;
        printf("(%d, %d)\n", i.x, i.y);

        /* accedo ai campi della struttura attraverso il puntatore usando -> */
        ptr->x = 1;
        ptr->y = 1;
        printf("(%d, %d)\n", ptr->x, ptr->y);

        return 0;
}
```

#### Passaggio di strutture a funzioni

Una variabile di un tipo struct può essere passata normalmenete ad una funzione; come abbiamo studiato il passaggio dei parametri in C avviene sempre per valore e questo può essere un problema in termini di prestazioni e spreco di risorse se la struct ha numerosi campi. Per questo motivo le stuct sono quasi sempre passata per riferimento, cioè passando in ingresso alla funzione un puntatore a struttura. Vediamo quindi esclusivamente il caso di passaggio per riferimento.

```c
#include<stdio.h>
#include<string.h>

struct studente {
        char *nome;
        char *cognome;
        char *matricola;
        int *voti;
        int eta;
        float media;
};

void calcola_media(struct studente *i);

int main(void){
        struct studente ottimo;
        struct studente medio;
        struct studente scarso;

        ottimo.nome = "Mario";
        ottimo.cognome = "Rossi";
        ottimo.matricola ="1234qwert";
        ottimo.eta = 21;
        ottimo.media = 0;
        int tmp1[10] = {28, 30, 30, 30, 29,27,28, 30, 30, 30};
        ottimo.voti = tmp1;

        medio.nome = "Andrea";
        medio.cognome = "Verdi";
        medio.matricola ="9876zxcvb";
        medio.eta = 24;
        medio.media = 0;
        int tmp2[10] = {26, 27, 24, 25, 26, 27, 23, 25, 24, 25};
        medio.voti = tmp2;

        scarso.nome = "Luigi";
        scarso.cognome = "Bianchi";
        scarso.matricola ="5678lkjhg";
        scarso.eta = 31;
        scarso.media = 0;
        int tmp3[10] = {18, 20, 23, 18, 19, 22, 18, 20, 20, 19};
        scarso.voti = tmp3;

        calcola_media(&ottimo);
        calcola_media(&medio);
        calcola_media(&scarso);

        printf("%s %s di eta' %d ha una media di %f\n", ottimo.nome, ottimo.cognome, ottimo.eta, ottimo.media);
        printf("%s %s di eta' %d ha una media di %f\n", medio.nome, medio.cognome, medio.eta, medio.media);
        printf("%s %s di eta' %d ha una media di %f\n", scarso.nome, scarso.cognome, scarso.eta, scarso.media);

        return 0;
}

void calcola_media(struct studente *i){
        float media = 0.0;
        for(int j=0; j<10; j++)
                i->media += i->voti[j];
        i->media = i->media / 10;te
}
```

```bash
vagrant@ubuntu2204:/lab/11_structs$ bin/1_structs
Mario Rossi di eta' 21 ha una media di 29.200001
Andrea Verdi di eta' 24 ha una media di 25.200001
Luigi Bianchi di eta' 31 ha una media di 19.700001
```

## Sistema Operativo

### I modelli di memoria

<p align=justify>
Uno dei concetti più complessi dei sistemi e della programmazione a basso livello (in linguaggio assembly del processore) è l'indirizzamento della memoria, ovvero come la CPU indirizza la memoria cioè in che modo questa permette l'accesso alle celle di memoria; questo è molto importante perchè influenza il modo con cui il programmatore vede la RAM. Anche se la RAM fisicamente è una sequenza ordinata di celle di 8 byte, l'indirizzamento della CPU può influenzare come il programmatore vede ed usa questa sequenza di byte. In questa sede faremo riferimento all'architettura: <code>x86</code> dei processori intel/amd. L'indirizzamento della memoria da parte del processore è argomento complesso in quanto, nella nostra architettura di riferimento, esistono diversi modi con cui i processori <code>x86</code> indirizzano la memoria. Nello specifico esistono quattro <b>modelli di memoria</code> che gli attuali processori della famiglia <code>x86</code> supportano:
</b>

1. **real mode flat model** (modello piatto in modalità reale)
2. **real mode segmented model** (modello segmentato in modalità reale)
3. **32-bit protected mode flat model** (modello piatto in modalità protetta)
4. **64-bit long mode flat model** (modello piatto in modalità lunga)

<p align=justify>
Nella programmazione per Linux moderno a 64 bit, sei praticamente limitato a un solo modello di memoria (modello piatto in modalità protetta), e una volta che comprenderai meglio l'indirizzamento della memoria, ne sarai molto contento.
I primi due modelli sono ormai un retaggio del passato, per intenderci il modello segmentato era usato dal <a href="https://it.wikipedia.org/wiki/DOS">DOS</a>, mentre il modello flat in real mode era usato dal <a href="https://it.wikipedia.org/wiki/CP/M">CP/M-80</a>. A partire da windows 95 e successivi (Windows 2000/XP/Vista/7/10/11) il modello di memoria utilizzato è il flat in protected mode. Attenzione che il protected mode flat model è disponibile solo a partire dal processore 80386; i processori precedenti: 8086, 8088 e 80286 non supportano questo modello. Possiamo considerare il protected model flat model come una versione più ampia del real mode flat model, il real mode segmented model è una bestia infernale che è stata introdotta da intel per questioni più di business che tecnologiche.
</p>

<p align=justify>
Il predecessore di tutti questi processori citati (8086, 8088, 80286 e 80386) l' 8080 supportava solo il primo modello: real mode flat model. Siamo circa alla metà degli anni settanta e le potenze di calcolo e di storage erano assai inferiori a quelle a cui siamo abituati oggi. L' 8080 era un processore ad 8 bit e quindi manipolava 8 bit d'informazione alla volta ma la dimensione dei registri interni alla CPU e del bus indirizzi era di 16 bit. Un bus indirizzi di 16 bit si traduce in una quantità totale di byte di memoria indirizzabili pari a $2^{16} = 65536 = 64KB$ che era un valore notevole considerando che le memorie in quegli anni erano di circa 4K-8K.
</p>

<p align=justify>
Lo schema d'indirizzamento dell' 8080 era molto semplice: il processore inseriva l'indirizzo di memoria sul bus indirizzo e dopo un certo tempo riceveva, sul bus dati, gli 8 bit presenti nella cella indirizzata dai 16 bit precedenti (indirizzo di memoria della cella).
</p>

<p align=justify>
Il sistema operativo più utilizzato con l'8080 era il CP/M-80. Questo sistema operativo risiedeva nella zona alta della memoria installata in modo da lasciare spazio e avere un punto di partenza coerente per i programmi transitori, cioè quelli che a differenza del sistema operativo venivano caricati in memoria ed eseguiti solo quando necessario. Quando il CP/M-80 leggeva un programma dal disco per eseguirlo, lo caricava in memoria bassa all'indirizzo $0100H$, cioè 256 byte dopo la cella più bassa di memoria.
Ti ricordo che ogni cifra esadecimale rappresenta 4 bit, infatti per rappresentare sedici cifre (0,1,2,3,4,5,6,7,8,9,A,B,C,D,E,F) ho bisogno di 4 bit: $2^4=16$ quindi il numero esadecimale $#0100 in binario diventa $0000-0001-0000-0000$ il cui valore decimale è $2^8=256$.
I primi 256 byte di memoria erano chiamati <i>program segment prefix</i> (PSP) ed erano usati per i buffer di I/O dei programmi. Il codice eseguibile del programma caricato in memoria iniziava solamente dopo l'indirizzo <code>0100H</code>
</p>


<table>
	<td>:memo: <b>Note</b>
	<p align=justify>
I microcomputer primordiali come i sistemi 8080 che eseguivano CP/M-80 avevano un'architettura della memoria semplice. I programmi venivano scritti per essere caricati e eseguiti a un indirizzo di memoria fisico specifico. Per CP/M, questo era 0100H. Il programmatore poteva assumere che qualsiasi programma iniziasse a 0100H e procedesse da lì. Gli indirizzi di memoria degli elementi di dati e delle procedure erano indirizzi fisici reali e ogni volta che il programma veniva eseguito, i suoi elementi di dati venivano caricati e riferiti esattamente nello stesso posto in memoria.
Tutto ciò è cambiato con l'arrivo dell'8086 e dei sistemi operativi specifici per l'8086 come CP/M-86 e PC DOS. I miglioramenti nell'architettura Intel introdotti con l'8086 hanno reso superflua l'assemblaggio del programma per essere eseguito a un indirizzo di memoria fisico specifico. Questa caratteristica è chiamata <b>relocatabilità</b> ed è una parte necessaria di qualsiasi sistema operativo moderno, specialmente quando più programmi possono essere in esecuzione contemporaneamente. Gestire la relocatabilità è complesso, una volta che ti sentirai più a tuo agio con il linguaggio assembly, diventerà un argomento degno di ulteriori ricerche.
	</p>
	</td>
</table>

<p align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/cpm-memory.png">
</p>

<p align=justify>
Il modello di memoria dell'8080, utilizzato con CP/M-80, era semplice; così quando Intel creò la sua prima CPU a 16 bit: l'8086, tentò di rendere facile per le persone tradurre il vecchio software CP/M-80 dall'8080 all'8086. Un modo per farlo era assicurarsi che un sistema di indirizzamento a 16 bit come quello dell'8080 funzionasse ancora sull'8086.
Il processore 8086 però aveva un bus indirizzi di 20 bit, mentre i registri interni ed il bus dati era di 16. Con 20 bit era possibile indirizzare $2^{20}=1MB$ di memoria che è una quantità sedici volte superiore rispeto ai 64K del precedessore 8080 ($16 x 64K = 1MB $). Intel quindi, anche se l'8086 poteva potenzialmente indirizzare una quantità di memoria sedici volte superiore rispeto all'8080, per rendere semplice il porting dei programmi precedentemente scritti per CP/M-80 su 8080, impostò il nuovo 8086 in modo che un programma potesse utilizzare un unico blocco di 64K (detto segmento) all'interno del 1MB massimo indirizzabile. Il programma quindi veniva eseguito interamente all'interno dei 64KB, cioè all'interno del proprio segmento, come se si trovasse di fatto all'interno della memoria massima indirizzabile del vecchio 8080.
Per ottenere questo funzionamento si fece uso dei registri di segmento che sono semplicemente registri della CPU che contegono gli indirizzi di memoria dove il segmento inizia. In altre parole, i registri di segmento sono dei semplici puntatori alla memoria che indicano dove, all'interno del megabyte di memoria dell'8086, inizierebbe un programma portato dal mondo dell'8080.
</p>

<p align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/8080model_inside8086.png">
</p>

<p align=justify>
Quando si parla dell'8086 e dell'8088, ci sono quattro registri di segmento da considerare. Nella figura di sopra, considera il registro chiamato CS (che sta per <b>code segment</b>) ancora una volta come un puntatore a una posizione all'interno del megabyte di memoria dell'8086. Questa posizione funge da punto di partenza per una regione di memoria di 64K, all'interno della quale un programma CP/M-80 rapidamente convertito potrebbe funzionare molto felicemente. Questo è stato un pensiero a breve termine molto saggio ma allo stesso tempo un pensiero a lungo termine catastroficamente sbagliato. Un elevato numero di programmi CP/M-80 è stato convertito per l'8086 nel giro di un paio d'anni. I problemi sono iniziati quando i programmatori hanno tentato di creare nuovi programmi da zero che non avevano mai visto l'8080 e non avevano bisogno del modello di memoria segmentato. Purtroppo il modello segmentato ha dominato l'architettura dell'8086. I programmi che necessitavano di più di 64K di memoria alla volta dovevano usare la memoria in blocchi da 64K, passando da un blocco all'altro cambiando valori dentro e fuori dai registri di segmento. Questo era un vero incubo. Tuttavia, c'è un buon motivo per impararlo: comprendere il modo in cui funziona l'indirizzamento della memoria segmentata in modalità reale ti aiuterà a comprendere come funzionano i due modelli piatti x86 e, nel processo, arriverai a capire molto meglio la natura della CPU.
</p>

<p align=justify>
Quando si opera in modalità reale segmentata, le CPU x86 possono utilizzare fino a un megabyte di memoria indirizzabile direttamente. Questa memoria è chiamata anche memoria in modalità reale (real mode memory).
Le CPU moderne possono gestire una quantità di memoria enormemente superiore a questa (1MB). Con le CPU originali 8086 e 8088, le 20 linee di indirizzo e 1 megabyte di memoria erano letteralmente tutto ciò che avevano. Le CPU Intel a 32 bit 386 e successive potevano indirizzare 4 gigabyte di memoria senza doverla suddividere in segmenti più piccoli. Quando una CPU a 32 bit opera in modalità protetta modello piatto, un segmento è di 4 gigabyte, quindi un segmento è, per la maggior parte, più che sufficiente, e si possono avere di più se nel sistema sono installati 8, 16 o 64 GB di memoria. Con la modalità lunga x64, beh, il tuo segmento può essere lungo quanto vuoi. Quanto a lungo può essere potrebbe sorprenderti. Tuttavia, c'era un'enorme quantità di software DOS scritto per sfruttare i segmenti ovunque e doveva essere gestito. Così, per mantenere la compatibilità con i vecchi 8086 e 8088, le CPU più recenti hanno ricevuto il potere di limitarsi a ciò che i chip più vecchi potevano indirizzare ed eseguire. Quando una CPU della classe Pentium o migliore deve eseguire software scritto per il modello a segmenti in modalità reale, utilizza un'astuzia che, temporaneamente, la fa diventare un 8086. Questo veniva chiamato modalità virtual-86 (virtual-86 mode), e forniva un'ottima retrocompatibilità attiva per il software DOS. Quando avvii una finestra MS-DOS o una "scatola DOS" sotto Windows NT e versioni successive di Windows, stai usando la modalità virtual-86 per creare ciò che equivale a una piccola isola in modalità reale all'interno del sistema di memoria in modalità protetta di Windows. Era l'unico modo valido per mantenere quella compatibilità retro attiva, per motivi che capirai abbastanza presto.
</p>


<p align=justify>
Nel modello segmentato in modalità reale, una CPU x86 può 'vedere' un intero megabyte di memoria. Tutto qui. Quando un processore lavora col modello segmentato in modalità reale si imposta da solo per usare 20 dei 32 o 64 pin d'indirizzo e quindi, sul bus indirizzi, possono passare solamente indirizzi lunghi 20 bit. Il problema con questo modello è che in questo modo anche se le CPU potrebbero vedere l'intero megabyte di memoria sono costrette a vedere il megabyte attraverso la limitazone dei 64K (data dai 16 bit del bus indirizzi); come puoi vedere nella figuara di sotto: Il lungo rettangolo rappresenta il megabyte di memoria a cui la CPU può accedere nel modello segmentato in modalità reale. La CPU è sulla destra. Al centro c'è un pezzo di cartone metaforico con una fessura tagliata. La fessura è larga 1 byte e lunga 65.536 byte (64K). La CPU può far scorrere quel pezzo di cartone su e giù per l'intera lunghezza del suo sistema di memoria. Tuttavia, in un dato momento, può accedere solo a 65.536 byte
</p>

<p align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/64kblinder.png">
</p>

<p align=justify>
La vista della memoria da parte della CPU nel modello segmentato in modalità reale è particolare; la CPU è costretta a guardare la memoria in blocchi e ciascun blocco è al massimo largo 65.536 byte (64K). Facendo uso di questo modello a pezzetti di memoria (detti segmenti) sapere quale segmento è attualmente in uso e come passare da uno all'altro è la vera sfida della programmazione in modalità reale a modello segmentato.
</p>

### I Segmenti

<p align=justify>
Fino a questo momento, abbiamo parlato informalmente dei segmenti come blocchi di memoria all'interno dello spazio di memoria più grande che la CPU può vedere e utilizzare. Nel contesto del modello segmentato in modalità reale, un segmento è una regione di memoria che inizia su un confine di <b>paragrafo</b> (<i>paragraph</i>) e si estende per un certo numero di byte. Nel modello segmentato in modalità reale, questo numero è minore o uguale a 64K (65.536).
</p>

<p align=justify>
Cosa sono quindi i paragrafi? Un <b>paragrafo è una misura di memoria pari a 16 byte</b>. Il termine paragrafo non è molto comune, e per lo più è usato solo in relazione ai <b>luoghi nella memoria dove i segmenti possono iniziare</b>. Qualsiasi indirizzo di memoria divisibile per 16 è chiamato <b>confine o limite del paragrafo</b> (<i> paragraph boundary</i>). Il primo confine del paragrafo è l'indirizzo 0. Il secondo è l'indirizzo 10H; il terzo 20H e così via (ricorda che 10H è equivalente a decimale 16). <b>Qualsiasi limite di paragrafo può essere considerato l'inizio di un segmento</b>. Questo non significa che un segmento inizi effettivamente ogni 16 byte su e giù in quel megabyte di memoria. Un segmento è come un ripiano in uno di quegli scaffali moderni regolabili. Sul lato posteriore dello scaffale ci sono molte piccole fessure distanziate di mezzo pollice l'una dall'altra. Un supporto per ripiano può essere inserito in una delle piccole fessure. Tuttavia, non ci sono centinaia di ripiani, ma solo quattro o cinque. Quasi tutte le fessure sono vuote e non utilizzate. Esistono affinché un numero molto più ridotto di ripiani possa essere regolato su e giù in altezza come necessario. In modo molto simile, <b>i limiti di paragrafo sono piccole fessure in cui un segmento può essere iniziato</b>. Nel modello segmentato in modalità reale, un programma può utilizzare solo quattro o cinque segmenti, ma ciascuno di quei segmenti può iniziare in uno dei <b>65.536 limiti di paragrafo esistenti nel megabyte di memoria disponibile</b> nel modello segmentato in modalità reale. Ecco di nuovo quel numero: 65.536 - il nostro amato 64K. <b>Ci sono 64K diversi limiti di paragrafo in cui un segmento può iniziare</b>. Il motivo per cui ci sono solamente 65536 limiti di paragrafo è semplice, la memoria misura $1MB=2^{20}$ ed i limiti di paragrafo iniziano ogni $16=2^4$ bit; quindi effettuando la divisione $2^{20}/2^4=2^{20-4}=2^{16}=65536$ otteniamo il numero di limiti di paragrafo in una memoria di 1MB. <b>Ogni limite di paragrafo ha un numero</b>. Come sempre, i numeri cominciano da 0 e arrivano a 64K meno uno; in decimale 65.535, o in esadecimale $0FFFFH$ (tutti i sedici bit a 1, in esadecimale quattro F). Poiché un segmento può iniziare in qualsiasi limite di paragrafo, <b>il numero del limite di paragrafo in cui un segmento inizia</b> è chiamato <b>indirizzo del segmento</b> di quel particolare segmento. Raramente, in effetti, parliamo di paragrafi o limiti di paragrafo. Quando vedi il termine indirizzo del segmento in connessione con il modello segmentato in modalità reale, tieni presente che ogni indirizzo di segmento è di 16 byte (un paragrafo) più in là nella memoria rispetto all'indirizzo del segmento precedente. Nella Figura di sotto, ogni barra ombreggiata è un indirizzo di segmento, e i segmenti iniziano ogni sedici byte. L'indirizzo di segmento più alto è 0FFFFH, che si trova a 16 byte (un paragrafo) dalla sommità della memoria di 1 megabyte in modalità reale. In sintesi: <b>i segmenti possono iniziare in qualsiasi indirizzo di segmento</b>. <b>Ci sono 65.536 indirizzi di segmento</b> distribuiti uniformemente nella memoria completa di un megabyte in modalità reale, <b>separati da sedici byte</b> (paragrafo). Un indirizzo di segmento è più un permesso che un obbligo; per tutti i 64K possibili indirizzi di segmento, solo cinque o sei vengono effettivamente utilizzati per iniziare segmenti in un dato momento. Pensa agli indirizzi di segmento come a delle fessure in cui possono essere inseriti i segmenti. E per quanto riguarda i segmenti stessi? La cosa più importante da capire su un segmento è che può essere lungo fino a 64K byte, ma non deve esserlo per forza. Un segmento può essere lungo solo un byte, o 256 byte, o 21.378 byte, o qualsiasi lunghezza inferiore a 64K.
</p>

<p align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/memory_address_vs_segment_address.png">
</p>

<p align=justify>
Per definire un segmento è sufficiente dichiarare il limite di paragrafo dal quale esso inizia (che diventerà l'indirizzo di quel segmento). Ma invece, cosa definisce quanto è lungo un segmento? Niente!. Un segmento è più un orizzonte che un luogo. Una volta che definisci dove inizia un segmento, quel segmento può racchiudere qualsiasi posizione nella memoria tra quel punto di partenza e l'orizzonte - che è 65.536 byte più in là. Niente stabilisce, ovviamente, che un segmento debba utilizzare tutta quella memoria. Nella maggior parte dei casi, quando un segmento è definito a qualche indirizzo di segmento, un programma considera solo i successivi pochi centinaia o forse qualche migliaio di byte come parte di quel segmento, a meno che non si tratti di un programma davvero di prima classe. La maggior parte dei principianti che leggono riguardo i segmenti li considerano come una sorta di allocazione di memoria, una regione di memoria protetta con pareti su entrambi i lati, riservata per un uso specifico. Non è assolutamente così e ciò è la cosa più lontana dalla verità che si possa pensare. <b>In modalità reale nulla è protetto all'interno di un segmento</b> e i <b>segmenti non sono riservati</b> per alcun accesso specifico. <b>I segmenti possono sovrapporsi</b>. (Le persone spesso non pensano a questo o non lo realizzano.) In un certo senso, i segmenti non esistono realmente, tranne come orizzonti oltre i quali un certo tipo di riferimento di memoria non può andare. Si torna a quel paraocchi/fessura/finestra della dimensione di un blocco di 64K che la CPU indossa. Vediamola in questo modo: <b>un segmento è la posizione nella memoria in cui sono posizionati i paraocchi da 64K della CPU</b>. Guardando la memoria attraverso i paraocchi, puoi vedere byte che partono dall'indirizzo di segmento e continuano fino a quando i paraocchi ti bloccano, 64K byte più in là. La chiave per comprendere questa definizione ammettiamo metafisica di un segmento è sapere come vengono utilizzati i segmenti - e comprendere questo richiede infine una discussione dettagliata sui registri della CPU.
</p>

### I Registri

<p align=justify>
Un registro è un tipo di memoria all'interno del chip della CPU, piuttosto che all'esterno della CPU in RAM o da qualche parte. L'8088, l'8086 e l'80286 sono spesso chiamati CPU a 16 bit perché i loro registri interni sono quasi tutti di 16 bit di dimensione. L'80386 e i suoi successori sono chiamati CPU a 32 bit perché la maggior parte dei loro registri interni sono di 32 bit di dimensione. Dalla metà degli anni 2000, molte delle nuove CPU x86 sono state progettate a 64 bit, con registri larghi 64 bit. Le CPU x86 hanno un numero abbastanza elevato di registri.
</p>

<p align=justify>
I registri svolgono molte funzioni, ma forse il loro compito più importante è quello di memorizzare gli indirizzi di posizioni importanti in memoria (l'indirizzo della prossima istruzione da eseguire, l'indirizzo all'inizio dello stack etc.). Se ricordi, l'8086 e l'8088 hanno 20 pin per il bus indirizzi, e il loro megabyte di memoria (che è la memoria segmentata in modalità reale di cui stiamo parlando) richiede indirizzi di 20 bit ($2^{20}=1MB$) ma i registri interni della CPU e quindi anche quello per indirizzare la memoria è di 16 bit.
</p>

<p align=justify>
Come si inserisce un indirizzo di memoria a 20 bit in un registro a 16 bit? Non lo si fa. Si inserisce un indirizzo a 20 bit in due registri a 16 bit. Ecco cosa succede: <b>tutte le posizioni (indirizzi) di memoria</b> nella memoria di un megabyte <b>sono composti da due parti</b>: <b>l'indirizzo di segmento</b> e <b>l'offset</b> all'interno di quel segmento del byte a cui vogliamo fare riferimento. Ogni byte in memoria si presume si trovi in un segmento. <b>L'indirizzo completo di un byte, quindi, consiste nell'indirizzo del suo segmento, insieme alla distanza del byte dall'inizio di quel segmento (detto offset)</b>. Ricorda che l'indirizzo del segmento è l'indirizzo del byte dove inizia il segmento che deve comunque trovarsi al limite di un paragrafo (alla fine di un blocco di 16 byte di memoria) quindi deve essere comunque un indirizzo il cui valore sia divisibile per 16. <b>La distanza del byte dall'inizio del segmento è l'indirizzo offset del byte</b>. Entrambi gli indirizzi devono essere specificati per descrivere completamente la posizione di un singolo byte all'interno del megabyte completo di memoria in modalità reale. Quando vengono scritti, l'indirizzo del segmento viene prima, seguito dall'indirizzo offset. I due sono separati da due punti. Gli indirizzi <b>segmento:offset</b> sono sempre scritti in esadecimale. Guarda la figura di sotto per chiarire meglio questo concetto. Un byte di dati che chiameremo <code>MyByte</code> esiste in memoria presso la posizione contrassegnata in nero. Il suo indirizzo è dato come <code>0001:0019</code>. Questo significa che MyByte si trova all'interno del segmento <code>0001H</code> ed è situato <code>0019H</code> byte dall'inizio di quel segmento. È una convenzione nella programmazione x86 che quando due numeri vengono utilizzati per specificare un indirizzo con un due punti tra di essi, non si termina ciascuno dei due numeri con una H per esadecimale. Gli indirizzi scritti nella forma segmento:offset si presume siano in esadecimale. L'universo è perverso e degli occhi acuti percepiranno che MyByte può avere altri due indirizzi legali perfettamente validi: <code>0000:0029</code> e <code>0002:0009</code>. Come mai? Tieni presente che un segmento può iniziare ogni 16 byte in tutta la memoria reale di un megabyte. Un segmento, una volta iniziato, abbraccia tutti i byte dalla sua origine fino a 65.535 byte più in alto in memoria. Non c'è nulla di sbagliato con i segmenti che si sovrappongono, e nella figura in basso abbiamo tre segmenti sovrapposti. MyByte è a 2DH byte nel primo segmento, che inizia all'indirizzo segmento 0000H. MyByte è a 1DH byte nel secondo segmento, che inizia all'indirizzo segmento 0001H. Non è che MyByte si trovi in due o tre posti contemporaneamente. Si trova in un solo posto, ma quel posto può essere descritto in uno qualsiasi dei tre modi.	
</p>

<p align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/mybyte.png">
</p>

<p align=justify>
Un byte arbitrario in qualche punto del mezzo del megabyte di memoria della modalità reale può cadere in letteralmente migliaia di segmenti diversi. Quale segmento contiene effettivamente il byte è strettamente una questione di convenzione. In sintesi: esprimere un indirizzo a 20 bit in due registri a 16 bit significa mettere l'indirizzo del segmento in un registro a 16 bit e l'indirizzo di offset in un altro registro a 16 bit. I due registri presi insieme identificano un byte tra tutti i 1.048.576 byte nella memoria del megabyte della modalità reale.
 </p>

### I registri di segmento

<p align=justify>
L'8088, l'8086 e l'80286 hanno esattamente quattro registri di segmento specificamente designati come contenitori degli indirizzi di memoria dove ha inizio uno specifico segmento. I processori 386 e successivi ne hanno altri due che possono essere utilizzati anche in modalità reale. (Devi essere consapevole del modello di CPU su cui stai eseguendo il tuo codice se intendi utilizzare i due registri di segmento aggiuntivi, poiché le CPU più vecchie, precedenti il 386, non hanno affatto questi registri.) Ogni registro di segmento è una zona di memoria a 16 bit che esiste all'interno del chip della CPU stessa. Non importa cosa stia facendo la CPU, se sta indirizzando qualche locazione in memoria, allora l'indirizzo di segmento di quella locazione è presente in uno dei sei registri di segmento. I registri di segmento hanno nomi che riflettono le loro funzioni generali: CS, DS, SS, ES, FS e GS. FS e GS esistono solo nei processori Intel x86 386 e successivi, ma sono ancora di dimensioni 16 bit. <b>Tutti i registri di segmento sono di dimensioni 16 bit</b>, indipendentemente dalla CPU. Questo è vero anche per le CPU a 32 e 64 bit.
</p>

<p align=justify>
<ul>
	<li>
		<b>CS</b> sta per segmento di codice. Le istruzioni della macchina esistono a un certo offset all'interno di un segmento di codice. L'indirizzo del segmento di codice dell'istruzione attualmente in esecuzione è contenuto in CS.
	</li>
	<li>
		<b>DS</b> sta per segmento di dati. Le variabili e altri dati esistono a un certo offset in un segmento di dati. Potrebbero esserci molti segmenti di dati, ma la CPU può utilizzare solo uno alla volta, collocando l'indirizzo di quel segmento nel registro DS. 
	</li>
	<li>
		<b>SS</b> sta per segmento di stack. Lo stack è un componente molto importante della CPU utilizzato per l'archiviazione temporanea di dati e indirizzi (chiamate a funzioni in c etc). Spiegheremo come funziona lo stack un più avanti; per ora è sufficiente comprendere che, come tutto il resto all'interno del megabyte di memoria della modalità reale, lo stack ha un indirizzo di segmento, che è contenuto in SS. 
	</li>
	<li>
		<b>ES</b> sta per segmento extra. Il segmento extra è esattamente quello: un segmento di riserva che può essere utilizzato per specificare una posizione in memoria. 	</li>
	<li>
		<b>FS</b> e <b>GS</b> sono clone di ES. Sono entrambi segmenti aggiuntivi senza un compito o specialità specifica. I loro nomi derivano dal fatto che sono stati creati dopo ES (pensa, E, F, G). Non dimenticare che esistono solo nelle CPU x86 386 e successive!
	</li>
</ul>
</p>

### I registri di segmento in x64

<p align=justify>
Ora, c'è qualcosa di strano riguardo ai registri di segmento nell'architettura x64: non vengono utilizzati nei programmi applicativi. Affatto. Pensateci: 64 bit possono identificare $2^{64}$ byte di memoria. In notazione scientifica decimale, sono $1,8 x 10^{19}$. Ad alta voce diremmo “18 exabyte.” Un exabyte è un miliardo di gigabyte, cioè un miliardo di miliardi di byte. Il punto fondamentale dei registri di segmento era permettere che 20 bit d'indirizzamento fossero gestiti da due registri da 16 bit. Quando un singolo registro da 64 bit può indirizzare quasi quanti più byte di memoria ci sono stelle nell'universo osservabile (non sto esagerando!), i registri di segmento diventano inutili, almeno nella programmazione applicativa. I sistemi operativi ne usano ancora due. Gli altri ci sono, ma possono causare problemi se cerchi di usarli. In breve, quando passi alla modalità lunga x64 (long x64), i familiari registri di segmento da 16 bit semplicemente scompaiono. Quindi, i processori x64 di Intel hanno 64 linee di indirizzo? No. Non c'è nemmeno cirtcuiteria all'interno dei chip per supportare più di 48 bit di indirizzo nelle vecchie CPU x64. (Intel ha aumentato questo valore a 52 bit per alcuni CPU high-end alcuni anni fa.) Da una prospettiva a 64 bit, i registri di segmento sono ormai storia.
</p>

### I registri General-Purpose

<p align=justify>
I registri di segmento esistono solo per contenere indirizzi di segmento. Possono essere costretti a fare poche altre cose in modalità reale, ma, in generale, i registri di segmento devono essere considerati specialisti nel contenere indirizzi di segmento. Le CPU x86 hanno un insieme di registri generalisti per svolgere il resto del lavoro del calcolo in linguaggio assembly. Tra le molte altre cose, <b>questi registri a uso generale vengono anche utilizzati per contenere gli indirizzi di offset</b> che devono essere abbinati agli indirizzi di segmento per individuare una singola posizione nella memoria. Contengono anche valori per le manipolazioni aritmetiche, per lo spostamento di bit (di più su questo più avanti) e molte altre cose. Sono davvero le tasche dell'artigiano all'interno della CPU.
</p>

<p align=justify>
Ma qui arriviamo a una delle differenze più grandi e ovvie tra le vecchie CPU x86 a 16 bit (l'8086, l'8088 e l'80286) e le nuove CPU x86 a 32 e 64 bit a partire dal 386: la dimensione dei registri a uso generale. La 'bitness' del mondo è quasi interamente definita dalla larghezza dei registri della CPU x86. Il primordiale 8080 aveva registri a 8 bit. Le CPU x86 a 16 bit (l'8086, l'8088, l'80186 e l'80286) avevano registri a 16 bit. Le CPU x86 a 32 bit a partire dal 386 hanno registri a 32 bit. E nel mondo x64, le CPU hanno 14 registri a 64 bit a uso generale. Due registri aggiuntivi, il puntatore dello stack (stack pointer, <b>SP</b>) e il puntatore base (base pointer, <b>BP</b>), sono specialisti e esistono nelle architetture a 16 bit, 32 bit e 64 bit. Il puntatore dello stack punta sempre alla cima dello stack. (molto di più nello stack nei paragrafi successivi.) Il punatore base è un po' come un segnalibro e viene usato per accedere ai dati "più in basso" nello stack; ancora una volta, arriveremo allo stack alla fine, e spiegherò questo in modo più approfondito. Come i registri di segmento, i registri a uso generale x64 sono posizioni di memoria esistenti all'interno del chip della CPU stessa. I registri a uso generale sono davvero generalisti in quanto tutti condividono un ampio insieme di capacità. Tuttavia, alcuni dei registri a uso generale hanno anche quello che chiamo un 'agenda nascosta': un compito o un insieme di compiti che solo esso può eseguire. Alcune delle agende nascoste sono in realtà limitazioni delle vecchie CPU a 16 bit. I nuovi registri generali a 32 bit e 64 bit sono molto più, beh, generali.
</p>

<p align=justify>
Nel nostro attuale mondo a 64 bit, i registri a uso generale rientrano in quattro classi generali: i registri a uso generale a 16 bit, i registri a uso generale estesi a 32 bit, i registri a uso generale a 64 bit e le metà dei registri a 8 bit. Queste quattro classi non rappresentano affatto quattro insiemi completamente distinti di registri. I registri a 8 bit, a 16 bit e a 32 bit sono in realtà nomi di aree all'interno dei registri a 64 bit. L'espansione dei registri nella storica famiglia di CPU x86 è avvenuta estendendo registri già esistenti nelle CPU più vecchie. Aggiungere una stanza alla tua casa non la rende due case, ma solo una casa più grande. E così è stato con i registri x86. Ci sono otto registri a uso generale a 16 bit: AX, BX, CX, DX, BP, SI, DI e SP. (SP e BP sono un po' meno generali rispetto agli altri, ma ci arriveremo.) Questi registri esistevano tutti nelle CPU 8086, 8088, 80186 e 80286. Sono tutti di 16 bit di dimensione e puoi inserire in essi qualsiasi valore che possa essere espresso in 16 bit o meno. Quando Intel ha ampliato l'architettura x86 a 32 bit nel 1985, ha raddoppiato la dimensione di tutti e otto i registri e ha dato loro nuovi nomi aggiungendo una E all'inizio di ciascun nome di registro, producendo EAX, EBX, ECX, EDX, EBP, ESI, EDI ed ESP.
Le cose cambiarono ancora nel 2003, quando Intel iniziò ad adottare l'architettura x64 di AMD. Ancora una volta, Intel aveva già la propria architettura a 64 bit, IA-64 Itanium, ma Itanium aveva alcune difficoltà tecniche sottili ma importanti nella sua microarchitettura. Intel quindi ingoiò il suo orgoglio e fece la cosa intelligente adottando l'architettura a 64 bit di successo di AMD. Purtroppo, l'8080 resta solo. La retrocompatibilità può estendersi solo fino a un certo punto prima di diventare più un problema che una caratteristica. L'architettura x64 ampliò la gamma di registri a uso generale da 32 a 64 bit. Questa volta il prefisso divenne R. Quindi ora invece del registro a 32 bit EAX, abbiamo RAX, e così via lungo l'elenco dei registri a 32 bit. Intel aggiunse anche otto nuovi registri a 64 bit che non erano mai stati parte della loro architettura prima. I loro nomi sono per lo più numeri: da R8 a R15. I registri x64 a 64 bit sono in verità registri all'interno di registri. Come molte cose, questo si mostra meglio che a dirlo. Dai un'occhiata alla figura di sotto, che illustra come funziona con i registri x64 RAX e R8.
RAX contiene EAX, AX, AH e AL. EAX contiene AX, AH e AL. AX contiene AH e AL. I nomi "RAX", "EAX", "AX", "AH" e "AL" sono tutti validi in x64. Puoi usare tutti questi nomi nei tuoi programmi in linguaggio assembly per accedere ai 64 bit contenuti in RAX o a determinate parti più piccole di esso. Vuoi accedere ai 32 bit inferiori di RAX? Usa il nome EAX. Vuoi accedere ai 16 bit più bassi di RAX? Usa AX.
</p>

<p align=center>
<img src=https://github.com/TheBitPoets/2cornot2c/blob/main/images/registers_inside_registers.png>
</p>

<p align=justify>
Quindi, nell'estensione a 64 bit gli otto registri originali furono ampliati a 64 bit, etichettati RAX, RBX, RCX, RDX, RSI, RDI, RBP, RSP. Inoltre, furono aggiunti otto nuovi registri, ai quali furono dati nomi secondo una nuova convenzione di denominazione: R8, R9, R10, R11, R12, R13, R14, R15
</p>

<p align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/general_purpose_register_32.png">
</p>

<p align=justify>
Lo stesso vale per i quattro registri di uso generale RAX, RBX, RCX e RDX, ma c'è una particolare variazione: i 16 bit inferiori sono divisi in due metà da 8 bit ciascuna. Quindi, ciò che abbiamo sono nomi di registri su quattro livelli. I registri a 16 bit AX, BX, CX e DX sono presenti come le porzioni inferiori a 16 bit di EAX, EBX, ECX ed EDX, che a loro volta sono le porzioni inferiori a 32 bit di RAX, RBX, RCX e RDX. Ma AX, BX, CX e DX sono a loro volta divisi in metà da 8 bit, e gli assemblatori riconoscono nomi speciali per le due metà. Le lettere A, B, C e D sono mantenute, ma invece della X, si specifica una metà con una H (per la metà alta) o una L (per la metà bassa). Ogni metà di registro è grande 1 byte (8 bit). Pertanto, per formare il registro a 16 bit AX, hai le metà di registro di dimensione byte AH e AL; all’interno di BX ci sono BH e BL, e così via. I nuovi registri x64 R8-R15 possono essere indirizzati come 64 bit, 32 bit, 16 bit e 8 bit. Tuttavia, lo schema AH/AL per i 16 bit inferiori è un trucco riservato solo a RAX-RDX. Lo schema di denominazione per i registri R fornisce un mnemonico: D per dword, W per word e B per byte. Ad esempio, se vuoi trattare gli 8 bit più bassi di R8, utilizzi il nome R8B. Non commettere l'errore da principiante di assumere che R8, R8D, R8W e R8B siano quattro registri separati e indipendenti! Una metafora migliore è pensare ai nomi dei registri come paese/stato/contea/città. Una città è una piccola porzione di una contea, che è una piccola porzione di uno stato, e così via. Se scrivi un valore in R8B, cambi il valore memorizzato in R8, R8D e R8W.
Ancora una volta, questo può essere mostrato meglio graficamente. La figura di sotto è un'espansione della figura di sopra e questa volta include tutti i registri a uso generale dell'x64. Questi registri sono una sorta di 'metà bassa'. A parte AH, BH, CH e DH, non c'è un nome per la metà alta di qualsiasi registro a uso generale. Naturalmente, è possibile accedere alla metà alta di qualsiasi registro utilizzando più di un'istruzione macchina. Non puoi semplicemente farlo per nome in un colpo solo, a meno che tu non stia trattando con le quattro eccezioni a 8 bit menzionate sopra. Essere in grado di trattare i registri AX, BX, CX e DX come metà da 8 bit può essere estremamente utile in situazioni in cui stai manipolando molte quantità da 8 bit. Ogni metà del registro può essere considerata un registro separato, dandoti il doppio del numero di posti dove mettere le cose mentre il tuo programma lavora. Come vedrai più avanti, trovare un posto dove incollare un valore in un momento critico è una delle grandi sfide che affrontano i programmatori di linguaggio assembly.
</p>

<p align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/8_16_32_64_bit_registers.png">
</p>




<p align=justify>
Ciascuno dei quattro registri mostrati nella figura di sopra è di dimensione 32 bit. Tuttavia, in ciascun registro, i 16 bit inferiori hanno un proprio nome. I 16 bit inferiori di ESI, ad esempio, possono essere referenziati come SI. I 16 bit inferiori di EDI possono essere referenziati come DI. Se stai scrivendo programmi da eseguire in modalità reale su una macchina 8088 come il vecchio IBM PC, puoi fare riferimento solo alla parte DI: i 16 bit superiori non esistono su quella CPU! Sfortunatamente, i 16 bit superiori dei registri generali a 32 bit non hanno nomi propri. Puoi accedere ai 16 bit bassi di ESI come SI, ma per accedere ai 16 bit superiori, devi fare riferimento a ESI e ottenere l'intero pacchetto a 32 bit.
</p>

<p align=justify>
Ciò discusso sopra per i registri ESI, EDI, EBP, ESP vale anche per gli altri quattro registri generali, EAX, EBX, ECX ed EDX. C'è un'ulteriore particolarità per tutti questi registri: i 16 bit inferiori sono suddivisi in due metà da 8 bit, quindi ciò che abbiamo sono nomi di registri non su due ma su tre livelli. I registri a 16 bit AX, BX, CX e DX sono presenti come le porzioni inferiori a 16 bit di EAX, EBX, ECX ed EDX; ma AX, BX, CX e DX stessi sono divisi in metà da 8 bit, e gli assemblatori riconoscono nomi speciali per le due metà. Le lettere A, B, C e D sono conservate, ma invece della X, una metà è specificata con un H (per metà alta) o un L (per metà bassa). Ogni metà del registro è grande un byte (8 bit). Così, formando il registro a 16 bit AX, hai le metà del registro di dimensione byte AH e AL; all'interno di BX ci sono BH e BL, e così via. Ancora una volta, questo può essere compreso meglio osservando la figura di sotto. 
</p>

<p align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/general_purpose_register_16.png">
</p>

 <p align=justify>
Come accennato in precedenza, una peculiarità di questo sistema è che non esiste un nome per la porzione alta a 16 bit dei registri a 32 bit. In altre parole, puoi leggere i 16 bit inferiori di EAX specificando AX in un'istruzione del linguaggio assembly, ma non c'è modo di specificare i 16 bit superiori da soli. Questo mantiene le convenzioni di denominazione per i registri un po' più semplici e la mancanza non è avvertita così spesso come potresti pensare. Una cosa da sapere sui registri a 8 bit è che puoi leggere e modificare una metà di un numero a 16 bit senza disturbare l'altra metà. Questo significa che se inserisci il valore esadecimale <code>76E9H</code> nel registro AX, puoi leggere il valore di un byte <code>76H</code> dal registro AH e <code>E9H</code> dal registro AL. Ancora meglio, se poi memorizzi il valore <code>0AH</code> nel registro AL e poi leggi di nuovo il registro AX, scoprirai che il valore originale di <code>76E9H</code> è stato cambiato in <code>760AH</code>. Essere in grado di trattare i registri AX, BX, CX e DX come metà a 8 bit può essere estremamente utile in situazioni in cui stai manipolando molte quantità a 8 bit. Ogni metà del registro può essere considerata un registro separato, offrendoti il doppio dei posti per mettere le cose mentre il tuo programma lavora.
</p>

<p align=justify>
Quindi riassumendo, una CPU x86-64 contiene un insieme di 16 registri a uso generale che memorizzano valori a 64 bit. Questi registri sono utilizzati per memorizzare dati interi e puntatori. Nella figura di sotto, i loro nomi iniziano tutti con %r (register), ma seguono altrimenti diverse convenzioni di denominazione, a causa dell'evoluzione storica dell'insieme di istruzioni. <b>L'originale 8086 aveva otto registri a 16 bit</b>, denominati AX, BX, CX, DX, SI, DI, BP, SP. Ognuno aveva uno scopo specifico, e pertanto furono dati nomi che riflettevano come dovevano essere utilizzati.E' possibile accedere al byte meno significativo di questi registri a 16 bit usando la L(low) e quindi avremo AL, BL, CL, DL, SIL, DIL, BPL, SPL ed usare la H (high) per il byte più significativo: AH, BH, CH, DH, SIH, DIH, BPH, SPH. <b>Con l'estensione a IA32</b> (estensione a 32 bit), questi registri furono ampliati a registri a 32 bit, etichettati EAX, EBX, ECX, EDX, ESI, EDI, EBP, ESP. Non si possono leggere i 16 bit più significati di questi 32 come invece accade per i registri a 16. <b>Nell'estensione a x86-64</b>, gli otto registri originali furono ampliati a 64 bit, etichettati RAX, RBX, RCX, RDX, RSI, RDI, RBP, RSP e furono aggiunti otto nuovi registri, usando una nuova convenzione di denominazione: R8, R9, R10, R11, R12, R13, R14, R15. Le istruzioni del set x86-64 possono operare su dati di diverse dimensioni memorizzati nei byte a ordine inferiore dei 16 registri. Le operazioni a livello di byte possono accedere al byte meno significativo, le operazioni a 16 bit possono accedere ai 2 byte meno significativi, le operazioni a 32 bit possono accedere ai 4 byte meno significativi, e le operazioni a 64 bit possono accedere all'intero registro.
</p>

<p align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/general_purpose_register_64.png">
</p>

### Instruction Pointer

<p align=justify>
IP è nn altro tipo di registro che vive all'interno di tutte le CPU Intel, compresa la x64. Il puntatore di istruzione IP (instruction pointer) è in una classe a parte. In modalità a 16 bit, il puntatore di istruzione viene semplicemente chiamato IP. In modalità a 32 bit, è EIP. In x64, è RIP. In tutti i casi, tuttavia, questo registro non è accessibile direttamente dal programmatore assembly. Viene invece accesso in modo indiretto quando si esegue un salto, una branch condizionale, una chiamata di procedura o un'interruzione. In una discussione generale non limitata a una modalità particolare, seguirò la convenzione e lo chiamerò IP. In radicale contrasto con il gruppo dei veri registri a uso generale, IP è uno specialista d'eccellenza - più uno specialista dei registri di segmento stessi. Può fare solo una cosa: <b>contiene l'indirizzo offset della prossima istruzione macchina da eseguire nel segmento di codice corrente</b>. <b>Un segmento di codice è un'area di memoria in cui sono memorizzate le istruzioni macchina</b>. <b>A seconda del modello di memoria che stai utilizzando, potrebbero esserci molti segmenti di codice in un programma, oppure (nella maggior parte dei casi) solo uno</b>. <b>Il segmento di codice corrente è quel segmento di codice il cui indirizzo di segmento è attualmente memorizzato nel registro del segmento di codice CS</b>. In un dato momento, l'istruzione macchina attualmente in esecuzione esiste all'interno del segmento di codice corrente. Nel modello segmentato a modalità reale, il valore in CS può cambiare frequentemente. Nei modelli piatti (che includono la modalità lunga x64), il valore in CS (quasi) mai cambia - e certamente non cambia su richiesta di un programma applicativo. Gestire i segmenti di codice e il puntatore di istruzione è ora compito del sistema operativo. Questo è particolarmente vero nella modalità lunga x64, dove c'è solo un segmento che contiene tutto, e i registri di segmento hanno così poco da fare nello spazio utente che sono praticamente invisibili ai programmi in spazio utente come quelli che scrivi.
</p>

<p align=justify>
Durante l'esecuzione di un programma, la CPU utilizza l'IP per tenere traccia di dove si trova nel segmento di codice corrente. Ogni volta che viene eseguita un'istruzione, l'IP viene incrementato di un certo numero di byte. Il numero di byte corrisponde alla dimensione dell'istruzione appena eseguita. Il risultato netto è spostare ulteriormente l'IP nella memoria in modo che punti all'inizio della prossima istruzione da eseguire. Le istruzioni possono avere dimensioni diverse, che variano tipicamente da 1 a 15 byte. La CPU conosce la dimensione di ogni istruzione che esegue. È attenta a incrementare l'IP esattamente del giusto numero di byte in modo che punti effettivamente all'inizio della prossima istruzione e non semplicemente a metà dell'ultima istruzione o a metà di qualche altra istruzione del tutto.
</p>

<p align=justify>
Se l'IP contiene l'indirizzo di offset della prossima istruzione macchina, dov'è l'indirizzo del segmento? <b>L'indirizzo del segmento è conservato nel registro del segmento di codice CS</b>. <b>Insieme, CS e IP contengono l'indirizzo completo della prossima istruzione macchina da eseguire</b>. La natura di questo indirizzo dipende da quale CPU stai utilizzando e per quale modello di memoria lo stai utilizzando. Negli 8086, 8088 e (di solito) 80286, l'IP ha una dimensione di 16 bit. Nelle CPU 386 e successive, l'IP (come tutti gli altri registri tranne i registri di segmento) passa a 32 bit di dimensione e diventa EIP.
</p>

<p align=justify>
Nel modello a segmenti in modalità reale, CS e IP lavorano insieme per fornire un indirizzo a 20 bit che punta a uno dei 1.048.576 byte nella memoria in modalità reale. Nei modelli flat (di cui parleremo tra breve), CS è impostato dal sistema operativo e mantenuto costante. IP gestisce tutto il puntamento delle istruzioni con cui tu, programmatore, devi interfacciarti. Nel modello flat a 16 bit (modello flat in modalità reale), ciò significa che IP può seguire l'esecuzione delle istruzioni attraverso un intero segmento di memoria di 64 KB. Il modello flat a 32 bit fa molto più del doppio di questo; 32 bit possono rappresentare 4.294.967.290 indirizzi di memoria differenti. In modalità lunga a 64 bit, bene, RIP può indirizzare tanta memoria quanto tu potresti inserire nella macchina nel corso della tua vita e certamente nella mia. Le opinioni sono divise su se mai ci saranno CPU a 128 bit. IP è noto per essere l'unico registro che non può né essere letto né scritto direttamente. Ci sono trucchi che possono essere usati per ottenere il valore corrente in IP, ma avere il valore di IP non è così utile come potresti pensare, e non dovrai farlo molto spesso.
</p>

### Flags Register

<p align=justify>
C'è un altro tipo di registro all'interno della CPU: quello che chiamiamo genericamente registro dei flag. Ha una dimensione di 16 bit nell'8086, 8088 e 80286, e il suo nome formale è FLAGS. Ha una dimensione di 32 bit nelle CPU a 32 bit, e il suo nome formale nelle CPU a 32 bit è EFLAGS. Il registro RFLAGS in x64 è di 64 bit. Poco meno della metà dei bit nel registro RFLAGS sono utilizzati come registri a bit singolo chiamati flag. (Il resto è non definito.) Ognuno di questi flag individuali ha un nome con un'abbreviazione di due caratteri, come CF, DF, OF, e così via, e ogni flag ha un significato molto specifico all'interno della CPU. Poiché un singolo bit può contenere solo due valori, 1 o 0, testare un flag in linguaggio assembly è davvero un'affare a due vie: o il valore di un flag è 1 o non lo è. Quando il valore del flag è 1, diciamo che il flag è impostato. Quando il valore del flag è 0, diciamo che il flag è azzerato. Quando il tuo programma esegue un test, quello che testa è uno o occasionalmente due dei flag a bit singolo nel registro RFLAGS. Poi prende un percorso di esecuzione separato a seconda dello stato del flag o dei flag. Ci sono istruzioni di salto separate per tutti i flag comuni, e alcune di più per testare coppie specifiche di flag. Il registro RFLAGS è quasi mai trattato come un'unità a meno che i flag non vengano salvati nello stack. Al momento ci stiamo concentrando sull'indirizzamento in memoria, quindi per ora prometto semplicemente di approfondire la lore dei flag in modo più dettagliato in momenti più appropriati più avanti.
</p>

###  Math Coprocessors and Registers

<p align=justify>
Sin dalla CPU 80486DX a 32 bit, c'è stato un coprocessore matematico sullo stesso chip di silicio con la CPU generica. Nei tempi antichi, il chip matematico era un circuito integrato completamente separato che si collegava al proprio socket sulla scheda madre. Le CPU x64 sono tutte dotate di coprocessori matematici integrati, con i propri registri e istruzioni macchina. L'architettura x64 utilizza la terza generazione di coprocessore matematico, AVX. Le architetture MMX e SSE sono le prime due generazioni e sono state introdotte prima di AVX. Spesso ci si pone la domanda: quando avremo CPU a 128 bit? La verità è che li abbiamo già, per le cose che contano. L'unico luogo in cui i registri a 128 bit sono essenziali è nelle applicazioni matematiche avanzate, come la modellazione 3D, l'elaborazione video, la crittografia, la compressione dei dati e l'intelligenza artificiale. Tutte le CPU moderne che incorporano il coprocessore SSE hanno registri a 128 bit per l'uso del coprocessore matematico. (La CPU generica non può utilizzarli direttamente.) E non finisce qui. Il coprocessore AVX alza la posta in gioco a 256 bit. E AVX 512, introdotto nel 2021, in gran parte per le CPU dei server, può fare i suoi calcoli nei registri a 512 bit. Con registri matematici a 128, 256 e 512 bit disponibili per l'elaborazione di numeri, non ha molto senso espandere i registri GP a 128 bit. I 64 bit sono ampiamente visti come una sorta di "punto debole" per l'informatica generica e dovrebbero rimanere tali per molto tempo. E' ben al di fuori del nostro scopo spiegare come usare l'SSE, tanto meno l'AVX. Un buon trattamento per principianti può essere trovato in Beginning x64 Assembly Programming di Jo Van Hoey (Apress, 2019). La programmazione del coprocessore matematico è sottile e complessa. Consiglierei di diventare ragionevolmente fluenti nell'assemblaggio x64 ordinario prima di immergersi nel lato matematico
</p>

### I quattro principali modelli di programmazione per x86

Ci sono quattro modelli di programmazione principali disponibili per l'uso sulle CPU Intel a 64 bit, sebbene due di essi siano ora considerati arcaici. Le differenze tra di essi risiedono (per lo più) nell'uso dei registri per indirizzare la memoria. (E le altre differenze, specialmente nella fascia alta, sono per la maggior parte nascoste da te dal sistema operativo.) In questa sezione, riassumerò i quattro modelli per riferimento storico. Solo uno di essi, la modalità lunga x64, verrà trattato in dettaglio successivamente.


## Real Mode Flat Model (modello piatto in modalità reale)

<p align=justify>
In modalità reale, se ricordi, la CPU può vedere solo un megabyte (1.048.576) di memoria. Puoi accedere a ogni singolo byte di quei milioni utilizzando il trucco del registro segmento:offset mostrato in precedenza per formare un indirizzo a 20 bit da due indirizzi a 16 bit contenuti in due registri. Oppure, puoi accontentarti di 64K di memoria e non preoccuparti affatto dei segmenti. Nel modello piatto della modalità reale, il tuo programma e tutti i dati su cui lavora devono esistere all'interno di un singolo blocco di memoria di 64K. Sessantaquattro kilobyte! Cosa potresti mai realizzare in soli 64K di byte? Bene, la prima versione di WordStar per l'IBM PC stava in 64K. Anche i primi tre rilasci principali di Turbo Pascal - in effetti, il programma Turbo Pascal stesso occupava molto meno di 64K perché compilava i suoi programmi in memoria. L'intero pacchetto Turbo Pascal - compilatore, editor di testo e alcuni strumenti vari - arrivò a poco più di 39K. Trentuno kilobyte! Non riesci nemmeno a scrivere una lettera a tua madre (usando Microsoft Word) in quel poco spazio al giorno d'oggi!
</p>

<p align=justify>
Cose spettacolari sono successe una volta in 64K, e mentre potresti non essere mai chiamato a limitarti al modello piatto in modalità reale, la disciplina che tutti quei programmatori ora con i capelli grigi hanno sviluppato a causa del numero limitato di risorse è molto utile. Più precisamente, il modello piatto in modalità reale è il "fratello minore" del modello piatto in modalità protetta, che è il modello di codice che userai quando programmi sotto Linux. Se impari i modi del modello piatto in modalità reale, il modello piatto in modalità protetta sarà un gioco da ragazzi. (Qualsiasi problema avrai non sarà con il codice assembly o i modelli di memoria, ma con i requisiti bizantini di Linux e le sue librerie di codice canoniche.) Il modello piatto in modalità reale è mostrato graficamente nella figura di sotto. Non c'è molto da dire. I registri di segmento sono tutti impostati per puntare all'inizio del blocco di 64K di memoria con cui puoi lavorare. (Il sistema operativo li imposta quando carica e esegue il tuo programma.) Tutti puntano a quello stesso posto e non cambiano mai finché il tuo programma è in esecuzione. Nessun registro di segmento, niente inganni con i segmenti, e nessuna delle complicazioni brutte che vengono con essi. Poiché un registro a 16 bit come BX può contenere qualsiasi valore da 0 a 65.535, può localizzare qualsiasi singolo byte all'interno del pieno 64K con cui il tuo programma deve lavorare. L'indirizzamento della memoria può quindi avvenire senza l'uso esplicito dei registri di segmento. I registri di segmento continuano a funzionare, ovviamente, dal punto di vista della CPU. Non scompaiono e sono ancora presenti, ma il sistema operativo li imposta a valori a sua scelta quando avvia il tuo programma, e quei valori saranno validi finché il tuo programma è in esecuzione. Non è necessario accedere ai registri di segmento in alcun modo per scrivere il tuo programma.
</p>

<p align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/real_mode_flat_model.png">
</p>

<p align=justify>
La maggior parte dei registri generali può contenere indirizzi di posizioni in memoria. Li usi in congiunzione con le istruzioni della macchina per prelevare dati dalla memoria e scriverli di nuovo.
In cima al segmento singolo in cui esiste il tuo programma, vedrai una piccola regione chiamata stack. Lo stack è una posizione di memorizzazione last in, first out (LIFO) con alcune proprietà e usi molto speciali. Spiegherò cos'è lo stack e come funziona in dettaglio successivamente.
</p>

## Real Mode Segmented Model (modello segmentato in modalità reale)

<p align=justify>
Il modello segmentato in modalità reale era il modello di programmazione principale durante l'era MS-DOS, e che entra ancora in gioco quando si avvia una finestra MS-DOS per eseguire un software 'legacy'. È un sistema complicato e brutto che richiede di ricordare molte piccole regole e insidie, ma è utile da comprendere perché illustra molto chiaramente la natura e la funzione dei segmenti. Si noti che sotto entrambi i modelli piatti è possibile strizzare un po' gli occhi e fingere che i segmenti e i registri di segmento non esistano realmente, ma sono entrambi ancora lì e funzionano, e una volta che ci si addentra in alcuni degli stili di programmazione più esotici, sarà necessario essere consapevoli di essi e comprendere come funzionano. Nel modello segmentato in modalità reale, il tuo programma può vedere l'intero 1 MB di memoria disponibile per la CPU in modalità reale. Ciò avviene combinando un indirizzo segmento a 16 bit con un indirizzo offset a 16 bit. Tuttavia, non si tratta semplicemente di unirli in un indirizzo a 32 bit. Devi tornare alla discussione sui segmenti nei paragrafi precedenti. Un indirizzo di segmento non è realmente un indirizzo di memoria. Un indirizzo di segmento specifica uno dei 65.535 spazi in cui un segmento può iniziare. Uno di questi spazi esiste ogni 16 byte dalla parte inferiore della memoria fino alla parte superiore. L'indirizzo di segmento 0000H specifica il primo di tali spazi, in corrispondenza della prima posizione nella memoria. L'indirizzo di segmento 0001H specifica il successivo spazio, che si trova 16 byte più in alto nella memoria. Saltando ulteriormente nella memoria altri 16 byte si arriva all'indirizzo di segmento 0002H, e così via. Puoi tradurre un indirizzo di segmento in un effettivo indirizzo di memoria a 20 bit moltiplicandolo per 16. L'indirizzo di segmento 0002H è quindi equivalente all'indirizzo di memoria 0020H, che è il 32° byte nella memoria.
</p>

<p align=justify>
Ma tale moltiplicazione non è qualcosa che devi fare. La CPU gestisce internamente la combinazione dei segmenti e degli offset in un indirizzo completo a 20 bit. Il tuo compito è dire alla CPU dove si trovano i due diversi componenti di quell'indirizzo a 20 bit. La notazione consueta è separare il registro del segmento dal registro dell'offset con due punti, come mostrato nel seguente esempio: 
</p>

* `SS:SP` 
* `SS:BP` 
* `ES:DI` 
* `DS:SI` 
* `CS:BX` 

<p align=justify>
Ognuna di queste cinque combinazioni di registri specifica un indirizzo completo a 20 bit. ES:DI, ad esempio, specifica l'indirizzo come la distanza in DI dall'inizio del segmento indicato in ES.
</p>

<p align=justify>
Il diagramma sottostante delinea il modello segmentato in modalità reale. In contrasto con il modello piatto in modalità reale (mostrato nella figura di sopra), il diagramma qui mostra tutta la memoria, non solo il piccolo blocco di 64K che il tuo programma del modello piatto in modalità reale può allocare quando viene eseguito. Un programma scritto per il modello segmentato in modalità reale può vedere tutta la memoria della modalità reale (1MB).
</p>

<p align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/real_mode_segmented_model.png">
</p>

<p align=justify>
Il diagramma mostra due segmenti di codice e due segmenti di dati. In pratica, puoi avere un numero ragionevole di segmenti di codice e di dati, non solo due di ciascuno. Puoi accedere a due segmenti di dati contemporaneamente, perché hai due registri di segmento disponibili per svolgere il lavoro: DS ed ES. (Nei processori 386 e successivi, hai due registri di segmento aggiuntivi, FS e GS.) Ognuno può specificare un segmento di dati e puoi trasferire dati da un segmento all'altro utilizzando alcune istruzioni macchina. Tuttavia, hai solo un registro di segmento di codice, CS. CS punta sempre al segmento di codice corrente e la prossima istruzione da eseguire è puntata dal registro IP. Non carichi valori direttamente in CS per passare da un segmento di codice a un altro. Le istruzioni macchina chiamati salti cambiano il segmento di codice necessario. Il tuo programma può estendersi su diversi segmenti di codice e quando un'istruzione di salto (di cui ce ne sono diversi tipi) deve portare l'esecuzione in un altro segmento di codice, cambia il valore in CS per te.
</p>

<p align=justify>
Esiste un solo segmento di stack per ogni singolo programma, specificato dal registro del segmento di stack SS. Il puntatore dello stack SP del registro punta all'indirizzo di memoria (relativo a SS, anche se alla direzione capovolta) in cui avrà luogo l'operazione dello stack successivo. La pila richiede alcune spiegazioni considerevoli, che riprenderò in diversi punti più avanti. È necessario tenere presente che in modalità reale, ci saranno parti del sistema operativo (e se si utilizza un 8086 o un 8088, sarà l'intero sistema operativo) in memoria con il tuo programma, insieme a importanti tabelle di dati di sistema. È possibile distruggere parti del sistema operativo con l'uso incauto dei registri di segmento, che causerà l'arresto anomalo del sistema operativo e porterà con sé il programma. Questo è il pericolo che ha spinto Intel a creare nuove funzionalità nelle sue CPU 80386 e successive per supportare una modalità "protetta". In modalità protetta, i programmi applicativi, ovvero i programmi scritti dall'utente, anziché il sistema operativo o i driver di periferica, non possono eliminare il sistema operativo o altri programmi applicativi in esecuzione in un altro punto della memoria tramite il multitasking. Questo è ciò che significa protetto. Infine, anche se è vero che c'era una sorta di rudimentale modalità protetta presente nell'80286, nessun sistema operativo l'ha mai veramente usata, e non vale la pena discuterne oggi
</p>

### 32-Bit Protected Mode Flat Model

<p align=justify>
Le CPU di Intel hanno implementato un'ottima architettura in modalità protetta sin da quando il 386 è apparso nel 1986. Tuttavia, i programmi applicativi non possono fare uso della modalità protetta da soli. Il sistema operativo deve impostare e gestire una modalità protetta prima che i programmi applicativi possano funzionare al suo interno. MS-DOS non poteva farlo, e Microsoft Windows non poteva davvero farlo nemmeno fino all'apparizione di Windows NT nel 1994. Linux, non avendo problemi di 'legacy' in modalità reale da affrontare, ha operato in modalità protetta sin dal suo primo apparire nel 1992. I programmi in linguaggio assembly in modalità protetta possono essere scritti sia per Linux che per le versioni di Windows da NT in poi. (Escludo Windows 9x per motivi tecnici. Il suo modello di memoria è un ibrido proprietario bizzarro tra modalità reale e modalità protetta, e molto difficile da comprendere completamente e ora quasi completamente irrilevante.)
</p>

<p align=justify>
Nota bene che i programmi scritti per Windows non devono necessariamente essere di natura grafica. Il modo più semplice per programmare in modalità protetta sotto Windows è creare applicazioni console, che sono programmi in modalità testo che vengono eseguiti in una finestra di testo chiamata console. La console è controllata attraverso una riga di comando quasi identica a quella di MS-DOS. Le applicazioni console utilizzano il modello piatto in modalità protetta e sono abbastanza semplici rispetto alla scrittura di applicazioni GUI per Windows. La modalità predefinita per Linux è una console testuale, quindi è ancora più facile creare programmi in assembly per Linux. Il modello di memoria è molto simile.  Il modello piatto in modalità protetta è mostrato nella figura di sotto.
</p>

<p align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/protected_mode_flat_model.png">
</p>

<p align=justify>
Il tuo programma vede un singolo blocco di indirizzi di memoria che vanno da zero a poco più di 4 gigabyte. Ogni indirizzo è una quantità a 32 bit. Tutti i registri a uso generale sono di dimensioni 32 bit, quindi un registro GP può puntare a qualsiasi posizione nello spazio di indirizzi completo di 4GB. Il puntatore di istruzione è anch'esso di 32 bit, quindi EIP può indicare qualsiasi istruzione macchina ovunque nei 4GB di memoria. I registri di segmento esistono ancora, ma funzionano in un modo radicalmente diverso. Non solo non devi preoccuparti di loro; non puoi farlo. I registri di segmento sono ora considerati parte del sistema operativo e nella quasi totalità dei casi non puoi né leggerli né modificarli direttamente. Il loro nuovo compito è definire dove esiste il tuo spazio di memoria da 4GB nella memoria fisica o virtuale. La memoria fisica può essere molto più grande di 4GB, e attualmente 4GB di memoria non è particolarmente costosa. Tuttavia, un registro a 32 bit può esprimere solo 4.294.967.296 posizioni diverse. Se hai più di 4GB di memoria nel tuo computer, il sistema operativo deve organizzare una regione da 4GB all'interno della memoria, e i tuoi programmi sono limitati a operare in questa regione. Definire dove nel tuo sistema di memoria più grande si trova questa regione da 4GB è compito dei registri di segmento, e il sistema operativo li tiene molto vicini ai suoi interessi.
</p>

<p align=justify>
La memoria virtuale è un sistema per il quale uno spazio di memoria molto più grande può essere "mappato" su uno spazio di archiviazione su disco, in modo che anche con solo 4 GB di memoria fisica nella tua macchina, la CPU possa indirizzare uno spazio di memoria "virtuale" di milioni di byte più grande. Ancora una volta, questo è gestito dal sistema operativo, e gestito in un modo che è quasi completamente trasparente al software che scrivi. È sufficiente capire che quando il tuo programma viene eseguito, riceve uno spazio di indirizzi di 4 GB in cui lavorare, e qualsiasi registro a 32 bit può potenzialmente indirizzare uno qualsiasi di quei 4 miliardi di locazioni di memoria, tutto da solo. Questa è una semplificazione eccessiva, specialmente per i normali PC desktop basati su Intel. Non tutti i 4 GB sono a disposizione del tuo programma, e ci sono certe parti dello spazio di memoria che non puoi usare o anche guardare. Purtroppo, le regole sono specifiche per il sistema operativo che stai eseguendo e non posso generalizzare troppo senza specificare Linux o Windows NT o qualche altro sistema operativo in modalità protetta. Ma vale la pena confrontare il modello piatto in modalità reale con il modello piatto in modalità protetta. La principale differenza è che nel modello piatto in modalità reale, il tuo programma possiede l'intero spazio di 64K di memoria che il sistema operativo gli restituisce. Nel modello piatto in modalità protetta, ti viene dato una porzione di 4 GB di memoria come tua, mentre altre porzioni appartengono ancora al sistema operativo. A parte ciò, le somiglianze sono sorprendenti: un registro a uso generale (GP) può da solo specificare qualsiasi locazione di memoria nell'intero spazio degli indirizzi di memoria, e i registri di segmento sono realmente gli strumenti del sistema operativo, non tuoi, del programmatore. (Ancora una volta, nel modello piatto in modalità protetta, un registro GP può contenere l'indirizzo di qualsiasi locazione nel suo spazio di 4 GB, ma tentare di leggere o scrivere effettivamente in certe locazioni sarà vietato dal sistema operativo e causerà un errore di esecuzione.)
</p>

<p align=justify>
Nota che non abbiamo ancora parlato in dettaglio delle istruzioni della macchina, e siamo stati in grado di definire in modo piuttosto chiaro l'universo in cui esistono e funzionano le istruzioni della macchina. L'indirizzamento della memoria e i registri sono fondamentali in questo settore. Se li conosci, le istruzioni saranno un gioco da ragazzi. Se non li conosci, le istruzioni non ti saranno di aiuto! La difficoltà nella programmazione per la modalità protetta col modello flat risiede nella comprensione del sistema operativo, dei suoi requisiti e delle sue restrizioni. Questo può essere una quantità sostanziale di apprendimento: Windows NT e Linux sono sistemi operativi principali che possono richiedere anni di studio per essere compresi bene.
</p>

### Memory Mapped Video

<p align=justify>
Il PC IBM originale utilizzava un meccanismo molto semplice ed estremamente ingegnoso per visualizzare testi e grafica a bassa risoluzione (secondo gli standard odierni). Una scheda video conteneva una certa quantità di memoria, e questa memoria era 'mappata' nello spazio di memoria fisica del PC. In altre parole, non c'era nulla di 'magico' nell'accesso alla memoria della scheda video. Semplicemente scrivendo dati a un indirizzo di memoria segmento:offset da qualche parte nel range di memoria contenuta sulla scheda video, qualcosa veniva visualizzato sul monitor. Questa tecnica consentiva ai programmi di visualizzare schermate complete di testo che apparivano 'all'improvviso', senza alcuna sensazione che il testo apparisse gradualmente dall'alto verso il basso, anche su macchine antiche con chip CPU incredibilmente lenti. L'organizzazione del buffer di memoria era semplice: partendo dall'indirizzo 0B00:0 (o 0B800:0 per display a colori) c'era un array di parole a due byte. Il primo byte in ciascuna parola era un codice di carattere ASCII. Ad esempio, il numero 41H codificava la lettera maiuscola 'A'. Il secondo byte era un attributo di testo: il colore del glifo, il colore della parte di sfondo della cella del carattere, o presentazioni speciali come la sottolineatura.
</p>

<p align=justify>
Questo sistema ha reso molto facile e molto veloce visualizzare il testo utilizzando librerie di linguaggio assembly relativamente semplici. Sfortunatamente, l'accesso diretto alla scheda video e alle periferiche di sistema è una violazione delle protezioni della modalità protetta. Il perché è semplice: la modalità protetta rende possibile l'esecuzione di più programmi contemporaneamente e, se più di un programma in esecuzione tentasse di modificare contemporaneamente la memoria video, ne risulterebbe un caos video. Il buon vecchio DOS era rigorosamente un sistema operativo a singola attività, quindi comunque solo un programma era in esecuzione alla volta. Per avere il multitasking in un modo che abbia senso, un sistema operativo deve gestire l'accesso al video, attraverso intricate librerie di codice di visualizzazione video che a loro volta accedono all'hardware di visualizzazione tramite software driver che girano accanto al kernel nello spazio del kernel. I driver consentono al sistema operativo di confinare l'output video di un singolo programma a una finestra sullo schermo, in modo che qualsiasi numero ragionevole di programmi in esecuzione possa visualizzare la propria uscita simultaneamente senza sovrapporsi all'uscita degli altri programmi. Ora, detto ciò, c'è un modo per impostare un buffer nella memoria utente e poi dire a Linux di usarlo per la visualizzazione video. Questo comporta un certo lavoro intorno al dispositivo framebuffer di Linux dev/fb0 e alle funzioni mmap e ioctl, ma non è affatto semplice e lontano da essere veloce. Il meccanismo è utile per portare antichi programmi DOS su Linux, ma per i nuovi programmi è di gran lunga più problematico di quanto ne valga la pena.
</p>

### Accesso diretto alle porte hardware

<p align=justify>
Negli anni del DOS, i PC avevano porte seriali e parallele controllate da chip di controllo separati sulla scheda madre. Come tutto il resto nella macchina, questi chip di controllo potevano essere accessibili direttamente da qualsiasi software in esecuzione sotto DOS. Scrivendo valori di controllo mappati a bits nei chip e creando routine di servizio per interruzioni personalizzate, si poteva creare software per interfacce seriali su misura, che permetteva ai lenti modem dial-up da 300 caratteri al secondo di quell'epoca di funzionare alla velocità massima possibile. Questo era routinario, ma con un po' di ingegno si potevano far fare all'hardware standard del computer cose per cui non era realmente destinato. Ancora una volta, come per il video, i requisiti del multitasking richiedono che il sistema operativo gestisca l'accesso alle porte, cosa che fa attraverso driver e librerie di codice; ma a differenza del video, usare driver per interfacciarsi con le porte è in realtà molto più semplice che controllare completamente le porte da soli.
</p>

### Chiamate dirette al BIOS

<p align=justify>
La terza tecnica dell'era DOS a cui abbiamo dovuto rinunciare a causa dei rigori della modalità protetta è l'invocazione diretta delle routine BIOS del PC. IBM ha inserito una libreria di codice nella memoria di sola lettura (ROM) per la gestione di base del video e delle periferiche come le porte. Nell'era DOS era possibile per il software invocare direttamente queste routine BIOS senza limitazione. La modalità protetta riserva le chiamate BIOS al sistema operativo, ma in verità, anche i sistemi operativi in modalità protetta fanno poco con le chiamate BIOS dirette al giorno d'oggi. Quasi tutto l'accesso a basso livello all'hardware avviene attraverso driver installabili. I sistemi operativi normalmente effettuano chiamate BIOS per determinare informazioni sulla configurazione hardware per cose come la gestione dell'alimentazione. Come sorta di premio di consolazione, Linux fornisce un elenco di funzioni a basso livello che possono essere chiamate attraverso un meccanismo molto simile alle chiamate BIOS, utilizzando l'interruzione software 80H.
</p>

### 64bit Long Mode

<p align=justify>
Tutti i computer al giorno d'oggi contengono CPU AMD o Intel che sono tecnicamente larghe 64 bit. Per utilizzare queste funzionalità a 64 bit, hai bisogno di un sistema operativo che sia stato esplicitamente compilato per esse e sappia come gestirle. Sia Windows che Linux sono disponibili in versioni compilate per la modalità lunga a 64 bit. Windows Vista e Windows XP sono stati disponibili in versioni a 64 bit per un po' di tempo. Windows 7 era disponibile sia in versioni a 32 bit che a 64 bit. E' utile avere un'idea di cosa offre la modalità lunga, in modo da poterla esplorare da solo mentre le tue abilità di programmazione maturano.
</p>

<p align=justify>
L'architettura x86 a 64 bit ha una storia peculiare: nel 2000, il concorrente di Intel, AMD, annunciò un superset a 64 bit dell'architettura IA-32. AMD non rilasciò CPU che implementavano questa nuova architettura fino al 2003, ma fu un attacco preventivo nelle guerre delle CPU. Intel aveva già un'architettura a 64 bit chiamata IA-64 Itanium, ma Itanium rappresentava una rottura netta con IA-32, e il software IA-32 non sarebbe potuto funzionare sui processori Itanium senza ricompilazione e, in alcuni casi, ricodifica. L'industria desiderava la compatibilità con le versioni precedenti, e la risposta all'architettura nuova di AMD fu così entusiastica che Intel fu costretta a recuperare terreno e implementare un'architettura compatibile con AMD, che chiamò Intel 64. Le prime CPU a 64 bit compatibili con AMD di Intel furono rilasciate alla fine del 2004. Il termine neutrale rispetto ai venditori "x86-64" viene ora applicato a caratteristiche implementate in modo identico da entrambe le aziende. L'architettura x86-64 definisce tre modalità generali: modalità reale, modalità protetta e modalità lunga. La modalità reale è una modalità di compatibilità che consente alla CPU di eseguire sistemi operativi e software più vecchi come DOS e Windows 3.1. In modalità reale, la CPU funziona proprio come fa una 8086 o un'altra CPU x86 in modalità reale, e supporta il modello piatto in modalità reale e il modello segmentato in modalità reale. La modalità protetta è anch'essa una modalità di compatibilità e fa sì che la CPU "appaia" come una CPU IA-32 per il software, in modo che le CPU x86-64 possano eseguire Windows 2000/XP/Vista/7 e altri sistemi operativi a 32 bit come Linux, oltre ai loro driver e applicazioni a 32 bit.
</p>

<p align=justify>
La modalità long è una vera modalità a 64 bit; e quando la CPU è in modalità long, tutti i registri sono larghi 64 bit e tutte le istruzioni macchina che agiscono su operandi a 64 bit sono disponibili. Tutti i registri disponibili in IA-32 sono presenti e sono stati estesi a 64 bit in larghezza. Le versioni a 64 bit dei registri sono rinominate a partire da R: EAX diventa RAX, EBX diventa RBX, e così via. Oltre ai familiari registri generali presenti in IA-32, ci sono otto nuovissimi registri generali a 64 bit senza controparti a 32 bit. Questi nuovi registri sono denominati R8 fino a R15.  x86-64 aggiunge otto registri SSE a 128 bit agli otto di IA-32, per un totale di 16. Tutti questi nuovi registri sono come manna dal cielo per i programmatori assembly in cerca di aumenti nella velocità di esecuzione. Il posto più veloce dove memorizzare i dati è nei registri, e i programmatori che hanno sofferto per la scarsità di registri delle prime CPU x86 guarderanno a quell'ammasso di ricchezza interna e rimarranno sbalorditi.
</p>

<p align=justify>
Come ho descritto in precedenza, 32 bit possono indirizzare solo 4 gigabyte di memoria. Sono state utilizzate varie astuzie per rendere disponibile più memoria ai programmi in esecuzione su CPU IA-32. In modalità long a 64 bit abbiamo un problema simile al contrario: 64 bit possono indirizzare un'immensità di memoria tale che i sistemi di memoria che richiedono uno spazio di indirizzo di 64 bit non saranno creati per molti anni a venire. (Mi trattengo un po' qui ricordando a me stesso e a tutti voi che abbiamo detto cose simili in passato, solo per ritrovarci con le mani nei capelli.) 64 bit possono indirizzare 16 exabyte. Un exabyte è 2^60 byte, che può essere descritto più comprensibilmente come un miliardo di gigabyte, che equivale a poco più di un quintilione di byte. Ci arriveremo prima o poi, ma non ci siamo ancora. La questione critica per il qui e ora è questa: gestire tutti i bit in quegli indirizzi a 64 bit richiede transistor all'interno della microarchitettura della CPU. Pertanto, invece di sprecare transistor sul chip per gestire le linee di indirizzo di memoria che non verranno utilizzate durante la vita prevista del chip della CPU (o anche dell'architettura x86-64 stessa), i produttori di chip hanno limitato il numero di linee di indirizzo che sono realmente funzionali nelle implementazioni attuali dei chip. I chip CPU x86-64 che puoi acquistare oggi implementano 48 bit di indirizzo per la memoria virtuale e solo 40 bit per la memoria fisica. Questo è ancora molto più memoria fisica di quanto tu possa inserire in qualsiasi computer fisico al momento: 2^40 rappresenta un terabyte; praticamente poco più di mille gigabyte, o un trilione di byte. Ci sono alcune differenze nel modo in cui Linux a 64 bit gestisce le chiamate di funzione, ma la modalità long a 64 bit è ancora un modello piatto, ed è molto più simile al modello piatto a 32 bit di quanto il modello piatto a 32 bit sia al modello segmentato della modalità reale che abbiamo subito per i primi 15 o 20 anni dell'era PC. Questo è sufficiente per ora riguardo alla piattaforma su cui il nostro codice verrà eseguito. 
</p>

## Il primo programmma assembly (eatsyscall.asm)

```asm
;  Executable name : eatsyscall
;  Version         : 1.0
;  Created date    : 4/25/2022
;  Last update     : 5/10/2023
;  Author          : Jeff Duntemann
;  Architecture    : x64
;  From            : x64 Assembly Language Step By Step, 4th Edition
;  Description     : A simple program in assembly for x64 Linux, using NASM 2.14,
;                    demonstrating the use of the syscall instruction to display text.
;                    Not for use with SASM.
;
;  Build using these commands:
;    nasm -f elf64 -g -F stabs eatsyscall.asm
;    ld -o eatsyscall eatsyscall.o
;

SECTION .data          ; Section containing initialised data
	
	EatMsg: db "Eat at Joe's!",10
 	EatLen: equ $-EatMsg	
	
SECTION .bss           ; Section containing uninitialized data	

SECTION .text          ; Section containing code

global 	_start	       ; Linker needs this to find the entry point!
	
_start:
    push rbp
    mov rbp,rsp

    mov rax,1           ; 1 = sys_write for syscall
    mov rdi,1           ; 1 = fd for stdout; i.e., write to the terminal window
    mov rsi,EatMsg      ; Put address of the message string in rsi
    mov rdx,EatLen      ; Length of string to be written in rdx
    syscall             ; Make the system call

    mov rax,60          ; 60 = exit the program
    mov rdi,0           ; Return value in rdi 0 = nothing to return
    syscall             ; Call syscall to exit
```

## Il primo programmma assembly in SASM (eatsyscallgcc.asm)

<p align=justify>
Se il tuo assemblatore è SAMS (un assemblatore grafico, al contrario di asm che è solo a riga di comando) il codice è leggermente differente, parleremo delle differenze nei paragrafi successivi
</p>

```asm
;  Executable name : eatsyscallgcc (For linking with gcc)
;  Version         : 1.0
;  Created date    : 4/25/2022    
;  Last update     : 4/10/2023     
;  Author          : Jeff Duntemann          
;  Architecture    : x64    
;  From            : x64 Assembly Language Step By Step, 4th Edition
;  Description     : A simple program in assembly for x64 Linux, using NASM 2.14,
;                  : demonstrating the use of the syscall instruction to display text.
;
;                  : Build using the default build configuration in SASM
;  
 
SECTION .data           ; Section containing initialized dat
 EatMsg: db "Eat at Joe's!",10
 EatLen: equ $-EatMsg
 
SECTION .bss            ; Section containing uninitialized data       
SECTION .text           ; Section containing code           

global   main           ; Linker needs this to find the entry point!

main:
  mov rbp,rsp            ; SASM may add another copy of this in debug mode!
 
  mov rax,1             ; 1 = sys_write for syscall    
  mov rdi,1             ; 1 = fd for stdout
                        ; write to theterminal window
  mov rsi,EatMsg        ; Put address of the message string in rsi
  mov rdx,EatLen        ; Length of string to be written in rdx
  syscall               ; Make the system call

  mov rax,60            ; 60 = exit the program 
  mov rdi,0             ; Return value in rdi 0 = nothing to return
  syscall               ; Call syscall to exit   
```

### Template per nasm

```asm
section .data
section .text
section .bss

global 	_start
	
_start:

     nop

; Put your experiments between the two nops...
; Put your experiments between the two nops...

     nop

     mov rax,60   	; Code for Exit Syscall
     mov rdi,0		; Return a code of zero    
     syscall		; Make kernel call      
```

### Template per sasm

```asm
section .data
section .text
section .bss

global main

main:
    mov rbp,rsp  ; Save stack pointer for debugger
    nop

; Put your experiments between the two nops...
; Put your experiments between the two nops...

     nop

     mov rax,60   	; Code for Exit Syscall
     mov rdi,0		; Return a code of zero    
     syscall		; Make kernel call      
```

<p align=justify>
Ciò di cui abbiamo bisogno è un punto di partenza contrassegnato come globale — qui, l'etichetta principale. (<b>L'uso di main è un requisito di SASM, non di NASM.</b> vedi il template di nasm sopra) Dobbiamo anche definire una sezione dati e una sezione testo come mostrato. La sezione dati (<code>.data</code>) contiene i dati a cui devono essere assegnati valori iniziali quando il programma viene eseguito. Il vecchio messaggio pubblicitario "Eat at Joe's" era un elemento dati nominato nella sezione dati. La sezione testo (<code>.text</code>) contiene il codice del programma. <b>Entrambe queste sezioni (<code>.data</code> <code>.text</code>) sono necessarie per creare un eseguibile, anche se una o entrambe sono vuote</b>. <b>La sezione contrassegnata <code>.bss</code> non è strettamente essenziale</b>, ma è utile averla se prevedi di sperimentare. <b>La sezione <code>.bss</code> contiene dati non inizializzati</b>, cioè spazio riservato per elementi dati a cui non vengono assegnati valori iniziali quando il programma inizia a essere eseguito. Questi sono fondamentalmente buffer vuoti, per dati che saranno generati o letti da qualche parte mentre il programma è in esecuzione. Per consuetudine, la sezione .bss si trova dopo la sezione .text. 
</p>

<p align=justify>
Nei template sono presenti due istruzioni NOP. Ricorda che le istruzioni NOP non fanno altro che richiedere un po' di tempo. Sono lì per rendere più facile guardare il programma nel debugger SASM. Per giocare con le istruzioni della macchina, inserisci le istruzioni di tua scelta tra i due commenti. Compila il programma, fai clic sul pulsante Debug e divertiti! Impostare un punto di interruzione in corrispondenza della prima istruzione inserita tra i commenti e fare clic su Debug. L'esecuzione inizierà e si fermerà in corrispondenza del punto di interruzione. Per osservare gli effetti di tale istruzione, fare clic sul pulsante Esegui passaggio. Ecco perché c'è la seconda istruzione NOP: quando si esegue un'istruzione a passo singolo, ci deve essere un'istruzione dopo quell'istruzione per l'esecuzione su cui mettere in pausa. Se la prima istruzione nella sandbox è l'ultima istruzione, l'esecuzione verrà "eseguita oltre il limite" nel primo passaggio singolo e il programma terminerà. Quando ciò accade, i riquadri Registri e Memoria di SASM diventeranno vuoti e non sarai in grado di vedere gli effetti di quell'unica istruzione! L'idea di correre fuori dal bordo del programma è interessante. Se fai clic sul pulsante Debug o premi il tasto di scelta rapida F5, vedrai cosa succede quando non chiudi correttamente il programma: Linux consegnerà un errore di segmentazione, che può avere una serie di cause. Tuttavia, ciò che è accaduto in questo caso è che il programma ha tentato di eseguire una posizione oltre la fine della sezione .text. Linux sa quanto è lungo il tuo programma e non ti permetterà di eseguire istruzioni che non erano presenti nel tuo programma quando è stato caricato. Non c'è alcun danno duraturo in questo, ovviamente. Linux è molto bravo a gestire programmi che si comportano male e malformati (specialmente quelli semplici), e nulla di ciò che probabilmente farai per caso avrà alcun effetto sull'integrità di Linux stesso. È possibile evitare di generare l'errore di segmentazione facendo clic sul pulsante rosso Stop prima di inviare l'esecuzione alla fine del piccolo programma sperimentale. SASM passerà dalla modalità di debug alla modalità di modifica. Tenere presente che se si esce dalla modalità di debug, non sarà più possibile visualizzare i registri o gli elementi di memoria. Naturalmente, se si desidera semplicemente far eseguire un programma, è possibile aggiungere alcune righe che effettuano una SYSCALL alla routine di uscita x64 alla fine della sandbox. In questo modo, se l'esecuzione viene eseguita dalla parte inferiore degli esperimenti, la chiamata SYSCALL interromperà automaticamente l'esecuzione. Di seguito è riportato il codice per l'uscita SYSCALL. Posiziona questo codice dopo il secondo NOP, e sei a posto.
</p>

```asm
mov rax,60   	; Code for Exit Syscall
mov rdi,0	; Return a code of zero    
syscall		; Make kernel call  
```

### Le Istruzione ed i loro operandi

<p align=justify>
L'attività più comune nel lavoro con il linguaggio assembly è spostare dati da un luogo all'altro. Ci sono diversi modi specializzati per farlo, ma solo un modo veramente generale: l'istruzione <code>MOV</code>. <code>MOV</code> può spostare un byte, una parola (16 bit), una doppia parola (32 bit) o una quadrupla parola (64 bit) di dati da un registro a un altro, da un registro alla memoria, o dalla memoria a un registro. <b>Ciò che <code>MOV</code> non può fare è spostare dati direttamente da un indirizzo in memoria a un altro indirizzo in memoria</b>. (Per farlo, sono necessarie due istruzioni MOV separate: prima dalla memoria a un registro e poi da quel registro di nuovo in un altro luogo nella memoria.) Il nome <code>MOV</code> è un po' fuorviante, poiché ciò che accade effettivamente è che i dati vengono copiati da una sorgente a una destinazione. Una volta copiati nella destinazione, tuttavia, i dati non scompaiono dalla sorgente, ma continuano a esistere in entrambi i luoghi. Questo confligge un po' con la nostra nozione intuitiva di spostare qualcosa, che di solito significa che qualcosa scompare da un luogo sorgente e riappare in un luogo di destinazione.
</p>

### Operandi Sorgente e Destinazione

<p align=justify>
La maggior parte delle istruzioni della macchina, inclusa <code>MOV</code>, ha uno o più operandi. (Alcune istruzioni non hanno operandi o operano implicitamente su registri o memoria. Quando questo è il caso, lo menzionerò nel testo.) Considera questa istruzione macchina: 
</p>	

```asm
 	mov rax,1
``` 
 
<p align=justify>
Ci sono due operandi nell'istruzione precedente. Il primo è RAX e il secondo è il numero 1. <b>Per convenzione nel linguaggio assembly, il primo operando (quello più a sinistra) appartenente a un'istruzione macchina è l'operando di destinazione</b>. <b>Il secondo operando da sinistra è l'operando sorgente</b>. Con l'istruzione  <code>MOV</code>, il significato dei due operandi è piuttosto letterale: l'operando sorgente viene copiato nell'operando di destinazione. Nell'istruzione precedente, l'operando sorgente (il valore letterale 1) viene copiato nell'operando di destinazione RAX. Il significato di sorgente e destinazione non è affatto così letterale in altre istruzioni, ma una regola generale è questa: ogni volta che un'istruzione macchina causa la generazione di un nuovo valore, quel nuovo valore viene posto nell'operando di destinazione. <b>Ci sono tre diversi tipi di dati che possono essere utilizzati come operandi</b>. Questi sono: <b>dati di memoria</b>, <b>dati di registri</b> e <b>dati immediati</b>. Ho esposto alcune istruzioni <code>MOV</code> di esempio nella tabella di sotto per darti un'idea di come i diversi tipi di dati sono specificati come operandi per l'istruzione <code>MOV</code>
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/move_and_its_operands.png">
</div>

### Dati Immediati

<p align=justify>
L'istruzione <code>MOV RAX,42h</code> è un buon esempio dell'uso di quello che si chiama <i>dato immediato</i>, acceduto attraverso una modalità di indirizzamento chiamata <b>indirizzamento immediato</b>. L'indirizzamento immediato prende il suo nome dal fatto che <b>l'elemento indirizzato è un dato incorporato direttamente nell'istruzione della macchina stessa</b>. La CPU non deve cercare altrove per trovare i dati immediati. Non si trova in un registro, né è memorizzato in un elemento dati da qualche parte nella memoria. I dati immediati si trovano sempre all'interno dell'istruzione che viene recuperata ed eseguita.
</p>

<p align=justify>
I dati immediati devono avere una dimensione appropriata per l'operando. Ad esempio, non puoi spostare un valore immediato a 16 bit in una sezione di registro a 8 bit come AH o DL. NASM non ti permetterà di assemblare un'istruzione come questa: 
</p>

```asm
	mov cl,067EFh 
 ```

<p align=justify>
CL è un registro a 8 bit e <code>067EFh</code> è una quantità a 16 bit. Non funziona! Poiché è incorporato direttamente in un'istruzione macchina, potresti pensare che i dati immediati sarebbero rapidi da accedere. Questo è vero solo fino a un certo punto: recuperare qualcosa dalla memoria richiede più tempo rispetto a recuperare qualcosa da un registro e le istruzioni sono, dopo tutto, memorizzate in memoria. Quindi, mentre indirizzare i dati immediati è un po' più veloce rispetto ad indirizzare dati normali memorizzati in memoria, nessuno dei due è così veloce come semplicemente estrarre un valore da un registro della CPU. Tieni anche presente che solo l'operando sorgente può essere un dato immediati. L'operando di destinazione è il luogo dove i dati arrivano, non da dove provengono. Poiché i dati immediati consistono in costanti letterali (numeri come 1, 0, 42 o 07F2Bh), cercare di copiare qualcosa nei dati immediati piuttosto che da essi non ha alcun significato ed è sempre un errore. NASM consente alcune interessanti forme di dati immediati. Ad esempio, la seguente è perfettamente legale, anche se non necessariamente utile come sembra a prima vista: 
</p>

```asm
	mov eax,'WXYZ'
```

<p align=justify>
Questa è una buona istruzione da caricare nel tuo assemblatore ed eseguire nel debugger. Guarda il contenuto del registro EAX nella vista registri: 0x5a595857 Questo potrebbe sembrare strano, ma guarda da vicino: gli equivalenti numerici dei caratteri ASCII maiuscoli W, X, Y e Z sono stati caricati in ordine in EAX. W è 57h, X è 58h, Y è 59h e Z è 5Ah. Ogni carattere equivalente ha una dimensione di 8 bit, quindi quattro di essi si adattano perfettamente nel registro a 32 bit EAX. Tuttavia, sono invertiti.
Bene, no. Ricorda il concetto di "endianness". L'architettura x86/x64 è "little endian", il che significa che il byte meno significativo in una sequenza multibyte è memorizzato all'indirizzo più basso. Questo si applica anche ai registri e ha senso una volta che capisci come ci riferiamo alle unità di memoria all'interno di un registro. La confusione nasce dalla nostra abitudine di leggere il testo da sinistra a destra, mentre leggiamo i numeri da destra a sinistra. Dai un'occhiata alla figura di sotto. (Questo esempio utilizza il registro a 32 bit EAX per rendere la figura meno complessa e più facile da capire.) Trattato come una sequenza di caratteri di testo, la W in WXYZ è considerata l'elemento meno significativo. EAX, tuttavia, è un contenitore per numeri, dove la colonna meno significativa è sempre (per le lingue occidentali) a destra. Il byte meno significativo in EAX lo chiamiamo AL, ed è lì che va la W. Il secondo byte meno significativo in EAX lo chiamiamo AH, ed è lì che va la X. I due byte più significativi in EAX non hanno nomi separati e non possono essere indirizzati individualmente, ma sono comunque byte a 8 bit e possono contenere valori a 8 bit come caratteri ASCII. Il carattere più significativo nella sequenza WXYZ è la Z, e viene memorizzato nel byte più significativo di EAX.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/strings_as_immediate_data.png">
</div>

### Dati di Registro

<p align=justify>
I dati memorizzati all'interno di un registro della CPU sono noti come <i>dati di registro</i>, e accedere ai dati di registro direttamente è una modalità di indirizzamento chiamata <b>indirizzamento per registro</b>. L'indirizzamento per registro viene effettuato semplicemente nominando il registro con cui vogliamo lavorare. Ecco alcuni esempi completamente legali di dati di registro e indirizzamento per registro:
</p>

```asm
	mov rbp,rsi   ; 64-bit
	add ecx,edx   ; 32-bit
	add di,ax     ; 16-bit
	mov bl,ch     ; 8-bit
```

<p align=justify>
Non stiamo parlando solo dell'istruzione <code>MOV</code> qui. L'istruzione <code>ADD</code> fa esattamente ciò che ci si può aspettare e aggiunge gli operandi sorgente e destinazione. La somma sostituisce qualunque cosa fosse presente nell'operando di destinazione. Indipendentemente dall'istruzione, l'indirizzamento dei registri avviene ogni volta che i dati in un registro vengono utilizzati direttamente. Certe operazioni non sono legali: esempio, spostare una sorgente di 8 byte in una destinazione di 2 byte e mentre spostare una sorgente di 2 byte in una destinazione di 8 byte potrebbe sembrare possibile e talvolta persino ragionevole, la CPU non lo supporta e non può essere fatto direttamente. Se ci provi, NASM ti darà questo errore.
</p>

```
 	error: invalid combination of opcode and operands
```

<p align=justify>
In altre parole, <b>se stai spostando dati da un registro a un altro, i registri sorgente e di destinazione devono avere la stessa dimensione</b>. Osservare i dati dei registri nel debugger è un buon modo per avere un'idea di come funziona, soprattutto quando stai iniziando. Facciamo un po' di pratica. Inserisci queste istruzioni nel tuo sandbox, costruisci l'eseguibile e carica l'eseguibile del sandbox nel debugger.
</p>

```asm
	xor rbx,rbx
 	xor rcx,rcx
 	mov rax,067FEh
 	mov rbx,rax
 	mov cl,bh
 	mov ch,bl
```

<p align=justify>
Imposta un punto di interruzione sulla prima delle istruzioni, quindi clicca su Esegui. Procedi passo dopo passo attraverso le istruzioni, prestando attenzione a quello che accade a RAX, RBX e RCX. Tieni presente che la finestra dei Registri di SASM non mostra le sezioni dei registri a 8 bit, 16 bit o 32 bit separatamente e individualmente. EAX fa parte di RAX, AX fa parte di EAX e CL fa parte di ECX, ecc. Qualsiasi cosa tu metta in RAX è già presente in EAX, AX e AL. Una volta terminato il passo dopo passo, clicca sull'icona rossa Stop per terminare il programma. Ricorda che se selezioni Debug ➪ Continua o cerchi di avanzare oltre la fine del programma, Linux ti darà un errore di segmentazione per non aver terminato il programma correttamente. Nulla sarà danneggiato dall'errore; ricorda che il sandbox non è previsto per essere un programma Linux completo e corretto. È buona prassi "terminare" il programma tramite Stop piuttosto che generare l'errore, tuttavia. Nota le prime due istruzioni. <b>Quando vuoi mettere il valore 0 in un registro, il modo più veloce è usare l'istruzione <code>XOR</code></b>, che esegue un'operazione XOR bitwise sugli operandi sorgente e destinazione. Sì, potresti usare
</p>

```asm
 	mov rbx,0
```

<p align=justify>
ma in questo modo si deve andare in memoria per caricare il valore immediato 0. L'operazione <code>XOR</code> tra un registro e se stesso non va in memoria né per l'operando sorgente né per l'operando di destinazione e pertanto è leggermente più veloce. Una volta azzerati RBX e RCX, ecco cosa succede: La prima istruzione (<code>mov rax,067FEh</code>) <code>MOV</code> è un esempio di indirizzamento immediato utilizzando registri a 64 bit. Il valore esadecimale a 16 bit <code>067FEH</code> viene spostato nel registro RAX. (Nota qui che puoi <code>MOV</code> un valore immediato di 16 bit o di qualsiasi altra dimensione che possa adattarsi al registro di destinazione.) La seconda istruzione (<code>mov rbx,rax</code>) utilizza l'indirizzamento del registro per copiare i dati del registro da EAX a EBX. La terza e la quarta istruzione <code>MOV</code> spostano entrambe i dati tra segmenti di registri a 8 bit piuttosto che a 16, 32 o 64 bit. Queste due istruzioni realizzano qualcosa di interessante. Guarda l'ultima visualizzazione del registro e confronta i valori di RBX e RCX. Spostando il valore da BX a CX un byte alla volta, è possibile invertire l'ordine dei due byte che costituiscono BX. La metà alta di BX (quello che a volte chiamiamo il byte più significativo, o MSB, di BX) è stata spostata nella metà bassa di CX. Poi la metà bassa di BX (quello che a volte chiamiamo il byte meno significativo, o LSB, di BX) è stata spostata nella metà alta di CX. Questo è solo un esempio dei tipi di trucchi che puoi fare con i registri a uso generale. Solo per disabituarti all'idea che l'istruzione <code>MOV</code> debba essere utilizzata per scambiare le due metà di un registro a 16 bit, lasciami suggerire di fare quanto segue: Torna a SASM e aggiungi questa istruzione alla fine della tua sandbox:
</p>

```asm
	xchg cl,ch
```

<p align=justify>
Ricostruisci la sandbox e torna al debugger per vedere cosa succede. L'istruzione <code>XCHG</code> scambia i valori contenuti nei suoi due operandi. Ciò che è stato scambiato in precedenza viene scambiato di nuovo e il valore in RCX corrisponderà ai valori già presenti in RAX e RBX. Una buona idea durante la scrittura dei primi programmi in linguaggio assembly è quella di ricontrollare periodicamente il set di istruzioni per vedere che ciò che si è messo insieme con quattro o cinque istruzioni non è possibile utilizzando una singola istruzione. Il set di istruzioni Intel è molto bravo a ingannarti in questo senso. C'è un'avvertenza qui: a volte un "caso speciale" è più veloce in termini di tempo di esecuzione della macchina rispetto a un caso più generale. La divisione per una potenza di 2 può essere eseguita utilizzando l'istruzione <code>DIV</code>, ma può anche essere eseguita utilizzando l'istruzione <code>SHR</code> (Shift Right). <code>DIV</code> è più generale (puoi usarlo per dividere per qualsiasi intero senza segno, non semplicemente potenze di 2), ma è molto più lento. La velocità delle singole istruzioni conta molto meno ora di quanto non lo fosse 30 anni fa. Detto questo, per i programmi con funzioni ripetitive complesse che vengono eseguite migliaia o centinaia di migliaia di volte in un ciclo, la velocità delle istruzioni può fare la differenza
</p>

### Dati di Memoria ed Effective Addresses

<p align=justify>
I dati immediati sono incorporati direttamente nell'istruzione macchina. I dati di registro vengono memorizzati in uno dei registri interni della CPU. Al contrario, i dati di memoria vengono memorizzati in qualche luogo nella porzione di memoria di sistema possudeta da un programma, a un indirizzo di memoria a 64 bit. Con una o due eccezioni importanti (le istruzioni sulle stringhe), <b>solo uno dei due operandi di un'istruzione può specificare una posizione di memoria</b>. In altre parole, puoi trasferire un valore immediato in memoria, un valore di memoria in un registro, o qualche altra combinazione simile, ma <b>non puoi trasferire un valore di memoria direttamente in un altro valore di memoria</b>. Questa è una limitazione intrinseca delle CPU Intel di tutte le generazioni (non solo x64), e dobbiamo farci i conti, per quanto possa essere scomodo a volte. <b>Per specificare che desideriamo i dati nella posizione di memoria contenuta in un registro piuttosto che i dati nel registro stesso, utilizziamo le parentesi quadre attorno al nome del registro</b>. In altre parole, per spostare il quadword in memoria all'indirizzo contenuto in RBX nel registro RAX, useremmo la seguente istruzione.
</p>

```asm
 mov rax,[rbx]
```

<p align=justify>
Le parentesi quadre possono contenere più del nome di un singolo registro a 64 bit, come impareremo in dettaglio più avanti. Ad esempio, puoi aggiungere una costante letterale a un registro all'interno delle parentesi quadre, e NASM eseguirà il calcolo. 
</p>

```asm
	mov rax,[rbx+16]
```

<p align=justify>
Lo stesso vale per l'aggiunta di due registri a uso generale, in questo modo: 
</p>

```asm
	mov rax,[rbx+rcx]
```

<p align=justify>
E come se non bastasse, puoi aggiungere due registri più una costante letterale. 
</p>

```asm
	mov rax,[rbx+rcx+11]
```

<p align=justify>
Naturalmente non tutto è consentito. <b>Ciò che si trova all'interno delle parentesi quadre è chiamato indirizzo efficace (<i>effective address</i>)</b> di un elemento dati in memoria, e ci sono regole che dettano ciò che può essere un indirizzo efficace valido e ciò che non può. Nell'attuale evoluzione dell'hardware Intel, è possibile sommare due registri per formare l'indirizzo efficace, ma non tre o più. In altre parole, queste non sono forme legali di indirizzo efficace: 

```asm
	mov rax,[rbx+rcx+rdx] 
 	mov rax,[rbx+rcx+rsi+rdi] 
```

### Il dato ed il suo indirizzo

<p align=justify>
Questo suona banale, ma fidati, è una cosa abbastanza facile da fare. Torniamo alla Definizione di dati nella Lista 5.1, avevamo questa definizione di dati e questa istruzione: 
</p>

```asm
	EatMsg: db "Mangia da Joe!" 
 	. . . . 
 	mov rsi, EatMsg 
```

<p align=justify>
Se hai avuto qualche esperienza con linguaggi di alto livello, il tuo primo istinto potrebbe essere quello di assumere che qualsiasi dato conservato in EatMsg verrà copiato in RSI. L'assemblaggio non funziona in questo modo. Quella istruzione <code>MOV</code> copia effettivamente l'indirizzo di EatMsg, non ciò che è memorizzato in (effettivamente, presso) EatMsg. <b>Nel linguaggio assemblatore, i nomi delle variabili rappresentano indirizzi, non dati!</b> Quindi, come si fa a "raggiungere" i dati rappresentati da una variabile come EatMsg? Ancora una volta, si fa con le parentesi quadre. 
</p>	

```asm
	mov rdx, [EatMsg]
```

<p align=justify>
Ciò che fa questa istruzione è andare alla posizione in memoria specificata dall'indirizzo rappresentato da EatMsg, prelevare i primi 64 bit di dati da quell'indirizzo e caricare quei dati in RDX partendo dal byte meno significativo in RDX. Date le informazioni che abbiamo definito per EatMsg, ciò sarebbero gli otto caratteri E, a, t, uno spazio, a, t, uno spazio e J.
</p>

### La dimensione dei dati di memoria

<p align=justify>
Ma cosa succede se si vuole lavorare con un solo byte e non con i primi otto? Fondamentalmente, se si desidera utilizzare un byte di dati, è necessario caricarlo in un contenitore di dimensione di un byte. Il registro RAX ha una dimensione di 64 bit. Tuttavia, possiamo indirizzare il byte meno significativo di RAX come AL. AL ha una dimensione di un byte e, rendendo AL l'operando di destinazione, possiamo riportare il primo byte di EatMsg in questo modo:
</p>

```asm
	mov al,[EatMsg] AL
```

<p align=justify>
ovviamente, è contenuto all'interno di RAX, non è un registro separato. Ma il nome "AL" ci permette di recuperare dalla memoria un solo byte alla volta. Possiamo eseguire un trucco simile usando il nome EAX per riferirci ai 4 byte inferiori (32 bit) di RAX: 
</p>	

```asm
 mov eax,[EatMsg]
```

<p align=justify>
Questa volta, i caratteri E, a, t e uno spazio vengono letti dalla memoria e inseriti nei quattro byte meno significativi di RAX. Il problema delle dimensioni diventa complicato quando si scrivono i dati in un registro in memoria. NASM non "ricorda" le dimensioni delle variabili, come fanno i linguaggi di livello superiore. Sa dove inizia EatMsg nella memoria, e basta. Devi dire a NASM quanti byte di dati spostare. Questa operazione viene eseguita da un identificatore di dimensioni. Ecco un esempio:
</p>	

```asm
  mov byte [EatMsg],'G'
```

<p align=justify>
Qui, diciamo a NASM che vogliamo spostare solo un singolo byte in memoria utilizzando l'identificatore di dimensione BYTE. Altri identificatori di dimensioni includono WORD (16 bit), DWORD (32 bit) e QWORD (64 bit).
</p>

<p align=justify>
Sii felice di imparare l'assembly Intel ai giorni nostri. Era molto più complicato negli anni passati. In modalità reale sotto DOS, c'erano diverse restrizioni sui componenti di un <i>effective addrress</i> che semplicemente non esistono oggi, né in modalità protetta a 32 bit né in modalità lunga a 64 bit. In modalità reale, solo alcuni registri generali x86 potevano contenere un indirizzo di memoria: BX, BP, SI e DI. Gli altri, AX, CX e DX, non potevano. Peggio ancora, ogni indirizzo aveva due parti. Dovevi prestare attenzione a quale segmento apparteneva un indirizzo e dovevi assicurarti di specificare il segmento quando non era ovvio.
</p>

### Il registro RFLAGS

<p align=justify>
RFlags è un vero e proprio cassetto di spazzatura di piccoli pezzi di informazioni disgiunte ed è difficile (e forse fuorviante) sedersi e descrivere tutto in dettaglio tutto in una volta. Quello che farò è descrivere brevemente i flag della CPU qui e poi in modo più dettagliato mentre li incontriamo discutendo delle varie istruzioni che modificano i valori dei flag o li usano durante un ramificamento. Un flag è un singolo bit di informazioni il cui significato è indipendente da qualsiasi altro bit. Un bit può essere impostato a 1 o azzerato a 0 dalla CPU secondo necessità. L'idea è di comunicare a te, il programmatore, lo stato di certe condizioni all'interno della CPU in modo che il tuo programma possa testare e agire in base agli stati di quelle condizioni. Molto più raramente, sei tu, il programmatore, a impostare un flag come modo per segnalare qualcosa alla CPU. RFlags nel suo insieme è un singolo registro a 64 bit sepolto all'interno della CPU. È l'estensione a 64 bit del registro EFlags a 32 bit, che a sua volta è l'estensione a 32 bit del registro Flags a 16 bit presente nelle antiche CPU 8086/8088. <b>Solo 18 bit del registro RFlags sono effettivamente flag</b>. Il resto è riservato per un uso futuro nelle generazioni future di CPU Intel.
</p>

<p align=justify>
È un po' un pasticcio, ma dai un'occhiata alla figura di sotto , che riassume tutti flags ttualmente definite nell'architettura x64. I flags su uno sfondo grigio sono quelle arcane che puoi ignorare tranquillamente per il momento. Gli spazi e le linee colorate di nero sono considerati riservati e non contengono flags definite. Ogni flags del registro RFlags ha un simbolo di due, tre o quattro lettere con cui la maggior parte dei programmatori le conosce. Ecco i flags più comuni, i loro simboli e brevi descrizioni di cosa rappresentano:
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/rflags_register.png">
</div>

<ul>
	<li>
		<p align=justify>
			<b>OF:</b> Il flag di Overflow è impostato quando il risultato di un'operazione aritmetica su una quantità intera firmata diventa troppo grande per adattarsi all'operando che occupava originariamente. OF è generalmente usato come il “flag di riporto” nell'aritmetica firmata.
		</p>
	</li>	
 	<li>
		<p align=justify>
			<b>DF:</b> Il flag di direzione è un'anomalia tra i flag in quanto comunica alla CPU qualcosa che si desidera che essa sappia, piuttosto che il contrario. Esso determina la direzione in cui l'attività si muove (verso la memoria alta o verso la memoria bassa) durante l'esecuzione delle istruzioni di stringa. Quando DF è attivato, le istruzioni di stringa procedono dalla memoria alta verso la memoria bassa. Quando DF è disattivato, le istruzioni di stringa procedono dalla memoria bassa verso la memoria alta.
		</p>
	</li>
  	<li>
		<p align=justify>
			<b>IF:</b> Il flag di abilitazione degli interrupt è un flag a due vie. La CPU lo imposta in determinate condizioni e puoi impostarlo tu stesso utilizzando le istruzioni STI e CLI—anche se probabilmente non lo farai; vedi sotto. Quando IF è impostato, gli interrupt sono abilitati e possono verificarsi su richiesta. Quando IF è disattivato, gli interrupt sono ignorati dalla CPU. I programmi ordinari potevano impostare e disattivare questo flag senza conseguenze in Modalità Reale, nell'era DOS. Sotto Linux (sia a 32 bit che a 64 bit) IF è riservato all'uso del sistema operativo e talvolta dei suoi driver. Se provi a utilizzare le istruzioni STI e CLI all'interno di uno dei tuoi programmi, Linux ti mostrerà un errore di protezione generale e il tuo programma verrà terminato. Considera IF come off-limits per la programmazione degli spazi utente, come stiamo discutendo in questo libro.
		</p>
	</li>
 	<li>
		<p align=justify>
			<b>TF:</b> Quando impostato, il flag di Trap consente ai debugger di gestire il passo singolo, costringendo la CPU ad eseguire solo un'istruzione prima di chiamare una routine di interrupt. Questo non è un flag particolarmente utile per la programmazione ordinaria, e non avrò nulla di più da dire al riguardo in questo libro.
		</p>
	</li>
 	<li>
		<p align=justify>
			<b>SF:</b> Il flag di segnale diventa attivo quando il risultato di un'operazione costringe l'operando a diventare negativo. Con negativo intendiamo solo che il bit di ordine più alto nell'operando (il bit di segno) diventa 1 durante un'operazione aritmetica con segno. Qualsiasi operazione che lascia il segno del risultato positivo azzererà SF.
		</p>
	</li>
 	<li>
		<p align=justify>
			<b>ZF:</b> Il flag Zero viene impostato quando i risultati di un'operazione diventano zero. Se l'operando di destinazione invece diventa un valore diverso da zero, ZF viene resettato. Userai questo flag molto spesso per i salti condizionali.
		</p>
	</li>
 	<li>
		<p align=justify>
			<b>A:</b> Il flag di trasporto ausiliario è utilizzato solo per l'aritmetica BCD. L'aritmetica BCD tratta ogni byte operando come una coppia di "nybbles" a 4 bit e consente di eseguire direttamente nel hardware della CPU un'aritmetica che si avvicina al decimale (base 10) utilizzando una delle istruzioni di aritmetica BCD. Queste istruzioni sono considerate obsolete e non sono presenti in x64. Non le tratto in questo libro.
		</p>
	</li>
 	<li>
		<p align=justify>
			<b>PF:</b> Il flag di parità sembrerà istantaneamente familiare a chiunque comprenda le comunicazioni dati seriali e totalmente bizzarro a chi non lo fa. PF indica se il numero di bit impostati (1) nel byte di ordine inferiore di un risultato è pari o dispari. Ad esempio, se il risultato è 0F2H, PF sarà resettato perché 0F2H (11110010) contiene un numero dispari di bit a 1. Allo stesso modo, se il risultato è 3AH (00111100), PF sarà impostato perché ci sono un numero pari (quattro) di bit a 1 nel risultato. Questo flag è una sopravvivenza dei tempi in cui tutte le comunicazioni informatiche venivano effettuate tramite una porta seriale, per la quale un sistema di rilevamento degli errori chiamato controllo della parità dipende dal sapere se un conteggio dei bit impostati in un byte di carattere è pari o dispari. PF è usato molto raramente e non lo descriverò ulteriormente.
		</p>
	</li>
 	<li>
		<p align=justify>
			<b>CF:</b> Il flag di riporto viene utilizzato nelle operazioni aritmetiche senza segno. Se il risultato di un'operazione aritmetica o di spostamento "riporta" un bit dall'operando, CF viene impostato. Altrimenti, se non viene riportato nulla, CF viene azzerato.
		</p>
	</li>
</ul>

<table>
	<td>⚠️ <b>Warning</b>
	<p align=justify>
Devi ricordare che le descrizioni sui flags fatte sopra sono solo generalizzazioni e sono soggette a specifiche restrizioni e casi speciali imposti da istruzioni individuali. Il comportamento dei flags varia ampiamente da istruzione a istruzione, anche se il significato dell'uso del flags può essere lo stesso in ogni caso. Ad esempio, alcune istruzioni che causano l'apparire di uno zero in un operando impostano ZF, mentre altre no. Purtroppo, non c'è un sistema e non c'è un modo facile per tenerlo chiaro nella tua mente. Quando intendi usare i flags nei test tramite istruzioni di salto condizionale, devi controllare ogni singola istruzione per vedere come vengono influenzate i vari flags.
	</p>
	</td>
</table>

<p align=justify>
Il registro RFlags è un registro, proprio come RAX, e quando si è in modalità di debug, il suo valore viene visualizzato nella vista Registri di SASM. I valori dei flags sono indicati tra parentesi quadre. Quando si inizia a eseguire il debug del codice in spazio utente, SASM mostra in genere i nomi dei flag PF, ZF e IF. [ PF ZF IF ] Ciò significa che, per qualsiasi motivo, quando Linux consente di iniziare il debug, vengono impostati i flag Parity, Zero e Interrupt Enable. Questi valori iniziali sono "residui" del codice eseguito in precedenza e non sono in alcun modo causati dal codice nel debugger. I loro valori, inoltre, non hanno alcun significato nella sessione di debug e quindi non hanno bisogno di interpretazione. Quando si esegue un'istruzione che influisce sui flag in una sessione di debug, SASM mostrerà il nome di un flag se tale flag è impostato o cancellerà il nome del flag se tale flag viene cancellato
</p>

### Aggiungere e Sottrarre 1 con INC e DEC

<p align=justify>
Una semplice lezione sul comportamento dei flags coinvolge le due istruzioni <code>INC</code> e <code>DEC</code>. Diverse istruzioni macchina x86 arrivano in coppie, tra cui <code>INC</code> e <code>DEC</code>. Esse incrementano e decrementano un operando di uno, rispettivamente. Aggiungere uno a qualcosa o sottrarre uno da qualcosa sono azioni che si verificano molto nella programmazione informatica. Se stai contando il numero di volte in cui un programma esegue un ciclo, contando i byte in una tabella, o facendo qualcosa che avanza o retrocede di uno alla volta, <code>INC</code> e <code>DEC</code> possono essere modi molto rapidi per rendere l'aggiunta o la sottrazione effettiva. Sia <code>INC</code> che <code>DEC</code> richiedono solo un operando. Un errore verrà segnalato dall'assemblatore se provi a utilizzare <code>INC</code> o <code>DEC</code> con due operandi o senza alcun operando. Nessuno dei due funzionerà sui dati immediati. Prova entrambi aggiungendo le seguenti istruzioni nel tuo sandbox. Costruisci il sandbox come al solito, entra in modalità debug e fai un passo attraverso di esso:
</p>

```asm
	 mov eax,0FFFFFFFFh
	 mov ebx,02Dh
	 dec ebx
	 inc eax
```

<p align=justify>
Osserva cosa succede ai registri EAX e EBX. Decrementare EBX trasforma prevedibilmente il valore 2DH nel valore 2CH. Incrementare 0FFFFFFFFH, d'altra parte, fa ripartire il registro EAX a 0, perché 0FFFFFFFFH è il valore non firmato più grande che può essere espresso in un registro a 32 bit. (Ho usato EAX nell'esempio qui perché riempire il registro a 64 bit RAX con bit richiede molti Fs!) Aggiungere 1 a esso lo riporta a zero, proprio come aggiungere 1 a 99 porta le due cifre più a destra della somma a zero creando il numero 100. La differenza con INC è che non c'è carry. Il flag Carry non è influenzato da INC, quindi non cercare di usarlo per eseguire aritmetica a più cifre.
</p>

<ul>
	<li>
		<p align=justify>
			Il flag di overflow (OF) è stato azzerato perché l'operando, interpretato come un intero con segno, non è diventato troppo grande per adattarsi in EBX. Questo potrebbe non esserti utile se non sai cosa rende un numero "con segno", quindi per il momento lasciamo stare.
		</p>	
	</li>
 	<li>
		<p align=justify>
			Il flag di segnale (SF) è stato azzerato perché il bit alto di EBX non è diventato 1 a seguito dell'operazione. Se il bit alto di EBX fosse diventato 1, il valore in EBX, interpretato come un valore intero firmato, sarebbe diventato negativo, e SF è impostato quando un valore diventa negativo. Come per OF, SF non è molto utile a meno che non si stia eseguendo aritmetica firmata.
		</p>	
	</li>
 	<li>
		<p align=justify>
			Il flag Zero (ZF) è stato azzerato perché l'operando di destinazione non è diventato zero. Se fosse diventato zero, ZF sarebbe stato impostato a 1.
		</p>	
	</li>
 	<li>
		<p align=justify>
			La flag di riporto ausiliario (AF) è stata azzerata perché non c'era alcun riporto BCD dai quattro bit inferiori di EBX ai successivi quattro bit superiori. (Le istruzioni BCD sono state rimosse dal set di istruzioni x64, quindi AF non è più utile oggi e può essere ignorata.)
		</p>	
	</li>
 	<li>
		<p align=justify>
			Il flag di parità (PF) è stato azzerato perché il numero di bit a 1 nell'operando dopo la decrescita era tre, e PF è azzerato quando il numero di bit nell'operando di destinazione è dispari. Controllalo tu stesso: il valore in EBX dopo l'istruzione DEC è 02Ch. In binario, questo è 00101100. Ci sono tre bit a 1 nel valore, e quindi PF è azzerato.
		</p>	
	</li>
</ul>

<p align=justify>
L'istruzione DEC non influisce sul flag IF, che è rimasto attivo. Infatti, quasi nulla cambia il flag IF, e le applicazioni in user space come la sandbox (e tutto il resto che è probabile tu scriva mentre impari l'assembly) sono vietate a modificare l'IF. Ora, esegui l'istruzione INC EAX e visualizza di nuovo i registri nella vista Console. Boom! Questa volta ci sono molte azioni.
</p>

<ul>
	<li>
		<p align=justify>
			La flag di parità PF è stata impostata perché il numero di bit 1 in EAX è ora zero, e PF è impostato quando il numero di bit 1 nell'operando diventa pari. Zero è considerato un numero pari.
		</p>
	</li>
 	<li>
		<p align=justify>
			Il flag Carry ausiliario AF è stato impostato perché i quattro bit inferiori in EAX sono passati da FFFF a 0000. Questo implica un riporto dei quattro bit inferiori ai quattro bit superiori, e AF è impostato quando si verifica un riporto dai quattro bit inferiori dell'operando. (Ancora una volta, non puoi usare AF nella programmazione x64.)
		</p>
	</li>
 	<li>
		<p align=justify>
			Il flag Zero ZF è stato impostato perché EAX è diventato zero.
		</p>
	</li>
 	<li>
		<p align=justify>
			Come prima, il flag IF non cambia e rimane impostato in ogni momento. Ricorda che l'IF appartiene esclusivamente a Linux e non è influenzato dal codice dell'utente.
		</p>
	</li>
</ul>

### Come i Flags cambiano l'esecuzione del programma

<p align=justify>
Osservare i flags cambiare valore dopo l'esecuzione delle istruzioni è un buon modo per imparare il comportamento dei flags. Tuttavia, lo scopo e il vero valore dei flags non risiedono nei loro valori, di per sé, ma in come influenzano il flusso delle istruzioni macchina nei tuoi programmi. Esiste un'intera categoria di istruzioni macchina che "saltano" a una posizione diversa nel tuo programma in base al valore corrente di una o più flags. Queste istruzioni sono chiamate <b>istruzioni di salto condizionale</b>, e la maggior parte dei flags in RFLAGS ha una o più istruzioni di salto condizionale associate. La maggior parte delle istruzioni macchina sono passi effettuati in un elenco che generalmente scorre dall'alto verso il basso. Le istruzioni di salto condizionale sono i test. Esse verificano la condizione di uno dei flags e continuano o saltano a una posizione diversa nel tuo programma. L'esempio più semplice di un'istruzione di salto condizionale, e quella che probabilmente utilizzerai di più, è <code>JNZ</code>, Salta Se Non Zero. L'istruzione <code>JNZ</code> verifica il valore del flag Zero. Se ZF è impostato (cioè, uguale a 1), non succede nulla, e la CPU passa a eseguire la prossima istruzione in sequenza. Tuttavia, se ZF non è impostato (cioè, se è azzerato e uguale a 0), allora l'esecuzione si sposta a una nuova destinazione nel tuo programma. Questo sembra peggio di quanto non sia. Non devi preoccuparti di aggiungere o sottrarre nulla. In quasi tutti i casi, la <b>destinazione è fornita come un'etichetta</b>. <b>Le etichette sono nomi descrittivi dati a posizioni nei tuoi programmi</b>. In NASM, un'etichetta è una stringa di caratteri seguita da due punti, generalmente posta su una riga contenente un'istruzione. Come molte cose nel linguaggio assembly, questo diventerà più chiaro con un semplice esempio. Apri un nuovo ambiente di lavoro e digita le seguenti istruzioni.
</p>

```asm
 	mov rax,5
 DoMore:  dec rax
	  jnz DoMore

	nop
```

<p align=justify>
Costruisci il codice e passa in modalità di debug. Osserva il valore di RAX nella vista Registri mentre esegui queste istruzioni. In particolare, osserva cosa succede nella finestra del codice sorgente quando esegui l'istruzione <code>JNZ</code>. <code>JNZ</code> salta sull'etichetta denominata come il suo operando se ZF è 0. Se ZF = 1, 'cade' sull'istruzione successiva. L'istruzione <code>DEC</code> decrementa il valore nel suo operando; qui, RAX. Finché il valore in RAX non cambia a 0, il flag Zero rimane azzerato. E finché il flag Zero è azzerato, JNZ salta di nuovo all'etichetta DoMore. Quindi, per cinque passaggi, DEC riduce il valore in RAX e JNZ salta di nuovo a DoMore. Ma non appena DEC riduce RAX a 0, il flag Zero si attiva, e JNZ 'cade' sull'istruzione NOP alla fine del codice. Strutture come questa si chiamano <b>cicli</b> e sono comuni in tutti i programmi, non solo nel linguaggio assembly. Il ciclo mostrato in precedenza non è utile, ma <b>dimostra come puoi ripetere un'istruzione quante volte ti serve, caricando un valore di conteggio iniziale in un registro e decrementando quel valore una volta per ogni passaggio nel ciclo</b>. L'istruzione <code>JNZ</code> testa ZF ogni volta che passa e sa di uscire dal ciclo quando il registro di conteggio arriva a 0. Possiamo rendere il ciclo un po' più utile senza aggiungere troppa complessità. Ciò che dobbiamo aggiungere è un elemento dati su cui il ciclo deve lavorare. 
</p>

```asm
section .data
	Snippet	db "KANGAROO"

section .text
	global main

main:
    mov rbp,rsp ;Save stack pointer for debugger

    nop     
; Put your experiments between the two nops...

	mov rbx,Snippet
	mov rax,8
DoMore:	add byte [rbx],32
	inc rbx
	dec rax
	jnz DoMore     
	
; Put your experiments between the two nops...
	nop
```

<p align=justify>
Il programma definisce una variabile e poi la modifica. Quindi, come possiamo vedere quali modifiche vengono apportate? SASM ha la capacità di visualizzare variabili in modalità debug. Dovrei notare qui che, al momento della scrittura, non ha la capacità di visualizzare regioni arbitrarie di memoria, in stile hexdump. I debugger più avanzati lo faranno. Quello che fa SASM è visualizzare variabili con nomi. Per utilizzare questa funzione, devi selezionare la casella di controllo Mostra memoria quando sei in modalità debug. (La casella di controllo è disattivata in modalità modifica.) Per impostazione predefinita, la finestra Mostra memoria è nella parte superiore della visualizzazione di SASM. Per mostrare il contenuto di una variabile nominata in un programma o in una sandbox che hai costruito, devi fare questo:
</p>


1. Entra nella modalità di debug.
2. Nel campo Variabile O Espressione, inserisci Snippet.
3. Nel campo Tipo, seleziona Smart dal menu a discesa più a sinistra.
4. Nel campo successivo, seleziona b dal menu a discesa.
5. Nel campo successivo, digita la lunghezza della variabile che desideri visualizzare, in byte. Per questo esempio, poiché il contenuto di Snippet è lungo otto caratteri, inserisci 8.

<p align=justify>
Una volta fatto ciò, vedrai “KANGAROO” nel campo Valore. È ciò che c'è nello Snippet. Una volta fatto, esegui il programma con Snippet a display. Dopo otto passaggi nel ciclo, “KANGAROO” è diventato “kangaroo”— come? Guarda l'istruzione <code>ADD</code> situata all'etichetta DoMore. In precedenza nel programma, avevamo copiato l'indirizzo di memoria di Snippet nel registro RBX. L'istruzione <code>ADD</code> aggiunge il valore letterale 32 a qualsiasi numero si trovi all'indirizzo memorizzato in RBX. Se guardi le tabelle ASCII noterai che la differenza tra il valore delle lettere maiuscole ASCII e le lettere minuscole ASCII è 32. Una K maiuscola ha il valore 4Bh, e una k minuscola ha il valore 6Bh. 6Bh–4Bh è 20h, che in decimale è 32. Quindi, se consideriamo le lettere ASCII come numeri, possiamo aggiungere 32 a una lettera maiuscola e trasformarla in una lettera minuscola.
</p>

<p align=justify>
Ciò che il ciclo fa è effettuare otto passaggi, uno per ogni lettera in "KANGAROO." Dopo ogni <code>ADD</code>, il programma incrementa l'indirizzo in RBX, il che mette il prossimo carattere di "KANGAROO" nel mirino. Decrementa anche RAX, che era stato caricato con il numero di caratteri nella variabile Snippet prima che il ciclo iniziasse. Quindi, all'interno dello stesso ciclo, il programma conta verso l'alto lungo la lunghezza di Snippet in RBX, mentre conta verso il basso la lunghezza delle lettere rimaste in RAX. Quando RAX arriva a zero, significa che abbiamo esaminato tutti i caratteri in Snippet e abbiamo finito. Gli operandi dell'istruzione  <code>ADD</code> meritano un'ulteriore analisi. <b>Mettere RBX tra parentesi quadre fa riferimento al contenuto di Snippet</b>, piuttosto che al suo indirizzo. Ma ciò che è più importante, lo specificatore di dimensione BYTE dice a NASM che stiamo scrivendo solo un singolo byte all'indirizzo di memoria in RBX. NASM non ha modo di sapere altrimenti. È possibile scrivere un byte, due byte, quattro byte, o otto byte in memoria contemporaneamente, a seconda di ciò che dobbiamo realizzare. Tuttavia, dobbiamo dire a NASM quanti byte vogliamo che utilizzi, con un specificatore di dimensione. 
</p>

### Valori Signed ed Unsigned

<p align=justify>
Nel linguaggio Assembly possiamo lavorare sia con valori numerici con segno che senza segno. I valori con segno, ovviamente, sono valori che possono diventare negativi. Un valore senza segno è sempre positivo. Ci sono istruzioni per le quattro operazioni aritmetiche di base nel set di istruzioni x64 e queste istruzioni possono operare su valori sia con segno che senza segno. (Con moltiplicazione e divisione, ci sono istruzioni separate per i calcoli con segno e senza segno) La chiave per comprendere la differenza tra valori numerici con segno e senza segno è sapere dove la CPU pone il segno. Non è un carattere trattino, ma effettivamente un bit nel modello binario che rappresenta il numero. Il bit più alto nel byte più significativo di un valore con segno è il <b>bit di segno</b>. Se il bit di segno è un 1, il numero è negativo. Se il bit di segno è un 0, il numero è positivo. Se intendiamo eseguire operazioni aritmetiche con segno, il bit più alto di un valore di registro o di una posizione di memoria è considerato il bit di segno. Se non intendiamo eseguire operazioni aritmetiche con segno, i bit più alti degli stessi valori negli stessi posti saranno semplicemente i bit più significativi di valori senza segno. La natura circa il segno di un valore si basa su come trattiamo il valore, non sulla natura del modello di bit sottostante che rappresenta il valore. Ad esempio, il numero binario 10101111 rappresenta un valore con segno o senza segno? La domanda è priva di senso senza contesto: se abbiamo bisogno di trattare il valore come un valore con segno, trattiamo il bit più significativo come il bit di segno, e il valore è -81. Se abbiamo bisogno di trattare il valore come un valore senza segno, trattiamo il bit alto semplicemente come un'altra cifra in un numero binario, e il valore è 175.
</p>

### Complemento a due e NEG

<p align=justify>
Un errore che i principianti commettono a volte è assumere che si possa rendere un valore negativo impostando il bit di segno a 1. Non è così! Non puoi semplicemente prendere il valore 42 e trasformarlo in -42 impostando il bit di segno. Il valore che otterrai sarà certamente negativo, ma non sarà -42. Un modo per avere un'idea di come i numeri negativi siano espressi nel linguaggio assembly è decrementare un numero positivo fino a entrare nel territorio negativo. Apri una sandbox pulita e inserisci queste istruzioni.
</p>

```asm
	mov eax,5
 DoMore: dec eax
	jmp DoMore
```

<p align=justify>
(Sto usando il registro EAX a 32 bit qui perché un registro “completo” a 64 bit è complicato da visualizzare sulla pagina stampata. Il concetto è lo stesso.) Costruisci il sandbox come al solito ed entra in modalità di debug. Nota che abbiamo aggiunto una nuova istruzione qui: <code>JMP</code>, e' un po' pericolosa: l'istruzione <code>JMP</code> non guarda i flag. Quando viene eseguita, salta sempre al suo operando; quindi, l'esecuzione tornerà all'etichetta DoMore ogni singola volta che JMP viene eseguita. Se sei astuto, noterai che non c'è modo di uscire da questa sequenza particolare di istruzioni, e sì, questo è il leggendario “ciclo infinito” in cui ti imbatterai di tanto in tanto. Quindi, assicurati di impostare un punto di interruzione sull'istruzione MOV inizial. Se clicchi sul quadrato rosso, SASM fermerà il programma. Sotto DOS, saresti rimasto bloccato e avresti dovuto riavviare il PC. Linux è una piattaforma di programmazione molto più robusta, una che non va in crisi al tuo più piccolo errore. Inizia a eseguire il sandbox passo dopo passo, e guarda EAX nella vista Registri. Il valore iniziale di 5 scenderà a 4, poi 3, poi 2, poi 1, poi 0, e poi…0FFFFFFFFh! Questa è l'espressione a 32 bit del valore semplice -1. Se continui a decrementare EAX, avrai un'idea di cosa succede.
</p>

```asm
 0FFFFFFFFh (-1)
 0FFFFFFFEh (-2)
 0FFFFFFFDh (-3)
 0FFFFFFFCh (-4)
 0FFFFFFFBh (-5)
 0FFFFFFFAh (-6)
 0FFFFFFF9h (-7)
```

<p align=justify>
…e così via. Quando i numeri negativi vengono gestiti in questo modo, li chiamiamo <b>complemento a due</b>. Nel linguaggio assembly Intel, <b>i numeri negativi sono memorizzati come la forma in complemento a due del loro valore assoluto</b>, che se ti ricordi dalla matematica delle scuole medie è la distanza di un numero da 0, sia nella direzione positiva che negativa. La magia di esprimere numeri negativi in forma di complemento a due è che la CPU non ha realmente bisogno di sottrarre a livello di transistor. Genera semplicemente il complemento a due del sottraendo e lo aggiunge al minuendo. Questo è relativamente facile per la CPU, e tutto avviene in modo trasparente per i tuoi programmi, dove la sottrazione viene eseguita come ti aspetteresti. La buona notizia è che quasi mai devi calcolare manualmente un valore in complemento a due. C'è un'istruzione macchina che lo farà per te: <code>NEG</code>. L'istruzione <code>NEG</code> prenderà un valore positivo come operando e ne nega quel valore, ovvero lo rende negativo. Lo fa generando la forma in complemento a due del valore positivo. Carica le seguenti istruzioni in un'area sicura e esegui un passo alla volta attraverso di esse. Guarda EAX nella vista Registri.
</p>

```asm
 mov eax,42
 neg eax
 add eax,42
```
<p align=justify>
In un colpo solo, 42 diventa 0FFFFFFD6h, l'espressione esadecimale del complemento a due di -42. Aggiungi 42 a questo valore e guarda EAX andare a 0. A questo punto, potrebbe sorgere la domanda: Quali sono i più grandi numeri positivi e negativi che possono essere espressi in uno, due, quattro o otto byte? Quei due valori, più tutti i valori intermedi, costituiscono l'intervallo di un valore espresso in un dato numero di bit. Ho presentato questo nella figura di sotto.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/range_of_signed_values.png">
</div>

<p align=justify>
Se sei abile e sai contare in esadecimale, potresti notare qualcosa qui dalla tabella: il valore positivo massimo e il valore negativo massimo per una data dimensione sono separati da un conteggio. Cioè, se stai lavorando a 8 bit e aggiungi uno al valore positivo massimo, 7Fh, ottieni 80h, il valore negativo massimo. Puoi osservare questo accadere in SASM eseguendo le seguenti due istruzioni in un sandbox e osservando RAX nel display dei Registri:
</p>

```asm
 mov rax,07FFFFFFFFFFFFFFFh
 inc rax
```

<p align=justify>
(Assicurati di avere il numero corretto di F! Ci sono un 7 e 15 F.) Dopo che l'istruzione MOV è stata eseguita, RAX mostrerà il valore decimale 9223372036854775807. Questo è il valore intero con segno più alto esprimibile in 64 bit. Incrementa il valore di 1 con l'istruzione INC, e immediatamente il valore in RAX diventa -9223372036854775808.
</p>

### Estensione del segno e MOVSX

<p align=justify>
C'è un sottile problema da evitare quando si lavora con valori con segno di dimensioni diverse. Il bit di segno è il bit alto in un byte, parola o doppia parola con segno. Ma cosa succede quando devi trasferire un valore con segno in un registro o in una posizione di memoria più grande? Cosa succede, ad esempio, se devi spostare un valore con segno a 16 bit in un registro a 32 bit? Se usi l'istruzione <code>MOV</code>, niente di buono. Prova questo.
</p>

```asm
 mov ax,-42
 mov ebx,eax
```

<p align=justify>
La forma esadecimale di -42 è 0FFD6h. Se hai quel valore in un registro a 16 bit come AX e usi <code>MOV</code> per spostare il valore in un registro più grande come EBX o RBX, il bit di segno non sarà più il bit di segno. In altre parole, una volta che -42 passa da un contenitore a 16 bit a un contenitore a 32 bit, cambia da -42 a 65494. Il bit di segno è ancora lì. Non è stato azzerato. Tuttavia, in un registro più grande, il vecchio bit di segno è ora solo un altro bit in un valore binario, senza significato speciale. Questo esempio è un po' fuorviante. Prima di tutto, non possiamo letteralmente spostare un valore da AX a EBX. <b>L'istruzione <code>MOV</code> gestirà solo operandi di registro della stessa dimensione</b>. Tuttavia, ricorda che AX è semplicemente i due byte inferiori di EAX. Possiamo spostare AX in EBX spostando EAX in EBX, ed è quello che abbiamo fatto nell'esempio precedente. Purtroppo, SASM non è in grado di mostrarci valori con segno a 8 bit, 16 bit o 32 bit. Il suo debugger può visualizzare solo RAX, e possiamo vedere AL, AH, AX o EAX solo vedendoli all'interno di RAX. Ecco perché, nell'esempio precedente, SASM mostra il valore che pensavamo fosse -42 come 65494. La visualizzazione dei Registri di SASM non ha concetto di un bit di segno tranne che nel bit più alto di un valore a 64 bit. Le moderne CPU Intel ci forniscono una via d'uscita da questa trappola, sotto forma dell'istruzione <code>MOVSX</code>. <code>MOVSX</code> significa 'Sposta con Estensione del Segno', ed è una delle molte istruzioni che non erano presenti nelle CPU originali 8086/8088. <code>MOVSX</code> è stata introdotta con la famiglia di CPU 386, e poiché Linux non può girare su nulla di più vecchio di una 386, puoi presumere che qualsiasi PC Linux supporti l'istruzione <code>MOVSX</code> Carica questo in un ambiente di test e prova.
</p>

```asm
 xor rax,rax
 mov ax,-42
 movsx rbx,ax
```

<p align=justify>
La prima riga serve semplicemente a azzerare RAX per garantire che non ci siano "avanzi" memorizzati in esso da codice eseguito in precedenza. Ricorda che SASM non può visualizzare AX singolarmente, quindi mostrerà RAX come contenente 65494. Tuttavia, quando trasferisci AX in RBX con <code>MOVSX</code>, il valore di RBX verrà quindi mostrato come -42. Ciò che è successo è che l'istruzione <code>MOVSX</code> ha eseguito l'estensione del segno sui suoi operandi, prendendo il bit di segno dalla quantità a 16 bit in AX e rendendolo il bit di segno della quantità a 64 bit in RBX. <code>MOVSX</code> è significativamente diverso da <code>MOV</code> in quanto <b></b>i suoi operandi possono essere di dimensioni diverse</p>. <code>MOVSX</code> ha diverse possibili variazioni, che ho riassunto nella figura di sotto.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/movsx_instruction.png">
</div>

<p align=justify>
Nota che l'operando di destinazione può essere solo un registro. La notazione qui è una che vedrai in molti riferimenti al linguaggio assembly nella descrizione degli operandi delle istruzioni. La notazione “r16” è un'abbreviazione per “qualsiasi registro a 16 bit.” Allo stesso modo, “r/m” significa “registro o memoria” ed è seguita dalla dimensione in bit. Ad esempio, “r/m16” significa “qualsiasi registro a 16 bit o posizione di memoria a 16 bit.” Detto ciò, potresti scoprire, dopo aver risolto alcuni problemi in assembly, che l'aritmetica con segno è usata meno spesso di quanto pensi. È buono sapere come funziona, ma non sorprenderti se passi mesi o addirittura anni senza mai averne bisogno.
</p>

### Operandi impliciti e MUL

<p align=justify>
Per la maggior parte del tempo, passi i valori alle istruzioni della macchina tramite uno o due operandi posti proprio lì sulla linea accanto al mnemonico. Questo è buono, perché quando dici <code>MOV RAX,RBX</code>, sai precisamente cosa si sta muovendo, da dove proviene e dove sta andando. Purtroppo, questo non è sempre il caso. Alcune istruzioni agiscono su registri o persino su posizioni di memoria che non sono dichiarate in un elenco di operandi. Queste istruzioni hanno infatti operandi, ma rappresentano assunzioni fatte dall'istruzione. Tali operandi sono chiamati <b>operandi impliciti</b> e non cambiano e non possono essere cambiati. Per aggiungere confusione, la maggior parte delle istruzioni che hanno operandi impliciti ha anche operandi espliciti. I migliori esempi di operandi impliciti nel set di istruzioni x64 sono le istruzioni di moltiplicazione e divisione. Il set di istruzioni x64 ha due insiemi di istruzioni per moltiplicare e dividere. Un insieme, <code>MUL</code> e <code>DIV</code>, che gestisce calcoli senza segno. L'altro, <code>IMUL</code> e <code>IDIV</code>, gestisce calcoli con segno <code>MUL</code> e <code>DIV</code> sono usati molto più frequentemente delle loro alternative a matematica con segno, e sono quelli di cui parlerò in questa sezione. L'istruzione <code>MUL</code> fa ciò che ti aspetteresti: moltiplica due valori e restituisce un prodotto. Tra le operazioni matematiche di base, tuttavia, la moltiplicazione ha un problema speciale: genera valori di output che sono spesso enormemente più grandi dei valori di input. Questo rende impossibile seguire il modello convenzionale negli operandi delle istruzioni Intel, dove il valore generato da un'istruzione va nell'operando di destinazione.
</p>

<p align=justify>
Considera un'operazione di moltiplicazione a 32 bit. Il valore più grande senza segno che può essere contenuto in un registro a 32 bit è 4.294.967.295. Moltiplicalo anche solo per due e ottieni un prodotto a 33 bit, che non potrà più essere contenuto in alcun registro a 32 bit. Questo problema ha afflitto le architetture Intel (tutte le architetture, in effetti) sin dall'inizio. Quando l'x86 era un'architettura a 16 bit, il problema era dove collocare il prodotto di due valori a 16 bit, che può facilmente superare un registro a 16 bit. I progettisti di Intel hanno risolto il problema nel unico modo possibile: <b>utilizzando due registri per contenere il prodotto</b>. Non è immediatamente ovvio per chi non è matematico, ma è vero (provalo su una calcolatrice!) che il prodotto più grande di due numeri binari può essere espresso in non più del doppio dei bit richiesti dal fattore più grande. In parole povere, qualsiasi prodotto di due valori a 16 bit può essere contenuto in 32 bit, e qualsiasi prodotto di due valori a 32 bit può essere contenuto in 64 bit. Quindi, mentre potrebbero essere necessari due registri per contenere il prodotto, mai più di due registri saranno necessari. Questo ci porta all'istruzione <code>MUL</code>. code>MUL</code> è un'istruzione curiosa dal punto di vista degli operandi: prende solo un operando, che contiene uno dei fattori da moltiplicare. L'altro fattore è implicito, così come la coppia di registri che riceve il prodotto del calcolo. <code>MUL</code> appare quindi ingannevolmente semplice.
</p>

```asm
 mul rbx
```

<p align=justify>
Ovviamente, se si sta eseguendo una moltiplicazione, qui è coinvolto qualcosa di più del semplice RBX. Gli operandi impliciti dipendono dalla dimensione di quello esplicito. Questo ci dà quattro variazioni, che ho riassunto nella figura di sotto.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/mul_instruction.png">
</div>

<p align=justify>
Il primo fattore è dato nel singolo operando esplicito, che può essere un valore in un registro o in una posizione di memoria. Il secondo fattore è implicito e sempre nel registro generico "A" appropriato alla dimensione del primo fattore. Se il primo fattore è un valore a 8 bit, il secondo fattore è sempre nel registro AL a 8 bit. Se il primo fattore è un valore a 16 bit, il secondo fattore si trova sempre nel registro AX a 16 bit e così via. Una volta che il prodotto richiede più di 16 bit, i registri DX vengono redatti per contenere la parte di ordine superiore del prodotto. Per "di alto livello" qui intendo la parte del prodotto che non rientra nel registro "A". Ad esempio, se si moltiplicano due valori a 16 bit e il prodotto è 02A456Fh, il registro AX conterrà 0456Fh e il registro DX conterrà 02Ah. Si noti che quando un prodotto è abbastanza piccolo da entrare interamente nel primo dei due registri che contengono il prodotto, il registro di ordine superiore (sia esso AH, DX, EDX o RDX) viene azzerato. I registri spesso scarseggiano nel lavoro di assemblaggio, ma anche se si è sicuri che le moltiplicazioni coinvolgano sempre prodotti di piccole dimensioni, non è possibile utilizzare il registro di ordine superiore per nient'altro mentre viene eseguita un'istruzione <code>MUL</code>. Si noti inoltre che i valori immediati non possono essere utilizzati come operandi per <code>MUL</code>; Cioè, non puoi farlo, per quanto sarebbe spesso utile indicare il primo fattore come un valore immediato
</p>

```asm
 mul 42
```

### MUL ed il Carry Flag

<p align=justify>
Non tutte le moltiplicazioni generano prodotti sufficientemente grandi da richiedere due registri. Per la maggior parte del tempo scoprirai che 64 bit sono più che sufficienti. Quindi, come puoi capire se ci sono cifre significative nel registro di ordine superiore? <code>MUL</code> imposta molto utilmente il flag di riporto CF quando il valore del prodotto oltrepassa il registro di ordine inferiore. Se, dopo una <code>MUL</code>, trovi CF impostato su 0, puoi ignorare il registro di ordine superiore, sicuro della conoscenza che l'intero prodotto si trova nel registro di ordine inferiore dei due registri. Vale la pena fare una rapida dimostrazione. Prima, prova una moltiplicazione 'piccola' dove il prodotto si adatterà facilmente in un singolo registro a 32 bit.
</p>

```asm
 mov eax,447
 mov ebx,1739
 mul ebx
```

<p align=justify>
Ricorda che stiamo moltiplicando EAX per EBX qui. Procedi attraverso le tre istruzioni e, dopo che l'istruzione MUL è stata eseguita, guarda nella vista dei Registri per vedere il prodotto in EDX e EAX. EAX contiene 777333 e EDX contiene 0. Guarda poi lo stato attuale dei vari flag. Nessun segno di CF, il che significa che CF è stato azzerato a 0. Successivamente, aggiungi le seguenti istruzioni al tuo sandbox, dopo le tre mostrate in precedenza:
</p>

```asm
 mov eax,0FFFFFFFFh
 mov ebx,03B72h
 mul ebx
```

<p align=justify>
Procedi come al solito, osservando il contenuto di EAX, EDX ed EBX nella vista Registri. Dopo l'istruzione <code>MUL</code>, guarda i flag nella vista Registri. Il flag di carry CF sarà impostato su 1 (quindi avere anche il flag di overflow OF, il flag di segno SF, il flag di abilitazione dell'interrupt IF e il flag di parità PF, ma questi non sono generalmente utili in aritmetica senza segno). Ciò che CF ti dice fondamentalmente qui è che ci sono cifre significative nella parte alta del prodotto, e queste sono memorizzate in EDX per le moltiplicazioni a 32 bit, RDX per le moltiplicazioni a 64 bit, e così via.
</p>

### Divisione senza segno con DIV

<p align=justify>
C'è una forte somiglianza tra l'istruzione di moltiplicazione senza segno <code>MUL</code> e l'istruzione di divisione senza segno <code>DIV</code>. <code>DIV</code> fa ciò che ti aspetteresti: divide un valore per un altro e ti dà un quoziente e un resto. Ricorda, qui stiamo facendo aritmetica intera e non decimale, quindi non c'è modo di esprimere un quoziente decimale come 17.76 o 3.14159. Questi richiedono la meccanica “in virgola mobile” dell'architettura della CPU, che è un argomento vasto e sottile che non affronterò. Nella divisione, non hai il problema che ha la moltiplicazione, di generare grandi valori di output per alcuni valori di input. Se dividi un valore a 16 bit per un altro valore a 16 bit, non otterrai mai un quoziente che non possa essere contenuto in un registro a 16 bit. D'altra parte, sarebbe utile poter dividere numeri molto grandi, e così gli ingegneri di Intel hanno creato qualcosa di molto simile a un'immagine speculare di <code>MUL</code>: per la divisione a 64 bit, posizioni un valore dividendo in RDX e RAX, il che significa che può avere fino a 128 bit di dimensione. Il divisore è memorizzato nell'unico operando esplicito di DIV, che può essere un registro o in memoria. (Come con  <code>MUL</code>, non puoi utilizzare un valore immediato come operando.) Il quoziente viene restituito in RAX e il resto in RDX. Questa è la situazione per una divisione completa a 64 bit. Come per  <code>MUL</code>, gli operandi impliciti di <code>DIV</code> dipendono dalla dimensione dell'unico operando esplicito, qui inteso come il divisore. Ci sono quattro “dimensioni” delle operazioni <code>DIV</code>, a seconda delle dimensioni dell'operando esplicito, il divisore. Questo è riassunto nella figura di sotto
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/div_instruction.png">
</div>

<p align=justify>
Non proverò nemmeno a stampare quale numero intero puoi memorizzare in 128 bit utilizzando due registri da 64 bit. In notazione scientifica, è 3,4 × 10³⁸. Considerando che 64 bit possono contenere 1,8 × 10¹⁹ e che questo è appena al di sotto del numero stimato di stelle nell'universo osservabile, suggerisco di trattare il numero come un'astrazione non visualizzata. Diamo un'occhiata a <code>DIV</code> Metti il seguente codice in una nuova sandbox:
</p>

```asm
 mov rax,250   	; Dividend 
 mov rbx,5    	; Divisor  
 div rbx        ; Do the DIV 
```

<p align=justify>
L'operando esplicito è il divisore, memorizzato in RBX. Il dividendo è in RAX. Procedi con il passaggio. Dopo l'esecuzione di <code>DIV</code>, il quoziente sarà posizionato in RAX, sostituendo il dividendo. Non c'è resto, quindi RDX è zero. Inserisci un nuovo dividendo e un divisore che non si dividono uniformemente; 247 e 17 funzioneranno. Una volta eseguita l'istruzione <code>DIV</code> con i nuovi operandi, guarda RDX. Dovrebbe contenere 9. Questo è il tuo resto. L'istruzione <code>DIV</code> non posiziona dati utili in nessuno dei flag. Infatti, DIV lascerà OF, SF, ZF, AF, PF e CF in stati indefiniti. Non provare a testare nessuno di quei flag in un'istruzione di salto dopo <code>DIV</code> Come puoi aspettarti, dividere per zero attiverà un errore che terminerà il tuo programma: un'eccezione aritmetica. <b>È una buona idea testare i valori del tuo divisore per assicurarti che non ci siano zeri nel divisore</b>. Ora, dividere zero per un numero diverso da zero non attiva un errore; semplicemente posizionerà valori zero nei registri del quoziente e del resto. Solo per divertimento, prova entrambi i casi nel tuo sandbox per vedere cosa succede.
</p>

### MUL e DIV sono dei ritardatari

<p align=justify>
Una comune domanda da principiante su <code>MUL</code> e <code>DIV</code> riguarda le due versioni "più piccole" di entrambe le istruzioni. (Vedi le figure di sopra) Se una moltiplicazione o divisione a 64 bit può gestire qualsiasi cosa l'architettura x64 può mettere nei registri, perché le versioni più piccole sono necessarie? È solo una questione di compatibilità con le vecchie CPU a 16 bit? Non del tutto. In molti casi, si tratta di velocità. Le istruzioni <code>MUL</code> e <code>DIV</code> sono vicine a essere le istruzioni più lente dell'intero insieme di istruzioni x64. Certamente non sono lente come una volta, ma rispetto ad altre istruzioni come <code>MOV</code> o <code>ADD</code> sono lente. Inoltre, sia le versioni a 32 bit che a 64 bit di entrambe le istruzioni sono più lente della versione a 16 bit, e la versione a 8 bit è la più veloce di tutte. <code>DIV</code> è più lenta di <code>MUL</code>, ma entrambe sono lente. Ora, l'ottimizzazione della velocità è un affare molto scivoloso nel mondo x86/x64— e non è qualcosa di cui i principianti dovrebbero preoccuparsi. Avere le istruzioni nella cache della CPU rispetto al doverle prelevare dalla memoria è una differenza di velocità che sovrasta la maggior parte delle differenze di velocità tra le istruzioni stesse. Altri fattori entrano in gioco nelle CPU più recenti che rendono le generalizzazioni sulla velocità delle istruzioni quasi impossibili, e certamente impossibili da affermare con qualsiasi precisione. Se stai eseguendo solo poche moltiplicazioni o divisioni isolate, non lasciare che tutto ciò ti disturbi. <b>Dove la velocità delle istruzioni può diventare importante è all'interno dei cicli in cui stai eseguendo molte operazioni continuamente</b>, come nella crittografia dei dati o nelle simulazioni fisiche. La mia personale euristica è di utilizzare la versione più piccola di <code>MUL</code> e <code>DIV</code> che i valori di input consentono—temperata dall'euristica ancora più forte che la maggior parte delle volte, la velocità delle istruzioni non importa. Quando sarai abbastanza esperto in assembly da prendere decisioni sulle prestazioni a livello di istruzione, lo saprai. Fino ad allora, concentrati sul rendere i tuoi programmi privi di bug e lascia stare la velocità alla CPU.
</p>

### Leggere ed Usare una guida all'assembly

<p align=justify>
La programmazione in linguaggio assembly riguarda i dettagli. Ci sono ampie somiglianze tra le istruzioni, ma sono le differenze a metterti nei guai quando inizi a fornire programmi all'occhio inflessibile dell'assemblatore. Ricordare un mare di piccoli dettagli intrecciati riguardanti diverse dozzine di istruzioni è brutale e non necessario. Anche i Grandi non cercano di tenere tutto in mente in ogni momento. La maggior parte tiene a disposizione qualche altro tipo di documento di riferimento per rinfrescare la memoria sui dettagli delle istruzioni della macchina.
</p>

<p align=justify>
Nel 1975, un documento completo e utile che riassumeva l'insieme delle istruzioni poteva essere stampato su entrambi i lati di una carta piegata in tre parti che poteva essere riposta in tasca nella camicia. Carte di questo tipo erano comuni, e si potevano ottenere per quasi qualsiasi microprocessore. Per motivi non chiari, erano chiamate "carte blu", anche se la maggior parte erano stampate su cartone bianco normale. All'inizio e a metà degli anni '80, ciò che un tempo era una singola carta era ora un opuscolo di 89 pagine, dimensionato per entrare nella tasca. La Guida di Riferimento per Programmatori di Intel per la famiglia di CPU 8086 veniva spedita con il Macro Assembler di Microsoft. Si adattava davvero nella tasca della camicia, a patto che nulla di più largo di una lista della spesa cercasse di condividere lo spazio. La potenza e la complessità dell'architettura x86 esplose a metà degli anni '80, e un riassunto completo di tutte le istruzioni in tutte le loro forme, più tutte le spiegazioni necessarie, divenne materiale di dimensioni da libro e, con il passare degli anni, richiese non uno ma diversi libri per essere coperto completamente. Intel fornisce versioni PDF della propria documentazione sui processori come download gratuiti, e puoi trovarli nel link sottostante.
</p>

[Intel® 64 and IA-32 Architectures Software Developer Manuals](https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html)

<p align=justify>
Vale la pena averli - ma dimentica di infilarli in tasca. Solo il riferimento del set di istruzioni rappresenta oltre 2.300 pagine in un singolo PDF, e ci sono diversi altri libri correlati per completare il set. Quello di cui hai bisogno è il Volume 2. La buona notizia è che puoi scaricare i file PDF gratuitamente e sfogliarli sul tuo PC o stampare solo le sezioni che potresti trovare utili per un progetto particolare. (I libri stampati sono disponibili su lulu.com, ma sono costosi.) Suggerisco decisamente di familiarizzare almeno in modo ragionevole con le istruzioni x64 comuni prima di affrontare il riferimento esaustivo (e sfinente!) di Intel. Trenta anni fa c'erano eccellenti guide di riferimento delle dimensioni di un libro per la famiglia di CPU x86, la migliore delle quali era il PC Magazine Technical Reference: The Processor and Coprocessor di Robert L. Hummel (Ziff-Davis Press, 1992). Anche se lo vedo regolarmente sui siti di libri usati, ti porterà solo fino al 486. Lo considero ancora una buona cosa da avere sulla tua libreria se lo avvisti da qualche parte e riesci a prenderlo a buon prezzo.
</p>

<p align=justify>
Il problema con i riferimenti al linguaggio assembly è che, per essere completi, non possono essere brevi. Tuttavia, gran parte della complessità degli insiemi di istruzioni x86/x64 ai giorni nostri risiede in istruzioni e meccanismi di indirizzamento della memoria che sono utili solo per sistemi operativi e driver. Per applicazioni di dimensioni contenute che girano in modalità utente, semplicemente non si applicano. Quindi, in omaggio a chi sta iniziando nel linguaggio assembly, ho messo insieme un riferimento per principianti alle istruzioni x86/x64 più comuni, nell' <a href="https://github.com/TheBitPoets/2cornot2c/blob/main/lab/lessons/ASSEMBLY/x64_Assembly_Language_Pocket_Reference.pdf">Appendice B</a>. Contiene almeno una pagina su ogni istruzione di cui parlo in questo libro, più alcune istruzioni aggiuntive che tutti dovrebbero conoscere. Non include descrizioni su ogni istruzione, ma solo le più comuni e utili. Una volta che sarai abbastanza abile da usare le istruzioni più arcane, dovresti essere in grado di leggere la documentazione x64 di Intel e farne buon uso. Alcune delle istruzioni del x86 a 32 bit sono state rimosse dall'insieme di istruzioni x64, e non le ho incluse. Il mnemonico dell'istruzione si trova in cima alla pagina al margine sinistro. A destra del mnemonico si trova il nome dell'istruzione, che è un po' più descrittivo del solo mnemonico. 
</p>

<p align=justify>
Immediatamente sotto il mnemonico c'è un minigrafico dei flag della CPU nel registro RFlags. Come ho descritto in precedenza, il registro RFlags è una raccolta di valori a 1 bit che mantengono alcune informazioni essenziali sullo stato della macchina per brevi periodi di tempo. Molte (ma non tutte) istruzioni x64 modificano i valori di uno o più flag. I flag possono essere quindi testati singolarmente da una delle istruzioni Jump On Condition, che cambiano il corso del programma a seconda degli stati dei flag. Ognuno dei flag ha un nome e ciascun flag ha un simbolo nel minigrafico dei flag. Con il tempo imparerai a conoscere i flag attraverso i loro simboli di due caratteri, ma fino ad allora, i nomi completi dei flag sono mostrati a destra del minigrafico. La maggior parte dei flag non viene utilizzata spesso (se non mai) nei lavori iniziali di linguaggio assembly. La maggior parte a cui presterai attenzione, in termini di flag, sono il Flag Zero (ZF) e il Flag di Riporto (CF). Ci sarà un asterisco (*) sotto il simbolo di qualsiasi flag influenzato dall'istruzione. Come il flag è influenzato dipende da cosa fa l'istruzione. Dovrai dedurlo dalla sezione Note. Quando un'istruzione non influenza affatto i flag, la parola <code>none</code> apparirà nel minigrafico dei flag. Nella pagina di esempio qui, il minigrafico indica che l'istruzione NEG influisce sul Flag Overflow, sul Flag di Segno, sul Flag Zero, sul Flag di Riporto Ausiliario, sul Flag di Parità e sul Flag di Riporto. I modi in cui i flag sono influenzati dipendono dai risultati dell'operazione di negazione sull'operando specificato. Questi modi sono riassunti nel secondo paragrafo della sezione Note.
</p>

<div aling=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/example_x86_reference.png">
</div>

### Legal Forms

<p align=justify>
Le istruzioni possono includere più di una forma legale. La forma di un'istruzione varia in base al tipo e all'ordine degli operandi ad essa passati. Ciò che le singole forme rappresentano effettivamente sono diversi codici operativi binari (<i>opcodes</i>). Ad esempio, sotto la superficie, l'istruzione <code>POP RAX</code> è il numero 058h, mentre l'istruzione <code>POP RSI</code> è il numero 05Eh. La maggior parte dei codici operativi x64 non sono singoli valori a 8 bit, e la maggior parte sono lunghi almeno due byte, spesso quattro o più. Quando vuoi utilizzare un'istruzione con un certo insieme di operandi, assicurati di controllare la sezione delle Forme Legali della guida di riferimento per quell'istruzione per assicurarti che la combinazione sia legale. Ora ci sono più forme legali rispetto ai vecchi tempi del DOS, e molte delle restrizioni residue riguardano i registri di segmento, che comunque non potrai usare quando scrivi normali applicazioni utente in modalità long a 64 bit. Nella pagina di riferimento dell'istruzione <code>NEG</code>, vedi che un registro di segmento non può essere un operando per NEG. (Se potesse, ci sarebbe un elemento NEG sr nell'elenco delle Forme Legali.)
</p>

### Operand Symbols
<p align=justify>
I simboli usati per indicare la natura degli operandi nella sezione <b>Legal Forms</b> sono riassunti in fondo a ogni pagina delle istruzioni nell'Appendice A. Sono quasi autoesplicativi, ma mi prenderò un momento per espanderli leggermente qui:
</p>

<p align=justify>
<ul>
	<li>
		<p align=justify>
			<b>r8</b> Un registro a 8 bit, metà, uno di AH, AL, BH, BL, CH, CL, DH o DL
		</p>
	</li>
	<li>
  		<p align=justify>
			<b>r16</b> Un registro a uso generale a 16 bit, uno tra AX, BX, CX, DX, BP, SP, SI o DI.
		</p>	
	</li>
 	<li>
  		<p align=justify>
			<b>r32</b> Un registro generale a 32 bit, uno tra EAX, EBX, ECX, EDX, EBP, ESP, ESI o EDI.
		</p>
	</li>
	<li> 
    		<p align=justify>
			<b>r64</b> Un registro a 64 bit di uso generale, uno di RAX, RBX, RCX, RDX, RBP, RSP, RSI, RDI, o uno di R8-R15
		</p>	
	</li>
 	<li>
    		<p align=justify>
			<b>sr</b> Uno dei registri di segmento, CS, DS, SS, ES, FS o GS
		</p>	
	</li>
 	<li>
    		<p align=justify>
			<b>m8</b> Un byte di memoria a 8 bit
		</p>	
	</li>
 	<li>
    		<p align=justify>
			<b>m16</b> Una parola di dati di memoria a 16 bit
		</p>	
	</li>
 	<li>
    		<p align=justify>
			<b>m32</b> Una parola di dati di memoria a 32 bit
		</p>	
	</li>
 	<li>
    		<p align=justify>
			<b>m64</b> Una parola di 64 bit di dati in memoria.
		</p>
	</li>
 	<li>
    		<p align=justify>
			<b>i8</b> Un byte a 8 bit di dati immediati.
		</p>	
	</li>
 	<li>
    		<p align=justify>
			<b>i16</b> Una parola a 16 bit di dati immediati.
		</p>	
	</li>
 	<li>
    		<p align=justify>
			<b>i32</b> Una parola a 32 bit di dati immediati.
		</p>	
	</li>
 	<li>
    		<p align=justify>
			<b>i64</b> Una parola a 64 bit di dati immediati.
		</p>	
	</li>
 	<li>
    		<p align=justify>
			<b>d8</b> Un spostamento a 8 bit con segno. Non ne abbiamo ancora parlato, ma uno spostamento è una distanza tra la posizione attuale nel codice e un'altra posizione nel codice a cui vogliamo saltare. È con segno (cioè, può essere negativo o positivo) perché uno spostamento positivo ti porta più in alto (in avanti) nella memoria, mentre uno spostamento negativo ti porta più in basso (indietro) nella memoria. Esamineremo questo concetto in dettaglio più avanti.
		</p>	
	</li>
 	<li>
    		<p align=justify>
			<b>d16</b> Uno spostamento firmato a 16 bit. Ancora una volta, per l'uso con istruzioni di salto e chiamata.
		</p>	
	</li>
 	<li>
    		<p align=justify>
			<b>d32</b> Un spostamento firmato a 32 bit.
		</p>
	</li>
 	<li>
  		<p align=justify>
			<b>d64</b> Un spostamento firmato a 64 bit.
		</p>
	</li>
</ul>
</p>

### Examples

<p align=justify>
Mentre la sezione delle Forme Legali mostra quali combinazioni di operandi sono legali per una data istruzione, la sezione Esempi mostra esempi dell'istruzione in uso reale, proprio come verrebbe codificata in un programma in linguaggio assembly. Ho cercato di fornire un buon campione di esempi per ciascuna istruzione, dimostrando la gamma di diverse possibilità con l'istruzione. Non tutte le singole forme legali saranno presenti negli esempi.
</p>

### Notes

<p align=justify>
La sezione Note della pagina di riferimento descrive brevemente l'azione dell'istruzione e fornisce informazioni su come influisce sui flag, su come potrebbe essere limitata nel suo utilizzo e su qualsiasi altro dettaglio che deve essere ricordato, specialmente su cose che i principianti potrebbero trascurare o male interpretare.
</p>

### Cosa manca

<p align=justify>
Ho omesso qualsiasi istruzione dall'insieme di istruzioni x64. L'Appendice B che non esiste più nell'Appendice B si differenzia dalla maggior parte dei riferimenti dettagliati al linguaggio assembly per il fatto che non include le informazioni sulla codifica dell'opcode binario, né indicazioni su quanti cicli di macchina vengono utilizzati da ciascuna forma dell'istruzione. La codifica binaria di un'istruzione è la sequenza effettiva di byte binari che la CPU digerisce e riconosce come istruzione macchina. Quello che noi chiameremmo POP RAX, la macchina lo vede come il numero binario 58h. Quello che chiamiamo ADD RSI,07733h, la macchina lo vede come la sequenza di 7 byte 48h 81h 0C6h 33h 77h 00h 00h. Le istruzioni macchina sono codificate in da un minimo di uno a un massimo di 15 byte a seconda di quale istruzione siano e quali siano i loro operandi. Disporre il sistema per determinare quale sarà la codifica per qualsiasi istruzione dato è estremamente complicato, in quanto i suoi byte componenti devono essere impostati bit per bit da diversi grandi tavoli. Ho deciso che questo libro non è il posto per quella particolare discussione e ho lasciato fuori le informazioni di codifica dall'Appendice B. (Questo problema è una delle ragioni per cui i libri di riferimento delle istruzioni Intel sono così grandi.)
</p>

<p align=justify>
Finalmente, non ho incluso nulla in questo libro che indichi quanti cicli macchina vengono spesi da un dato comando macchina. Un ciclo macchina è un impulso dell'orologio master che fa magicamente funzionare il PC. Ogni istruzione utilizza un certo numero di quei cicli per svolgere il proprio lavoro, e il numero varia in base a criteri che non spiegherò in questo libro. Peggio ancora, il numero di cicli macchina utilizzati da una data istruzione varia da un modello di processore Intel all'altro. Un'istruzione può utilizzare meno cicli sul Pentium rispetto al 486, o forse più. (In generale, le istruzioni macchina Intel hanno iniziato ad utilizzare meno cicli di clock nel corso degli anni, ma ciò non è vero per ogni singola istruzione.) Inoltre, come spiega Michael Abrash nel suo immenso libro Michael Abrash's Graphics Programming Black Book (Coriolis Group Books, 1997), conoscere i requisiti di ciclo per istruzioni individuali è raramente sufficiente per permettere anche a un esperto programmatori in linguaggio assembly di calcolare quanto tempo impiegherà una data serie di istruzioni per essere eseguita. La cache della CPU, il prefetching, la previsione dei salti, l'iperthreading e un numero qualsiasi di altri fattori si combinano e interagiscono per rendere tali calcoli quasi impossibili, tranne in termini generali. Lui ed io concordiamo entrambi sul fatto che non sia un argomento adatto ai principianti, ma se desideri sapere di più in un certo momento, ti consiglio di cercare il suo libro e vedere da te.
</p>

### Esaminiamo `EASTSYSCALL.ASM`

```asm
;  Executable name : eatsyscall
;  Version         : 1.0
;  Created date    : 4/25/2022
;  Last update     : 5/10/2023
;  Author          : Jeff Duntemann
;  Architecture    : x64
;  From            : x64 Assembly Language Step By Step, 4th Edition
;  Description     : A simple program in assembly for x64 Linux, using NASM 2.14,
;                    demonstrating the use of the syscall instruction to display text.
;                    Not for use with SASM.
;
;  Build using these commands:
;    nasm -f elf64 -g -F stabs eatsyscall.asm
;    ld -o eatsyscall eatsyscall.o
;

SECTION .data          ; Section containing initialised data
	
	EatMsg: db "Eat at Joe's!",10
 	EatLen: equ $-EatMsg	
	
SECTION .bss           ; Section containing uninitialized data	

SECTION .text          ; Section containing code

global 	_start	       ; Linker needs this to find the entry point!
	
_start:
    push rbp
    mov rbp,rsp

    mov rax,1           ; 1 = sys_write for syscall
    mov rdi,1           ; 1 = fd for stdout; i.e., write to the terminal window
    mov rsi,EatMsg      ; Put address of the message string in rsi
    mov rdx,EatLen      ; Length of string to be written in rdx
    syscall             ; Make the system call

    mov rax,60          ; 60 = exit the program
    mov rdi,0           ; Return value in rdi 0 = nothing to return
    syscall             ; Call syscall to exit
```

<p align=justify>
Come hai visto quando l'hai eseguito, il programma <code>EASTSYSCALL.ASM</code> visualizza una (breve) riga di testo sullo schermo. "Eat at Joe's!" Per questo, hai dovuto fornire 35 righe di testo all'assemblatore! Molte di quelle 35 righe sono commenti e non necessari nel senso più stretto, ma fungono da documentazione interna per permetterti di capire cosa sta facendo il programma (o, cosa più importante, come lo sta facendo) sei mesi o un anno da adesso. 
</p>

<p align=justify>
Uno degli obiettivi della programmazione in linguaggio assembly è utilizzare il minor numero possibile di istruzioni per portare a termine il lavoro. Ciò non significa creare un file di codice sorgente il più breve possibile. La dimensione del file sorgente non ha nulla a che fare con la dimensione del file eseguibile assemblato da esso! Più commenti metti nel tuo file, meglio ricorderai come funzionano le cose all'interno del programma la prossima volta che lo riprendi. Penso che ti sorprenderà quanto velocemente la logica di un complicato programma in linguaggio assembly si affievolisca nella tua mente. Dopo non più di 48 ore di lavoro su altri progetti, sono tornato a progetti in assembly e ho dovuto faticare per tornare alla velocità massima nello sviluppo. I commenti non sono né tempo né spazio sprecato. IBM soleva dire: "Una riga di commenti per riga di codice." Questo è buono—e dovrebbe essere considerato un minimo per il lavoro in linguaggio assembly. Un approccio migliore (che seguirò in effetti negli esempi più complicati più avanti nel capitolo) è usare una breve riga di commento a destra di ogni riga di codice, insieme a un blocco di commenti all'inizio di ciascuna sequenza di istruzioni che lavorano insieme per portare a termine un compito discreto. In cima a ogni programma dovrebbe esserci una sorta di blocco di commenti standardizzato, contenente alcune informazioni importanti.
</p>

<p align=justify>
<ul>
	<li>
		<p align=justify>
		Il nome del file di codice sorgente.
		</p>
	</li>
 	<li>
		<p align=justify>
		Il nome del file eseguibile.
		</p>
	</li>
 	<li>
		<p align=justify>
		 The date you created the file.
		</p>
	</li>
 	<li>
		<p align=justify>
		La data in cui hai modificato per lasta il file
		</p>
	</li>
 	<li>
		<p align=justify>
		Il nome della persona che l'ha scritto.
		</p>
	</li>
 	<li>
		<p align=justify>
		Il nome e la versione dell'assemblatore utilizzato per crearla
		</p>
	</li>
 	<li>
		<p align=justify>
		Una descrizione 'generale' di cosa fa il programma o la libreria. Prendi tutto lo spazio di cui hai bisogno. Non importa la dimensione o la velocità del programma eseguibile.
		</p>
	</li>
 	<li>
		<p align=justify>
		Una copia dei comandi utilizzati per costruire il file, presa dal file make se utilizzi un file make o dalla dialog di Build di SASM se utilizzi SASM.
		</p>
	</li>
</ul>
</p>

<p align=justify>
La sfida con un blocco di commento iniziale è aggiornarlo per riflettere lo stato attuale del tuo progetto. Nessuno dei tuoi strumenti lo farà automaticamente. Sta a te.
</p>

### Sezione .data

<p align=justify>
I normali programmi utente (che girano nello spazio utente e non in quello kernel) scritti per Linux sono divisi in <b>tre sezioni</b>. L'ordine in cui queste sezioni si presentano nel tuo programma non è davvero importante, ma per convenzione la sezione <b>.data</b> viene prima, seguita dalla sezione <b>.bss</b> e poi dalla sezione <b>.text</b>. <b>La sezione .data contiene definizioni di dati di elementi inizializzati</b>. I dati inizializzati sono dati che hanno un valore prima che il programma inizi a essere eseguito. Questi valori fanno parte del file eseguibile. Vengono caricati in memoria quando il file eseguibile viene caricato in memoria per l'esecuzione. Non devi caricarli con i loro valori e non vengono utilizzati cicli di macchina nella loro creazione al di là di quanto necessario per caricare il programma nel suo insieme in memoria. La cosa importante da ricordare sulla sezione .data è che maggiore è il numero di elementi di dati inizializzati che definisci, più grande sarà il file eseguibile e più tempo ci vorrà per caricarlo da disco in memoria quando lo esegui. Parleremo in dettaglio di come vengono definiti gli elementi di dati inizializzati a breve.
</p>

### Sezione .bss

<p align=justify>
Non tutti gli elementi di dati devono avere valori prima che il programma inizi a essere eseguito. Quando leggi dati da un file sul disco, ad esempio, hai bisogno di un posto dove inserire i dati dopo che arrivano dal disco. I buffer di dati come quello sono definiti nella sezione <b>Block Start Symbol</b> (<b>.bss</b>) del tuo programma. E' stato chiamato in altri modi nel corso degli anni, come Buffer Start Symbol. L'acronimo non ha importanza. Nella sezione .bss, allochi blocchi di memoria da utilizzare in seguito e dai nomi a quei blocchi, questi blocchi conterranno dei valori solo successivamente, durante l'esecuzione del programma. Tutti gli assemblatori hanno un modo per riservare un certo numero di byte per un buffer e dare un nome a quel buffer, ma non specifichi quali valori devono essere memorizzati nel buffer. I valori appariranno dopo a seguito dell'azione del programma mentre il programma è in esecuzione. <b>C'è una differenza cruciale tra gli elementi di dati definiti nella sezione .data e gli elementi di dati definiti nella sezione .bss</b>: Gli elementi di dati nella sezione .data aumentano la dimensione del tuo file eseguibile. Gli elementi di dati nella sezione .bss non lo fanno. Un buffer che occupa 16.000 byte (o più, a volte molto di più) può essere definito in .bss e aggiungere quasi nulla (circa 50 byte per la descrizione) alla dimensione del file eseguibile. Questo è possibile grazie al modo in cui il caricatore di Linux porta il programma nella memoria. Quando compili il tuo file eseguibile, il linker di Linux aggiunge informazioni al file descrivendo tutti i simboli che hai definito, compresi i simboli che nominano gli elementi di dati. Il caricatore sa quali elementi di dati non hanno valori iniziali, e riserva spazio in memoria per loro quando porta l'eseguibile dal disco. Gli elementi di dati con valori iniziali vengono letti insieme ai loro valori. Avere una sezione .bss vuota non aumenta la dimensione del tuo file eseguibile, e cancellare una sezione .bss vuota non riduce la dimensione del tuo file eseguibile.
</p>

### Sezione .text

<p align=justify>
Le vere istruzioni macchina che compongono il tuo programma vanno nella sezione <b>.text</b>. Ordinariamente, non ci sono elementi di dati definiti in .text. La sezione .text contiene simboli chiamati <b>etichette</b> (labels) che identificano posizioni nel codice del programma per salti e chiamate, ma al di là di questo, è tutto qui. Tutte le etichette globali devono essere dichiarate nella sezione .text, altrimenti le etichette non possono essere "visibili" al di fuori del tuo programma, né dal linker di Linux né dal caricatore di Linux. Esaminiamo la questione delle etichette con maggiore attenzione.
</p>

### Labels (Etichette)

<p align=justify>
Un'etichetta è una sorta di segnalibro, che descrive un punto nel codice del programma e gli dà un nome più facile da ricordare rispetto a un indirizzo di memoria nudo e crudo. Le etichette vengono utilizzate per indicare i luoghi dove le istruzioni di salto devono saltare e per dare nomi alle procedure in linguaggio assembly richiamabili. Spiegherò come tutto ciò viene fatto successivamente. Nel frattempo, ecco le cose più importanti da sapere sulle etichette.
</p>

<ul>
	<li>
		<p align=justify>Le etichette devono iniziare con una lettera, con un trattino basso, un punto o un punto interrogativo. Questi ultimi tre (<code>_</code>, <code>.</code>, <code>?</code> hanno significati speciali per l'assemblatore, quindi non usarli finché non sai come l'assemblatore li interpreta.</p>
	</li>
	<li>
		<p align=justify>Le etichette devono essere seguite da due punti quando vengono definite. Questo è fondamentalmente ciò che dice a NASM che l'identificatore che si sta definendo è un'etichetta. NASM ignorerà se non ci sono due punti e non segnalerà un errore, ma i due punti fissano la questione e prevengono che un mnemonico di istruzione digitato in modo errato venga scambiato per un'etichetta. Quindi usa i due punti!</p>
	</li>
	<li>
		<p align=justify>Le etichette fanno distinzione tra maiuscole e minuscole. Ad esempio, yikes:, Yikes: e YIKES: sono tre etichette completamente diverse</p>
	</li>
</ul>

<p align=justify>
Più tardi, vedremo tali etichette utilizzate come obiettivi delle istruzioni di salto e chiamata. Ad esempio, la seguente istruzione macchina trasferisce il flusso di esecuzione delle istruzioni alla posizione contrassegnata dall'etichetta GoHome: 
</p>

```asm
jmp GoHome
```

<p align=justify>
Nota che i due punti non vengono utilizzati qui. I due punti vengono posti solo dove l'etichetta è definita, non dove viene riferita. Pensa in questo modo: usa i due punti quando stai contrassegnando una posizione, non quando ci stai andando. C'è solo un'etichetta in <code>eatsyscall.asm</code>, e questa è un po' speciale. <b>L'etichetta <code>_start</code> indica dove inizia il programma</b>. (È sensibile alle maiuscole, quindi non provare a usare _START o _Start.) <b>Questa etichetta deve essere contrassegnata come globale nella parte superiore della sezione <code>.text</code></b>. Ora se invece di utilizzare nasm (che l'assemblatore a riga di comando) stai usando SASM, un assemblatore con interfaccia grafica (GUI) questo cambia un po' le cose. Quando compili un programma in linguaggio assembly in SASM, l'etichetta _start diventa main. SASM usa il compilatore Gnu C gcc per fungere da intermediario tra NASM e il linker Linux, ld. Quello che fa SASM, in un certo senso, è creare un programma C senza alcun codice C al suo interno. Tutti i programmi C devono avere un punto di partenza, e in un programma C quel punto di partenza è sempre main. Ci sono motivi per fare ciò che coinvolgono il collegamento di funzioni scritte in C al tuo programma assembly, come spiegherò più avanti. Ricorda questo: quando assembli da un file make, usa _start. Quando assembli da dentro SASM, usa main.
</p>

### Variabili per i dati inizializzati

<p align=justify>
L'identificatore <code>EatMsg</code> nella sezione <code>.data</code> definisce una variabile. Specificamente, <b>EatMsg è una variabile di tipo stringa</b> (di cui parleremo tra poco), ma comunque, <b>come tutte le variabili, fa parte di una classe di elementi che chiamiamo dati inizializzati</b>: qualcosa che arriva con un valore e non solo una scatola vuota nella quale possiamo inserire un valore in un momento futuro. <b>Una variabile è definita associando un identificatore a una direttiva di definizione dei dati</b>. Le direttive di definizione dei dati appaiono in questo modo:
</p>

```asm
 MyByte:	db 07h 			; 8 bits in size     
 MyWord: 	dw 0FFFFh  		; 16 bits in size   
 MyDouble: 	dd 0B8000000h 		; 32 bits in size 
 MyQuad:     	dq 07FFFFFFFFFFFFFFFh  	; 64 bits in size  
```

<p align=justify>
Pensa alla direttiva <code>DB</code> come "Definisci Byte." <code>DB</code> riserva un byte di memoria per la memorizzazione dei dati. Pensa alla direttiva <code>DW</code> come "Definisci Parola." <code>DW</code> riserva una parola (16 bit, o due byte) di memoria per la memorizzazione dei dati. Pensa alla direttiva <code>DD</code> come "Definisci Doppio." DD riserva una doppia word in memoria per la memorizzazione. <code>DQ</code> significa "Definisci Quad," cioè una quad word, che ha una dimensione di 64 bit.
</p>

### Variabili Stringa

<p align=justify>
Le variabili stringa sono un caso speciale interessante. Una stringa è proprio questo: <b>una sequenza di caratteri</b>, tutti in fila in memoria. Una variabile stringa è definita in <code>eatsyscall.asm</code>: 
</p>

```asm
	EatMsg: db "Eat at Joe's!", 10 
 ```

<p align=justify>
Le stringhe sono un'eccezione alla regola generale secondo cui una direttiva di definizione dei dati riserva una particolare quantità di memoria. <b>La direttiva DB di solito riserva solo un byte. Tuttavia, una stringa può essere di qualsiasi lunghezza tu desideri</b>. Poiché non esiste una direttiva di dati che riserva 17 byte o 42, le stringhe sono definite semplicemente associando un'etichetta con il punto in cui la stringa inizia. L'etichetta EatMsg e la sua direttiva DB specificano un byte in memoria come punto di partenza della stringa. Il numero di caratteri nella stringa è ciò che dice all'assemblatore quanti byte di memoria riservare per quella stringa. Possono essere utilizzati caratteri di singola virgoletta (‘) o di doppia virgoletta (”) per delimitare una stringa, e la scelta spetta a te, a meno che tu non stia definendo un valore di stringa che contiene uno o più caratteri di virgoletta. Nota che in <code>eatsyscall.asm</code> la variabile di stringa EatMsg contiene un carattere di singola virgoletta usato come apostrofo. Poiché la stringa contiene un carattere di singola virgoletta, devi delimitarla con doppi apici. Il contrario è anche vero: se definisci una stringa che contiene uno o più caratteri di doppia virgoletta, devi delimitarla usando caratteri di singola virgoletta:
</p>	

```asm
	Yukkh: db 'He said, "How disgusting!" and threw up.', 10
```

<p align=justify>
Puoi combinare più sottostringhe separate in una singola variabile di stringa separando le sottostringhe con virgole. Questo è un modo perfettamente legale (e a volte utile) per definire una variabile di stringa: 
</p>

```asm
	TwoLineMsg: db ""Eat at Joe's...",10,
	"...Ten million flies can't ALL be wrong!", 10
```

<p align=justify>
Ma a che serve il numero letterale 10 usato nei precedenti esempi di stringa? In Linux, il carattere di fine riga (EOL) ha il valore numerico decimale pari a 10 , o 0Ah. Indica al sistema operativo dove finisce una riga inviata per la visualizzazione nella console. Qualsiasi testo successivo visualizzato nella console verrà mostrato sulla riga successiva, al margine sinistro. Nella variabile TwoLineMsg, il carattere EOL tra le due sottostringhe indicherà a Linux di visualizzare la prima sottostringa su una riga della console e la seconda sottostringa sulla riga della console sottostante. <br> Puoi concatenare numeri individuali all'interno di una stringa, ma devi ricordare che, come con EOL, non appariranno come numeri. Una stringa è una stringa di caratteri. Un numero aggiunto a una stringa sarà interpretato dalla maggior parte delle routine del sistema operativo come un carattere ASCII. Per mostrare numeri in una stringa, devi rappresentarli come caratteri ASCII, sia come letterali di carattere, come il carattere cifra 7, sia come gli equivalenti numerici ai caratteri ASCII, come 37h.
</p>

<p align=justify>
Nel lavoro di assemblaggio ordinario, quasi tutte le variabili di stringa sono definite utilizzando la direttiva <code>DB</code> e possono essere considerate stringhe di byte. (Un carattere ASCII è grande un byte.) Puoi definire variabili di stringa utilizzando <code>DW</code>, <code>DD</code> o <code>DQ</code>, ma vengono gestite in modo leggermente diverso rispetto a quelle definite con <code>DB</code>. Considera queste variabili: 
</p>

 ```asm
        WordString: dw 'CQ' 
        DoubleString: dd 'Stop' 
        QuadString: dq 'KANGAROO' 
 ```

 <p align=justify>
La direttiva <code>DW</code> definisce una variabile a lunghezza parola (word), una parola (16 bit) può contenere due caratteri a 8 bit. Allo stesso modo, la direttiva <code>DD</code> definisce una variabile a doppia parola (32 bit, double word), che può contenere quattro caratteri a 8 bit. La direttiva <code>DQ</code> definisce una variabile a quadrupla parola, che può contenere otto caratteri a 8 bit. La gestione differente si verifica quando carichi queste stringhe nominate nei registri. Considera queste tre istruzioni:
 </p>

 ```asm
	mov ax,[WordString]
	mov edx,[DoubleString]
	mov rax,[QuadString]
```

<p align=justify>
<b>Ricorda qui che per spostare i dati da una variabile in un registro, devi inserire il nome della variabile (che è il suo indirizzo) tra parentesi quadre</b>. Senza le parentesi quadre, ciò che sposti nel registro è l'indirizzo della variabile in memoria, non quali dati esistono a quell'indirizzo. Nella prima istruzione <code>MOV</code>, i caratteri <code>CQ</code> vengono posizionati nel registro <code>AX</code>, con il carattere <code>C</code> nel registro <code>AL</code> e la <code>Q</code> in <code>AH</code>. Nella seconda istruzione <code>MOV</code>, i caratteri <code>Stop</code> vengono caricati in <code>EDX</code> <b>in ordine little-endian</b>, con la <code>S</code> nel byte di ordine più basso di <code>EDX</code>, la <code>t</code> nel secondo byte più basso, e così via. Se guardi la stringa <code>QuadString</code> caricata in <code>RAX</code> da SASM, vedrai che contiene “OORAGNAK” scritto al contrario. Caricare stringhe in un singolo registro in questo modo (supponendo che ci stiano!) è molto meno comune (e meno utile) rispetto a usare <code>DB</code> per definire stringhe di caratteri, e non ti capiterà spesso di farlo. Poiché eatsyscall.asm non definisce dati non inizializzati nella sua sezione .bss, rimanderò la discussione di tali definizioni finché non esamineremo il prossimo programma di esempio.
</p>

### Derivare la lunghezza della stringa con EQU e $

<p align=justify>
Sotto la definizione di <code>EatMsg</code> nel file <code>eatsyscall.asm</code> c'è un construtto interessante. 
</p>	

```asm
	EatLen: equ $-EatMsg
```

<p align=justify>
Questo è un esempio di una classe più ampia di cose chiamate calcoli a tempo di assemblaggio. Quello che stiamo facendo qui è calcolare la lunghezza della variabile stringa <code>EatMsg</code> e rendere quel valore di lunghezza accessibile al codice del programma attraverso l'etichetta <code>EatLen</code>. In qualsiasi punto del tuo programma, se hai bisogno di usare la lunghezza di <code>EatMsg</code>, puoi usare l'etichetta <code>EatLen</code>. Una dichiarazione contenente la direttiva <code>EQU</code> è chiamata <b>un'uguaglianza o simbolo</b> (<i>equate</i>). <b>Un simbolo è un modo per associare un valore a un'etichetta</b>. Tale etichetta è quindi trattata in molto simile a una costante C. Ogni volta che l'assemblatore incontra un'equazione durante l'assemblaggio, sostituirà il nome dell'equazione con il suo valore. Ecco un esempio: 
</p>	
	
```asm 
 FieldWidth: equ 10
```

<p align=justify>
Qui, stiamo dicendo all'assemblatore che l'etichetta <code>FieldWidth</code> rappresenta il valore numerico 10. Una volta definito il simbolo, le seguenti due istruzioni macchina di sotto, fanno esattamente la stessa cosa:
<p>

```asm
	mov eax,10
	mov eax,FieldWidth
```

<p align=justify>
Ci sono due vantaggi in questo:
</p>

<ul>
	<li>
		<p align=justify>
		Un simbolo rende l'istruzione più facile da comprendere utilizzando un nome descrittivo per un valore. Sappiamo a cosa serve il valore 10; è la larghezza di un campo.
		</p>
	</li>
 	<li>
		<p align=justify>
		Un simbolo rende i programmi più facili da modificare in futuro. Se la larghezza del campo cambia da 10 a 12 in un dato momento, dobbiamo modificare solo un'unica riga nel file del codice sorgente invece di farlo ovunque accediamo alla larghezza del campo.
		</p>
  	</li>
</ul>

<p align=justify>
Non sottovalutare il valore di questo secondo vantaggio. Una volta che i tuoi programmi diventano più grandi e più sofisticati, potresti trovarti a utilizzare un valore particolare dozzine o centinaia di volte all'interno di un singolo programma. O rendi quel valore un simbolo e cambi una sola riga per modificare un valore utilizzato 267 volte, oppure puoi esaminare il tuo codice e cambiare individualmente tutti e 267 usi del valore, tranne per i cinque o sei che perdi, causando caos quando successivamente compili e esegui il tuo programma. Combinare il calcolo in linguaggio assembly con i simboli consente di fare cose meravigliose in modo molto semplice. Come spiegherò a breve, per visualizzare una stringa in Linux, devi passare sia l'indirizzo della stringa che la sua lunghezza al sistema operativo. Puoi rendere la lunghezza della stringa un simbolo in questo modo.
</p>

```asm
	EatMsg: db "Eat at Joe's!",10
	EatLen: equ 14
```

<p align=justify>
Questo funziona, perché la stringa EatMsg è in effetti lunga 14 caratteri, incluso il carattere EOL. Ma supponiamo che Joe venda il suo ristorante a Ralph e tu sostituisca "Joe" con "Ralph". Devi cambiare non solo il messaggio dell'annuncio ma anche la sua lunghezza.
</p>

```asm
 	EatMsg: db "Eat at Ralph's!",10
 	EatLen: equ 16 
 ```

<p align=justify>
Quali sono le probabilità che tu ti scordi di aggiornare l'equivalente di EatLen con la nuova lunghezza del messaggio? Se fai spesso questo tipo di errore, succederà. Con un calcolo a tempo di assemblaggio, cambi semplicemente la definizione della variabile stringa e la sua lunghezza viene calcolata automaticamente da NASM durante il tempo di assemblaggio. Come? In questo modo.
</p>

```asm
	EatMsg: db "Eat at Ralph's!",10
	EatLen: equ $-EatMsg
```

<p align=justify>
Tutto dipende dal token magico "qui", espresso dall'umile simbolo del dollaro. Durante la fase di assemblaggio, l'assemblatore analizza i tuoi file di codice sorgente e costruisce un file intermedio con estensione <code>.o</code> (il file oggetto). Il token <code>$</code> segna il punto in cui l'assemblatore si trova nella costruzione del file intermedio (non del file di codice sorgente!). L'etichetta EatMsg segna l'inizio della stringa dello slogan pubblicitario. Immediatamente dopo l'ultimo carattere di EatMsg c'è l'etichetta EatLen. Ricorda, le etichette non sono dati, ma posizioni, e nel caso del linguaggio assembly, indirizzi. Quando l'assemblatore raggiunge l'etichetta EatLen, il valore di <code>$</code> è la posizione immediatamente dopo l'ultimo carattere di EatMsg. Il calcolo durante l'assemblaggio consiste nel prendere la posizione rappresentata dal token <code>$</code> (che quando il calcolo è completato contiene la posizione appena dopo la fine della stringa EatMsg) e sottrarre da essa la posizione dell'inizio della stringa EatMsg. <code>Fine – Inizio = Lunghezza</code>. Questo calcolo viene eseguito ogni volta che assembli il file, quindi ogni volta che modifichi il contenuto di EatMsg, il valore di EatLen sarà ricalcolato automaticamente. Puoi cambiare il testo all'interno della stringa come preferisci e non dover mai preoccuparti di cambiare un valore di lunghezza da nessuna parte nel programma. Il calcolo durante l'assemblaggio ha altri usi, ma questo è il più comune e l'unico che probabilmente userai come principiante.
</p>


### Lo Stack (LIFO: Last in, First out)

<p align=justify>
Lo stack è un meccanismo di memorizzazione integrato direttamente nell'hardware della CPU. Intel non l'ha inventato; lo stack è stato parte integrante dell'hardware dei computer fin dagli anni '50.
Lo stack è un tipo di struttura dati della famiglia LIFO: last in, first out. I dati vengono inseriti sulla cima dello stack e rimangono nello stack finché non li estraiamo in ordine inverso a come li abbiamo inseriti, esattamente come faremmo con una pila di piatti. Lo stack non esiste in qualche area separata della CPU. Esiste nella memoria ordinaria e, in effetti, quello che chiamiamo “lo stack” è davvero un modo per gestire i dati nella memoria. Lo stack è un luogo dove possiamo riporre uno o due (o quanti più si vogliono) valori per il momento e tornare su di essi un po' più tardi. La principale virtù dello stack è che non richiede che diamo ai dati memorizzati un nome. Mettiamo quei dati nello stack e li recuperiamo più tardi in base alla loro posizione, o in alcuni casi accedendo allo stack utilizzando un indirizzamento di memoria ordinario relativo a un punto fisso nella memoria dello stack. 
</p>

<p align=justify>
Il gergo relativo all'uso dello stack riflette la metafora della pila di piatti: quando mettiamo qualcosa nello stack, diciamo che lo spingiamo (<i>push</i>); quando recuperiamo qualcosa dallo stack, diciamo che lo estraiamo (<i>pop</i>). Lo stack cresce o si riduce man mano che i dati vengono aggiunti o rimossi. L'elemento più recentemente spinto nello stack si dice che si trovi in cima allo stack. Quando estraiamo un elemento dallo stack, ciò che otteniamo è l'elemento in cima allo stack. E' tutto più chiaro concettualmente nella figura di sotto.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/stack.png">
</div>

<p align=justify>
Nell'architettura x64, la parte superiore dello stack è contrassegnata da un registro chiamato <b>stack pointer</b>, con il nome formale <b>RSP</b>. È un registro a 64 bit, e <b>contiene l'indirizzo di memoria dell'ultimo elemento inserito nello stack</b>.
</p>

<p align=justify>
A rendere le cose un po' più difficili da visualizzare è il fatto che <b>lo stack Intel è fondamentalmente capovolto</b>. Se si immagina un'area di memoria con l'indirizzo più basso nella parte inferiore e l'indirizzo più alto nella parte superiore, lo stack inizia verso l'alto dal soffitto e, man mano che gli elementi vengono spinti sullo stack, lo stack cresce verso il basso, verso la memoria bassa. La Figura di sotto mostra in termini generali come Linux organizza la memoria che fornisce al programma quando quest'ultimo viene eseguito. Nella parte inferiore della memoria ci sono le tre sezioni che definisci nel tuo programma: <code>.text</code> agli indirizzi più bassi, seguito da <code>.data</code>, seguito da <code>.bss</code>. Lo stack si trova all'estremità opposta del blocco di memoria del programma. Tra la fine della sezione <code>.bss</code> e la parte superiore dello stack c'è fondamentalmente una memoria vuota. I programmi C utilizzano abitualmente questo spazio di memoria libero per allocare variabili "al volo" in una regione chiamata <b>heap</b>. Anche i programmi di assemblaggio possono farlo, anche se non è così facile come sembra. Ho disegnato l'heap nella figura perché è importante sapere dove si trova nella mappa di memoria dello spazio utente. Analogamente allo stack, l'heap aumenta o si riduce man mano che le strutture di dati vengono create (allocando memoria) o distrutte (rilasciando memoria). La cosa importante da ricordare (soprattutto se hai avuto precedenti esperienze di scrittura di assembly per DOS) è che non siamo più in modalità reale. Quando l'app inizia l'esecuzione, Linux riserva un intervallo contiguo di memoria virtuale per lo stack che per impostazione predefinita è qualcosa come 8 gigabyte. (L'esatta quantità di memoria virtuale dipende da come Linux è configurato e può variare.) Di queste, solo poche pagine vengono effettivamente salvate nella parte superiore dello spazio degli indirizzi virtuali. Quando lo stack cresce verso il basso ed esaurisce la memoria fisica, si verifica un errore di pagina e il sistema operativo esegue il mapping di una quantità maggiore di memoria fisica nello spazio degli indirizzi virtuali e quindi diventa disponibile per l'uso dello stack. Questo continua fino a quando l'intero spazio virtuale non è esaurito, cosa che in pratica non accade mai a meno che il programma non stia consumando voracemente lo spazio dello stack a causa di un bug. La memoria virtuale è una cosa meravigliosa ma complicata. Il punto è che lo stack della tua app può avere praticamente tutta la memoria di cui ha bisogno grazie alla memoria virtuale e non devi più preoccuparti di rimanere senza. L'unica cautela che dovrei prendere nel guardare la figura di sotto è che le dimensioni relative delle sezioni del programma rispetto allo stack non dovrebbero essere viste come letterali. Si possono avere migliaia di byte di codice di programma e decine di migliaia di byte di dati in un programma assembly mediocre, ma rispetto a questo, lo stack è ancora piuttosto piccolo: poche centinaia di byte al massimo e generalmente meno
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/linux_memory.png">
</div>

### Istruzione Push

<p align=justify>
Puoi inserire i dati nello stack in diversi modi, ma il modo più semplice comporta due istruzioni della macchina correlate, PUSH e PUSHFQ. Le due sono simili nel loro funzionamento e differiscono principalmente per ciò che inseriscono nello stack:
</p>

<ul>
	<li>
		<p align=justify>
			<code>PUSH</code> inserisce nello stack(spinge, <i>push</i>) un registro a 16 bit o 64 bit o un valore di memoria che è specificato da te nel tuo codice sorgente. Nota che <b>non puoi spingere un valore a 8 bit o a 32 bit nello stack!</b> Riceverai un errore se ci provi.
		</p>
	</li>
	<li>
		<p align=justify>
			<code>PUSHFQ</code> spinge l'intero registro RFlags a 64 bit nello stack. (La Q significa "quadword" qui.) Questo nonostante più della metà dei flag in RFlags siano riservati e non abbiano alcun uso. Non utilizzerai spesso PUSHFQ, ma c'è se ne hai bisogno.
		</p>
	</li>
</ul>

<p align=justify>
Ecco alcuni esempi delle istruzioni della famiglia PUSH in uso
</p>

```asm
	pushfq		; Push the RFlags register       
	push rax	; Push the RAX register
	push bx		; Push the 16-bit register BX
	push [rdx]   	; Push the quadword in memory at RDX
```

<p align=justify>
Nota che <code>PUSHFQ</code> non richiede operandi. Genererai un errore di assemblatore se provi a dare operandi a PUSHFQ; l'istruzione spinge il registro RFlags a 64 bit nello stack, e questo è tutto ciò che è in grado di fare. 
</p>

<p align=justify>
<code>PUSH</code> funziona in questo modo, per operandi a 64 bit: prima RSP viene decrementato di 64 bit (otto byte) in modo che punti a un'area vuota di memoria nello stack lunga otto byte. Poi ciò che deve essere spinto nello stack viene scritto in memoria all'indirizzo in RSP. Voilà! I dati sono al sicuro nello stack, e RSP è sceso di otto byte verso il fondo della memoria. <code>PUSH</code> può anche spingere valori a 16 bit nello stack, e quando lo fa, l'unica differenza è che RSP si sposta di due byte invece che otto. Tutta la memoria tra la posizione iniziale di RSP e la sua posizione attuale (la cima dello stack) contiene dati reali che sono stati esplicitamente spinti nello stack e presumibilmente verranno estratti dallo stack in seguito. Alcuni di questi dati sono stati spinti nello stack dal sistema operativo prima di eseguire il tuo programma
</p>

<p align=justify>
Cosa può e non può essere spinto nello stack in modalità <b>long x64</b> è ragionevolmente semplice: <b>Qualsiasi dei registri a 16 bit e 64 bit a uso generale può essere spinto individualmente nello stack</b>. Non puoi spingere AL o BH o qualsiasi altro registro a 8 bit. <b>Dati immediati a 16 bit e 64 bit possono essere spinti nello stack</b>. I programmi user-space di Linux non possono spingere i registri di segmento nello stack in nessuna circostanza. <b>Con x64, i registri di segmento appartengono al sistema operativo e non sono disponibili per i programmi user-space</b>. Per quanto strano possa sembrare, i valori a 32 bit (inclusi tutti i registri a 32 bit) non possono essere spinti nello stack.
</p>

### Istruzione Pop

<p align=justify>
In generale, ciò che viene spinto deve essere rimosso, altrimenti si possono incorrere in diversi tipi di problemi. Rimuovere un elemento di dati dallo stack è più facilmente fatto con un'altra coppia di istruzioni, <code>POP</code> e <code>POPFQ</code>. Come ci si potrebbe aspettare, <code>POP</code> è l'istruzione generale per rimuovere un elemento alla volta, mentre <code>POPFQ</code> è dedicata alla rimozione dei flags del registro RFlags.
</p>

```asm
	popfq		; Pop the top 8 bytes from the stack into RFlags
	pop rcx		; Pop the top 8 bytes from the stack into RCX  
	pop bx		; Pop the top 2 bytes from the stack into BX
	pop [rbx]	; Pop the top 8 bytes from the stack into memory at EBX
```

<p align=justify>
Come per <code>PUSH</code>, <code>POP</code> opera solo su operandi a 16 bit o 64 bit. Non cercare di estrarre dati dallo stack in un registro a 8 bit o 32 bit come AH o ECX. POP funziona praticamente allo stesso modo di <code>PUSH</code>, ma al contrario. Come con <code>PUSH</code>, <b>quanto viene estratto dallo stack dipende dalla dimensione dell'operando</b>. Estrarre dallo stack in un registro a 16 bit preleva i due byte superiori dallo stack. Estrarre dallo stack in un registro a 64 bit preleva gli otto byte superiori dallo stack. Nota che niente nella CPU né in Linux ricorda le dimensioni degli elementi dati che posizioni nello stack. Spetta a te conoscere la dimensione dell'ultimo elemento inserito nello stack. Se l'ultimo elemento che hai inserito nello stack era un registro a 16 bit, estrarre dallo stack in un registro a 64 bit porterà via sei byte in più dallo stack rispetto a quelli che hai inserito. Questo è chiamato <b>disallineamento dello stack</b> e non è altro che un problema, uno dei motivi per cui dovresti lavorare con registri a 64 bit e valori di memoria ogni volta che puoi ed evitare di usare lo stack con valori a 16 bit. Quando un'istruzione <code>POP</code> viene eseguita, le cose funzionano in quest'ordine: Prima, i dati all'indirizzo attualmente memorizzato in RSP vengono copiati dallo stack e collocati nell'operando di <code>POP</code>, qualunque tu abbia specificato. Dopo di che, RSP viene incrementato (anziché decrementato) della dimensione dell'operando—sia 16 bit che 64 bit— in modo che di fatto RSP si muova rispettivamente di due o otto byte verso l'alto nello stack, lontano dalla memoria bassa. È significativo che RSP venga decrementato prima di posizionare una parola nello stack al momento di <code>PUSH</code>, ma incrementato dopo aver rimosso una parola dallo stack al momento di <code>POP</code>. Alcune altre CPU al di fuori dell'universo x86 operano in modo opposto, il che va bene—basta non confonderle. Per x86/x64, questo è sempre vero: A meno che lo stack non sia completamente vuoto, RSP punta a dati reali, non a spazio vuoto. Di solito, non devi ricordare questo fatto, poiché <code>PUSH</code> e <code>POP</code> lo gestiscono tutto per te e non devi tenere traccia manualmente di ciò a cui RSP punta.
</p>

### PUSHA E POPA sono stati rimossi

<p align=justify>
Quasi tutto ciò che avevi nell'assembly a 32 bit è ancora presente nell'assembly x64. Alcune cose sono cambiate, ma molto poco è stato rimosso quando x86 è diventato x64. Sono stati fatti dei sacrifici. Quattro istruzioni sono completamente scomparse: <code>PUSHA</code>, <code>PUSHAD</code>, <code>POPA</code> e <code>POPAD</code>. Nelle architetture precedenti, <b>queste istruzioni venivano utilizzate per pushare o poppare tutti i registri a scopo generale contemporaneamente</b>. Quindi, perché sono scomparse? Non ho mai trovato una spiegazione autorevole, ma ho una teoria: ci sono molti più registri a scopo generale in x64. Pushare 15 registri a 64 bit nello stack invece di 7 registri a 32 bit occupa un grande spazio nello stack. (Il puntatore dello stack ESP non è stato influenzato da PUSHA/POPA per ovvi motivi, dato che ESP definisce lo stack!) Se vuoi preservare i registri a scopo generale nello stack per qualche motivo, dovrai pusharli e popparli singolarmente.
</p>

### Push e Pop in dettaglio

<p align=justify>
Se hai ancora qualche dubbio su come funziona lo stack, permettimi di presentarti un esempio che mostra come opera lo stack in dettaglio, con valori reali. A scopo di chiarezza nel diagramma associato, utilizzerò registri a 16 bit piuttosto che registri a 64 bit. Questo mi permetterà di mostrare i singoli byte nello stack. Funziona allo stesso modo con valori a 64 bit. La differenza, ancora una volta, è che otto byte vengono spinti o rimossi piuttosto che due. La Figura di sotto mostra come appare lo stack dopo l'esecuzione di ciascuna delle quattro istruzioni. (Sto usando valori a 16 bit nella figura per chiarezza. Il meccanismo è lo stesso per i valori a 64 bit.) I valori dei quattro registri generali X a 16 bit in un ipotetico punto dell'esecuzione di un programma sono mostrati nella parte superiore della figura. AX viene spinto per primo nello stack. Il suo byte meno significativo si trova a RSP, e il suo byte più significativo si trova a RSP+1. (Ricorda che entrambi <b>i byte vengono spinti nello stack contemporaneamente, come un'unità!</b>)
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/how_stack_works.png">
</div>

<p align=justify>
Ogni volta che uno dei registri a 16 bit viene inserito nello stack, RSP viene decrementato di due byte, scendendo verso la memoria bassa. Le prime tre colonne mostrano AX, BX e CX che vengono spinti nello stack, rispettivamente. Ma nota cosa succede nella quarta colonna, quando viene eseguita l'istruzione POP DX. Il puntatore dello stack viene incrementato di due byte e si allontana dalla memoria bassa. DX ora contiene una copia del contenuto di CX. Di fatto, CX è stato inserito nello stack e poi immediatamente estratto in DX. Se vuoi provare le istruzioni in figura, apri un nuovo ambiente e aggiungi queste istruzioni macchina:
</p>

```asm
	xor rax,rax  ;We first zero out all 4 64-bit "x" registers
	xor rbx,rbx  ;so there are no "leftovers" in the high bits
	xor rcx,rcx
	xor rdx,rdx

	mov ax,01234h  ;Place values in AX, BX, and CX
	mov bx,04ba7h
	mov cx,0ff17h

	push ax		;Push AX,BX,& CX onto the stack       
	push bx
	push cx

	pop dx		;Pop the top of the stack into DX.         
```

<p align=justify>
Vai in modalità debug e esegui passo-passo queste istruzioni, osservando sia il puntatore dello stack RSP che i quattro registri a 16 bit dopo ogni passo. Puoi seguire l'azione anche nella figura di sopra. Sì, è un modo indiretto piuttosto complesso per copiare il valore di CX in DX. <code>MOV DX,CX</code> è molto più veloce e diretto. Tuttavia, a volte è necessario spostare i valori dei registri tramite lo stack. Ricorda che <b>l'istruzione MOV non opererà sul registro RFlags</b>. Se vuoi caricare una copia di RFlags in un registro a 64 bit, devi prima spingere RFlags nello stack con PUSHFQ e poi estrarre il valore dei flag dallo stack nel registro di tua scelta con POP. Quindi, per ottenere RFlags in RBX, si utilizza il seguente codice. Puoi vederlo funzionare mettendo queste righe in un sandbox e procedendo passo-passo attraverso di esse.
</p>

```asm
	xor rbx,rbx	; Clear rbx
	pushfq		; Push the RFlags register onto the stack          
	pop qword rbx   ; ...and pop it immediately into RBX...why not POPFQ??
```

<p align=justify>
Sebbene tu possa ripristinare i valori dei flag in RFlags utilizzando <code>POPFQ</code>, non tutti i bit di RFlags possono essere modificati estraendoli dallo stack in RFlags. I bit VM e RF non sono influenzati da POPFQ. Piccole insidie come questa suggeriscono che non dovresti cercare di salvare e ripristinare i flag finché non sai precisamente cosa stai facendo.
</p>

### Syscall del kernel

<p align=justify>
Lo stack dovrebbe essere considerato un luogo dove riporre temporaneamente le cose. <b>Gli oggetti memorizzati nello stack</b> non hanno nomi e in generale <b>devono essere rimossi dallo stack nell'ordine inverso in cui sono stati aggiunti</b>. Ultimo arrivato, primo servito, ricorda. LIFO! Un ottimo uso dello stack consente ai pochi registri di svolgere molteplici funzioni. Se hai bisogno di un registro per mantenere temporaneamente un valore da utilizzare nella CPU e tutti i registri sono occupati, spingi uno dei registri occupati nello stack. Il suo valore rimarrà sicuro nello stack mentre usi il registro per altre cose. Quando hai finito di usare il registro, estrai il suo vecchio valore dallo stack—e hai guadagnato i vantaggi di un registro aggiuntivo senza averne realmente uno. (Il costo, ovviamente, è il tempo che spendi per spostare il valore di quel registro dentro e fuori dallo stack. Non è qualcosa che vuoi fare nel mezzo di un ciclo spesso ripetuto!) <b>La memorizzazione a breve termine durante l'esecuzione del programma è l'uso più semplice e ovvio dello stack</b>, ma il suo <b>utilizzo più importante è probabilmente nell'invocazione di procedure e nei servizi del kernel di Linux</b>. E ora che comprendi lo stack, possiamo affrontare la misteriosa questione delle chiamate di sistema di Linux.
</p>

<p align=justify>
Tutto il resto in <code>eatsyscall.asm</code> è preparazione per l'unica istruzione che esegue il vero lavoro del programma: visualizzare una riga di testo nella console di Linux. Al cuore del programma c'è una chiamata al sistema operativo Linux. Una seconda chiamata a Linux è alla fine, quando il programma si conclude e deve informare Linux che ha finito. Ci sono diverse centinaia di servizi del kernel Linux disponibili. Uno dei servizi che Linux fornisce è un semplice accesso in modalità testo al display del tuo PC. Per le esigenze di <code>eatsyscall.asm</code> - che è solo una lezione per scrivere e far funzionare il tuo primo programma in linguaggio assembly - servizi semplici sono sufficienti. Quindi, come utilizziamo i servizi di Linux? Se hai guardato da vicino <code>eatsyscall.asm</code>, dovresti ricordare due istanze dell'istruzione macchina <code>SYSCALL</code>. Nelle istanze x64 di Linux, l'istruzione <code>SYSCALL</code> è il modo in cui accedi ai servizi del kernel Linux.
</p>

<p align=justify>
Nelle versioni a 32 bit di Linux, l'interruzione software <code>INT 80h</code> era il modo per raggiungere il dispatcher dei servizi del kernel. <code>INT 80h</code> non viene più utilizzato. L'architettura x64 ci offre qualcosa di molto meglio: l'istruzione <code>SYSCALL</code>. La sfida nell'accesso ai servizi del kernel è la seguente: passare l'esecuzione a una libreria di codice senza avere idea di dove si trovi quella libreria. L'istruzione <code>SYSCALL</code> guarda in un registro della CPU a cui i programmi in user-space non possono accedere. Quando il kernel di Linux si avvia, inserisce l'indirizzo del suo dispatcher dei servizi in questo registro. Una delle prime cose che fa l'istruzione <code>SYSCALL</code> è elevare il suo livello di privilegio dal livello 3 (utente) al livello 0 (kernel). Poi legge l'indirizzo nel registro di dispatch dei servizi e salta a quell'indirizzo per invocare il dispatcher. La maggior parte delle chiamate di sistema x64 che utilizzano <code>SYSCALL</code> hanno parametri, che vengono passati nei registri della CPU. Quali registri? Non è casuale. Infatti, c'è qualcosa chiamata <b>System V Application Binary Interface</b> (<b>ABI</b>) per Linux, che definisce un intero sistema per passare parametri a Linux tramite SYSCALL. Fa anche di più, ma ciò che ci interessa qui è il meccanismo che ti consente di chiamare i servizi del kernel utilizzando <code>SYSCALL</code>.
</p>

### ABI (Application Binary Interface)

<p align=justify>
Questo è un buon punto per una breve digressione. Se hai esperienza di programmazione, probabilmente hai già sentito parlare di "chiamate API" o "l'API di Windows". Qual è, allora, la differenza tra un ABI e un API? API sta per interfaccia di programmazione delle applicazioni. Un'API è una raccolta di funzioni chiamabili da utilizzare principalmente da linguaggi di programmazione di alto livello come Pascal o C. È possibile per un programma in linguaggio assembly chiamare una funzione API, e te lo mostrerò più avanti. Un'interfaccia binaria applicativa, al contrario, è una descrizione dettagliata di ciò che accade a livello di codice macchina quando un pezzo di codice macchina binario parla con un altro o con hardware di CPU come i registri. È uno strato "sotto" l'API. L'ABI definisce una raccolta di funzioni fondamentali chiamabili, generalmente fornite dal sistema operativo, come avviene in Linux. Questa definizione descrive come passare parametri alle molte funzioni di servizio del kernel. Un ABI definisce anche come i linkers collegano i moduli compilati o assemblati in un unico programma eseguibile binario e molte altre cose.
</p>

### Lo Schema dei Parametri del Registro ABI

<p align=justify>
Esaminiamo più da vicino il programma <code>eatsyscall.asm</code>. Il codice seguente scrive un messaggio testuale nella console di Linux:
</p>

```asm
	mov rax,1		; 1 = sys_write for syscall         
	mov rdi,1		; 1 = fd for stdout; i.e., write to the terminal window
                        
	mov rsi,EatMsg		; Put address of the message string in rsi
 	mov rdx,EatLen		; Length of string to be written in rdx

	syscall          	; Make the system call
```

<p align=justify>
In poche parole, questo codice colloca determinati valori in determinati registri e poi esegue l'istruzione <code>SYSCALL</code>. Il dispatcher dei servizi di Linux raccoglie i valori posti in quei registri e poi chiama la funzione specificata in RAX. C'è un sistema per specificare quali registri vengono utilizzati per quale servizio e quali parametri (se presenti) per quel servizio. Il modo migliore per spiegare è mostrarti le prime due righe della tabella delle chiamate di sistema dell'ABI System V, nella tabella di sotto.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/system_call_conventions_for_system_v_abi.png">
</div>

<p align=justify>
Tutte le colonne tranne System Call sono registri. System Call è il nome leggibile dall'uomo della chiamata di sistema, che è il nome utilizzato da linguaggi di alto livello come Pascal e C per effettuare chiamate di sistema tramite l'istruzione SYSCALL. Il registro RAX è dedicato al codice numerico che specifica la chiamata di sistema da effettuare. Il nome della chiamata di sistema 1 è <code>sys_write</code>. I registri dopo il nome della chiamata di sistema (RDI, RSI) contengono i parametri. L'ABI specifica sei registri da utilizzare per i parametri. Non tutte le chiamate di sistema richiedono sei parametri. La chiamata <code>sys_write</code> utilizzata in <code>eatsyscall.asm</code> neha solo tre. L'elenco dei parametri inizia sempre con RDI e utilizza i registri nell'ordine dato nella tabella. 
<br>	RDI, RSI, RDX, R10, R8, R9.<br> 
Dopo che i parametri di una chiamata di sistema sono stati tutti assegnati ai registri, eventuali registri rimasti inutilizzati per la chiamata di sistema non si applicano alla chiamata di sistema e vengono lasciati vuoti. I parametri per <code>sys_write</code> sono questi.
</p>

<ul>
	<li>
		<p align=justify>
			<b>RDI</b>: Il descrittore di file su cui verrà scritto il testo. In Linux (e in tutte le varianti di Unix) il descrittore di file per <code>sys_write</code> è 1.
		</p>
	</li>
	<li>
		<p align=justify>
			<b>RSI</b>: L'indirizzo del testo da scrivere nella console.
		</p>
	</li>
	<li>
		<p align=justify>
			<b>RDX</b>: La lunghezza (numero di caratteri) del testo da scrivere sulla console
		</p>
	</li>
</ul>

<p align=justify>
Se una chiamata di sistema deve restituire un valore numerico, quel valore viene restituito dal sistema in RAX.
</p>

### Terminare un programma via SYSCALL

<p align=justify>
C'è un secondo comando SYSCALL in eatsyscall.asm, e ha un compito umile ma cruciale: chiudere il programma e restituire il controllo a Linux. Questo sembra più semplice di quanto sia, e una volta che comprendi un po' meglio gli interni di Linux, inizierai ad apprezzare il lavoro che deve essere fatto sia per avviare un processo sia per chiuderlo. Tuttavia, dal punto di vista del tuo stesso programma, è estremamente semplice: inserisci il numero del servizio sys_exit in RAX, inserisci un codice di ritorno in RDI e poi esegui SYSCALL:
</p>

```asm
	mov rax,60	; 60 = sys_exit to exit the program gracefully
	mov rdi,0	; Return value in rdi 0 = nothing to return
 	syscall        	; Call syscall to exit this program
```

<p align=justify>
Il codice di ritorno è un valore numerico che puoi definire come preferisci. Tecnicamente, non ci sono restrizioni su cosa sia (a parte il fatto di dover adattarsi a un registro a 64 bit), ma per convenzione, un valore di ritorno di 0 significa "tutto ha funzionato correttamente; arresto normale." Valori di ritorno diversi da 0 indicano tipicamente un errore di qualche tipo. Tieni presente che nei programmi più grandi, devi fare attenzione a cose che non funzionano come previsto: un file su disco non può essere trovato, un'unità disco è piena e così via. Se un programma non riesce a svolgere il proprio compito e deve terminare prematuramente, dovrebbe avere un modo per dirti (o in alcuni casi, a un altro programma) cosa è andato storto. Il codice di ritorno è un buon modo per farlo. Uscire in questo modo non è solo una cortesia. Ogni programma x64 che scrivi deve uscire effettuando una chiamata a <code>sys_exit</code> tramite il dispatcher dei servizi del kernel. Se un programma semplicemente "scivola via" dal limite, in realtà si fermerà, ma Linux solleverà un errore di segmentazione e non avrai idea di cosa sia successo. Questa è la ragione per cui i tuoi programmi "sandbox" sono utilizzati solo per il debugging all'interno di SASM. Sono frammenti di programma e genereranno un errore di segmentazione se li lasci semplicemente funzionare. I programmi scritti in SASM utilizzano elementi della Standard C Library, che fornisce ai programmi una sezione "codice di arresto" che effettivamente effettua la chiamata di sistema per l'uscita. Tali programmi terminano eseguendo un'istruzione RET, come spiegherò in seguito.
</p>

### Registri sporcati da una SYSCALL

<p align=justify>
Anche se x64 ti offre il doppio del numero di registri a uso generale rispetto a x86, non tutti quei registri "a uso generale" sono liberi per essere utilizzati ovunque e in qualsiasi momento. Da uno a sei di quei registri sono richiesti per effettuare una chiamata di sistema Linux con SYSCALL. Quelli sei sono indicati nella tabella di sopra. Il numero di registri utilizzati varia in base alla chiamata di sistema, e dovrai consultarli in una tabella delle chiamate di sistema per vedere quanti ne servono. Se una chiamata di sistema non ha bisogno di tutti e sei i registri dei parametri SYSCALL (<code>sys_read</code> e <code>sys_write</code> ne utilizzano solo tre), puoi utilizzare quelli che non sono richiesti per quella chiamata di sistema nel tuo codice. <b>L'istruzione SYSCALL stessa utilizza internamente RAX, RCX e R11</b>. <b>Dopo che la SYSCALL restituisce, non puoi presumere che RAX, RCX o R11 avranno gli stessi valori che avevano prima della SYSCALL</b>.
</p>

### Progettare un programma

<p align=justify>
A questo punto, sai gran parte di ciò che devi sapere per progettare e scrivere piccole utility che svolgono un lavoro significativo - un lavoro che potrebbe persino essere utile. In questa sezione, affronteremo la sfida di scrivere un programma utility dal punto di vista dell'ingegneria per risolvere un problema. Questo comporta più che semplicemente scrivere codice. Comporta dichiarare il problema, suddividerlo nelle sue parti costitutive e poi ideare una soluzione al problema come una serie di passaggi e test che possono essere implementati come un programma in linguaggio assembly. E' difficile scrivere un programma assembly non banale senza salti condizionali e difficile spiegare i salti condizionali senza dimostrarli in un programma non banale. Abbiamo accennato ai salti nei paragrafi precedenti e li affronteremo in dettaglio in quelli successivi. I salti che sto usando nel programma dimostrativo in questa sezione sono piuttosto diretti.
</p>

<p align=justify>
A un livello molto alto, il problema da risolvere qui può essere formulato in questo modo: <b>convertire eventuali caratteri minuscoli in un file di dati in maiuscolo</b>. Tenendo presente ciò, è una buona idea prendere appunti sul problema. In particolare, prendi appunti sui limiti di qualsiasi soluzione proposta. Una volta li chiamavamo i “limiti” della soluzione, e devono essere tenuti a mente mentre pensiamo al programma che risolverà il problema.
</p>


<ul>
	<li>
		<p align=justify>
			Lavoreremo sotto Linux. 
		</p>
	</li>
 	<li>
		<p align=justify>
			I dati esistono in file su disco.
		</p>
	</li>
 	<li>
		<p align=justify>
			Non sappiamo prima quanto saranno grandi i file.
		</p>
	</li>
 	<li>
		<p align=justify>
			 Non c'è una dimensione massima né minima per i file.
		</p>
	</li>
 	<li>
		<p align=justify>
			Utilizzeremo la reindirizzamento I/O per passare i nomi dei file al programma.
		</p>
	</li>
 	<li>
		<p align=justify>
			Tutti i file di input sono nello stesso schema di codifica. Il programma può assumere che un carattere 'a' in un file sia codificato nello stesso modo di un 'a' in un altro file. (Nel nostro caso, questo è ASCII.) 
		</p>
	</li>
 	<li>
		<p align=justify>
			 Dobbiamo preservare il file originale nella sua forma originale, piuttosto che leggere i dati dal file originale e poi scriverli di nuovo nel file originale. (Perché? Se il processo si blocca, abbiamo distrutto il file originale senza generare completamente un file di output.)
		</p>
	</li>
 	
</ul>

<p align=justify>
Una volta che comprendiamo la natura del problema il più a fondo possibile, possiamo iniziare a creare una soluzione. Poi, poco a poco, affini la soluzione dichiarata suddividendo i passaggi più grandi in quelli più piccoli che i passaggi più grandi contengono. Nel nostro caso, la soluzione è piuttosto facile da esprimere in termini generali. Per iniziare, ecco una forma che la dichiarazione potrebbe assumere.
</p>

```
 Read a character from the input file.
 Convert the character to uppercase (if necessary)
 Write the character to the output file.
 Repeat until done.
```

<p align=justify>
Questa è davvero una soluzione, sebbene possa sembrare un estremo "punto di vista dall'alto". È carente di dettagli, ma non di funzioni. Se eseguiamo i passaggi elencati, avremo un programma che fa ciò che abbiamo bisogno che faccia. Nota anche che le affermazioni fornite non sono affermazioni scritte in alcun linguaggio di programmazione. Di certo non sono istruzioni di linguaggio assembly. Sono descrizioni di diverse azioni, indipendenti da qualsiasi sistema particolare per realizzare quelle azioni. Elenchi di affermazioni come questo, poiché non sono deliberatamente scritti come codice per un particolare ambiente di programmazione, sono chiamati <i>pseudocodice</i>.
</p>

<p align=justify>
Dalla nostra prima dichiarazione completa ma priva di dettagli della soluzione, ci spostiamo verso una dichiarazione della soluzione più dettagliata. Lo facciamo affinando le dichiarazioni in pseudocodice in modo che ognuna sia più specifica su come deve essere eseguita l'azione descritta. Ripetiamo questo processo, aggiungendo più dettagli ogni volta, fino a quando ciò che abbiamo può essere prontamente tradotto in istruzioni di linguaggio assembly reali. Questo processo, chiamato affinamento successivo, non è specifico per il linguaggio assembly. Viene utilizzato con tutti i linguaggi di programmazione in una misura o nell'altra, ma funziona in modo particolarmente efficace con l'assembly. Diamo un'occhiata allo pseudocodice fornito in precedenza e creiamo una nuova versione con ulteriori dettagli. Sappiamo che stiamo per usare Linux per il programma — fa parte delle specifiche e uno dei limiti di qualsiasi soluzione — quindi possiamo iniziare ad aggiungere dettagli specifici al modo di fare tali cose in Linux. Il prossimo affinamento potrebbe apparire così.
</p>

```
 Read a character from standard input (stdin)
 Test the character to see if it's lowercase.
 If the character is lowercase, convert it to uppercase by subtracting 20h.
 Write the character to standard output (stdout).
 Repeat until done.
 Exit the program by calling sys_exit.
```

<p align=justify>
Ad ogni passaggio, guarda a lungo e con attenzione ciascuna dichiarazione di azione per vedere quali dettagli potrebbe nascondere e amplia quei dettagli nella prossima raffinazione. A volte questo sarà facile; a volte, beh, non così facile. Nella versione precedente, la dichiarazione "Ripeti fino a completamento" suona piuttosto semplice e ovvia all'inizio, fino a quando non pensi a cosa significa "completamento" qui: esaurire i dati nel file di input. Come facciamo a sapere quando il file di input è privo di caratteri? Questo potrebbe richiedere un po' di ricerca, ma nella maggior parte dei sistemi operativi (inclusi Linux) la routine che chiami per leggere i dati da un file restituisce un valore. Questo valore può indicare una lettura riuscita, un errore di lettura o risultati in casi speciali come "fine del file" (EOF). I dettagli precisi possono venire dopo; ciò che conta qui è che dobbiamo testare per EOF quando leggiamo i caratteri dal file. Una versione espansa (e leggermente riorganizzata) del pseudocodice della soluzione potrebbe apparire in questo modo.
</p>

```
 Read a character from standard input (stdin)
 Test if we have reached End Of File (EOF)
 If we have reached EOF, we're done, so jump to exit
 Test the character to see if it's lowercase.
 If the character is lowercase, convert it to uppercase by subtracting 20h.
 Write the character to standard output (stdout).
 Go back and read another character.
 Exit the program by calling sys_exit
```

<p align=justify>
E così procediamo, aggiungendo dettagli ogni volta. Nota che questo inizia a sembrare un po' più codice di programma ora. Con l'aumento del numero di istruzioni, è utile aggiungere etichette a quelle istruzioni che rappresentano obiettivi di salto in modo da non confondere gli obiettivi di salto, anche in pseudocodice. Aiuta anche a suddividere lo pseudocodice in blocchi, con istruzioni correlate raggruppate insieme. Prima o poi arriveremo a qualcosa di simile al seguente.
</p>

```
 Read:  Set up registers for the sys_read kernel call.
 Call sys_read to read from stdin.
 Test for EOF.
 If we're at EOF, jump to Exit.
 Test the character to see if it's lowercase.
 If it's not a lowercase character, jump to Write.
 Convert the character to uppercase by subtracting 20h.
 Write: Set up registers for the Write kernel call.
 Call sys_write to write to stdout.
 Jump back to Read and get another character.
 Exit:  Set up registers for terminating the program via sys_exit.
 Call sys_exit
```

<p align=justify>
Tutti i linguaggi di programmazione hanno le loro peculiarità, le loro limitazioni e una "forma" generale. Se tieni a mente questa forma mentre elabori il tuo pseudocodice, la transizione finale al codice reale sarà più semplice. A un certo punto, il tuo pseudocodice avrà tutti i dettagli che può contenere e rimanere comunque pseudocodice. Per andare oltre, dovrai iniziare a trasformare il tuo pseudocodice in codice assembly reale. Ciò significa che devi prendere ogni istruzione e chiederti: So come convertire questa istruzione in pseudocodice in una o più istruzioni di linguaggio assembly? Questo è particolarmente vero quando sei un principiante, ma anche dopo aver acquisito esperienza come programmatore in linguaggio assembly, potresti non sapere tutto ciò che c'è da sapere. Nella maggior parte dei linguaggi di programmazione (incluso l'assembly), ci sono spesso diversi o a volte molti modi diversi di implementare una determinata azione. Alcuni potrebbero essere più veloci di altri; alcuni potrebbero essere più lenti ma più facili da leggere e modificare. Alcune soluzioni potrebbero essere limitate a un sottoinsieme della gamma completa delle CPU Intel. Il tuo programma deve essere eseguito su CPU x86 più vecchie? O puoi presumere che tutti avranno un sistema con una CPU a 64 bit? (Le tue note originali dovrebbero includere tali condizioni di vincolo per qualsiasi soluzione utilizzabile al problema originale.)
</p>

<p align=justify>
Il salto dallo pseudocodice alle istruzioni potrebbe sembrare grande, ma la buona notizia è che una volta convertito il tuo pseudocodice in istruzioni, puoi creare un file di codice sorgente in linguaggio assembly e lasciare che SASM lo analizzi per scovare i tuoi errori sintattici. Aspettati di dedicare del tempo a correggere errori assembly e poi bug del programma, ma se hai affrontato il processo di raffinamento con una mente chiara e una pazienza ragionevole, potresti essere sorpreso da quanto sia buono un programma al tuo primo tentativo. Una traduzione competente del precedente pseudocodice in assembly reale è mostrata nel codice di sotto. (Questa è la versione che si collega tramite gcc invece di ld. Aprila e compilala in SASM.) Leggila e verifica se riesci a seguire la traduzione dallo pseudocodice, sapendo ciò che già conosci sul linguaggio assembly. Il codice mostrato funzionerà ma non è 'completo' in alcun senso reale. È un 'primo taglio' per il codice reale nel processo di raffinamento successivo. Ha bisogno di una riflessione approfondita su quanto sia buono e quanto sia completa la soluzione al problema originale. Un programma funzionante non è necessariamente un programma finito.
</p>

```asm
section .bss
	Buff resb 1

section .data

section .text
	global main

main:
    mov rbp, rsp   ; for correct debugging

Read:
    mov rax,0      ; Specify sys_read call
	mov rdi,0      ; Specify File Descriptor 0: Standard Input
	mov rsi,Buff   ; Pass address of the buffer to read to
	mov rdx,1      ; Tell sys_read to read one char from stdin
	syscall        ; Call sys_read

	cmp rax,0      ; Look at sys_read's return value in RAX
	je Exit        ; Jump If Equal to 0 (0 means EOF) to Exit:
			       ; or fall through to test for lowercase

	cmp byte [Buff],61h    ; Test input char against lowercase 'a'
	jb Write               ; If below 'a' in ASCII chart, not lowercase
	cmp byte [Buff],7Ah    ; Test input char against lowercase 'z'
	ja Write               ; If above 'z' in ASCII chart, not lowercase

                           ; At this point, we have a lowercase character
	sub byte [Buff],20h    ; Subtract 20h from lowercase to give uppercase...
                           ; ...and then write out the char to stdout
Write:  
    mov rax,1      ; Specify sys_write call
    mov rdi,1      ; Specify File Descriptor 1: Standard output
    mov rsi,Buff   ; Pass address of the character to write
    mov rdx,1      ; Pass number of chars to write
    syscall	       ; Call sys_write...
    jmp Read       ; ...then go to the beginning to get another character
        
Exit:   ret        

;Exit:
     mov rax,60    ; 60 = exit the program
;    mov rdi,0     ; Return value in rdi 0 = nothing to return
;    syscall       ; Call syscall to exit
```

<p align=justify>
Sembra complicato, ma consiste quasi interamente in istruzioni e concetti di cui abbiamo già discusso. Ecco alcune note su cose che potresti non comprendere completamente a questo punto.
</p>

<ul>
	<li>
		<p align=justify>
			<code>Buff</code> è una variabile non inizializzata e quindi si trova nella sezione .bss del programma. È uno spazio riservato con un indirizzo. Buff non ha un valore iniziale e non contiene nulla fino a quando non leggiamo un carattere da stdin e lo memorizziamo lì.
		</p>
	</li>
 	<li>
		<p align=justify>
			Quando una chiamata a <code>sys_read</code> restituisce 0, <code>sys_read</code> ha raggiunto la fine del file da cui sta leggendo. Se restituisce un valore positivo, questo valore è il numero di caratteri che ha letto dal file. In questo caso, poiché abbiamo richiesto solo un carattere, <code>sys_read</code> restituirà un conteggio di 1 o 0 per indicare che non ci sono più caratteri.
		</p>
	</li>
 	<li>
		<p align=justify>
			L'istruzione <code>CMP</code> confronta i suoi due operandi e imposta i flag di conseguenza. L'istruzione di salto condizionale che segue ogni istruzione <code>CMP</code> agisce in base allo stato dei flag.
		</p>
	</li>
 	<li>
		<p align=justify>
			L'istruzione <code>JB</code> (Jump If Below) salta se l'operando sinistro del <code>CMP</code> precedente è inferiore in valore rispetto al suo operando destro.
		</p>
	</li>
 	<li>
		<p align=justify>
			L'istruzione <code>JA</code> (Salta se Maggiore) salta se l'operando sinistro del <code>CMP</code> precedente è superiore in valore rispetto all'operando destro.
		</p>
	</li>
 	<li>
		<p align=justify>
			Poiché un indirizzo di memoria (come <code>Buff</code>) punta semplicemente a una posizione in memoria di dimensioni non specifiche, devi inserire il qualificatore BYTE tra CMP e il suo operando di memoria per dire all'assemblatore che vuoi confrontare due valori a 8 bit. In questo caso, i due valori a 8 bit sono un carattere ASCII come w e un valore esadecimale come 7Ah.
		</p>
	</li>
 	<li>
		<p align=justify>
			Poiché i programmi scritti in SASM utilizzano la Standard C Library, di solito terminano con un'istruzione RET anziché con la funzione SYSCALL Exit.
		</p>
	</li>
</ul>

<p align=justify>
L'esecuzione del programma eseguibile avviene utilizzando la reindirizzamento I/O. La riga di comando per uppercaser1 appare così.
</p>

```
./uppercaser1> outputfile < inputfile
```

<p align=justify>
Sia il file di input che il file di output possono essere qualsiasi file di testo. Ecco una cosa da provare
</p>

```asm
./uppercaser1> allupper.txt < uppercaser1.asm
```

<p align=justify>
Il file allupper.txt verrà creato quando esegui il programma e sarà riempito con il codice sorgente del programma, forzando tutti i caratteri a maiuscolo. Nota che se stai lavorando all'interno di SASM, puoi inserire il testo da convertire nella finestra di Input. (Carica un file di testo puro in un editor di testo e estrai del testo tramite il comando Copia, quindi incollalo nella finestra di Input tramite Incolla.) Quando esegui il programma, leggerà il testo dalla finestra di Input, lo forzerà a maiuscolo e poi scriverà il testo convertito nella finestra di Output. SASM mappa la finestra di Input a stdin e la finestra di Output a stdout.
</p>

<p align=justify>
Specialmente mentre sei un principiante, potresti scoprire, mentre tenti questo ultimo passo di passare dal pseudocodice alle istruzioni per la macchina, che hai frainteso qualcosa o dimenticato qualcosa e che il tuo pseudocodice non è completo o corretto. (O entrambi!) Potresti anche renderti conto che ci sono modi migliori per fare qualcosa nelle istruzioni in assembly rispetto a quello che una traduzione letterale del pseudocodice potrebbe darti. Apprendere è un'attività disordinata e, non importa quanto tu pensi di essere bravo, continuerai sempre a imparare. Un buon esempio, e uno che potrebbe effettivamente esserti venuto in mente mentre leggi il precedente codice assembly, è questo: il programma non ha alcun rilevamento degli errori. Presume semplicemente che qualsiasi nome di file di input inserito dall'utente per la reindirizzazione I/O sia un file esistente e non corrotto con dati al suo interno, che ci sarà spazio sull'unità corrente per il file di output, e così via. È un modo per operare pericoloso, anche se Dio sa che è stato fatto. Le chiamate di sistema Linux relative ai file restituiscono valori di errore e qualsiasi programma che le utilizza dovrebbe esaminare quei valori di errore e agire di conseguenza. Ci saranno quindi momenti in cui dovrai seriamente riorganizzare il tuo pseudocodice a metà del processo, o addirittura scartarlo completamente e ricominciare da capo. Queste intuizioni hanno la fastidiosa abitudine di verificarsi quando sei in quella fase finale di conversione del pseudocodice in istruzioni per la macchina. Sii pronto.
</p>

<p align=justify>
E c'è un'altra questione che potrebbe esserti venuta in mente, se sai qualcosa sui file I/O a basso livello: la chiamata al kernel sys_read di Linux non è limitata a restituire un singolo carattere alla volta. Passi l'indirizzo di un buffer a sys_read, e sys_read cercherà di riempire quel buffer con quanti più caratteri dal file di input come gli dici di fare. Se configuri un buffer di 500 byte, puoi chiedere a sys_read di portare 500 caratteri da stdin e metterli in quel buffer. Una singola chiamata a sys_read può quindi fornire 500 caratteri (o 1.000, o 16.000) su cui lavorare, tutti in una volta. Questo riduce il tempo che Linux impiega a muoversi avanti e indietro tra il suo filesystem e il tuo programma, ma cambia anche in modo significativo la forma del programma. Riempie il buffer, e poi devi scorrere il buffer un carattere alla volta, convertendo quello che c'è in minuscolo in maiuscolo. Sì, avresti dovuto saperlo in anticipo, mentre affinavi una soluzione in pseudocodice al tuo problema—e dopo un po' di tempo lo farai. Ci sono un numero scoraggiante di dettagli di questo tipo che devi avere a portata di mano nella tua mente, e non li memorizzerai tutti in un pomeriggio. Di tanto in tanto, una tale rivelazione può costringerti a 'riavvolgere' un paio di iterazioni e riformulare parte del tuo pseudocodice.
</p>

### Scansionare un Buffer

<p align=justify>
È il caso dell'esempio attuale. Il programma ha bisogno di gestione degli errori, che in questo caso implica principalmente il test dei valori di ritorno da sys_read e sys_write e la visualizzazione di messaggi significativi sulla console Linux. Non c'è differenza tecnica tra la visualizzazione dei messaggi di errore e la visualizzazione di slogan per i diner a buon mercato, quindi potrei lasciarti aggiungere la gestione degli errori da solo come esercizio. (Non dimenticare stderr.) La sfida più interessante, tuttavia, riguarda l'I/O di file bufferizzato. Le chiamate di sistema Unix read e write sono orientate ai buffer e non ai caratteri, quindi dobbiamo rielaborare il nostro pseudocodice per riempire i buffer con i caratteri e poi elaborare i buffer.
</p>

<p align=justify>
Torniamo al pseudocodice e proviamo.
</p>

```
 Read:  Set up registers for the sys_read kernel call.
        Call sys_read to read a buffer full of characters from stdin.
        Test for EOF.
        If we're at EOF, jump to Exit.
 
        Set up registers as a pointer to scan the buffer.
 Scan:  Test the character at buffer pointer to see if it's lowercase.
        If it's not a lowercase character, skip conversion.
        Convert the character to uppercase by subtracting 20h.
        Decrement buffer pointer.
        If we still have characters in the buffer, jump to Scan.
 
Write: Set up registers for the Write kernel call.
       Call sys_write to write the processed buffer to stdout.
       Jump back to Read and get another buffer full of characters.
 
Exit:  Set up registers for terminating the program via sys_exit.
       Call sys_exit.
```

<p align=justify>
Questo aggiunge tutto ciò di cui hai bisogno per leggere un buffer da disco, esaminare e convertire i caratteri nel buffer e poi scrivere di nuovo il buffer su disco. (Naturalmente, il buffer deve essere ingrandito da un carattere a una dimensione utile, come 1024 caratteri.) Il succo del trucco del buffer è impostare un puntatore nel buffer e poi esaminare e (se necessario) convertire il carattere all'indirizzo espresso dal puntatore. Poi spostiamo il puntatore al carattere successivo nel buffer e facciamo la stessa cosa, ripetendo il processo finché non abbiamo trattato tutti i caratteri nel buffer. Scansionare un buffer è un ottimo esempio di un ciclo in linguaggio assembly. Ad ogni passaggio attraverso il ciclo dobbiamo testare qualcosa per vedere se siamo finiti e se dovremmo uscire dal ciclo. Il “qualcosa” in questo caso è il puntatore. Possiamo impostare il puntatore all'inizio del buffer e testare per vedere quando raggiunge la fine, oppure potremmo impostare il puntatore alla fine del buffer e lavorare verso l'inizio, testando per vedere quando raggiungiamo l'inizio del buffer. Entrambi gli approcci funzioneranno. Tuttavia, partire dalla fine e lavorare verso l'inizio del buffer può essere fatto un po' più rapidamente e con meno istruzioni. (Spiegherò il perché a breve.) La nostra prossima rifinitura dovrebbe iniziare a parlare di specifiche: quali registri fanno cosa, e così via.
</p>

```
 Read:  Set up registers for the sys_read kernel call.
        Call sys_read to read a buffer full of characters from stdin.
        Store the number of characters read in RSI
        Test for EOF (rax = 0).
        If we're at EOF, jump to Exit.
 
        Put the address of the buffer in rsi.
        Put the number of characters read into the buffer in rdx.
 Scan:  Compare the byte at [r13+rbx] against 'a'.
        If the byte is below 'a' in the ASCII sequence, jump to Next.
        Compare the byte at [r13+rbx] against 'z'.
        If the byte is above 'z' in the ASCII sequence, jump to Next.
        Subtract 20h from the byte at [r13+rbx].
 Next:  Decrement rbx by one.
        Jump if not zero to Scan.
 Write: Set up registers for the Write kernel call.
        Call sys_write to write the processed buffer to stdout.
        Jump back to Read and get another buffer full of characters.
 Exit:  Set up registers for terminating the program via sys_exit.
        Call sys_exit.
```

<p align=justify>
Questo affinamento riconosce che non c'è un solo test da effettuare, ma due. I caratteri minuscoli rappresentano un intervallo nella sequenza ASCII, e gli intervalli hanno inizio e fine. Dobbiamo determinare se il carattere in esame rientra nell'intervallo. Per farlo, è necessario testare il carattere per vedere se è inferiore al carattere più basso nell'intervallo delle minuscole (a) o superiore al carattere più alto nell'intervallo delle minuscole (z). Se il carattere in questione non è minuscolo, non è necessaria alcuna elaborazione, e passiamo al codice che aumenta il puntatore al carattere successivo. Navigare all'interno del buffer coinvolge due registri. L'indirizzo dell'inizio del buffer è posto in R13. Il numero di caratteri nel buffer è posto nel registro RBX. Se si sommano i due registri, si ottiene l'indirizzo dell'ultimo carattere nel buffer. Se si decrementa il contatore dei caratteri in RBX, la somma di R13 e RBX punterà al penultimo carattere nel buffer. Ogni volta che si decrementa RBX, si avrà l'indirizzo di un carattere più vicino all'inizio del buffer. Quando RBX viene deprivato di uno fino a zero, sarete all'inizio del buffer, e tutti i caratteri saranno stati elaborati.
</p>

<p align=justify>
Ma aspetta... non è del tutto vero. C'è un bug nel pseudocodice, ed è uno dei bug più comuni per i principianti in tutto il linguaggio assembly: il leggendario errore "off by one". La somma di R13 e RBX punterà a un indirizzo oltre la fine del buffer. E quando il conteggio in RBX scende a zero, un carattere—quello all'inizio del buffer—rimarrà inesaminato e (se è minuscolo) intoccato. Il modo più semplice per spiegare da dove proviene questo bug è disegnarlo, come ho fatto nella figura di sotto. C'è un file di testo molto breve nel l'archivio delle liste per questo libro chiamato gazabo.txt. Contiene solo la singola parola senza senso gazabo e il marcatore EOL, per un totale di sette caratteri. La figura di sotto mostra il file gazabo.txt come apparirebbe dopo che Linux lo carica in un buffer in memoria. L'indirizzo del buffer è stato caricato nel registro R13, e il numero di caratteri (qui, 7) è stato caricato in RBX. Se sommi R13 e RBX, l'indirizzo risultante va oltre la fine del buffer in una memoria non utilizzata (si spera!).
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/off_by_one_error.png">
</div>

<p align=justify>
Questo tipo di problema può verificarsi ogni volta che si iniziano a mescolare gli offset degli indirizzi e i conteggi delle cose. I conteggi iniziano da 1, e gli offset iniziano da 0. Il carattere #1 si trova realmente all'offset 0 dall'inizio del buffer, il carattere #2 si trova all'offset 1, e così via. Stiamo cercando di utilizzare un valore in RBX sia come conteggio che come offset, e se gli offset nel buffer sono assunti da 0, un errore di uno è inevitabile. La soluzione è semplice: decrementare l'indirizzo del buffer (che è memorizzato in R13) di 1 prima di cominciare la scansione. R13 ora punta alla posizione di memoria immediatamente prima del primo carattere nel buffer. Con R13 impostato in questo modo, possiamo utilizzare il valore di conteggio in R13 sia come conteggio che come offset. Quando il valore in R13 è decrementato a 0, abbiamo elaborato il carattere g e usciamo dal ciclo. Un esperimento interessante è “commentare” l'istruzione macchina DEC R13 e poi eseguire il programma. Questo si fa semplicemente mettendo un punto e virgola all'inizio della riga contenente DEC R13 e ricompilando. Digita gazabo o qualsiasi altra cosa in minuscolo nella finestra di input e poi esegui il programma.
</p>

### Dallo Pseudocodice al codice Assembly

<p align=justify>
A questo punto farò quel salto spaventoso verso le istruzioni della macchina reale, ma per brevità mostrerò solo il ciclo stesso.
</p>

```asm
 ; Set up the registers for the process buffer step:
     mov rbx,rax          ; Place the number of bytes read into rbx
     mov r13,Buff         ; Place address of buffer into r13
     dec r13              ; Adjust r13 to offset by one
 
; Go through the buffer and convert lowercase to uppercase characters:
 Scan:
     cmp byte [r13+rbx],61h  ; Test input char against lowercase 'a'
     jb Next                 ; If below 'a' in ASCII, not lowercase
     cmp byte [r13+rbx],7Ah  ; Test input char against lowercase 'z'
     ja Next                 ; If above 'z' in ASCII, not lowercase
                             ; At this point, we have a lowercase char
     sub byte [r13+rbx],20h  ; Subtract 20h to give uppercase...
 Next:
     dec rbx                 ; Decrement counter
     jnz Scan                ; If characters remain, loop back
```

<p align=justify>
Lo stato del buffer e dei registri puntatore prima di iniziare la scansione è mostrato nella seconda parte della figura di sopra. La prima volta, il valore in RBX è il conteggio dei caratteri nel buffer. La somma R13 + RBX punta al carattere EOL alla fine del buffer. La volta successiva, RBX viene decrementato a 6, e R13 + RBX punta alla lettera o in gazabo. Ogni volta che decretiamo RBX, controlliamo il flag Zero usando l'istruzione JNZ, che salta di nuovo all'etichetta Scan quando il flag Zero non è impostato. Nell'ultima passata attraverso il ciclo, RBX contiene 1, e R13 + RBX punta alla lettera g nella primissima posizione del buffer. Solo quando RBX è decrementato a zero JNZ "scorre" e il ciclo termina. I puristi potrebbero pensare che decrementare l'indirizzo in R13 prima che inizi il ciclo sia un trucco rischioso. Hanno in parte ragione: dopo essere stato decrementato, R13 punta a una posizione in memoria al di fuori dei limiti del buffer. Se il programma tentasse di scrivere in quella posizione, un'altra variabile potrebbe essere corrotta, o potrebbe verificarsi un errore di segmentazione. La logica del ciclo non richiede di scrivere in quell'indirizzo particolare, ma potrebbe facilmente esserlo fatto per errore.
</p>

<p align=justify>
Il codice di sotto mostra il programma completato, completamente commentato con tutto il pseudocodice convertito in codice assembly.
</p>

```asm
 ;  Executable name  : 	uppercaser2gcc
 ;  Version          : 	2.0
 ;  Created date     : 	6/17/2022
 
 ;  Last update      : 	5/8/2023

 ;  Author           : 	Jeff Duntemann

 ;  Description      : 	A simple program in assembly for Linux, using NASM 2.15.05
 ;		       	demonstrating simple text file I/O
 ;			(through redirection) for reading an input file to
 ;			a buffer in blocks, forcing lowercase characters to
 ;			uppercase, and writing the modified buffer to
 ;			an output file.
 ;                    
 ;                    
 ;  Run it this way in a terminal window:
 ;
 ;    uppercaser2> (output file) < (input file)  
 ;
 ;  Build in SASM using the default make lines and x64 checked
 ;

 SECTION .bss      		; Section containing uninitialized data
    
	BUFFLEN  equ 128	; Length of buffer       
	Buff:	 resb BUFFLEN  	; Text buffer itself

 SECTION .data			; Section containing initialised data         

 SECTION .text			; Section containing code         

global main           		; Linker needs this to find the entry point
main:
    mov rbp,rsp       ; for correct debugging
; Read a buffer full of text from stdin:
Read:
    mov rax,0        ; Specify sys_read call
    mov rdi,0        ; Specify File Descriptor 0: Standard Input
    mov rsi,Buff     ; Pass offset of the buffer to read to
    mov rdx,BUFFLEN  ; Pass number of bytes to read at one pass
    syscall          ; Call sys_read to fill the buffer
    mov r12,rax      ; Copy sys_read return value to r12 for later
    cmp rax,0        ; If rax=0, sys_read reached EOF on stdin
    je Done          ; Jump If Equal (to 0, from compare)
; Set up the registers for the process buffer step:
    mov rbx,rax      ; Place the number of bytes read into rbx
    mov r13,Buff     ; Place address of buffer into r13
    dec r13          ; Adjust count to offset
; Go through the buffer and convert lowercase to uppercase characters:
Scan:
    cmp byte [r13+rbx],61h  ; Test input char against lowercase 'a'
    jb .Next                ; If below 'a' in ASCII, not lowercase
    cmp byte [r13+rbx],7Ah  ; Test input char against lowercase 'z'
    ja .Next                ; If above 'z' in ASCII, not lowercase
                            ; At this point, we have a lowercase char
    sub byte [r13+rbx],20h  ; Subtract 20h to give uppercase...
.Next:
    dec rbx                 ; Decrement counter
    cmp rbx,0
    jnz Scan                ; If characters remain, loop back
; Write the buffer full of processed text to stdout:
Write:
    mov rax,1		    ; Specify sys_write call             
    mov rdi,1               ; Specify File Descriptor 1: Standard output
    mov rsi,Buff            ; Pass offset of the buffer
    mov rdx,r12             ; Pass # of bytes of data in the buffer
    syscall            	    ; Make kernel call     
    jmp Read                ; Loop back and load another buffer full

; All done! Let's end this party:
 Done:
   ret
```

<p align=justify>
C'è un difetto in SASM su cui potresti inciampare, se stai testando programmi come uppercaser2gcc all'interno di SASM, utilizzando le finestre di Immissione e Uscita. Il problema è che la finestra di Uscita può contenere solo una certa quantità di testo. Se riempi il buffer della finestra di Uscita, ulteriori output non genereranno errori, ma l'ultimo pezzo di testo spingerà il primo pezzo di testo fuori dal bordo superiore della finestra di Uscita. Una volta che hai un programma ragionevolmente funzionante in SASM, salva il file EXE su disco. Poi esci da SASM, apri una finestra del terminale, naviga nella directory del progetto ed esegui il tuo programma lì. Non so se Linux imponga un limite su quanto testo può passare attraverso stdout, ma ho passato alcuni file piuttosto grandi a stdout senza che alcun testo andasse perso.
</p>

### Operazioni sui Bit

<p align=justify>
Il linguaggio assembly si basa molto sui bit. I bit, dopotutto, sono ciò di cui sono composti i byte, e una competenza essenziale del linguaggio assembly è costruire byte e smontarli di nuovo. Una tecnica chiamata bit mapping è ampiamente utilizzata nel linguaggio assembly. Il bit mapping assegna significati speciali ai singoli bit all'interno di un byte per risparmiare spazio e spremere l'ultimo piccolo bit di utilità da una certa quantità di memoria. C'è una famiglia di istruzioni nel set di istruzioni x64 che ti consente di manipolare i bit all'interno dei byte applicando operazioni logiche booleane tra byte su base bit per bit. Queste sono le istruzioni logiche bitwise: <code>AND</code>, <code>OR</code>, <code>XOR</code> e <code>NOT</code>. Un'altra famiglia di istruzioni ti consente di spostare i bit avanti e indietro all'interno di un singolo byte o parola. Queste sono le istruzioni di shift/rotate più utilizzate: <code>ROL</code>, <code>ROR</code>, <code>RCL</code>, <code>RCR</code>, <code>SHL</code> e <code>SHR</code>. 
</p>

### Bit Numbering

<p align=justify>
Gestire i bit richiede che abbiamo un modo per specificare quali bit stiamo trattando. Per convenzione, i bit nel linguaggio assembly sono numerati, partendo da 0, dal bit meno significativo nel byte, word, doppio word o altro elemento che stiamo utilizzando come mappa di bit. Il bit meno significativo è quello con il valore più basso nel sistema numerico binario. È anche il bit all'estrema destra, se scrivi il valore come un numero binario nel modo convenzionale. L'ho mostrato nella figura di sotto, per una word a 16 bit. La numerazione dei bit funziona esattamente allo stesso modo, indipendentemente da quanti bit stai trattando: byte, word, doppio word o quadword. Il bit 0 è sempre all'estremità destra, e i numeri dei bit aumentano verso sinistra.
</p>

<div aling=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/bit_numbering.png"
</div>

<p align=justify>
Quando conti i bit, inizia con il bit all'estremità destra e numerali verso sinistra a partire da 0.
</p>

### Operazioni Binarie

<p align=justify>
Il termine logica booleaniana suona arcano e minaccioso, ma sorprendentemente riflette le realtà del pensiero e dell'azione ordinari. L'operatore booleano <ocde>AND</ocde>, ad esempio, si presenta in molte delle decisioni che prendi ogni giorno della tua vita. Ad esempio, per scrivere un assegno che non venga rifiutato, devi avere denaro nel tuo conto corrente <code>AND</code> assegni nel tuo libretto degli assegni. Nessuno dei due da solo svolgerà il lavoro. Non puoi scrivere un assegno che non hai, e un assegno senza denaro dietro di esso verrà rifiutato. Le persone che vivono con i loro libretti degli assegni utilizzano spesso l'operatore <code>AND</code>. Quando i matematici parlano di logica booleaniana, manipolano valori astratti chiamati Vero e Falso. L'operatore <code>AND</code> funziona in questo modo: <i>Condizione1 <code>AND</code> Condizione2</i>i> sarà considerato Vero se entrambe Condizione1 e Condizione2 sono Vere. Se una delle condizioni è Falsa, il risultato sarà Falso. Ci sono infatti quattro diverse combinazioni dei due valori di input, quindi le operazioni logiche tra due valori sono solitamente riassunte in una forma chiamata tabella di verità. La tabella di verità per l'operatore logico <code>AND</code> (non l'istruzione <code>AND</code> ancora; ci arriveremo a breve) è mostrata nella figura di sotto.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/and_table.png">
</div>

<p align=justify>
Non c'è nulla di misterioso nella tabella della verità. È solo un riepilogo di tutte le possibilità dell'operatore AND applicato a due condizioni di input. La cosa importante da ricordare riguardo l'AND è che solo quando entrambi i valori di input sono Veri, anche il risultato sarà Vero. Questo è il modo in cui i matematici vedono l'AND. In termini di linguaggio assembly, l'istruzione AND analizza due bit e produce un terzo bit in base ai valori dei primi due bit. Per convenzione, consideriamo un bit 1 come Vero e un bit 0 come Falso. La logica è identica; stiamo solo usando simboli diversi per rappresentare Vero e Falso. Tenendo presente questo, possiamo riscrivere la tabella della verità dell'AND per renderla più significativa per il lavoro in linguaggio assembly. Vedi la figura di sotto.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/and_table_asm.png">
</div>

### Istruzione AND

<p align=justify>
L'istruzione AND incarna questo concetto nel set di istruzioni x64. L'istruzione AND esegue l'operazione logica AND su due operandi di dimensioni simili e sostituisce l'operando di destinazione con il risultato dell'operazione nel suo complesso. (Ricorda che l'operando di destinazione è l'operando più vicino al mnemonico.) In altre parole, considera questa istruzione: 
</p>

```asm
	and al,bl. 
 ```

<p align=justify>
Ciò che accadrà qui è che la CPU eseguirà un gruppo di otto operazioni AND bitwise sugli otto bit in AL e BL. Il bit 0 di AL viene messo in AND con il bit 0 di BL, il bit 1 di AL viene messo in AND con il bit 1 di BL, e così via. Ogni operazione AND genera un bit di risultato, e quel bit viene posizionato nell'operando di destinazione (qui, AL) dopo che tutte e otto le operazioni AND sono state eseguite. Questo è un filo comune tra le istruzioni della macchina che eseguono un'operazione su due operandi e producono un risultato: il risultato sostituisce il primo operando (l'operando di destinazione) e non il secondo!
</p>

### Mascherare i Bit

<p align=justify>
Un uso importante dell'istruzione AND è isolare uno o più bit da un valore di byte, parola, dword o qword. Isolare qui significa semplicemente impostare tutti i bit indesiderati su un valore affidabile di 0. Per esempio, supponiamo di essere interessati a testare i bit 4 e 5 di un valore per vedere quali sono. Per farlo, dobbiamo essere in grado di ignorare gli altri bit (dal bit 0 al 3 e dal 6 al 7), e l'unico modo per ignorare in modo sicuro i bit è impostarli a 0. AND è la soluzione. Impostiamo una maschera di bit in cui i numeri dei bit che vogliamo esaminare e testare sono impostati su 1, e i bit che desideriamo ignorare sono impostati su 0. Per mascherare tutti i bit tranne i bit 4 e 5, dobbiamo configurare una maschera in cui i bit 4 e 5 sono impostati su 1, mentre tutti gli altri bit sono 0. Questa maschera in binario è 00110000B o 30H. (Per verificarlo, conta i bit dall'estremità destra del numero binario, iniziando da 0.) Questa maschera di bit viene quindi messa in AND con il valore in questione. La figura di sotto mostra questa operazione in azione, con la maschera di bit 30H appena descritta e un valore iniziale di 9DH.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/and_instruction.png">
</div>

<p align=justify>
I tre valori binari coinvolti sono mostrati disposti verticalmente, con il bit meno significativo (cioè, l'estremità destra) di ciascun valore in cima. Dovresti essere in grado di seguire ogni operazione AND e verificarla consultando la tabella precendete. Il risultato finale è che tutti i bit tranne i bit 4 e 5 sono garantiti essere 0 e possono quindi essere ignorati in sicurezza. I bit 4 e 5 potrebbero essere sia 0 che 1. (Ecco perché dobbiamo testarli; non sappiamo quale sia il loro valore.) Con il valore iniziale di 9DH, il bit 4 risulta essere 1 e il bit 5 risulta essere 0. Se il valore iniziale fosse stato un altro, i bit 4 e 5 potrebbero essere entrambi 0, entrambi 1, o qualche combinazione dei due. Non dimenticare: <b>il risultato dell'istruzione AND sostituisce l'operando di destinazione dopo che l'operazione è completata</b>.
</p>

### Istruzione OR

<p align=justify>
Correlato strettamente all'operazione logica AND è OR, che, come l'operazione logica AND, ha una realizzazione con lo stesso nome nel set di istruzioni x86/x64. Strutturalmente, l'istruzione OR funziona in modo identico a AND. Solo la sua tabella della verità è diversa: mentre AND richiede che entrambi i suoi operandi siano 1 affinché il risultato sia 1, OR è soddisfatto che almeno un operando abbia un valore di 1. La tabella della verità per OR è mostrata nella figura di sotto.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/or_instruction.png">
</div>

<p align=justify>
Poiché è inadeguato per isolare i bit, l'istruzione OR viene utilizzata molto meno frequentemente rispetto all'AND.
</p>

### Istruzione XOR

<p align=justify>
In una classe a sé stante c'è l'operazione OR esclusivo, incarnata nell'istruzione XOR. XOR, di nuovo, fa in termini generali ciò che fa AND e OR: esegue un'operazione logica bit per bit sui suoi due operandi, e il risultato sostituisce l'operando di destinazione. L'operazione logica, tuttavia, è esclusiva o, il che significa che <b>il risultato è 1 solo se i due operandi sono diversi</b> (cioè 1 e 0 oppure 0 e 1). La tabella di verità per XOR (vedi figura di sotto) dovrebbe rendere questa nozione leggermente scivolosa un po' più chiara.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/xor_instruction.png">
</div>

<p align=justify>
Guarda la figura di sopra con attenzione! Nei primi e ultimi casi, dove i due operandi sono gli stessi, il risultato è 0. Nei due casi centrali, dove i due operandi sono diversi, il risultato è 1. Si possono fare alcune cose interessanti con l'istruzione XOR, ma la maggior parte di esse è un po' arcana per un libro per principianti come questo. Un uso non ovvio ma utile di XOR è questo: eseguire l'XOR di qualsiasi valore contro se stesso produce 0. In altre parole, se esegui l'istruzione XOR con entrambi gli operandi come lo stesso registro, quel registro verrà azzerato a 0: 
</p>

```asm
 xor rax,rax ; Azzerare il registro rax.
```

<p align=justify>
Nei tempi passati, questo era più veloce che caricare uno 0 in un registro da dati immediati utilizzando MOV. Anche se non è più il caso, è un trucco interessante da conoscere. Come funziona dovrebbe essere ovvio dalla lettura della tabella della verità, ma per chiarirlo l'ho mostrato nella di sotto. Segui ciascuna delle singole operazioni di esclusione OR attraverso la figura fino al suo valore di risultato. Poiché ogni bit in AL è messo in XOR contro se stesso, in ogni caso le operazioni di XOR avvengono tra due operandi identici. A volte entrambi sono 1, a volte entrambi sono 0, ma in ogni caso i due sono gli stessi. Con l'operazione XOR, quando i due operandi sono gli stessi, il risultato è sempre 0. Voilà! Zero in un registro.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/xor_to_zero_register.png">
</div>

### Istruzione NOT

<p align=justify>
La più facile da capire tra tutte le istruzioni logiche bit a bit è NOT. La tabella della verità per NOT è più semplice rispetto alle altre esaminate perché NOT prende solo un operando. E ciò che fa è semplice: NOT prende lo stato di ciascun bit nel suo unico operando e cambia quel bit nel suo stato opposto. Ciò che era 1 diventa 0, e ciò che era 0 diventa 1. Mostro questo nella figura di sotto.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/not_instruction.png">
</div>

### I segmenti di registro non rispondono alla logica

<p align=justify>
Non accederai direttamente ai registri di segmento fino a quando non ti immergerai nelle profondità della programmazione del sistema operativo. I registri di segmento ora appartengono al sistema operativo, e i programmi nello spazio utente non possono modificarli in alcun modo. Ma anche quando inizi a lavorare a livello di sistema operativo, i registri di segmento presentano limitazioni significative. Una di queste limitazioni è che non possono essere utilizzati con nessuna delle istruzioni logiche bit a bit. Se ci provi, l'assemblatore ti darà un errore "Uso illegale del registro di segmento". Se hai bisogno di eseguire un'operazione logica su un registro di segmento, devi prima copiare il valore del registro di segmento in uno dei registri a uso generale, eseguire l'operazione logica sul registro GP, e poi copiare il risultato dal registro GP di nuovo nel registro di segmento. I registri a uso generale sono chiamati "a uso generale" per una ragione, e i registri di segmento non sono in alcun modo a uso generale. Sono specialisti nell'indirizzamento della memoria, e se mai devi lavorare sui valori dei segmenti, l'approccio generale è fare il lavoro in un registro a uso generale e poi copiare il valore modificato di nuovo nel registro di segmento in questione.
</p>

### Shiftare i Bit

<p align=justify>
L'altro modo di manipolare i bit all'interno di un byte è un po' più diretto: li sposti verso un lato o l'altro. Ci sono alcuni dettagli nel processo, ma le istruzioni di spostamento più semplici sono piuttosto ovvie: <code>SHL</code> sposta il suo operando a sinistra, mentre <code>SHR</code> sposta il suo operando a destra. Tutte le istruzioni di spostamento (compresi quelle leggermente più complesse che descriverò tra poco) hanno la stessa forma generale, illustrata qui dall'istruzione <code>SHL</code>:
</p>

```asm
 shl <register/memory>,<count>
```

<p align=justify>
Il primo operando è l'obiettivo dell'operazione di spostamento, cioè il valore che stai per spostare. Può essere dati di registro o dati di memoria, ma non dati immediati. Il secondo operando specifica il numero di bit con cui spostare.
</p>

<p align=justify>
Questo operando <count> ha una storia peculiare. Sugli antichi 8086 e 8088, poteva essere una delle due cose: il numero immediato 1, o il registro CL. (Non CX!) Se specificavi il conteggio come 1, allora lo spostamento sarebbe stato di un bit. Se volevi spostare più di un bit alla volta, dovevi prima caricare il conteggio dello spostamento nel registro CL. Nei tempi precedenti a quando i registri generali x86 divennero davvero generali, contare le cose era l'”agenda nascosta” di CX (e quindi di CL). Contava gli spostamenti, i passaggi nei cicli, gli elementi di stringa e alcune altre cose. È per questo che a volte viene chiamato registro conteggio e può essere ricordato dalla C in conteggio. A partire dal 286 e per tutte le CPU x86/x64 più recenti, l'operando <count> può essere qualsiasi valore immediato da 0 a 255. Il conteggio degli spostamenti può anche essere passato in CL se lo preferisci. Nota che non puoi specificare RCX per il conteggio, anche se “contiene” CL. <b>Anche in x64, le istruzioni di spostamento richiedono davvero un valore immediato da 0 a 255 o CL</b>b>. <b>Qualsiasi altro registro specificato per il valore di conteggio attiverà un errore dell'assemblatore</b>. Ovviamente, spostare di 0 bit è inutile, ma è possibile e non è considerato un errore. Fai attenzione alla tua digitazione. Ora, c'è un'importante asterisco nel paragrafo precedente: non puoi spostare più posizioni di quante ne abbia il registro di destinazione. In modalità lunga a 64 bit, non puoi spostare (o ruotare; vedi la sezione successiva) più di 63 conteggi. Tentare di farlo non attiverà un errore. Semplicemente non funzionerà. 
</p>

### Come funziona lo shifting dei bit

<p align=justify>
Comprendere le istruzioni di spostamento richiede di pensare ai numeri spostati come numeri binari, e non come numeri esadecimali o decimali. Un esempio semplice partirebbe dal registro AX che contiene un valore di 0B76FH. (Sto usando AX per l'esempio qui per mantenere i numeri binari brevi e comprensibili, ma le istruzioni di spostamento possono essere utilizzate su registri di qualsiasi dimensione.) Espressa come numero binario (e quindi come modello di bit), 0B76FH è la seguente:
</p>

```
 1011011101101111
```

<p align=justify>
Tieni presente che ogni cifra in un numero binario è un bit. Se esegui un'istruzione <code>SHL AX,1</code>, ciò che troveresti in AX dopo lo spostamento è il seguente:
</p>

```
0110111011011110
```

<p align=justify>
Un 0 è stato inserito all'estremità destra del numero, e tutto quanto è stato spostato verso sinistra di una cifra. Nota che un bit 1 è stato spostato all'estremità sinistra del numero nel nulla cosmico. Puoi persino usare le istruzioni di shift su CL, con CL che contiene il conteggio. Questo è legale, anche se sembra peculiare, e potrebbe non essere la migliore idea:
</p>

```asm
 mov cl,1
 shl cl,cl
```

<p align=justify>
Quello che accade in questo esempio è che il valore di conteggio in CL viene spostato a sinistra dal valore che contiene CL. Qui il bit 1 in CL viene spostato per diventare un bit 2. Se questo sembra ancora strano, mettilo in una sandbox e osserva i registri.
</p>

### Colpire i Bit nel Carry Flag

<p align=justify>
Spostare un po' a sinistra un valore binario non significa esattamente mandare quel bit nel nulla cosmico. Un bit spostato fuori dall'estremità sinistra di un valore binario viene spostato in un contenitore temporaneo per i bit chiamato Flag di Riporto (CF, Carry Flag) . Il Flag di Riporto è uno di quei bit informativi raccolti insieme nel registro RFlags, che ho descritto nei paragrafi precedenti. Puoi testare lo stato del Flag di Riporto con un'istruzione di branching, come spiegherò un po' più avanti. Tuttavia, tieni presente, quando usi le istruzioni di shift, che molte altre istruzioni diverse usano il Flag di Riporto (non solo le istruzioni di shift). Se sposti un bit nel Flag di Riporto con l'intento di testare quel bit più tardi per vedere cosa è, testalo prima di eseguire un'altra istruzione che influisce sul Flag di Riporto. Quella lista include tutte le istruzioni aritmetiche, tutte le istruzioni logiche bit a bit, alcune altre istruzioni varie e, naturalmente, tutte le altre istruzioni di shift. Se sposti un bit nel Flag di Riporto e poi esegui immediatamente un'altra istruzione di shift, il bit spostato nel Flag di Riporto in precedenza verrà spedito fuori dall'estremità del mondo nel nulla cosmico.
</p>

### L'istruzione Rotate

<p align=justify>
Detto questo, se il destino di un bit non è quello di perdersi nel nulla cosmico, è necessario utilizzare le istruzioni di rotazione RCL, RCR, ROL e COR. Le istruzioni di rotazione sono quasi identiche alle istruzioni di spostamento, ma con una differenza cruciale: il bit sbattuto fuori da un'estremità dell'operando riappare all'estremità opposta dell'operando. Quando si ruota un operando di più di un bit, i bit marciano costantemente in una direzione, cadendo dall'estremità e riapparendo immediatamente all'estremità opposta. I bit quindi "ruotano" attraverso l'operando mentre viene eseguita l'istruzione di rotazione. Come tante cose, questo si vede meglio graficamente che a parole. Dai un'occhiata alla figura di sotto. L'esempio mostrato qui è l'istruzione <code>ROL</code> (Rotate Left), ma l'istruzione <code>ROR</code> funziona allo stesso modo, con i bit che si muovono nella direzione opposta. Un valore binario iniziale di <code>10110010</code> (0B2h) viene inserito in AL. Quando viene eseguita un'istruzione <code>ROL AL,1</code> tutti i bit in AL marciano verso sinistra di una posizione. Il bit a 1 in posizione 7 esce dall registro AL a sinistra ma gira e riappare immediatamente a destra in posizione 0. Anche in questo caso, il <code>ROR</code> funziona esattamente allo stesso modo, ma il movimento dei bit è da sinistra a destra invece che (come con <code>ROL</code>) da destra a sinistra. Il numero di bit in base ai quali viene ruotato un operando può essere un valore immediato o un valore in CL.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/how_rotate_works.png">
</div>

### Ruotare i Bit attraverso il Carry Flag

<p align=justify>
C'è un secondo paio di istruzioni di rotazione nel set di istruzioni x86/x64: <code>RCR</code> (Ruota Carry a Destra, Rotate Carry Right) e <code>RCL</code> (Ruota Carry a Sinistra, (Rotate Carry Left). Queste operano come ROL e ROR, ma con una differenza: I bit che vengono spostati fuori dalla fine di un operando e rientrano nell'operando all'inizio viaggiano attraverso il flag Carry. Il percorso che un singolo bit percorre in una rotazione tramite CF è quindi di un bit più lungo rispetto a quello che sarebbe in ROL e ROR. L'ho mostrato graficamente nella figura di sotto.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/how_rotate_with_carry_flag_works.png">
</div>

### Settare un valore conosciuto nel Carry Flag

<p align=justify>
È anche utile ricordare che le istruzioni precedenti possono lasciare valori nel CF, e quei valori verranno ruotati in un operando durante un'istruzione RCL o RCR. Alcune persone hanno la comprensione errata che il CF venga forzato a 0 prima di un'istruzione di shift o rotate, e questo non è affatto vero. Se un'altra istruzione lascia un bit 1 nel CF immediatamente prima di un'istruzione RCR o RCL, quel bit 1 entrerà obbedientemente nell'operando di destinazione, che tu lo voglia o meno. Se è importante iniziare una rotazione con un valore noto nel CF, c'è una coppia di istruzioni x86 che faranno il lavoro per te: <code>CLC</code> e <code>STC</code>. <code>CLC</code> azzera il flag di carry a 0. <code>STC</code> imposta il flag di carry a 1. Nessuna delle due istruzioni prende un operando e nessuna ha altri effetti.
</p>

###  Bit-Bashing

<p align=justify>
Linux ha un metodo piuttosto conveniente per visualizzare il testo sullo schermo. Il problema è che visualizza solo testo: se vuoi visualizzare un valore numerico da un registro come una coppia di cifre esadecimali, Linux non può aiutarti. Devi prima convertire il valore numerico nella sua rappresentazione stringa e poi visualizzare la rappresentazione stringa chiamando il servizio kernel sys_write tramite syscall. Convertire numeri esadecimali in cifre esadecimali non è difficile, e il codice che svolge questo compito dimostra diversi dei nuovi concetti che stiamo esplorando in questo capitolo. Il codice di sotto è il nucleo essenziale di un'utilità di dump esadecimale. Quando reindirizzi il suo input da un file di qualsiasi tipo, leggerà quel file 16 byte alla volta e visualizzerà quei 16 byte in una riga, come 16 valori esadecimali separati da spazi. Il codice contiene un numero di nuove tecniche che vale la pena discutere.
</p>

```asm
;  Executable name : hexdump1gcc
;  Version         : 2.0
;  Created date    : 5/9/2022
;  Last update     : 5/8/2023
;  Author          : Jeff Duntemann
;  Description     : A simple program in assembly for Linux, using NASM 2.15
;    under the SASM IDE, demonstrating the conversion of binary values to 
;    hexadecimal strings. It acts as a very simple hex dump utility for files, 
;    without the ASCII equivalent column.
;
;  Run it this way:
;    hexdump1gcc < (input file)  
;
;  Build using SASM's default build setup for x64

;
SECTION .bss              ; Section containing uninitialized data

	BUFFLEN	equ 16        ; We read the file 16 bytes at a time
	Buff: 	resb BUFFLEN  ; Text buffer itself, reserve 16 bytes
	
SECTION .data             ; Section containing initialised data

    HexStr:	db " 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00",10
    HEXLEN equ $-HexStr

    Digits: db "0123456789ABCDEF"
		
SECTION .text             ; Section containing code

global  main              ; Linker needs this to find the entry point!
	
main:
    mov rbp,rsp       ; SASM Needs this for debugging

; Read a buffer full of text from stdin:
Read:
    mov rax,0             ; Specify sys_read call 0
    mov rdi,0             ; Specify File Descriptor 0: Standard Input
    mov rsi,Buff          ; Pass offset of the buffer to read to
    mov rdx,BUFFLEN       ; Pass number of bytes to read at one pass
    syscall               ; Call sys_read to fill the buffer
    mov r15,rax           ; Save # of bytes read from file for later
    cmp rax,0             ; If rax=0, sys_read reached EOF on stdin
    je Done               ; Jump If Equal (to 0, from compare)

; Set up the registers for the process buffer step:parm
    mov rsi,Buff          ; Place address of file buffer into esi
    mov rdi,HexStr        ; Place address of line string into edi
    xor rcx,rcx           ; Clear line string pointer to 0

; Go through the buffer and convert binary values to hex digits:
Scan:
    xor rax,rax           ; Clear rax to 0

; Here we calculate the offset into the line string, which is rcx X 3
    mov rdx,rcx               ; Copy the pointer into line string into rdx
;   shl rdx,1                 ; Multiply pointer by 2 using left shift
;   add rdx,rcx               ; Complete the multiplication X3
    lea rdx,[rdx*2+rdx]       ; This does what the above 2 lines do!
                              ; See discussion of LEA later in Ch. 9

; Get a character from the buffer and put it in both rax and rbx:
    mov al,byte [rsi+rcx]     ; Put a byte from the input buffer into al
    mov rbx,rax               ; Duplicate byte in bl for second nybble

; Look up low nybble character and insert it into the string:
    and al,0Fh                   ; Mask out all but the low nybble
    mov al,byte [Digits+rax]     ; Look up the char equivalent of nybble
    mov byte [HexStr+rdx+2],al   ; Write the char equivalent to line string

; Look up high nybble character and insert it into the string:
    shr bl,4                     ; Shift high 4 bits of char into low 4 bits
    mov bl,byte [Digits+rbx]     ; Look up char equivalent of nybble
    mov byte [HexStr+rdx+1],bl   ; Write the char equivalent to line string

; Bump the buffer pointer to the next character and see if we're done:
    inc rcx         ; Increment line string pointer
    cmp rcx,r15     ; Compare to the number of characters in the buffer
    jna Scan        ; Loop back if rcx is <= number of chars in buffer

; Write the line of hexadecimal values to stdout:
    mov rax,1       ; Specify syscall call 1: sys_write
    mov rdi,1       ; Specify File Descriptor 1: Standard output
    mov rsi,HexStr  ; Pass address of line string in rsi
    mov rdx,HEXLEN  ; Pass size of the line string in rdx
    syscall         ; Make kernel call to display line string
    jmp Read        ; Loop back and load file buffer again

; All done! Let's end this party:
Done:
    ret             ; Return to the glibc shutdown code
```

<p align=justify>
Il programma hexdump1 è fondamentalmente un programma di filtro e ha lo stesso meccanismo generale di filtro cutilizzato nel programma uppercaser. Le parti importanti del programma per questa discussione sono quelle che leggono 16 byte dal buffer di input e li convertono in una stringa di caratteri da visualizzare sulla console Linux. Questo è il codice tra l'etichetta <code>Scan</code> e l'istruzione <code>RET</code>. Farò riferimento a quel blocco di codice nella discussione che segue.
</p>

### Dividere un Byte in due Nibble

<p align=justify>
Ricorda che i valori letti da Linux da un file vengono letti in memoria come valori binari. L' esadecimale è un modo per visualizzare i valori binari, e per visualizzare i valori binari come cifre esadecimali ASCII visibili, devi fare alcune conversioni. Visualizzare un singolo valore binario a 8 bit richiede due cifre esadecimali. I quattro bit inferiori in un byte sono rappresentati da una cifra (la cifra meno significativa o la cifra più a destra), e i quattro bit superiori del byte sono rappresentati da un'altra cifra (la cifra più significativa o la cifra più a sinistra). Il valore binario <code>11100110</code>, per esempio, è equivalente a <code>E6</code> in esadecimale. Convertire un valore a 8 bit in due cifre a 4 bit deve essere fatto una cifra alla volta, il che significa che dobbiamo separare il singolo byte in due quantità a 4 bit, che sono spesso chiamate <b>nibble</b>, specialmente nel lavoro di assemblaggio. Nel programma <code>hexdump1</code>, un byte viene letto da Buff e viene collocato in due registri, RAX e RBX. Questo viene fatto perché separare il nibble alto da quello basso in un byte è distruttivo, in quanto di fatto annulliamo il nibble che non vogliamo. Per isolare il nibble basso in un byte, dobbiamo mascherare il nibble alto indesiderato. Questo viene fatto con un'istruzione AND:
</p>

```asm
 and al,0Fh

```

<p align=justify>
Il costante immediato 0Fh espresso in binario è 00001111. Se segui l'operazione attraverso la tabella di verità AND (Tabella 9.2), vedrai che qualsiasi bit ANDato contro 0 è 0. ANDiamo il nibble alto del registro AL con 0000, che azzera qualsiasi cosa possa esserci. ANDando il nibble basso contro 1111 lascia i bit del nibble basso esattamente come erano. Quando abbiamo finito, abbiamo il nibble basso del byte letto da Buff in AL.
</p>

### Shiftare il nibble alto nel nibble basso

<p align=justify>
Mascherare l' high nybble dal byte di input in AL lo distrugge. Abbiamo bisogno di quel high nybble, ma abbiamo una seconda copia in RBX, ed è da quella copia che estrarremo l'high nybble. Come per il low nybble, lavoreremo effettivamente con gli otto bit meno significativi di RBX, detti BL. Ricorda che BL è solo un modo diverso di riferirsi agli otto bit più bassi di RBX. Non è un registro diverso. Se un valore è caricato in RBX, i suoi otto bit meno significativi sono in BL. Potremmo mascherare il low nybble in BL con un'istruzione AND, lasciando indietro l'high nybble, ma c'è un problema: mascherare i quattro bit bassi di un byte non rende i quattro bit alti un nybble. Dobbiamo in qualche modo spostare i quattro bit alti del byte di input nei quattro bit bassi. Il modo più veloce per farlo è spostare semplicemente BL a destra di quattro bit. Questo è ciò che fa l'istruzione <code>SHR BL,4</code>. Il low nybble viene semplicemente spostato fuori dal bordo di BL, nel flag di carry, e poi nel nulla cosmico. Dopo lo shift, ciò che era l'high nybble in BL è ora il low nybble. A questo punto, abbiamo il low nybble del byte di input in AL e l'high nybble del byte di input in BL. La prossima sfida è convertire il numero binario a quattro bit in un nybble (ad esempio, 1110) nel suo carattere esadecimale ASCII visualizzabile; in questo esempio, è il carattere “E”.
</p>

### Usare una Lookup Table

<p align=justify>
Nella sezione .data del programma è definita una lookup table molto semplice. La tabella Digits ha questa definizione: 
</p>

```asm
	Digits db '0123456789ABCDEF'
```

<p align=justify>
È importante notare che ogni cifra occupa una posizione nella stringa il cui offset dall'inizio della stringa è il valore che rappresenta. In altre parole, il carattere ASCII 0 si trova all'inizio della stringa, a zero byte dall'inizio della stringa. Il carattere 7 si trova a sette byte dall'inizio della stringa, e così via. Noi "cerchiamo" un carattere nella tabella Digits usando un riferimento di memoria:
</p>

```asm
mov al,byte [Digits+rax]
```

<p align=justify>
Come nella maggior parte del linguaggio assembly, tutto qui dipende dall' addressing della memoria. Il primo carattere esadecimale nella tabella di ricerca si trova all'indirizzo in Digits. Per ottenere la cifra desiderata, dobbiamo indicizzare nella tabella di ricerca. Lo facciamo aggiungendo un offset nella tabella all'indirizzo all'interno delle parentesi quadre. Questo offset è il nybble in AL. Aggiungendo l'offset in AL all'indirizzo di Digits (usando RAX) ci porta direttamente al carattere che è l'equivalente ASCII del valore in AL. Ho illustrato questo graficamente nella figura di sotto. Ci sono due aspetti che potrebbero risultare confusi riguardo all'istruzione MOV che recupera una cifra da Digits e la posiziona in AL:
</p>

<ul>
	<li>
		<p align=justify>
			Dobbiamo usare RAX nel riferimento di memoria piuttosto che AL, perché AL non può partecipare ai calcoli degli indirizzi effettivi. Non dimenticare che AL è "all'interno" di RAX! (Magari parleremo di più sui calcoli degli indirizzi effettivi un po' più tardi in questo capitolo.)
		</p>
	</li>
 	<li>
		<p align=justify>
			Stiamo sostituendo il nybble in AL con il suo equivalente carattere. L'istruzione prima recupera l'equivalente carattere del nybble dalla tabella e poi memorizza di nuovo l'equivalente carattere in AL. Il nybble che era in AL viene sovrascritto e quindi è scomparso.
		</p>
	</li>
</ul

<p align=justify>
Finora, abbiamo letto un carattere dalla tabella di ricerca in AL. La conversione di quel nybble è stata completata. Il compito successivo sembra semplice ma in realtà è sorprendentemente complesso: scrivere il carattere ASCII esadecimale ora memorizzato in AL nella stringa di visualizzazione in HexStr.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/using_a_lookup_table.png">
</div>

### Moltiplicare attraverso Shifting e Somme

<p align=justify>
Il programma hexdump1 legge i byte da un file e li visualizza in righe, con 16 byte rappresentati in esadecimale in ciascuna riga. Un campione dell'output di hexdump1 è mostrato qui.
</p>

```
3B 20 20 45 78 65 63 75 74 61 62 6C 65 20 6E 61
6D 65 20 3A 20 45 40 54 53 59 53 43 40 4C 4C 0D
0A 3B 20 20 56 65 72 73 69 6F 6E 20 20 20 20 20
20 20 20 20 3A 20 30 2E 30 0D 0A 3B 20 20 43 72
65 60 74 65 64 20 64 60 74 65 20 20 20 20 3A 20
30 2F 37 2F 32 30 30 39 0D 0A 3B 20 20 4C 60 73
74 20 75 70 64 60 74 65 20 20 20 20 20 3A 20 32
2F 30 38 2F 32 30 30 39 0D 0A 3B 20 20 40 75 74
68 6F 72 20 20 20 20 20 20 20 20 20 20 3A 20 4A
```

<p align=justify>
Ognuna di queste righe è una visualizzazione dello stesso elemento di dati: HexStr, una stringa di 48 caratteri con un valore EOL (0ah) alla fine. Ogni volta che hexdump1 legge un blocco di 16 byte dal file di input, li formatta come cifre esadecimali ASCII e li inserisce in HexStr. In un certo senso, questo è un altro tipo di manipolazione tabellare, tranne per il fatto che invece di cercare qualcosa in una tabella, stiamo scrivendo valori in una tabella basata su un indice. Un modo per pensare a HexStr è come una tabella di 16 voci, ciascuna lunga tre caratteri. (Vedi figura di sotto.) In ciascuna voce, il primo carattere è uno spazio, e il secondo e il terzo carattere sono le cifre esadecimali stesse. I caratteri di spazio sono già presenti, come parte della definizione originale di HexStr nella sezione .data. L'originale HexStr "vuoto" ha 0 caratteri in tutte le posizioni delle cifre esadecimali. Per "riempire" HexStr con dati "reali" per la visualizzazione di ciascuna riga, dobbiamo scorrere HexStr in un ciclo di linguaggio assembly, scrivendo separatamente il carattere del nybble inferiore e il carattere del nybble superiore in HexStr.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/table_of_16_three_byte_entries.png">
</div>

<p align=justify>
Il problema difficile qui è che ad ogni passaggio attraverso il ciclo, dobbiamo "aumentare" l'indice in HexStr di tre invece che solo di uno. L'offset di una di quelle voci da 3 byte in HexStr è l'indice dell'entrata moltiplicato per tre. Ho già descritto le istruzioni MUL, che gestiscono la moltiplicazione senza segno arbitraria nel set di istruzioni x86/x64. Tuttavia, MUL è lenta rispetto ad altre istruzioni. Ha anche altre limitazioni, specialmente i modi in cui richiede registri specifici per i suoi operandi impliciti. Fortunatamente, con un po' di astuzia, ci sono altri modi più veloci per moltiplicare in assembly. Questi modi si basano sul fatto che è molto facile e veloce moltiplicare per potenze di due, usando l'istruzione SHL (Shift Left). Potrebbe non essere immediatamente ovvio per te, ma <b>ogni volta che sposti una quantità di un bit a sinistra, stai moltiplicando quella quantità per due</b>. Sposta una quantità di due bit a sinistra e la moltiplichi per quattro. Spostala di tre bit a sinistra e stai moltiplicando per otto, e così via. Puoi credere alla mia parola per questo, oppure puoi realmente vedere che succede in una sandbox. Configura una nuova sandbox in SASM ed inserisci le seguenti istruzioni:
</p>

```asm
 mov al,3
 shl al,1
 shl al,1
 shl al,2
```

<p align=justify>
Costruisci il sandbox e vai in modalità debug. Poi segui le istruzioni, osservando il valore di RAX cambiare nella vista Registri per ogni passaggio. La prima istruzione carica il valore 3 in AL. La successiva istruzione sposta AL a sinistra di un bit. Il valore in AL diventa 6. La seconda istruzione SHL sposta AL a sinistra di un bit ancora, e il 6 diventa 12. La terza istruzione SHL sposta AL di due bit, e il 12 diventa 48. L'ho mostrato graficamente nella figura di sotto.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/multiplying_by_shifting.png">
</div>

<p align=justify>
Ma cosa fai se vuoi moltiplicare per tre? Facile: moltiplichi per 2 e poi aggiungi un'altra copia del moltiplicando al prodotto. Nel programma hexdump1, si fa in questo modo:
</p>

```asm
 mov rdx,rcx   ; Copy the character counter into edx
 shl rdx,1     ; Multiply pointer by 2 using left shift
 add rdx,rcx   ; Complete the multiplication X3
```

<p align=justify>
Qui, il moltiplicando viene caricato dal contatore di ciclo RCX in RDX. RDX viene poi spostato a sinistra di un bit per moltiplicarlo per 2. Infine, RCX viene aggiunto una volta al prodotto RDX per effettuare una moltiplicazione per 3. La moltiplicazione per altri numeri che non sono potenze di due può essere eseguita combinando un SHL e uno o più ADD. Per moltiplicare un valore in RCX per sette, faresti così:
</p>

```asm
 mov rdx,rcx   ; Keep a copy of the multiplicand in rcx
 shl rdx,2     ; Multiply rdx by 4  
 add rdx,rcx   ; Makes it X 5
 add rdx,rcx   ; Makes it X 6
 add rdx,rcx   ; Makes it X 7
```

<p align=justify>
Questo potrebbe sembrare goffo, ma sorprendentemente, è ancora più veloce rispetto all'uso di MUL! (E c'è un modo ancora più veloce per moltiplicare per tre che ti mostrerò un po' più avanti in questo capitolo.) Una volta che hai capito come è impostata la tabella delle stringhe HexStr, scrivere le cifre esadecimali al suo interno è semplice. La cifra esadecimale meno significativa è in AL, e la cifra esadecimale più significativa è in BL. Scrivere entrambe le cifre esadecimali in HexString avviene attraverso un indirizzo di memoria effettivo a tre parti:
</p>

```asm
 mov byte [HexStr+rdx+2],al ; Write LSB char digit to line string
 mov byte [HexStr+rdx+1],bl ; Write MSB char digit to line string
```

<p align=justify>
Riferisciti a due figure prima, per calcolare questo da solo: inizi con l'indirizzo di HexStr nella sua interezza. RDX contiene l'offset del primo carattere in un dato ingresso. Per ottenere l'indirizzo dell'ingresso in questione, aggiungi HexStr e RDX. Tuttavia, quell'indirizzo è del primo carattere nell'ingresso, che in HexStr è sempre un carattere spazio. La posizione del digit LSB in un ingresso è l'offset dell'ingresso +2, e la posizione del digit MSB in un ingresso è l'offset dell'ingresso +1. L'indirizzo del digit LSB è quindi HexStr + l'offset dell'ingresso + 2. L'indirizzo del digit MSB è quindi HexStr + l'offset dell'ingresso + 1.
</p>

### Flags, Tests e Branches

<p align=justify>
L'idea delle istruzioni di salto condizionale è semplice e senza di essa non si può fare molto in assembly. Ho usato i salti condizionali in modo informale negli ultimi programmi di esempio senza dire molto al riguardo, perché il senso dei salti era piuttosto ovvio dal contesto ed erano necessari per dimostrare altre cose. Ma sotto la semplicità dell'idea dei salti in linguaggio assembly si nasconde una grande complessità. È tempo di approfondire e coprire questo in dettaglio.
</p>

### Salti Incondizionati

<p align=justify>
Un salto è proprio questo: un cambiamento brusco nel flusso di esecuzione delle istruzioni. Ordinariamente, le istruzioni vengono eseguite una dopo l'altra, in ordine, passando dalla memoria bassa alla memoria alta. Le istruzioni di salto alterano l'indirizzo della prossima istruzione da eseguire. Esegui un'istruzione di salto, e zac! All'improvviso sei da un'altra parte. Un'istruzione di salto può spostare l'esecuzione avanti nella memoria o indietro. Può piegare l'esecuzione in un ciclo (e può legare la logica del tuo programma in nodi). Ci sono due tipi di salti: condizionali e incondizionati. Un salto incondizionato è un salto che avviene sempre. Prende questa forma.
</p>

```asm
  jmp <label>
```

<p align=justify>
Quando questa istruzione viene eseguita, la sequenza di esecuzione passa all'istruzione situata all'etichetta specificata da <code>label</code>. È così semplice.
</p>
	
### Salti Condizionati

<p align=justify>
Un'istruzione di salto condizionale è uno di quei famosi test che ho introdotto nel Capitolo 1. Quando viene eseguita, un salto condizionale testa qualcosa, di solito uno, occasionalmente due, o molto più raramente tre dei flag nel registro RFlags. Se il flag o i flag testati si trovano in uno stato particolare, l'esecuzione salterà a un'etichetta da qualche altra parte; altrimenti, semplicemente passa all'istruzione successiva nella sequenza. Questa natura a due vie è importante. O un'istruzione di salto condizionale salta o passa. Salto o nessun salto. Non può saltare in uno di due luoghi o tre. Se salta o meno dipende dal valore corrente di un insieme molto ridotto di bit all'interno della CPU. Come ho menzionato precedentemente in questo libro discutendo del registro RFlags nel suo insieme, c'è un flag che viene impostato a 1 da alcune istruzioni quando il risultato di quella istruzione è zero: il flag Zero ZF. L'istruzione DEC (DECrement) è un buon esempio. DEC sottrae 1 dal suo operando. Se con quella sottrazione l'operando diventa zero, ZF è impostato a 1. Una delle istruzioni di salto condizionale, JZ (Jump if Zero), testa ZF. Se ZF risulta impostato a 1, si verifica un salto e l'esecuzione si trasferisce all'etichetta dopo il mnemonico JZ. Se ZF risulta essere 0, l'esecuzione passa all'istruzione successiva nella sequenza. Questo potrebbe essere il salto condizionale più comune nell'intero set di istruzioni x86/x64. È spesso usato quando si conta un registro fino a zero mentre si esegue un ciclo e, quando il conteggio del registro raggiunge zero grazie all'istruzione DEC, il ciclo termina e l'esecuzione riprende all'istruzione subito dopo il ciclo. Ecco un esempio semplice (sebbene non ottimale), usando istruzioni che dovresti già capire.
</p>

```asm
 mov [RunningSum],0 ; Clear the running total
 mov rcx,17         ; We're going to do this 17 times

 WorkLoop:
   add [RunningSum],3 ; Add three to the running total
   dec rcx            ; Subtract 1 from the loop counter
   jz SomewhereElse    ; If the counter is 0, we're done!
   jmp WorkLoop
```

<p align=justify>
La variabile RunningSum è stata definita in precedenza con il modificatore DQ, rendendola di dimensione 64 bit. Prima che inizi il ciclo, impostiamo un valore in RCX, che funge da registro contatore e contiene il numero di volte che attraverseremo il ciclo. Il corpo del ciclo è dove viene eseguita un'operazione ad ogni passaggio attraverso il ciclo. In questo esempio è un'unica istruzione ADD, ma il corpo potrebbe contenere decine o centinaia di istruzioni. Dopo che il lavoro del ciclo è completato, il registro contatore viene decrementato di 1 con un'istruzione DEC. Subito dopo, l'istruzione JZ testa il flag Zero. Decrementare RCX da 17 a 16, o da 4 a 3, non attiva ZF, e l'istruzione JZ semplicemente passa oltre. L'istruzione dopo JZ è un'istruzione di salto incondizionato, che obbedientemente e costantemente riporta l'esecuzione all'etichetta WorkLoop ogni volta. Ora, decrementare RCX da 1 a 0 attiva ZF... e questo è il momento in cui il ciclo termina. JZ ci porta finalmente fuori dal ciclo saltando a SomewhereElse (un'etichetta nel programma più grande che non è mostrata qui), e l'esecuzione esce dal ciclo. Potresti essere abbastanza acuto (o abbastanza esperto) da pensare che questo sia un modo orribile per impostare un ciclo, e hai ragione. (Ciò non significa che non sia mai stato fatto, né che tu stesso non possa farlo in un momento di impazienza nel cuore della notte.) Ciò che stiamo realmente cercando ogni volta che attraversiamo il ciclo è quando una condizione—il flag Zero—non è impostata, e c'è un'istruzione per questo.
</p>

### Saltare sull'assenza di una condizione

<p align=justify>
Ci sono diverse istruzioni di salto condizionale, di cui ne discuterò alcune, ma non tutte, in questo libro. Il loro numero è aumentato dal fatto che quasi ogni istruzione di salto condizionale ha un alter ego: un salto quando la condizione specificata non è impostata su 1. L'istruzione JZ fornisce un buon esempio di salto su una condizione. JZ salta a una nuova posizione nel segmento di codice se il flag Zero (ZF) è impostato su 1. L'alter ego di JZ è JNZ (Salta se Non Zero). JNZ salta a un'etichetta se ZF è 0 e passa avanti se ZF è 1. Questo può essere confuso all'inizio, perché JNZ salta quando ZF è uguale a 0. Tieni presente che il nome dell'istruzione si applica alla condizione testata e non necessariamente al valore binario del flag. Nell'esempio di codice precedente, JZ è saltato quando l'istruzione DEC ha decrementato un contatore a zero. La condizione testata è qualcosa di connesso con un'istruzione precedente, non semplicemente lo stato di ZF. Pensala in questo modo: una condizione solleva un flag. “Alzare un flag” significa impostare il flag su 1. Quando una delle numerose istruzioni costringe un operando a un valore di zero (che è la condizione), il flag Zero viene alzato. La logica dell'istruzione si riferisce alla condizione, non al flag. Come esempio, miglioriamo il piccolo ciclo mostrato prima cambiando la logica del ciclo per utilizzare JNZ:
</p>

```asm
 mov word [RunningSum],0  ; Clear the running total
 mov ecx,17               ; We're going to do this 17 times

 WorkLoop:
 add word [RunningSum],3  ; Add 3 to the running total
 dec ecx                  ; Subtract 1 from the loop counter
 jnz WorkLoop             ; If the counter is 0, we're done!
```

<p align=justify>
L'istruzione JZ è stata sostituita con un'istruzione JNZ. Questo ha molto più senso, poiché per chiudere il ciclo dobbiamo saltare, e chiudiamo il ciclo solo quando il contatore è maggiore di 0. Il salto di ritorno all'etichetta WorkLoop avverrà solo quando il contatore è maggiore di 0. Una volta che il contatore si riduce a 0, il ciclo è considerato completato. JNZ "continua" ed il codice che segue il ciclo (che non mostro qui) viene eseguito. Il punto è che se puoi posizionare il compito successivo del programma immediatamente dopo l'istruzione JNZ, non hai affatto bisogno di utilizzare l'istruzione JMP incondizionata. L'esecuzione delle istruzioni passerà semplicemente in modo naturale al compito successivo da eseguire. Il programma avrà un flusso più naturale e meno ingarbugliato dall'alto verso il basso e sarà più facile da leggere e comprendere.
</p>

### Flags

<p align=justify>
Precedentemente, ho spiegato il registro RFlags e descritto brevemente gli scopi di tutti i flag in esso contenuti. RFlags è scarso; più della metà è riservata per usi futuri e quindi indefinita. La maggior parte dei flag definiti non è particolarmente utile, specialmente quando stai appena iniziando come programmatori assembly. Il flag Carry (CF) e il flag Zero (ZF) costituiranno il 90 percento del tuo coinvolgimento con i flag come principiante, mentre il flag Direction (DF), il flag Sign (SF) e il flag Overflow (OF) insieme rappresentano un ulteriore 9.998 percento. Potrebbe essere una buona idea rileggere quella parte su RFalgsora, nel caso in cui la tua comprensione dell'etichetta dei flag sia un po' arrugginita. Come ho spiegato in precedenza, JZ salta quando ZF è 1, mentre JNZ salta quando ZF è 0. La maggior parte delle istruzioni che eseguono un'operazione su un operando (come AND, OR, XOR, INC, DEC e tutte le istruzioni aritmetiche) impostano ZF in base ai risultati dell'operazione. D'altra parte, le istruzioni che semplicemente spostano dati (come MOV, XCHG, PUSH e POP) non influenzano ZF né alcuno degli altri flag. (Ovviamente, POPF influisce sui flag estraendo il valore in cima allo stack in essi.) Un'eccezione irritante è l'istruzione NOT, che esegue un'operazione logica sul suo operando ma non imposta alcun flag — anche quando provoca che il suo operando diventi 0. Prima di scrivere codice che dipende dai flag, controlla il tuo riferimento delle istruzioni per assicurarti che tu abbia compreso correttamente l'etichetta dei flag per quella particolare istruzione. 
</p>

### Confronti con CMP

<p align=justify>
Un uso principale delle flag è nel controllo dei cicli. Un altro è nelle comparazioni tra due valori. I tuoi programmi dovranno spesso sapere se un valore in un registro o nella memoria è uguale a un altro valore. Inoltre, potresti voler sapere se un valore è maggiore di un valore o minore di un valore se non è uguale a quel valore. Esiste un'istruzione di salto per soddisfare ogni esigenza, ma qualcosa deve impostare le flag a beneficio dell'istruzione di salto. L'istruzione CMP (CoMPare) è quella che imposta le flag per i compiti di confronto. L'uso di CMP è semplice e intuitivo. Il secondo operando viene confrontato con il primo e diverse flag vengono impostate di conseguenza:
</p>

```asm
cmp <op1>,<op2>    ; Sets OF, SF, ZF, AF, PF, and CF
```

<p align=justify>
Il senso del confronto può essere ricordato se si riformula semplicemente il confronto in termini aritmetici.
</p>

```asm
 Result = <op1> - <op2>
```

<p align=justify>
CMP è in gran parte un'operazione di sottrazione in cui il risultato della sottrazione viene scartato e solo i flag sono influenzati. Il secondo operando viene sottratto dal primo. In base ai risultati della sottrazione, i flag che influenzano vengono impostati ai valori appropriati. Dopo un'istruzione CMP, puoi saltare in base a diverse condizioni aritmetiche. Le persone che hanno una ragionevole conoscenza della matematica, e i programmatori FORTRAN o Pascal, riconosceranno le condizioni: Uguale, Diverso, Maggiore di, Minore di, Maggiore o uguale a, e Minore o uguale a. Il senso di questi operatori deriva dai loro nomi ed è esattamente come il senso degli operatori equivalenti nella maggior parte dei linguaggi di alto livello.
</p>

### Una giungla di istruzioni JUMP

<p align=justify>
C'è una serie disorientante di istruzioni di salto, ma quelle che trattano le relazioni aritmetiche si suddividono bene in sole sei categorie, una categoria per ciascuna delle sei condizioni che ho appena elencato. La complicazione nasce dal fatto che ci sono due mnemonici per ogni istruzione della macchina, ad esempio, JLE (Salta se Minore o Uguale) e JNG (Salta se Non Maggiore di). Questi due mnemonici sono sinonimi in quanto l'assemblatore genera l'identico opcode binario quando incontra uno dei due mnemonici. I sinonimi sono una comodità per te programmatore in quanto offrono due modi alternativi di pensare a una data istruzione di salto. Nell'esempio precedente, Salta se Minore o Uguale è logicamente identico a Salta se Non Maggiore. (Pensaci!) Se l'importanza del confronto precedente era vedere se un valore è minore o uguale a un altro, useresti il mnemonico JLE. D'altra parte, se stavi testando per essere sicuro che una quantità non fosse maggiore di un'altra, useresti JNG. La scelta è tua. Un'altra complicazione è che c'è un insieme separato di istruzioni per i confronti aritmetici firmati e non firmati. Non ho parlato molto della matematica del linguaggio assembly in questo libro e quindi non ho detto molto sulla differenza tra quantità firmate e non firmate. Una quantità firmata è quella in cui il bit alto della quantità è considerato un flag incorporato che indica se la quantità è negativa. Se quel bit è 1, la quantità è considerata negativa. Se quel bit è 0, la quantità è considerata positiva. L'aritmetica firmata nel linguaggio assembly è complessa e sottile e non è così utile come potresti pensare immediatamente. Non la coprirò in dettaglio in questo libro, anche se la maggior parte dei libri di linguaggio assembly la trattano in una certa misura. Tutto ciò che devi sapere per avere una comprensione di alto livello dell'aritmetica firmata è che, nell'aritmetica firmata, le quantità negative sono legali e il bit più significativo di un valore è trattato come il bit di segno. (Se il bit di segno è impostato su 1, il valore è considerato negativo.) L'aritmetica non firmata, d'altra parte, non riconosce numeri negativi, e il bit più significativo è solo un bit in più nel numero binario che esprime il valore in esame.
</p>

<p align=justify>
Per distinguere i salti firmati da quelli non firmati, i mnemonici usano due espressioni diverse per la relazione tra due valori:
</p>

<ul>
	<li>
		<p align=justify>
			I valori con segno sono considerati maggiori o minori. Ad esempio, per verificare se un operando con segno è maggiore di un altro, utilizzeresti il mnemonico JG (Salta se Maggiore) dopo un'istruzione CMP.
		</p>
	</li>
 	<li>
		<p align=justify>
			I valori non firmati sono considerati come se fossero sopra o sotto. Ad esempio, per determinare se un operando non firmato è maggiore (sopra) di un altro, si utilizzerà il mnemonico JA (Salta se sopra) dopo un'istruzione CMP.
		</p>
	</li>
</ul>

<p align=justify>
La tabella di sotto riassume i mnemonici di salto aritmetico e i loro sinonimi. Qualsiasi mnemonico contenente le parole sopra o sotto è per valori senza segno, mentre qualsiasi mnemonico contenente le parole maggiore o minore è per valori con segno. Confronta i mnemonici con i loro sinonimi e vedi come i due rappresentano punti di vista opposti da cui guardare istruzioni identiche.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/Jump_Instruction_Mnemonics.png">
</div>

<p align=justify>
La figura di sopra serve semplicemente ad espandere i mnemonici in una forma più comprensibile e ad associare un mnemonico con il suo sinonimo. La figura di sotto, d'altra parte, ordina i mnemonici in base alla condizione logica e al loro utilizzo con valori con segno e senza segno. Nella figura di sotto sono inoltre elencati i flag i cui valori vengono testati da ciascuna istruzione di salto. Notate che alcune delle istruzioni di salto richiedono uno dei due possibili valori del flag per eseguire il salto, mentre altre richiedono entrambi i valori del flag. Diversi salti con segno confrontano due dei flag l'uno contro l'altro. JG, ad esempio, salterà quando ZF è 0 o quando il Flag di Segno (SF) è uguale al Flag di Overflow (OF). Non spenderò ulteriore tempo a spiegare la natura del Flag di Segno o del Flag di Overflow. Finché non hai compreso il significato di ciascuna istruzione, capire esattamente come le istruzioni testano i flag può aspettare finché non hai acquisito un po' di esperienza nella programmazione.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/Arithmetic_Tests_Useful_After_CMP_Instruction.png">
</div>

<p align=justify>
Alcune persone hanno difficoltà a capire come i mnemonici JE e JZ siano sinonimi, così come lo sono JNE e JNZ. Pensa di nuovo a come viene effettuato un confronto all'interno della CPU: il secondo operando viene sottratto dal primo, e se il risultato è 0 (indica che i due operandi erano in effetti uguali), il flag Zero ZF viene impostato su 1. Ecco perché JE e JZ sono sinonimi: entrambi stanno semplicemente testando lo stato del flag Zero.
</p>

### Cercare un bit a 1 con TEST

<p align=justify>
L'insieme di istruzioni x86/x64 riconosce che il testing dei bit è molto comune nel linguaggio assembly e fornisce quello che equivale a un'istruzione CMP per i bit: TEST. TEST esegue un'operazione logica AND tra due operandi e poi imposta i flag come farebbe l'istruzione AND, senza alterare l'operando di destinazione, come farebbe AND. Ecco la sintassi dell'istruzione TEST:
</p>

```asm
test <operand>,<bit mask>
```

<p align=justify>
L'operando della maschera di bit dovrebbe contenere un bit 1 in ogni posizione in cui si desidera cercare un bit 1 nell'operando, e bit 0 in tutti gli altri bit. Ciò che fa il TEST è eseguire l'operazione logica AND tra l'operando di destinazione dell'istruzione e la maschera di bit e poi impostare i flag come farebbe l'istruzione AND. Il risultato dell'operazione AND viene scartato e l'operando di destinazione non cambia. Ad esempio, se vuoi determinare se il bit 3 di RAX è impostato su 1, potresti utilizzare questa istruzione:
</p>

```asm
 test rax,08h       ; Bit 3 in binary is 00001000B, or 08h
```

<p align=justify>
Il bit 3, ovviamente, non ha il valore numerico 3: devi guardare il pattern di bit della maschera e esprimerlo come un valore binario o esadecimale. (Il bit 3 rappresenta il valore 8 in binario.) Usare il binario per costanti letterali è perfettamente legale in NASM ed è spesso l'espressione più chiara di ciò che stai facendo quando lavori con le maschere di bit.
</p>

```asm
 test rax,00001000B ; Bit 3 in binary is 00001000B, or 08h
```

<p align=justify>
L'operando di destinazione RAX non cambia a seguito dell'operazione, ma la tabella della verità AND è affermata tra RAX e il modello binario 00001000. Se il bit 3 in RAX è un bit 1, allora il flag Zero è azzerato a 0. Se il bit 3 in RAX è un bit 0, allora il flag Zero è impostato a 1. Perché? Se esegui un AND tra 1 (nel mascheramento dei bit) e 0 (in RAX), ottieni 0. (Controlla nella tabella di verità della AND, che ho mostrato nei paragrafi precedenti.) E se tutte e otto le operazioni AND bitwise restituiscono 0, il risultato è 0 e il flag Zero è sollevato a 1, indicando che il risultato è 0. La chiave per comprendere TEST è pensare a TEST come a una sorta di Fantasma dell'Opcode, dove l'Opcode è AND. TEST indossa una maschera (per così dire) e finge di essere AND, ma poi non porta a termine i risultati dell'operazione. Imposta semplicemente i flag come se fosse avvenuta un'operazione AND. L'istruzione CMP di cui abbiamo parlato prima è un altro Fantasma dell'Opcode e ha la stessa relazione con SUB che TEST ha con AND. CMP sottrae il suo secondo operando dal primo, ma non completa l'operazione e non memorizza il risultato nell'operando di destinazione. Imposta semplicemente i flag come se fosse avvenuta una sottrazione. Come abbiamo già visto, questo può essere molto utile quando è combinato con istruzioni di salto condizionale. Ecco qualcosa di importante da tenere a mente: TEST è utile solo per trovare bit 1. Se hai bisogno di identificare bit 0, devi prima invertire ogni bit nel suo stato opposto con l'istruzione NOT. NOT cambia tutti i bit 1 in bit 0 e cambia tutti i bit 0 in bit 1. Una volta che tutti i bit 0 sono stati invertiti in bit 1, puoi testare per un bit 1 dove hai bisogno di trovare un bit 0. (A volte è utile disegnarlo su un foglio per tenere tutto chiaro nella tua mente.) Infine, TEST non testerà in modo affidabile la presenza di due o più bit 1 nell'operando contemporaneamente. TEST non verifica la presenza di un modello di bit; verifica la presenza di un singolo bit 1. In altre parole, se hai bisogno di verificare che entrambi i bit 4 e 5 siano impostati a 1, TEST non funzionerà.
</p>

### Cercare un bit a 0 con  BT

<p align=justify>
Come ho spiegato, TEST ha i suoi limiti: non è adatto a determinare quando un bit è impostato a 0. TEST è presente sin dai primi CPU X86, ma i processori 386 e più recenti hanno un'istruzione che ti consente di testare sia i bit 0 che i bit 1. BT (Bit Test) svolge un compito molto semplice: copia il bit specificato dal primo operando nel flag di carry CF. In altre parole, se il bit selezionato era un bit 1, il flag di carry diventa impostato. Se il bit selezionato era un bit 0, il flag di carry viene azzerato. Puoi quindi usare qualsiasi delle istruzioni di salto condizionale che esaminano e agiscono sullo stato di CF. BT è facile da usare. Richiede due operandi: l'operando di destinazione è il valore che contiene il bit in questione. L'operando sorgente è il numero ordinale del bit che vuoi testare, contando da 0:
</p>

```asm
  bt <value containing bit>,<bit number>
```

<p align=justify>
Una volta eseguita un'istruzione BT, dovresti immediatamente testare il valore nel flag Carry e diramarti in base al suo valore. Ecco un esempio.
</p>

```asm
 bt  rax,4   ; Test bit 4 of RAX
 jnc quit    ; We're all done if bit 4 = 0
```

<p align=justify>
Qualcosa di cui fare attenzione, specialmente se sei abituato a usare TEST, è che non stai creando una maschera di bit. Con l'operando sorgente di BT stai specificando il numero ordinale di un bit. La costante letterale 4 mostrata nel codice precedente è il numero del bit, non il valore del bit, e questa è una differenza cruciale. Nota anche nel codice precedente che stiamo facendo un salto se CF non è impostato; questo è ciò che fa JNC (Salta se Non C'è Riporto).
</p>

###  X64 Long Mode Memory Addressing

<p align=justify>
In molti modi, la vita è migliore ora. E non sto parlando solo di odontoiatria moderna, networking plug-and-play e CPU a otto core. Programmavo in assembly per le CPU 8088 in modalità reale nel primo IBM PC. E ricordo l'indirizzamento della memoria in modalità reale. Come l'odontoiatria negli anni '50, l'indirizzamento della memoria in modalità reale basato su 8088 era semplicemente... doloroso. Era un terribile groviglio di restrizioni, insidie e limiti, tutti i quali urlavano che la CPU aveva disperatamente bisogno di più transistor sul die. Ad esempio, l'indirizzamento della memoria era limitato a BX e BP nella maggior parte delle istruzioni, il che significava un sacco di manovre ingegnose quando diversi elementi separati dovevano essere indirizzati in memoria contemporaneamente. E pensare alla gestione dei segmenti ancora mi fa rabbrividire. Beh, negli ultimi 40 anni le nostre CPU della famiglia Intel hanno ottenuto praticamente tutti i transistor di cui avevano bisogno, e la maggior parte di quelle frustranti limitazioni di indirizzamento della memoria a 16 bit sono semplicemente scomparse. Puoi indirizzare la memoria con uno qualsiasi dei registri a scopo generale. Puoi persino indirizzare la memoria direttamente con il puntatore dello stack RSP, qualcosa che il suo antenato a 16 bit SP non poteva fare. (Non dovresti cambiare il valore in RSP senza una considerevole attenzione, ma RSP può ora partecipare a modalità di indirizzamento dalle quali il puntatore dello stack era escluso nel regno della modalità reale a 16 bit.)
</p>

<p align=justify>
La modalità protetta a 32 bit sulla famiglia di CPU 386 ha introdotto uno schema di indirizzamento della memoria a uso generale in cui tutti i registri GP potevano partecipare in modo uguale. L'indirizzamento della memoria nella modalità long x64 implementa lo stesso schema con pochissime modifiche. L'ho schematizzato nella Figura 9.9, che potrebbe benissimo essere la figura più importante di tutto questo libro. L'indirizzamento della memoria è l'abilità chiave nel lavoro con il linguaggio assembly. Se non capisci come la CPU indirizza la memoria, niente altro ha importanza.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/x64_long_mode_memory_addressing.png">
</div>

<p align=justify>
Quando ho studiato e compreso per la prima volta questo schema, con ferite ancora sanguinanti dall'indirizzamento della memoria segmentata a 16 bit 8088, sembrava troppo bello per essere vero. Ma è vero! Ecco le regole
</p>

<ul>
	<li>
		<p align=justify>
		I registri base e indice possono essere qualsiasi dei registri generali a 64 bit, incluso RSP
		</p>
	</li>
 	<li>
		<p align=justify>
		Lo spostamento può essere qualsiasi costante a 32 bit, sia un valore letterale che un valore nominato. È ovvio che 0, sebbene legale, non è utile.
		</p>
	</li>
 	<li>
		<p align=justify>
		La scala deve essere uno dei valori 1, 2, 4 o 8. Ecco tutto! Il valore 1 è legale, ma dato che la scala è usata per moltiplicare un altro valore, 1 non fa nulla di utile.
		</p>
	</li>
 	<li>
		<p align=justify>
		Il registro degli indici viene moltiplicato per la scala prima che vengano effettuate le addizioni. In altre parole, non è (base + indice) × scala. Solo il registro degli indici può essere moltiplicato per la scala.
		</p>
	</li>
 	<li>
		<p align=justify>
		Tutti gli elementi sono facoltativi e possono essere utilizzati in quasi qualsiasi combinazione
		</p>
	</li>
 	<li>
		<p align=justify>
		Sia i registri a 32 bit che quelli a 64 bit possono essere utilizzati, ma non è possibile mescolare le dimensioni dei registri in un singolo indirizzo. Cioè, i registri in un'unica operazione di indirizzamento della memoria devono essere tutti a 32 bit o tutti a 64 bit.
		</p>
	</li>
 	<li>
		<p align=justify>
		I registri a 16 bit e a 8 bit non possono essere utilizzati nell'indirizzamento della memoria.
		</p>
	</li>
</ul>

<p align=justify>
All'interno di quelle regole, ci sono diversi modi per accedere alla memoria, raccogliendo i componenti dell'indirizzo mostrati nella figura di sopra in diverse combinazioni. Gli esempi sono mostrati nella figura di sotto.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/64_Bit_Long_Mode_Memory_Addressing_Schemes.png">
</div>

### Calcolo dell' Effective Address

<p align=justify>
Ognuna delle righe nella figura di sopra riassume un metodo di espressione di un indirizzo di memoria in modalità lunga a 64 bit. Tutti tranne i primi due coinvolgono un po' di aritmetica tra due o più termini all'interno delle parentesi che significano un indirizzo. Questa aritmetica è chiamata calcolo dell'effective address, e il risultato del calcolo è l'effective address. Questo termine indica l'indirizzo che verrà utilizzato per leggere o scrivere nella memoria, indipendentemente da come viene espresso. Il calcolo dell'effective address viene eseguito dall'istruzione, quando l'istruzione viene eseguita. L'effective address nello schema Base è semplicemente il valore a 64 bit memorizzato nel registro GP tra le parentesi. Non è coinvolto alcun calcolo, ma ciò che vediamo nel codice sorgente non è un indirizzo letterale o simbolico. Quindi, anche se l'istruzione è codificata con un nome di registro tra le parentesi, l'indirizzo che verrà inviato al sistema di memoria quando il codice viene eseguito è memorizzato all'interno del registro. Nella maggior parte dei casi in cui si tratta di un effective address, c'è un certo operare aritmetico. Ad esempio, nello schema Base + Indice, il contenuto dei due registri GP tra le parentesi vengono aggiunti quando l'istruzione viene eseguita per formare l'effective address.
</p>

### Displacements (Scostamento)

<p align=justify>
Tra i diversi componenti di un indirizzo in modalità long x64 legale, il termine di spostamento è in realtà il più difficile da comprendere. Come ho indicato nel paragrafo precedente, il termine di spostamento può essere un indirizzo letterale, ma in tutti i miei anni di programmazione assembly in modalità protetta non l'ho mai fatto né ho visto qualcun altro farlo. Il motivo? Non sai quasi mai l'indirizzo letterale di qualcosa al momento della compilazione. C'è un altro motivo per non utilizzare indirizzi letterali, di cui parlerò a breve. Quando il termine di spostamento è isolato, è praticamente sempre un indirizzo simbolico. Con questo intendo un elemento di dati con un nome che hai definito nelle tue sezioni .data o .bss, come la variabile HexStr del programma hexdump1 nell'elenco 9.1:
</p>

```asm
 mov rax,HexStr
```

<p align=justify>
Ciò che viene posto in RAX qui è l'indirizzo dato alla variabile HexStr quando il programma viene caricato in memoria dal sistema operativo. Come tutti gli indirizzi, è solo un numero, ma viene determinato quando il programma viene caricato piuttosto che al momento della codifica, come farebbe un indirizzo numerico costante letterale. Si noti anche che il precedente blocco di codice sorgente carica un indirizzo in RAX, non il valore in memoria a quell'indirizzo. Per quello hai bisogno delle parentesi:
</p>

```asm
 mov rax,[HexStr]
```

<p align=justify>
Molti principianti si confondono quando vedono quelli che sembrano essere due termini di spostamento in un unico indirizzo. La confusione deriva dal fatto che se NASM vede due (o più) valori costanti in un riferimento di memoria, li combinerà durante il tempo di assemblaggio in un unico valore di spostamento, che viene posizionato in RAX dall'istruzione MOV. È ciò che viene fatto qui:
</p>

```asm
 mov rax,HexStr+3
```

<p align=justify>
Nota l'assenza di parentesi. L'indirizzo a cui si fa riferimento simbolicamente tramite la variabile chiamata HexStr viene semplicemente aggiunto alla costante letterale 3 per formare un singolo valore di spostamento. La caratteristica chiave di un termine di spostamento è che non viene memorizzato in un registro.
</p>

### Il problema della dimensione dello scostamento in x64

<p align=justify>
Ora, c'è un problema specifico per x64 riguardo ai dislocamenti: un valore di dislocamento non deve superare i 32 bit di dimensione. Perché? Come a volte devo dire... è complicato. E non ha nulla a che fare con il numero di bit di indirizzo supportati nel silicio di una data CPU x64. In parole povere, limitare i dislocamenti a 32 bit è stata una decisione di design di AMD all'alba del tempo x64 che "è rimasta." Potrebbe essere corretto un giorno — o non lo sarà. Ma, ehi, non dire mai "mai." Nel frattempo, dobbiamo solo convivere con esso.
</p>

### Base Addressing (indirizzamento di base)

<p align=justify>
Quando escludi l'indirizzamento per spostamento, tutto l'indirizzamento della memoria x64 si basa su registri. Lo schema di indirizzamento di Base utilizza semplicemente un singolo registro nel quale è stato caricato un indirizzo. Si chiama Base perché tutti gli schemi di indirizzamento più complessi partono da Base e lo estendono. Ecco un esempio di indirizzamento di Base:
</p>

```asm
 mov qword rax,[rcx]
```

<p align=justify>
Questa istruzione prende il valore a 64 bit memorizzato nella memoria all'indirizzo contenuto nel registro RCX e lo carica nel registro RAX.
</p>

### Base + Displacement Addressing

<p align=justify>
Uno schema di indirizzamento semplice e comune è Base + Displacement, e l'ho dimostrato nel programma hexdump1 nella Lista 9.1. L'istruzione che inserisce un carattere ASCII nella riga di output appare così:
</p>

```asm
 mov byte [HexStr+rdx+2],al
```

<p align=justify>
Ciò che accade qui è che un valore di carattere a 8 bit memorizzato nel registro AL viene scritto nel byte in memoria indirizzato come HexStr+RDX+2. Questo è un perfetto esempio di un caso in cui ci sono due termini di spostamento che NASM combina in uno. Il nome della variabile HexStr si risolve in un numero (l'indirizzo di HexStr) e si aggiunge facilmente alla costante letterale 2. Quindi, in verità, c'è solo un termine di base (RDX) e un termine di spostamento. È anche un buon esempio di come i registri a 8 bit abbiano ancora il loro utilizzo, soprattutto quando si trattano valori a 8 bit come i caratteri ASCII. Nota anche che l'ordine dei termini in un indirizzo non conta. L'indirizzo efficace potrebbe essere stato RDX+HexStr+2.
</p>

### Base + Index Addressing

<p align=justify>
Forse il sistema di indirizzamento singolo più comune è Base + Indice, nel quale l'indirizzo effettivo viene calcolato sommando i contenuti di due registri GP all'interno delle parentesi. Ho dimostrato questo schema di indirizzamento nel Capitolo 8, nel programma uppercaser2 nell'Elenco 8.2. Convertire un carattere nel buffer di input da minuscolo a maiuscolo viene effettuato sottraendo 20h da esso:
</p>

```asm
 sub byte [r13+rbx],20h
```

<p align=justify>
L'indirizzo del buffer era precedentemente posizionato in RBP, e il numero in RCX è lo spostamento dall'inizio del buffer del carattere in fase di elaborazione durante un dato passaggio nel ciclo. Aggiungere l'indirizzo del buffer con uno spostamento nel buffer porta all'indirizzo effettivo del carattere su cui agisce l'istruzione SUB. Ma aspetta... perché non usare l'indirizzamento Base + Displacement? Questa istruzione sarebbe legale:
</p>

```asm
 sub byte [Buff+rbx],20h
```

<p align=justify>
Tuttavia, se ricordi dal programma (e varrebbe la pena tornare indietro e leggere il testo associato), dovevamo decrementare l'indirizzo di Buff di 1 prima di iniziare il ciclo. Ma aspetta ancora... potremmo far fare a NASM quella piccola modifica aggiungendo un secondo termine di spostamento di -1? In effetti, potremmo farlo, e funzionerebbe. Il ciclo centrale del programma uppercaser2 apparirebbe quindi così:
</p>

```asm
; Set up the registers for the process buffer step:
 
     mov rbx,rax          ; Place the number of bytes read into rbx
     mov r13,Buff         ; Place address of buffer into r13
 ;    dec r13                We don't need this instruction anymore!
 
; Go through the buffer and convert lowercase to uppercase characters:
 
Scan:
     cmp byte [r13-1+rbx],61h  ; Test input char against lowercase 'a'
     jb Next                   ; If below 'a' in ASCII, not lowercase
     cmp byte [r13-1+rbx],7Ah  ; Test input char against lowercase 'z'
     ja Next                  ; If above 'z' in ASCII, not lowercase
 
                              ; Now we have a lowercase char
     sub byte [r13-1+rbx],20h ; Subtract 20h to give uppercase…
 
Next:
     dec rbx                  ; Decrement counter
     jnz Scan                 ; If characters remain, loop back

```

<p align=justify>
L'istruzione DEC R13 nel primo blocco non è più necessaria, e nel codice precedente quella riga è commentata. NASM fa i calcoli, e l'indirizzo di Buff viene decrementato di 1 all'interno dell'espressione dell'indirizzo effettivo quando il programma si carica. Questo è effettivamente il modo corretto di programmare questo particolare ciclo, e ci ho pensato a lungo se mostrarlo di nuovo nel Capitolo 8 o aspettare di poter spiegare gli schemi di indirizzamento della memoria in dettaglio. Alcune persone trovano il nome “Base + Displacement” confuso, perché nella maggior parte dei casi, il termine Displacement contiene un indirizzo, e il termine Base è un registro che contiene un offset in un elemento di dati a quell'indirizzo. La parola displacement somiglia alla parola offset nell'esperienza della maggior parte delle persone, il che può portare a confusione. Questo è uno dei motivi per cui non metto in evidenza i nomi dei vari schemi di indirizzamento della memoria in questo libro e certamente non raccomando di memorizzare i nomi. Comprendere come funziona il calcolo dell'indirizzo effettivo e ignorare i nomi degli schemi.
</p>

### Index X Scale + Displacement Addressing

<p align=justify>
L'indirizzamento Base + Index è ciò che tipicamente utilizzerai per esaminare un buffer in memoria byte per byte. Ma cosa succede se hai bisogno di accedere a un elemento di dati in un buffer o in una tabella dove ogni elemento di dati non è un singolo byte, ma una parola o una doppia parola? Questo richiede una logica di indirizzamento della memoria leggermente più potente. A proposito, l'array di parole è il termine generale per ciò che ho definito un buffer o una tabella. Altri scrittori possono chiamare una tabella un array, specialmente quando il contesto della discussione è un linguaggio di alto livello. Ma tutti e tre i termini si riducono alla stessa definizione: una sequenza di elementi di dati in memoria, tutti della stessa dimensione e della stessa definizione interna. Nei programmi che ti ho mostrato finora, abbiamo parlato solo di tabelle e buffer molto semplici consistenti in una sequenza di valori a 1 byte tutti in fila. La tabella Digits nel programma hexdump1 è una di queste tabelle:
</p>

```asm
 Digits: db "0123456789ABCDEF"
```

<p align=justify>
Consiste in 16 caratteri ASCII a byte singolo in sequenza in memoria, a partire dall'indirizzo rappresentato dai Digits. Puoi accedere al carattere “C” all'interno dei Digits in questo modo, utilizzando l'indirizzamento Base + Displacement:
</p>

```asm
 mov rcx,12
 mov rdx,[Digits+rcx]
```

<p align=justify>
Ma cosa succede se hai una tabella contenente valori numerici a 64 bit? Una tale tabella è abbastanza facile da definire:
</p>

```asm
 Sums: dq "15,12,6,0,21,14,4,0,0,19"
```

<p align=justify>
Il qualificatore DQ informa NASM che ogni elemento nella tabella Sums è una quantità di 64 bit (quad word). Le costanti letterali inseriscono un valore numerico in ciascun elemento della tabella. L'indirizzo del primo elemento (qui, 15) in Sums è semplicemente l'indirizzo della tabella nel suo insieme. Quindi qual è l'indirizzo del secondo elemento, 12? E come si accede a esso dal codice assembly? Tieni presente che la memoria è indirizzata byte per byte, e non doppio word per doppio word o quad word per quad word. La seconda voce nella tabella si trova a un offset di 8 byte all'interno della tabella. Se provassi a fare riferimento alla seconda voce nella tabella usando un indirizzo [Sums+1], otterresti uno dei byte all'interno del quad word del primo elemento della tabella, e questo non sarebbe utile. Qui entra in gioco il concetto di scaling. Un indirizzo può includere un termine di scala, che è un moltiplicatore e può essere uno dei valori letterali 2, 4 o 8. (La costante letterale 1 è tecnicamente legale, ma poiché la scala è un moltiplicatore, 1 non è un valore di scala utile.) Il prodotto dell'indice e dei termini di scala è aggiunto allo spostamento per dare l'indirizzo efficace. Questo è noto come schema di indirizzamento Indice × Scala + Displacement. Tieni presente che il termine di scala può essere utilizzato solo con il termine di indice. Tipicamente, il termine di scala è la dimensione dei singoli elementi nella tabella. Se la tua tabella consiste in valori di word da 2 byte, la scala sarebbe 2. Se la tua tabella consiste in valori di double word da 4 byte, la scala sarebbe 4. Se la tua tabella consiste in valori di quad word da 8 byte, la scala sarebbe 8.
</p>

<p align=justify>
Il modo migliore per spiegare questo è con un diagramma. Nella Figura di sotto, ci troviamo di fronte all'indirizzo [DQTable+ECX*8]. DQTable è una tabella di valori a parola quadrupla (64 bit). L'indirizzo di DQTable è lo spostamento. Il registro RCX è l'indice e, per questo esempio, contiene 2, che è il numero dell'elemento della tabella che vuoi accedere. Poiché si tratta di una tabella di parole quadruple di 8 byte, il valore di scala è 8. Nota anche che il simbolo di moltiplicazione non è una “x” ma un asterisco. Il simbolo di moltiplicazione “×” non fa parte del set di caratteri ASCII, quindi, come nella maggior parte dei linguaggi di alto livello, l'assembly utilizza l'asterisco come simbolo dell'operatore di moltiplicazione. Poiché ogni elemento della tabella è di 8 byte, l'offset dell'elemento #2 dall'inizio della tabella è 16. L'indirizzo effettivo dell'elemento viene calcolato moltiplicando prima l'indice per la scala e poi aggiungendo il prodotto all'indirizzo di DQTable. Eccolo!
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/how_address_scaling_works.png">
</div>

### Altri Schemi d'Indirizzamento

<p align=justify>
Qualsiasi schema di indirizzamento che include la scalatura funziona in questo modo. Le differenze risiedono in quali altri termini vengono considerati nell'indirizzo effettivo. Lo schema Base + Indice × Scala aggiunge un indice scalato a un valore base in registro piuttosto che a uno spostamento:
</p>

```asm
mov rcx,2           ; Index is in rcx
mov rbp,DDTable     ; Table address is in rbp
mov rdx,[rbp+rcx*8] ; Put the selected element into rdx
```

<p align=justify>
Non lavorerai sempre con l'indirizzo di una variabile predefinita come DDTable. A volte l'indirizzo della tabella verrà da qualche altra parte, più spesso da una tabella bidimensionale composta da un certo numero di sotto-tabelle in memoria, ciascuna delle quali contiene un certo numero di elementi. Tali tabelle vengono accedute in due fasi: Prima si deriva l'indirizzo della sotto-tabella nella tabella esterna, e poi si deriva l'indirizzo dell'elemento desiderato all'interno della sotto-tabella. L'esempio più conosciuto di questo tipo di tabella bidimensionale è qualcosa che ho presentato in edizioni precedenti di questo libro, scritto per DOS. Il buffer di memoria video testo di 25 righe × 80 caratteri sotto DOS era una tabella bidimensionale. Ciascuna delle 25 righe era una tabella di 80 caratteri, e ciascun carattere era rappresentato da una parola di 2 byte. (Un byte era il valore ASCII, e l'altro byte specificava attributi come colore, sottolineatura, e così via.) Quindi, il buffer nel suo insieme era una tabella complessiva di 24 tabelle più piccole, ciascuna contenente 80 valori di parola di 2 byte. Quel tipo di sistema di accesso video è morto con DOS; Linux non consente l'accesso diretto alla memoria video del PC. È stato fatto molto nell'era DOS, tuttavia, ed è un buon esempio di tabella bidimensionale. La scalabilità ti servirà bene per tabelle con elementi di 2 byte, 4 byte o 8 byte. E se la tua tabella è composta da elementi di 3 byte? O di 5 byte? O di 17 byte? Ahimè, in tali casi dovrai fare dei calcoli aggiuntivi per concentrare su un particolare elemento. Il calcolo dell'indirizzo efficace non farà tutto il lavoro da solo. La stringa di visualizzazione della linea è una tabella di elementi di 3 byte. Ciascun elemento contiene un carattere di spazio seguito dai due caratteri esadecimali. Poiché gli elementi sono lunghi tre caratteri, la scala non può essere effettuata all'interno dell'istruzione e deve essere gestita separatamente. Non è difficile. La scalabilità per gli elementi di 3 byte nella tabella HexStr nel programma hexdump1 è fatta in questo modo:
</p>

```asm
mov rdx,rcx     ; Copy the character counter into rdx
shl rdx,1       ; Multiply counter by 2 using left shift
add rdx,rcx     ; Complete the multiplication X3
```

<p align=justify>
Il calcolo per moltiplicare un valore in RDX per 3 viene effettuato con una combinazione di un'istruzione SHL per moltiplicare per 2, seguita da un'istruzione ADD che aggiunge una terza copia del valore dell'indice al valore dell'indice spostato, moltiplicando efficacemente il valore originale per 3. La scalatura per altri valori di indice può essere effettuata allo stesso modo. La scalatura per 5 sarebbe eseguita spostando il valore dell'indice a sinistra di 2 bit, moltiplicandolo così per 4, seguita dall'aggiunta di un'altra copia del valore dell'indice per completare la moltiplicazione per 5. In termini generali, per scalare un valore di indice per X:
</p>

1. Trova la potenza di 2 più grande di X.
2. Sposta il valore dell'indice a sinistra di quella potenza di 2.
3. Aggiungi una copia del valore dell'indice originale alla copia spostata tante volte quanto è necessario per completare la moltiplicazione per X.

<p align=justify>
Ad esempio, se X è 11, il calcolo della scala verrebbe fatto in questo modo:
</p>

```asm
 mov rdx,rcx ; Copy the index into rdx
 shl rdx,3   ; Multiply index X 8 by shifting index left 3X
 add rdx,rcx ; Add first of 3 additional copies of index
 add rdx,rcx ; Add second of 3 additional copies of index
 add rdx,rcx ; Add third of 3 additional copies of index
```

<p align=justify>
Questo funziona meglio per valori di dimensioni relativamente piccole; una volta che superi 20, ci saranno molte istruzioni ADD. A quel punto, la risposta non è calcolare la scala ma cercare la scala in una tabella appositamente definita per un determinato valore di scala. Ad esempio, supponi che gli elementi della tua tabella siano lunghi ciascuno 25 byte. Potresti definire una tabella con multipli di 25:
</p>

```asm
ScaleValues: dd 0,25,50,75,100,125,150,175,200,225,250,275
```

<p align=justify>
Per scalare un valore indice di 6 per una dimensione di voce di 25, dovresti cercare il prodotto di 6 × 25 nella tabella in questo modo.
</p>

```asm
 mov rcx,6
 mov rax,[ScaleValues+rcx*4]
```

<p align=justify>
Il valore in RAX ora contiene l'indirizzo efficace del primo byte dell'elemento 6, contando gli elementi (come al solito) da 0.
</p>

### Istruzione LEA

<p align=justify>
Ma aspetta, c'è di più. Una delle istruzioni più bizzarre e sotto alcuni aspetti più meravigliose nell'architettura Intel è LEA, Carica Indirizzo Efficace. In superficie, ciò che fa è semplice: calcola un indirizzo efficace utilizzando i termini tra le parentesi del suo operando sorgente e carica quell'indirizzo in un qualsiasi registro a 64 bit dato come operando di destinazione. Guarda di nuovo il codice mostrato poco prima dell'inizio di questa sezione. L'istruzione MOV cerca l'elemento con indice 6 nella tabella ScaleValues. Per cercare l'elemento all'indice 6, deve prima calcolare l'indirizzo efficace dell'elemento all'indice 6. Questo indirizzo viene poi utilizzato per accedere alla memoria. Ma cosa succede se vuoi salvare quell'indirizzo in un registro per utilizzarlo successivamente senza doverlo calcolare di nuovo? Ecco cosa fa LEA. Ecco LEA in azione:
</p>

```asm
 lea rbx,[ScaleValues+rcx*4]
```

<p align=justify>
Quello che succede qui è che la CPU calcola l'indirizzo effettivo fornito all'interno delle parentesi e carica quell'indirizzo nel registro RBX. Tenere presente che le singole voci di una tabella non dispongono di etichette e quindi non è possibile farvi riferimento direttamente. LEA ti dà la possibilità di calcolare l'indirizzo effettivo di qualsiasi elemento in una tabella (o qualsiasi indirizzo calcolabile!) e di inserire quell'indirizzo in un registro. Di per sé questo è molto utile. Tuttavia, LEA ha uno scopo "off-label": fare matematica veloce senza turni, aggiunte o MUL. Se ricordi, c'è un calcolo nel programma hexdump1gcc che moltiplica per 3 usando uno spostamento e un'addizione
</p>

```asm
 mov rdx,rcx   ; Copy the character counter into rdx
 shl rdx,1     ; Multiply pointer by 2 using left shift
 add rdx,rcx   ; Complete the multiplication X3
```

<p align=justify>
Questo funziona. Ma guarda cosa possiamo usare che fa esattamente la stessa cosa.
</p>

```asm
 mov rdx,rcx         ; Copy the character counter into rdx
 lea rdx,[rdx*2+rdx] ; Multiply rdx X 3
```

<p align=justify>
Non solo questo è praticamente sempre più veloce rispetto alle operazioni di spostamento combinate con le addizioni, ma è anche più chiaro dal tuo codice sorgente che tipo di calcolo viene effettivamente eseguito. Il fatto che ciò che finisce in RDX potrebbe non essere in realtà l'indirizzo legale di nulla è irrilevante. LEA non cerca di fare riferimento all'indirizzo che calcola. Esegue i calcoli sui valori all'interno delle parentesi e deposita il risultato nell'operando di destinazione. Lavoro terminato. La memoria non viene toccata e i flag non vengono influenzati. Naturalmente, sei limitato da quali calcoli possono essere effettuati che producono indirizzi efficaci. Ma subito, puoi moltiplicare qualsiasi registro GP per 2, 3, 4, 5, 8 e 9. Non è matematica arbitraria, ma moltiplicare per 2, 3, 4, 5, 8 e 9 si verifica regolarmente nel lavoro di assembly, e puoi combinare LEA con spostamenti e addizioni per fare calcoli più complessi e “riempire i buchi.” Puoi anche usare più istruzioni LEA in fila. Due istruzioni LEA consecutive possono moltiplicare un valore per 10, il che è davvero utile:
</p>

```asm
 lea rbx,[rbx*2]      ; Multiply rbx X 2, put product in RBX
 lea rbx,[rbx*4+rbx]  ; Multiply rbx X 5 for a total of X 10
```

<p align=justify>
Alcune persone considerano questo uso di LEA un trucco meschino, ma in tutti gli anni in cui ho lavorato con l'assembly x86/x64 non ho mai visto un inconveniente. Prima di lanciare cinque o sei istruzioni nella pentola per cucinare una particolare moltiplicazione, verifica se due o tre LEA possono fare lo stesso lavoro. LEA svolge il suo lavoro in un ciclo di macchina, e la matematica della CPU non diventa più veloce di così!
</p>


### Tabella di traduzione caratteri

<p align=justify>
Esiste un tipo di ricerca in tabella che è (o forse era) talmente comune che gli ingegneri di Intel hanno integrato un'intera istruzione nell'architettura x86 per farlo. Il tipo di ricerca in tabella a cui alludevo è la conversione dei caratteri. Nei primi anni '80 avevo bisogno di convertire i set di caratteri in modi diversi, il più semplice dei quali era forzare tutti i caratteri minuscoli in maiuscolo. E così nei paragrafi precedenti abbiamo costruito un programma semplice che scorreva un file un buffer alla volta, acquisendo caratteri, convertendo tutti i caratteri minuscoli in maiuscolo e poi riscrivendoli nuovamente in un nuovo file. La conversione stessa era semplice: facendo riferimento alla tabella ASCII per la relazione tra tutti i caratteri maiuscoli e i loro associati caratteri minuscoli, potevamo convertire un carattere minuscolo in maiuscolo semplicemente sottraendo 20h (32) dal carattere. Questo è affidabile, ma è molto un caso speciale. Succede proprio che i caratteri minuscoli ASCII siano sempre 32 più alti nella tabella rispetto ai loro equivalenti caratteri maiuscoli. Cosa fai se hai bisogno di convertire tutti i caratteri “barra verticale” (ASCII 124) in punti esclamativi? (Dovetti farlo una volta, perché uno dei vecchi mainframe non riusciva a gestire le barre verticali.) Puoi scrivere codice speciale per ciascun caso individuale con cui devi confrontarti... ...oppure puoi usare una tabella di traduzione.
</p>

### Tabella di traduzione

<p align=justify>
Una tabella di traduzione è un tipo speciale di tabella e funziona nel seguente modo: si imposta una tabella di valori, con un'entrata per ogni possibile valore che deve essere tradotto. Un numero (o un carattere, trattato come un valore numerico) viene utilizzato come indice nella tabella. Alla posizione dell'indice nella tabella c'è un valore che viene utilizzato per sostituire il valore originale utilizzato come indice. In breve, il valore originale accede alla tabella e trova un nuovo valore che sostituisce il valore originale, traducendo così il vecchio valore in uno nuovo. Lo abbiamo già fatto una volta, nel programma hexdump1gcc nella sezione 9.1. Ricorda la tabella delle cifre:
</p>

```asm
Digits: db "0123456789ABCDEF"
```

<p align=justify>
Questa è una tabella di traduzione, anche se all'epoca non l'ho chiamata così. L'idea, se ricordi, era di separare le due metà da 4 bit di un byte da 8 bit e convertire quei valori da 4 bit in caratteri ASCII che rappresentano cifre esadecimali. Il focus all'epoca era separare i byte in due nybbles tramite operazioni logiche bit a bit, ma c'era anche una traduzione in corso. La traduzione è stata realizzata da queste tre istruzioni.
</p>

```asm
mov al,byte [rsi+rcx]    ; Put a byte from the input buffer
 			 ; into al
and al,0Fh               ; Mask out all but the low nybble
mov al,byte [Digits+rax] ; Look up the char equivalent of nybble
```

<p align=justify>
La prima istruzione carica un byte dal buffer di input nel registro AL a 8 bit. La seconda istruzione maschera tutto tranne il basso nybble di AL. La terza istruzione esegue un recupero della memoria: utilizza il valore in AL per indicizzare nella tabella Digits e riporta qualsiasi valore fosse nella voce ALth nella tabella. (Questo deve essere fatto utilizzando RAX tra parentesi, perché AL non può prendere parte ai calcoli dell'indirizzo efficaci. Ricorda solo che AL è il byte di ordine più basso nel registro RAX.) Se AL teneva premuto 0, il calcolo dell'indirizzo effettivo aggiungeva 0 all'indirizzo di Digits, riportando la voce 0 della tabella, che è il carattere ASCII per 0. Se AL teneva premuto 5, il calcolo dell'indirizzo effettivo aggiungeva 5 all'indirizzo di Digits, riportando la quinta voce della tabella, che è il carattere ASCII per 5. E così andrebbe per tutti i 16 possibili valori che possono essere espressi in un nybble a 4 bit. Fondamentalmente, il codice viene utilizzato per tradurre un numero nell'equivalente del carattere ASCII di quel numero. Ci sono solo 16 cifre esadecimali possibili, quindi la tabella di conversione in hexdump1gcc deve essere lunga solo 16 byte. Un byte contiene abbastanza bit per rappresentare 256 valori diversi, quindi se vogliamo tradurre valori di dimensioni in byte, avremo bisogno di una tabella con 256 voci. Tecnicamente, il set di caratteri ASCII utilizza solo i primi 128 valori, ma come ho descritto in precedenza in questo libro, i valori "alti" di 128 sono stati spesso assegnati a caratteri speciali come lettere non inglesi, caratteri "box-draw", simboli matematici e così via. Un uso comune della traduzione dei caratteri consiste nel convertire tutti i caratteri con valori superiori a 128 in qualcosa di inferiore a 128 per evitare il caos nei sistemi più vecchi che non sono in grado di gestire valori ASCII estesi. Una tabella di questo tipo è abbastanza facile da definire in un programma in linguaggio assembly:
</p>

```asm
UpCase:
 db 20h,20h,20h,20h,20h,20h,20h,20h,20h,09h,0Ah,20h,20h,20h,20h,20h
 db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
 db 20h,21h,22h,23h,24h,25h,26h,27h,28h,29h,2Ah,2Bh,2Ch,2Dh,2Eh,2Fh
 db 30h,31h,32h,33h,34h,35h,36h,37h,38h,39h,3Ah,3Bh,3Ch,3Dh,3Eh,3Fh
 db 40h,41h,42h,43h,44h,45h,46h,47h,48h,49h,4Ah,4Bh,4Ch,4Dh,4Eh,4Fh
 db 50h,51h,52h,53h,54h,55h,56h,57h,58h,59h,5Ah,5Bh,5Ch,5Dh,5Eh,5Fh
 db 60h,41h,42h,43h,44h,45h,46h,47h,48h,49h,4Ah,4Bh,4Ch,4Dh,4Eh,4Fh
 db 50h,51h,52h,53h,54h,55h,56h,57h,58h,59h,5Ah,7Bh,7Ch,7Dh,7Eh,20h
 db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
 db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
 db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
 db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
 db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
 db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
 db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
 db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
```

<p align=justify>
La tabella UpCase è definita in 16 righe di 16 valori esadecimali separati. Il fatto che sia suddivisa in 16 righe nell'elenco del codice è puramente per leggibilità su schermo o pagina stampata e non influisce sulla tabella binaria che NASM genera nel file .o di output. Una volta in binario, si tratta di 256 valori a 8 bit in fila. Una rapida nota sintattica qui: quando si definiscono tabelle (o qualsiasi struttura dati contenente più valori predefiniti), le virgole vengono utilizzate per separare i valori all'interno di una singola definizione. Non è necessario usare virgole alla fine delle righe delle definizioni DB nella tabella precedente. Ogni definizione DB è separata e indipendente, ma poiché sono adiacenti in memoria, possiamo trattare le 16 definizioni DB come un'unica tabella di 256 byte. Qualsiasi tabella di traduzione può essere vista come espressione di una o più “regole” che governano cosa avviene durante il processo di traduzione. La tabella UpCase mostrata in precedenza esprime queste regole di traduzione:
</p>

<ul>
	<li>
		<p align=justify>
		Tutti i caratteri ASCII minuscoli vengono tradotti in maiuscolo
		</p>
	</li>
 	<li>
		<p align=justify>
		Tutti i caratteri ASCII stampabili inferiori a 127 che non sono minuscoli vengono tradotti in se stessi. (Non vengono esattamente "lasciati in pace", ma vengono comunque tradotti, solo negli stessi caratteri.)
		</p>
	</li>
 	<li>
		<p align=justify>
		Tutti i valori dei caratteri "alti" da 127 a 255 vengono tradotti nel carattere di spazio ASCII (32, o 20h)
		</p>
	</li>
 	<li>
		<p align=justify>
		Tutti i caratteri ASCII non stampabili (fondamentalmente, i valori 0–31, più 127) vengono tradotti in spazi tranne che per i valori 9 e 10.
		</p>
	</li>
 	<li>
		<p align=justify>
		I valori dei caratteri 9 e 10 (tabulazione e fine riga) sono tradotti come se stessi.
		</p>
	</li>
</ul>

<p align=justify>
Non male per un singolo dato, eh? (Immagina solo quanto lavoro sarebbe fare tutto quel fastidio solo con istruzioni di macchina!)
</p>

### Tradurre con MOV o XLAT

<p align=justify>
Quindi, come utilizziamo la tabella UpCase? Il modo ovvio sarebbe questo:
</p>

<ul>
	<li>
		<p align=justify>
			Carica il carattere da tradurre in AL.
		</p>
	</li>
 	<li>
		<p align=justify>
			Crea un riferimento di memoria utilizzando AL come termine base e UpCase come termine di spostamento, e sposta il byte al riferimento di memoria in AL, sostituendo il valore originale usato come termine base.
		</p>
	</li>
</ul>

<p align=justify>
L'istruzione MOV ipotetica apparirebbe così
</p>

```asm
 mov al, byte [UpCase+al]
```

<p align=justify>
C'è solo un problema: NASM non ti permette di fare questo. In modalità protetta a 32 bit e in modalità long x64, il registro AL non può partecipare ai calcoli dell'indirizzo efficace, né possono farlo gli altri registri a 8 bit. Entra in gioco XLAT. L'istruzione XLAT è codificata in modo rigido per utilizzare determinati registri in modi specifici. I suoi due operandi sono entrambi impliciti:
</p>

<ul>
	<li>
		<p align=justify>
			L'indirizzo della tabella di traduzione deve essere in RBX.
   		</p>
	</li>
 	<li>
		<p align=justify>
			Il carattere da tradurre deve essere in AL
		</p>
	</li>
 	<li>
		<p align=justify>
			Il carattere tradotto sarà restituito in AL, sostituendo il carattere originariamente posto in AL.
		</p>
	</li>
</ul>

<p align=justify>
Con i registri configurati, l'istruzione XLAT non ha operandi ed è utilizzata tutta da sola:
</p>

```asm
 xlat
```

<p align=justify>
Sarò onesto: XLAT è meno vantaggioso di quanto fosse in passato. In modalità long x64, la stessa cosa può essere fatta con la seguente istruzione:
</p>

```asm
 mov al, byte [UpCase+rax]
```

<p align=justify>
Il registro a 64 bit RAX può sostituire il piccolo AL a 8 bit quando si calcola un indirizzo efficace del carattere usato per tradurre il carattere in AL. C'è solo un problema: devi rimuovere eventuali valori "residui" nei 56 bit superiori di RAX, altrimenti potresti indicizzare accidentalmente ben oltre i limiti della tabella di traduzione. Il problema non si presenta con XLAT poiché l'istruzione XLAT utilizza solo AL per l'indice, ignorando qualsiasi altra cosa possa trovarsi nei bit superiori di RAX. Azzerare RAX prima di caricare il valore da tradurre in AL viene fatto in uno di questi due modi comuni:
</p>

```asm
 xor rax,rax
 mov rax,0
```

<p align=justify>
In verità, dato il requisito di XLAT di utilizzare AL e RBX, è una cosa neutra, ma il tema più ampio della traduzione dei caratteri tramite tabelle è davvero ciò che sto cercando di presentare qui. Il codice di sotto mette tutto in azione. Il programma come mostrato fa esattamente quello che fa il programma uppercaser2: forza tutti i caratteri minuscoli in un file di input a essere maiuscoli e li scrive in un file di output. Non l'ho chiamato "uppercaser3" perché è un traduttore di caratteri per scopi generali. In questo particolare esempio, con la tabella UpCase, traduce i caratteri minuscoli in maiuscoli; tuttavia, quella è semplicemente una delle regole che esprime la tabella UpCase. Cambia la tabella e cambiano le regole. Puoi tradurre qualsiasi valore o tutti i 256 valori differenti in un byte in qualsiasi valore o valori a 8 bit. Ho aggiunto una seconda tabella al programma per farti sperimentare. La tabella Personalizzata esprime queste regole:
</p>

<ul>
	<li>
		<p align=justify>
		Tutti i caratteri ASCII stampabili inferiori a 127 vengono tradotti in se stessi. (Non vengono precisamente "lasciati in pace" ma vengono comunque tradotti, solo negli stessi caratteri.)   			</p>
	</li>
 	<li>
		<p align=justify>
		Tutti i valori dei caratteri "alti" da 127 a 255 vengono tradotti nel carattere di spazio ASCII (32, o 20h.)		
		</p>
	</li>
 	<li>
		<p align=justify>
		Tutti i caratteri ASCII non stampabili (fondamentalmente, i valori 0–31, più 127) vengono tradotti in spazi tranne i valori 9 e 10.		
		</p>
	</li>
	 <li>
		<p align=justify>
		I valori dei caratteri 9 e 10 (tabulazione e fine riga) sono tradotti come se stessi.
		</p>
	</li>
</ul>

<p align=justify>
Fondamentalmente, lascia inalterati tutti i caratteri stampabili (più tab e EOL) e converte tutti gli altri valori dei caratteri in 20h, il carattere spazio. Puoi sostituire l'etichetta Custom con UpCase nel programma, apportare modifiche alla tabella Custom e provarla. Converti quel fastidioso barre verticale in un punto esclamativo. Cambia tutti i caratteri “Z” in “Q.” Cambiare le regole è fatto modificando la tabella. Il codice non cambia affatto! Come nei programmi precedenti, xlat1gcc legge dall'input standard e scrive nell'output standard. Copia del testo negli appunti e incollalo nella finestra di input di SASM. Poi esegui il programma e guarda cosa scrive nella finestra di output.
</p>

```asm
;  Executable name : xlat1gcc
;  Version         : 2.0
;  Created date    : 8/21/2022
;  Last update     : 7/17/2023
;  Author          : Jeff Duntemann
;  Description     : A simple program in assembly for Linux, 
;                  : using NASM 2.15, demonstrating the XLAT 
;                  : instruction to translate characters using 
;                  : translation tables.
;
;  Run it either in SASM or using this command in the Linux terminal:
;
;     xlat1gcc < input file > output file
;
;       If an output file is not specified, output goes to stdout
;
;  Build using SASM's default build setup for x64
;  To test from a terminal, save out the executable to disk.

SECTION .data       ; Section containing initialised data
	
    StatMsg: db "Processing...",10
    StatLen: equ $-StatMsg
    DoneMsg: db "...done!",10
    DoneLen: equ $-DoneMsg
	
; The following translation table translates all lowercase characters
; to uppercase. It also translates all non-printable characters to 
; spaces, except for LF and HT. This is the table used by default in 
; this program.
    UpCase: 
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,09h,0Ah,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,21h,22h,23h,24h,25h,26h,27h,28h,29h,2Ah,2Bh,2Ch,2Dh,2Eh,2Fh
    db 30h,31h,32h,33h,34h,35h,36h,37h,38h,39h,3Ah,3Bh,3Ch,3Dh,3Eh,3Fh
    db 40h,41h,42h,43h,44h,45h,46h,47h,48h,49h,4Ah,4Bh,4Ch,4Dh,4Eh,4Fh
    db 50h,51h,52h,53h,54h,55h,56h,57h,58h,59h,5Ah,5Bh,5Ch,5Dh,5Eh,5Fh
    db 60h,41h,42h,43h,44h,45h,46h,47h,48h,49h,4Ah,4Bh,4Ch,4Dh,4Eh,4Fh
    db 50h,51h,52h,53h,54h,55h,56h,57h,58h,59h,5Ah,7Bh,7Ch,7Dh,7Eh,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h

; The following translation table is "stock" in that it translates all
; printable characters as themselves, and converts all non-printable
; characters to spaces except for LF and HT. You can modify this to
; translate anything you want to any character you want. To use it,
; replace the default table name (UpCase) with Custom in the code below.
    Custom: 
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,09h,0Ah,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,21h,22h,23h,24h,25h,26h,27h,28h,29h,2Ah,2Bh,2Ch,2Dh,2Eh,2Fh
    db 30h,31h,32h,33h,34h,35h,36h,37h,38h,39h,3Ah,3Bh,3Ch,3Dh,3Eh,3Fh
    db 40h,41h,42h,43h,44h,45h,46h,47h,48h,49h,4Ah,4Bh,4Ch,4Dh,4Eh,4Fh
    db 50h,51h,52h,53h,54h,55h,56h,57h,58h,59h,5Ah,5Bh,5Ch,5Dh,5Eh,5Fh
    db 60h,61h,62h,63h,64h,65h,66h,67h,68h,69h,6Ah,6Bh,6Ch,6Dh,6Eh,6Fh
    db 70h,71h,72h,73h,74h,75h,76h,77h,78h,79h,7Ah,7Bh,7Ch,7Dh,7Eh,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h
    db 20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h,20h

SECTION .bss            ; Section containing uninitialized data

    READLEN	    equ 1024        ; Length of buffer
    ReadBuffer: resb READLEN    ; Text buffer itself
	
SECTION .text           ; Section containing code

global  main

main:
    mov rbp,rsp      ; This keeps gdb happy...

; Display the "I'm working..." message via stderr:
    mov rax,1        ; Specify sys_write call
    mov rdi,2        ; Specify File Descriptor 2: Standard error
    mov rsi,StatMsg  ; Pass address of the message
    mov rdx,StatLen  ; Pass the length of the message
    syscall          ; Make kernel call

; Read a buffer full of text from stdin:
read:
    mov rax,0           ; Specify sys_read call
    mov rdi,0           ; Specify File Descriptor 0: Standard Input
    mov rsi,ReadBuffer  ; Pass address of the buffer to read to
    mov rdx,READLEN     ; Pass number of bytes to read at one pass
    syscall
    mov rbp,rax         ; Copy sys_read return value for safekeeping
    cmp rax,0           ; If rax=0, sys_read reached EOF
    je done             ; Jump If Equal (to 0, from compare)

; Set up the registers for the translate step:
    mov rbx,UpCase      ; Place the address of the table into rbx
    mov rdx,ReadBuffer  ; Place the address of the buffer into rdx
    mov rcx,rbp         ; Place number of bytes in the buffer into rcx
    
; Use the xlat instruction to translate the data in the buffer:
translate:
    xor rax,rax             ; Clear rax
    mov al,byte [rdx-1+rcx] ; Load character into AL for translation
    xlat                    ; Translate character in AL via table
    mov byte [rdx-1+rcx],al ; Put the xlated character back in buffer
    dec rcx                 ; Decrement character count
    jnz translate           ; If there are more chars in the buffer, repeat

; Write the buffer full of translated text to stdout:
write:
    mov rax,1           ; Specify sys_write call
    mov rdi,1           ; Specify File Descriptor 1: Standard output
    mov rsi,ReadBuffer  ; Pass address of the buffer
    mov rdx,rbp         ; Pass the # of bytes of data in the buffer
    syscall             ; Make kernel call
    jmp read            ; Loop back and load another buffer full

; Display the "I'm done" message via stderr:
done:	
    mov rax,1           ; Specify sys_write call
    mov rdi,2           ; Specify File Descriptor 2: Standard error
    mov rsi,DoneMsg     ; Pass address of the message
    mov rdx,DoneLen     ; Pass the length of the message
    syscall             ; Make kernel call

; All done! Let's end this party:
    ret                 ; Return to the glibc shutdown code
```

### Tabelle al posto di calcoli

<p align=justify>
La standardizzazione tra i sistemi informatici ha reso la traduzione dei caratteri molto meno comune di quanto fosse in passato, ma le tabelle di traduzione possono essere estremamente utili in altre aree. Una di queste è per eseguire operazioni matematiche più veloci. Considera la seguente tabella:
</p>

```asm
 Squares: db 0,1,4,9,16,25,36,49,64,81,100,121,144,169,196,225
```

<p align=justify>
Nessun mistero qui: Squares è una tabella dei quadrati dei numeri da 0 a 15. Se avessi bisogno del quadrato di 14 in un calcolo, potresti usare MUL, che è più lento della maggior parte delle istruzioni e richiede due registri GP. Oppure potresti semplicemente ottenere il risultato dalla tabella Squares:
</p>

```asm
 mov rcx,14
 mov al,byte [Squares+rcx]
```

<p align=justify>
Ecco! RAX ora contiene il quadrato di 14. Puoi fare lo stesso trucco con XLAT, anche se richiede di utilizzare determinati registri. Ricorda anche che XLAT è limitato a quantità di 8 bit. La tabella dei quadrati mostrata qui è la tabella dei valori quadrati più grande che XLAT può utilizzare, poiché il successivo valore quadrato (di 16) è 256, che non può essere espresso in 8 bit e quindi una tabella di ricerca che lo contenga non può essere utilizzata da XLAT. Rendere le voci di una tabella di ricerca dei valori quadrati di dimensione 16 bit ti permetterà di includere i quadrati di tutti gli interi fino a 255. E se dai a ciascuna voce nella tabella 32 bit, puoi includere i quadrati di interi fino a 65.535, ma sarebbe una tabella molto sostanziale! Non ho spazio in questo libro per approfondire la matematica in virgola mobile, ma una volta si faceva molto frequentemente uso di tabelle per cercare valori per cose come le radici quadrate. I moderni CPU con sistemi matematici come AVX rendono tali tecniche molto meno allettanti. Tuttavia, quando si è di fronte a una sfida di calcolo matematico, dovresti sempre tenere a mente la possibilità di utilizzare tabelle di ricerca.
</p>

### Procedure

<p align=justify>
Tutti i linguaggi di programmazione comunemente usati oggi implementano procedure in una forma o nell'altra, e il linguaggio assembly non fa eccezione. Il tuo programma in linguaggio assembly può avere numerose procedure. In effetti, non c'è limite al numero di procedure che puoi includere in un programma, purché il numero totale di byte di codice contenuti da tutte le procedure insieme, più i dati che utilizzano, possa essere contenuto nella memoria che Linux assegna a esso. Al giorno d'oggi, con la memoria economica disponibile in blocchi multi-gigabyte, scrivere codice che non si adatta all'allocazione di Linux è sempre meno probabile. Qualsiasi complessità tu possa generare in linguaggio assembly può essere gestita con le procedure. Cominciamo presto con un esempio di procedure in azione. Leggi attentamente il codice di sotto e vediamo cosa lo fa funzionare e (per essere più precisi) cosa aiuta a mantenerlo comprensibile.
</p>

```asm
;  Executable name : hexdump2gcc
;  Version         : 2.0
;  Created date    : 5/9/2022
;  Last update     : 5/17/2023
;  Author          : Jeff Duntemann
;  Description     : A simple hexdump utility demonstrating the use of
;                  : assembly language procedures
;
;  Build using SASM's 64-bit build feature, which uses gcc & requires "main"
;  To run, type or paste some text into SASM's Input window and click Run.
;  The hex dump of the input text will appear in SASM's Output window.

SECTION .bss       ; Section containing uninitialized data

    BUFFLEN        EQU 10h
    Buff:          resb BUFFLEN

SECTION .data      ; Section containing initialised data

; Here we have two parts of a single useful data structure, implementing
; the text line of a hex dump utility. The first part displays 16 bytes in
; hex separated by spaces. Immediately following is a 16-character line 
; delimited by vertical bar characters. Because they are adjacent, the two
; parts can be referenced separately or as a single contiguous unit.
; Remember that if DumpLin is to be used separately, you must append an
; EOL before sending it to the Linux console.

DumpLine:       db " 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 "
DUMPLEN         EQU $-DumpLine
ASCLine:        db "|................|",10
ASCLEN          EQU $-ASCLine
FULLLEN         EQU $-DumpLine

; The HexDigits table is used to convert numeric values to their hex
; equivalents. Index by nybble without a scale: [HexDigits+eax]
HexDigits:      db "0123456789ABCDEF"

; This table is used for ASCII character translation, into the ASCII
; portion of the hex dump line, via XLAT or ordinary memory lookup. 
; All printable characters "play through" as themselves. The high 128 
; characters are translated to ASCII period (2Eh). The non-printable
; characters in the low 128 are also translated to ASCII period, as is
; char 127.
DotXlat: 
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 20h,21h,22h,23h,24h,25h,26h,27h,28h,29h,2Ah,2Bh,2Ch,2Dh,2Eh,2Fh
    db 30h,31h,32h,33h,34h,35h,36h,37h,38h,39h,3Ah,3Bh,3Ch,3Dh,3Eh,3Fh
    db 40h,41h,42h,43h,44h,45h,46h,47h,48h,49h,4Ah,4Bh,4Ch,4Dh,4Eh,4Fh
    db 50h,51h,52h,53h,54h,55h,56h,57h,58h,59h,5Ah,5Bh,5Ch,5Dh,5Eh,5Fh
    db 60h,61h,62h,63h,64h,65h,66h,67h,68h,69h,6Ah,6Bh,6Ch,6Dh,6Eh,6Fh
    db 70h,71h,72h,73h,74h,75h,76h,77h,78h,79h,7Ah,7Bh,7Ch,7Dh,7Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
			
	
SECTION .text      ; Section containing code

;-------------------------------------------------------------------------
; ClearLine:   Clear a hex dump line string to 16 0 values
; UPDATED:     5/9/2022
; IN:          Nothing
; RETURNS:     Nothing
; MODIFIES:    Nothing
; CALLS:       DumpChar
; DESCRIPTION: The hex dump line string is cleared to binary 0 by
;              calling DumpChar 16 times, passing it 0 each time.

ClearLine:
    push rax       ; Save all caller's r*x GP registers
    push rbx
    push rcx
    push rdx
    
    mov  rdx,15    ; We're going to go 16 pokes, counting from 0
.poke:	
    mov rax,0      ; Tell DumpChar to poke a '0'
    call DumpChar  ; Insert the '0' into the hex dump string
    sub rdx,1      ; DEC doesn't affect CF!
    jae .poke       ; Loop back if RDX >= 0
    
    pop rdx        ; Restore caller's r*x GP registers
    pop rcx
    pop rbx
    pop rax
    ret            ; Go home

;-------------------------------------------------------------------------
; DumpChar:    "Poke" a value into the hex dump line string.
; UPDATED:     5/9/2022
; IN:          Pass the 8-bit value to be poked in RAX.
;              Pass the value's position in the line (0-15) in RDX 
; RETURNS:     Nothing
; MODIFIES:    RAX, ASCLin, DumpLin
; CALLS:       Nothing
; DESCRIPTION: The value passed in RAX will be put in both the hex dump
;              portion and in the ASCII portion, at the position passed 
;              in RDX, represented by a space where it is not a
;              printable character.

DumpChar:
    push rbx    ; Save caller's RBX
    push rdi    ; Save caller's RDI

; First we insert the input char into the ASCII portion of the dump line
    mov bl,[DotXlat+rax]      ; Translate nonprintables to '.'
    mov [ASCLine+rdx+1],bl    ; Write to ASCII portion

; Next we insert the hex equivalent of the input char in the hex portion
; of the hex dump line:
    mov rbx,rax               ; Save a second copy of the input char
    lea rdi,[rdx*2+rdx]       ; Calc offset into line string (RDX X 3)

; Look up low nybble character and insert it into the string:
    and rax,000000000000000Fh      ; Mask out all but the low nybble
    mov al,[HexDigits+rax]    ; Look up the char equiv. of nybble
    mov [DumpLine+rdi+2],al   ; Write the char equiv. to line string

; Look up high nybble character and insert it into the string:
    and rbx,00000000000000F0h      ; Mask out all the but second-lowest nybble
    shr rbx,4                      ; Shift high 4 bits of byte into low 4 bits
    mov bl,[HexDigits+rbx]    ; Look up char equiv. of nybble
    mov [DumpLine+rdi+1],bl   ; Write the char equiv. to line string

; Done! Let's return:
    pop rdi     ; Restore caller's RDI
    pop rbx	    ; Restore caller's RBX
    ret         ; Return to caller

;-------------------------------------------------------------------------
; PrintLine:    Displays DumpLin to stdout
; UPDATED: 	    5/8/2023
; IN:           DumpLin, FULLEN
; RETURNS:      Nothing
; MODIFIES:     Nothing
; CALLS:        Kernel sys_write
; DESCRIPTION:  The hex dump line string DumpLin is displayed to stdout 
;          using syscall function sys_write. Registers used are preserved.

PrintLine:
        
    push rax          ; Alas, we don't have pushad anymore.
    push rbx
    push rcx
    push rdx
    push rsi
    push rdi
        
    mov rax,1         ; Specify sys_write call
    mov rdi,1         ; Specify File Descriptor 1: Standard output
    mov rsi,DumpLine  ; Pass address of line string
    mov rdx,FULLLEN   ; Pass size of the line string
    syscall           ; Make kernel call to display line string

    pop rdi           ; Nor popad.
    pop rsi
    pop rdx
    pop rcx
    pop rbx
    pop rax
    ret               ; Return to caller


;-------------------------------------------------------------------------
; LoadBuff:    Fills a buffer with data from stdin via syscall sys_read
; UPDATED:     5/8/2023
; IN:          Nothing
; RETURNS:     # of bytes read in R15
; MODIFIES:    RCX, R15, Buff
; CALLS:       syscall sys_read
; DESCRIPTION: Loads a buffer full of data (BUFFLEN bytes) from stdin 
;              using syscall sys_read and places it in Buff. Buffer
;              offset counter RCX is zeroed, because we're starting in
;              on a new buffer full of data. Caller must test value in
;              R15: If R15 contains 0 on return, we've hit EOF on stdin.
;              Less than 0 in R15 on return indicates some kind of error.

LoadBuff:
    push rax      ; Save caller's RAX
    push rdx      ; Save caller's RDX
    push rsi      ; Save caller's RSI
    push rdi      ; Save caller's RDI

    mov rax,0     ; Specify sys_read call
    mov rdi,0     ; Specify File Descriptor 0: Standard Input
    mov rsi,Buff      ; Pass offset of the buffer to read to
    mov rdx,BUFFLEN   ; Pass number of bytes to read at one pass
    syscall       ; Call syscall's sys_read to fill the buffer
    mov r15,rax   ; Save # of bytes read from file for later
    xor rcx,rcx   ; Clear buffer pointer RCX to 0

    pop rdi       ; Restore caller's RDI
    pop rsi       ; Restore caller's RSI
    pop rdx       ; Restore caller's RDX
    pop rax       ; Restore caller's RAX
    ret           ; And return to caller

GLOBAL main ; You need to declare "main" here because SASM uses gcc
            ; to do builds.

; ------------------------------------------------------------------------
; MAIN PROGRAM BEGINS HERE
;-------------------------------------------------------------------------

main:
    mov rbp,rsp; for correct debugging

; Whatever initialization needs doing before loop scan starts is here:
    xor r15,r15     ; Zero out r15,rsi, and rcx
    xor rsi,rsi		
    xor rcx,rcx
    call LoadBuff   ; Read first buffer of data from stdin
    cmp r15,0       ; If r15=0, sys_read reached EOF on stdin
    jbe Exit

; Go through the buffer and convert binary byte values to hex digits:
Scan:
    xor rax,rax                ; Clear RAX to 0
    mov al,byte[Buff+rcx]      ; Get a byte from the buffer into AL
    mov rdx,rsi	               ; Copy total counter into RDX
    and rdx,000000000000000Fh  ; Mask out lowest 4 bits of char counter
    call DumpChar              ; Call the char poke procedure

; Bump the buffer pointer to the next character and see if buffer's done:
    inc rsi           ; Increment total chars processed counter
    inc rcx           ; Increment buffer pointer
    cmp rcx,r15       ; Compare with # of chars in buffer
    jb .modTest       ; If we've processed all chars in buffer...
    call LoadBuff     ; ...go fill the buffer again
    cmp r15,0         ; If r15=0, sys_read reached EOF on stdin
    jbe Done          ; If we get EOF, we're done

; See if we're at the end of a block of 16 and need to display a line:
.modTest:
    test rsi,000000000000000Fh ; Test 4 lowest bits in counter for 0
    jnz Scan                   ; If counter is *not* modulo 16, loop back
    call PrintLine             ; ...otherwise print the line
    call ClearLine             ; Clear hex dump line to 0's
    jmp Scan                   ; Continue scanning the buffer

; All done! Let's end this party:
Done:
    call PrintLine   ; Print the final "leftovers" line

Exit:	
    mov rsp,rbp
    ret
```

<p align=justify>
Ammetto, che sembra un po' spaventoso. Sono più di 200 righe di codice e rappresenta di gran lunga il programma più grande di questo libro finora. Tuttavia, quello che fa è abbastanza semplice. È un'estensione diretta del programma hexdump1gcc dall'elenco 9.1. Se ricordi, un programma di hexdump prende un file di qualsiasi tipo (testo, eseguibile, dati binari, qualunque cosa) e lo visualizza sullo schermo (qui, sulla console Linux) in modo che ogni byte del programma sia mostrato in esadecimale. L'elenco 9.1 faceva questa operazione. Ciò che hexdump2gcc aggiunge è una seconda colonna di visualizzazione in cui vengono mostrati i caratteri ASCII stampabili (lettere, numeri, simboli) nella loro forma “vera”, con i caratteri non stampabili rappresentati da un carattere di riempimento. Questo carattere di riempimento è tipicamente un carattere punto ASCII, ma è solo una convenzione e può essere qualsiasi cosa. Se salvi il file eseguibile su disco da SASM, puoi visualizzare un hexdump di qualsiasi file Linux utilizzando hexdump2gcc, invocandolo in questo modo.
</p>

```
$./hexdump2gcc < filename
```

<p align=justify>
L'operatore di reindirizzamento I/O < prende i dati esistenti nel file che nomini a destra e passa quei dati all'input standard. Il programma hexdump2gcc prende dati dall'input standard e li stampa in formato dump esadecimale, 16 byte per riga, per quante più righe serve a mostrare l'intero file. 
Data la complessità di hexdump2gcc, potrebbe essere utile mostrarti come funziona il programma attraverso il pseudocodice prima di addentrarci troppo nelle meccaniche di come funziona internamente un meccanismo di procedura. Ecco come funziona il programma, da un'altezza (alta):
</p>
	
```
 As long as there is data available from stdin, do the
 following:
 	Read data from stdin
 	Convert data bytes to a suitable hexadecimal/ASCII display form
    	Insert formatted data bytes into a 16-byte hex dump line
    	Every 16 bytes, display the hex dump line
```

<p align=justify>
Questo è un buon esempio di una prima iterazione di pseudocodice, quando sai approssimativamente cosa vuoi che il programma faccia ma sei ancora un po' confuso su come farlo esattamente. Dovrebbe darti un vantaggio nella comprensione dello pseudocodice molto più dettagliato (e orientato al 'come') mostrato qui:
</p>

```
Zero out the byte count total (RSI) and offset counter (RCX)
Call LoadBuff to fill a buffer with first batch of data from stdin
    Test number of bytes fetched into the buffer from stdin
        If the number of bytes was 0, the file was empty;
jump to Exit
Scan:
    Get a byte from the buffer and put it in AL
    Derive the byte's position in the hex dump line string
    Call DumpChar to poke the byte into the line string
    Increment the total counter and the buffer offset counter
    Test and see if we've processed the last byte in the
buffer:
        If so, call LoadBuff to fill the buffer with data from stdin
        Test number of bytes fetched into the buffer from stdin
            If the number of bytes was 0, we hit EOF; jump to Exit
    Test and see if we've poked 16 bytes into the hex dump line
        If so, call PrintLine to display the hex dump line
 Loop back to Scan
 Exit:
    Shut down the program gracefully per Linux requirements
```

<p align=justify>
ci sono riferimenti espliciti a procedure qui. Penso che possano essere quasi autoesplicativi dal contesto, il che è il segno di una buona procedura. Per esempio, CALL LoadBuff significa "eseguire una procedura che carica il buffer." Questo è ciò che fa LoadBuff, e questo è tutto ciò che fa LoadBuff. Non devi affrontare tutti i dettagli di come LoadBuff svolge il suo lavoro. Questo rende più facile afferrare il flusso logico più ampio espresso dal programma nel suo insieme. Dai un'occhiata al codice di sotto e cerca di capire come il precedente pseudocodice si relaziona alle istruzioni della macchina effettive. Una volta che hai una comprensione di questo, possiamo iniziare a parlare delle procedure in modo più approfondito.
</p>

### Chiamare e Ritornare

<p align=justify>
Proprio all'inizio del blocco principale del programma in hexdump2gcc c'è un'istruzione macchina che non ho mai usato prima in questo libro.
</p>

```asm
 call LoadBuff
```

<p align=justify>
L'etichetta LoadBuff si riferisce a una procedura. Come potresti aver capito (soprattutto se hai programmato in un linguaggio più antico come BASIC o FORTRAN), CALL LoadBuff semplicemente dice alla CPU di andare a eseguire una procedura chiamata LoadBuff e poi tornare quando LoadBuff ha finito di essere eseguita. LoadBuff è definito precedentemente nel codice, ma per chiarezza nella seguente discussione lo riprodurrò qui. LoadBuff è un buon primo esempio di una procedura, perché è abbastanza lineare in termini di logica, e utilizza istruzioni e concetti di cui abbiamo già discusso. Come i programmi in linguaggio assembly in generale, una procedura come LoadBuff inizia a essere eseguita dall'inizio, esegue in modo sequenziale le istruzioni nel suo corpo, e a un certo punto termina. La fine non deve necessariamente essere proprio in fondo alla sequenza di istruzioni, ma la “fine” di una procedura è sempre il punto dove la procedura torna nella parte del programma che l'ha chiamata. Questo punto è ovunque tu veda l'alter ego di CALL, RET (per RETorno).
</p>

```asm
LoadBuff:
    push rax       ; Save caller's RAX
    push rdx       ; Save caller's RDX
    push rsi       ; Save caller's RSI
    push rdi       ; Save caller's RDI
    mov rax,0      ; Specify sys_read call
    mov rdi,0      ; Specify File Descriptor 0: Standard
 Input
    mov rsi,Buff   ; Pass offset of the buffer to read to
    mov rdx,BUFFLEN   ; Pass number of bytes to read at one pass
    syscall        ; Call syscall's sys_read function fill the buffer
    mov r15,rax    ; Save # of bytes read from file for later
    xor rcx,rcx     ; Clear buffer pointer RCX to 0
    pop rdi        ; Restore caller's RDI
    pop rsi         ; Restore caller's RSI
    pop rdx         ; Restore caller's RDX
    pop rax         ; Restore caller's RAX
    ret             ; And return to caller
```

<p align=justify>
In un esempio molto semplice come LoadBuff, il RET si trova alla fine della sequenza di istruzioni nella procedura. Tuttavia, il RET può trovarsi ovunque nella procedura, e ci sono situazioni in cui può essere più semplice avere più di un'istruzione RET in una procedura. Quale delle diverse istruzioni RET riporta effettivamente l'esecuzione al chiamante dipende da ciò che fa la procedura e dalle circostanze che incontra, ma questo è irrilevante. Ogni RET è un "punto di uscita" che riporta al codice che ha chiamato la procedura e (cosa più importante) tutte le istruzioni RET all'interno di una procedura riportano l'esecuzione allo stesso identico punto: l'istruzione immediatamente dopo l'istruzione CALL che ha invocato la procedura.
</p>

<p align=justify>
I punti importanti della struttura della procedura sono i seguenti:
</p>

<ul>
	<li>
		<p align=justify>
			Una procedura deve iniziare con un'etichetta, che è (come dovresti ricordare) un identificatore seguito da due punti.
		</p>
	</li>
 	<li>
		<p align=justify>
			Da qualche parte all'interno della procedura, deve esserci almeno un'istruzione RET.
		</p>
	</li>
 	<li>
		<p align=justify>
			Potrebbero esserci più di un'istruzione RET. L'esecuzione deve tornare da una procedura attraverso un'istruzione RET, ma ci possono essere più di una porta d'uscita da una procedura. Quale uscita viene presa dipende dal flusso di esecuzione della procedura, ma con istruzioni di salto condizionale si possono avere uscite ovunque soddisfino i requisiti della logica della procedura. Tutte quelle uscite portano allo stesso posto: l'istruzione dopo l'istruzione CALL che ha chiamato la procedura.
		</p>
	</li>
 	<li>
		<p align=justify>
			Una procedura può utilizzare CALL per chiamare un'altra procedura. (Di più su questo a breve.)
		</p>
	</li>
</ul>

<p align=justify>
I mezzi tramite i quali operano CALL e RET possono sembrare familiari: CALL prima inserisce l'indirizzo della prossima istruzione dopo di essa nello stack. Poi CALL trasferisce l'esecuzione all'indirizzo rappresentato dall'etichetta che nomina la procedura, in questo caso LoadBuff. Le istruzioni contenute nella procedura vengono eseguite. Infine, la procedura viene terminata dall'istruzione RET. L'istruzione RET estrae l'indirizzo di ritorno dalla cima dello stack e trasferisce l'esecuzione a quell'indirizzo. Poiché l'indirizzo inserito era l'indirizzo della prima istruzione dopo l'istruzione CALL, l'esecuzione continua come se CALL non avesse affatto cambiato il flusso dell'esecuzione delle istruzioni. Vedi figura di sotto
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/calling_procedure_and_returning.png">
</div>

### Chiamate all'interno di chiamate

<p align=justify>
All'interno di una procedura puoi fare qualsiasi cosa che puoi fare all'interno del programma principale stesso. Questo include chiamare altre procedure da una procedura e fare chiamate SYSCALL ai servizi del kernel Linux. C'è un semplice esempio in hexdump2gcc: la procedura ClearLine chiama la procedura DumpChar per "cancellare" la variabile della linea di dump esadecimale.
</p>

```asm
DumpLine:
 ClearLine:
    push rax       ; Save all caller's r*x GP registers
    push rbx
    push rcx
    push rdx
    mov rdx,15     ; We're going to go 16 pokes, counting from 0
 .poke:
    mov rax,0      ; Tell DumpChar to poke a '0'
    call DumpChar  ; Insert the '0' into the hex dump string
    sub rdx,1      ; DEC doesn't affect CF!
    jae .poke      ; Loop back if RDX>= 0
    pop rdx        ; Restore all caller's r*x registers
    pop rcx
    pop rbx
    pop rax
    ret            ; Go home
```

<p align=justify>
Fondamentalmente, ciò che fa ClearLine è fare un uso speciale della procedura DumpChar, che spiegherò in dettaglio a breve. Quando è piena di dati e visualizzata sulla console, la variabile DumpLine appare così.
</p>

```
 75 6D 70 32 2E 61 73 6D 0A 09 6E 61 73 6D 20 2D |ump2.asm..nasm -|
```

<p align=justify>
Ogni valore esadecimale a due caratteri e ogni carattere ASCII nella colonna ASCII a destra, è stato inserito tramite una singola chiamata a DumpChar. Sono necessarie 16 chiamate a DumpChar per "riempire" la variabile DumpLine. A quel punto può essere visualizzata. Dopo che DumpLine è stata visualizzata nella console, hexdump2gcc continua il suo ciclo e inizia a riempire di nuovo DumpLine. Ogni 16 chiamate a DumpChar, hexdump2gcc mostra DumpLine sulla console... eccetto per l'ultima volta. Un file che viene scaricato sulla console potrebbe non essere (e di solito non è) un preciso multiplo di 16 byte. Quindi la visualizzazione finale di DumpLine potrebbe riguardare una riga parziale di due, tre, nove, undici o quanti più caratteri meno di sedici, che chiamo "avanzi". Quando viene visualizzata una riga parziale, gli ultimi byte nella riga scaricata potrebbero essere dati "vecchi" inviati alla console nella visualizzazione precedente di DumpLine. Per evitare ciò, DumpLine viene azzerato immediatamente dopo ogni volta che viene visualizzato nel terminale. Questo è ciò che fa ClearLine. Dopo una chiamata a ClearLine, DumpLine appare in questo modo:
</p>

```
 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................|
```

<p align=justify>
ClearLine fa la cosa semplice e ovvia: chiama DumpChar 16 volte, passando ogni volta a DumpChar il valore 0 in RAX. DumpChar 'inietta' un equivalente ASCII sia del valore esadecimale 00 che di un punto ASCII per rappresentare il valore 0 in tutte le posizioni nella colonna ASCII. 00 non è un carattere ASCII visualizzabile e, come tutti i caratteri non visualizzabili, è rappresentato da un punto nell'output del hexdump.
</p>

### Il pericolo della ricorsione accidentale

<p align=justify>
Chiamare procedure dall'interno di procedure richiede di prestare almeno un po' di attenzione a una cosa: lo spazio dello stack. Ricorda che ogni chiamata a procedura spinge un indirizzo di ritorno a 64 bit nello stack. Questo indirizzo di ritorno non viene rimosso dallo stack fino a quando non viene eseguita l'istruzione RET per quella procedura. Se esegui un'altra istruzione CALL prima di tornare da una procedura, la seconda istruzione CALL spinge un altro indirizzo di ritorno nello stack. Se continui a chiamare procedure dall'interno di procedure, un indirizzo di ritorno si accumulerà nello stack per ogni CALL fino a quando non inizierai a tornare da tutte quelle procedure annidate. Questo era un vero problema sotto DOS, quando la memoria era scarsa e i programmi potevano allocare solo poche centinaia di byte di memoria allo stack, a volte anche meno. Ogni indirizzo spinto nello stack fa crescere lo stack in direzione delle sezioni .data e .text del programma. Chiamare in modo "profondo" potrebbe far collidere lo stack con i dati o il codice, causando un crash del programma che spesso portava giù anche DOS. Sotto x64 Linux hai a disposizione molta più memoria, più un gestore della memoria virtuale nel sistema operativo, e dovresti annidare procedure letteralmente milioni di volte per avere problemi, e questo sarebbe davvero un programma ambizioso. Tuttavia... puoi comunque incorrere in un problema simile abusando di una tecnica di programmazione avanzata chiamata ricorsione. Nella ricorsione, una procedura chiama se stessa per completare il proprio lavoro. Questo spesso sembra peculiare ai principianti, ma è un modo rispettato e legittimo di esprimere un certo tipo di logica di programma. Il trucco con la ricorsione, naturalmente, è sapere quando fermarsi. Per ogni CALL a se stessa, una procedura ricorsiva deve alla fine eseguire un RET. Anche se la procedura ricorsiva chiama se stessa dozzine o centinaia di volte, fintanto che le istruzioni CALL bilanciano le istruzioni RET, non succederà nulla di male.
I problemi iniziano quando scrivi una procedura ricorsiva in modo errato e la logica che determina quando utilizzare quella fondamentale istruzione RET è codificata in modo errato. Quando ritornare è generalmente regolato da un'istruzione di salto condizionale. Se sbagli il senso o l'etichetta del flag di quell'istruzione, la procedura non ritorna mai, ma continua a chiamarsi ripetutamente. Su un PC moderno, una procedura in linguaggio assembly può chiamarsi un milione di volte in un secondo o meno. A un certo punto, lo stack raggiunge il limite estremo della sua crescita (impostato dal sistema operativo) dove esaurisce lo spazio di memoria. Quando ciò accade, Linux ti restituisce un errore di segmentazione. Come ho detto, la ricorsione è un argomento avanzato e non spiegherò come usarla correttamente in questo libro. Lo menziono qui solo perché è possibile utilizzare la ricorsione accidentalmente. Seguendo il nostro esempio attuale, supponi di stare programmando ClearLine a tarda notte, e nel punto in cui ClearLine chiama DumpChar, scrivi in modo confuso CALL ClearLine dove intendevi scrivere CALL DumpChar. Non scuotere la testa; programmo dal 1970 e l'ho fatto più di una volta. Prima o poi lo farai anche tu. ClearLine non è stato progettato per essere ricorsivo, quindi andrà in un ciclo non proprio infinito, chiamandosi fino a esaurire la memoria dello stack e generare un errore di segmentazione. Aggiungi "ricorsione accidentale" alla lista dei bug che cerchi quando Linux ti restituisce un errore di segmentazione. Appartiene alla categoria di bug che chiamo "rari ma inevitabili."
</p>

### Un errore di etichetta sul flag di cui fare attenzione

<p align=justify>
E mentre parliamo di bug, la procedura ClearLine è piuttosto semplice e svolge un lavoro semplice. Fornisce anche un utile momento di insegnamento su un bug relativo ai flag che mette in difficoltà regolarmente i principianti. Dai un'occhiata al seguente modo alternativo di codificare ClearLine:
</p>

```asm
ClearLine:
    push rax       ; Save all caller's r*x GP registers
    push rbx
    push rcx
    push rdx
    
    mov  rdx,15    ; We're going to go 16 pokes, counting
 from 0
 
.poke:
    mov rax,0      ; Tell DumpChar to poke a '0'
    call DumpChar  ; Insert the '0' into the hex dump string
    sub rdx,1      ; DEC doesn't affect CF!
    jae .poke       ; Loop back if RDX>= 0
    
    pop rdx        ; Restore caller's r*x GP registers
    pop rcx
    pop rbx
    pop rax
    ret            ; Go home
```

<p align=justify>
Funzionerebbe? Se lo pensi, ripensaci. Sì, stiamo contando da 15 a 0, facendo 16 passaggi attraverso un semplice ciclo. Sì, l'istruzione DEC è usata molto nei cicli, quando contiamo fino a zero. Ma questo ciclo è un po' diverso, poiché dobbiamo fare del lavoro quando il valore del contatore in RDX è 0 e poi decrimentare un'altra volta. Il salto condizionale mostrato è JAE, Jump Above or Equal. Deve saltare di nuovo a Poke quando il valore in EDX scende sotto zero. DEC conterà un contatore fino a zero e poi sotto zero senza problemi... quindi perché JAE non salta dopo DEC? Il senso è giusto. Tuttavia, l'etichetta dei flag è sbagliata. Se controlli il riferimento all'istruzione nell'Appendice B per JAE, vedrai che salta quando CF=0. La CPU non capisce il “senso” in JAE. Non è una mente; è solo una piccola pila di sabbia molto pulita. Tutto ciò che capisce è che l'istruzione JAE salta quando CF=0. Ora, se guardi l'istruzione DEC nell'Appendice B e scrutinizzi l'elenco dei flag, vedrai che DEC non influenza affatto CF, e CF è ciò che JAE esamina prima di decidere se saltare o meno. Questo è il motivo per cui usiamo l'istruzione SUB per decrimentare il registro del contatore in questo caso, perché SUB influisce su CF e consente all'istruzione JAE di funzionare correttamente. Non ci sono problemi di velocità; SUB è altrettanto veloce quanto DEC. La lezione qui è che devi capire i modi in cui le istruzioni di salto condizionale interpretano i vari flag. Il senso di un salto può essere ingannevole. È l'etichetta dei flag che conta.
</p>

### Le Procedure ed i dati di cui hanno bisogno

<p align=justify>
I programmi svolgono il loro lavoro agendo sui dati: dati nei buffer, dati in variabili denominate e dati nei registri. Le procedure sono spesso create per eseguire un singolo tipo di manipolazione su un particolare tipo di dati. I programmi che chiamano tali procedure le trattano come tritacarne di dati: un certo tipo di dati entra, e un dato trasformato di un altro tipo esce. Inoltre, i dati vengono spesso forniti a una procedura per controllare o dirigere il lavoro che essa svolge. Una procedura potrebbe aver bisogno di un valore conteggio per sapere quante volte eseguire un'operazione, ad esempio, o potrebbe aver bisogno di una maschera di bit da applicare a dei valori di dati per qualche motivo, e quella maschera di bit potrebbe non essere precisamente la stessa ogni volta. Quando scrivi procedure, devi decidere quali dati la procedura necessiti per svolgere il suo lavoro e come quei dati saranno resi disponibili alla procedura. Ci sono due classi generali di dati nel lavoro in assembly (e nella maggior parte della programmazione in lingue non esotiche) in base al metodo di accesso: globale e locale. I dati globali sono molto comuni nel lavoro in puro assembly, specialmente per programmi di dimensioni contenute come quelli che presento in questo libro. I dati globali sono accessibili da qualsiasi codice in qualsiasi punto del programma. Un elemento di dati globale è definito nelle sezioni .data o .bss del programma. I registri della CPU sono anche contenitori per dati globali, poiché i registri fanno parte della CPU e possono essere accessibili da qualsiasi punto di un programma.
La nozione di dati globali diventa più complessa quando si separa un programma in un programma principale e in più gruppi di procedure chiamate librerie, come spiegherò tra poco in questo capitolo. Ma per programmi semplici, il modo più ovvio per passare dati a una procedura è spesso il migliore: mettere i dati in uno o più registri e poi chiamare la procedura. Abbiamo già visto questo meccanismo in azione, nel fare chiamate ai servizi del kernel Linux tramite l'istruzione SYSCALL. Per l'input della console, si mette il numero del servizio in RAX, il descrittore del file in RDI, l'indirizzo di una stringa in RSI e la lunghezza della stringa in RDX. Poi si effettua la chiamata con SYSCALL. Non è diverso per le procedure ordinarie. Si scrive una procedura presupponendo che, quando la procedura inizia a essere eseguita, i valori di cui ha bisogno siano in registri particolari. Devi assicurarti che il codice che chiama la procedura metta i valori giusti nei registri giusti prima di chiamare la procedura, ma in realtà non è più complesso di così. Tabelle, buffer e altri elementi dati nominati vengono accessi dalle procedure proprio come da qualsiasi altra parte del programma, tramite espressioni di indirizzamento della memoria "tra le parentesi."
</p>

### Salvare i registri del chiamante

<p align=justify>
Una volta che inizi a scrivere programmi significativi in assembly, ti renderai conto che non puoi mai avere abbastanza registri, e (a differenza dei linguaggi di alto livello come C e Pascal) non puoi semplicemente crearne di più quando ne hai bisogno. I registri devono essere usati con attenzione, e scoprirai che all'interno di qualsiasi programma di complessità significativa, tutti i registri sono generalmente in uso tutto il tempo. Entrare in una procedura dall'interno del tuo programma principale (o da un'altra procedura) comporta un problema specifico e sottile. Puoi chiamare una procedura da qualsiasi punto — il che significa che non saprai sempre quali registri sono già in uso quando viene chiamata la procedura. O lo saprai? Esiste una convenzione riguardo quali registri devono essere preservati all'interno di una procedura e quali non lo devono essere. Questa convenzione fa parte dell'interfaccia binaria di applicazione System V ABI x86-x64. Alcuni registri sono considerati 'volatili', il che significa che possono essere modificati da una procedura, mentre altri sono 'non volatili', il che significa che devono essere preservati. Attendi; sta arrivando. Se una procedura esamina solo un valore di registro (ma non lo modifica), non è necessario preservare il registro. Ad esempio, una procedura può assumere che un certo registro contenga un valore di contatore di cui ha bisogno per indicizzare una tabella, e può utilizzare liberamente quel registro finché non vengono apportate modifiche al suo valore. Tuttavia, ogni volta che un registro viene modificato da una procedura (a meno che il chiamante non si aspetti esplicitamente un valore di ritorno in un registro), deve essere salvato e ripristinato prima che la procedura esegua RET per tornare al chiamante. 
</p>	

<p align=justify>
Il salvataggio dei valori dei registri avviene con PUSH:
</p>

```asm
 push rbx
 push rsi
 push rdi
```

<p align=justify>
Ogni istruzione PUSH inserisce un valore di registro a 64 bit nello stack. Quei valori rimarranno al sicuro nello stack fino a quando non verranno estratti nuovamente negli stessi registri poco prima di tornare al chiamante:
</p>

```asm
 pop rdi
 pop rsi
 pop rbx
 ret
```

<p align=justify>
C'è un dettaglio assolutamente cruciale qui, uno che causa una moltitudine di bug nei programmi molto peculiari: i valori del chiamante devono essere estratti dallo stack nell'ordine inverso rispetto a come sono stati inseriti. In altre parole, se inserisci RBX, seguito da RSI, seguito da RDI, devi estrarli dallo stack in questo ordine: RDI, seguito da RSI, seguito da RBX. La CPU estrarrà obbedientemente i valori memorizzati nello stack in qualsiasi registro nell'ordine che scrivi. Ma se sbagli l'ordine, in sostanza stai cambiando i registri del chiamante invece di salvarli. Ciò che era in RBX potrebbe ora trovarsi in RDI, e la logica del programma del chiamante potrebbe semplicemente andare in crisi. Ho mostrato come questo accade quando inizialmente spiegai lo stack, ma potrebbe non essere stato chiaro all'epoca. Dai un veloce sguardo alla figura dello stack e vedi cosa succede nella colonna più a destra. Il valore di CX era stato inserito nello stack, ma l'istruzione successiva era POP DX. Ciò che era in CX ora si trovava in DX. Se è quello che vuoi, va bene—e a volte potrebbe essere il modo migliore per risolvere un problema particolare. Ma se stai spingendo i valori dei registri per preservarli, l'ordine degli inserimenti e delle estrazioni è assolutamente critico. Il modo migliore per affrontare la preservazione dei registri è di inserire/estrarre qualsiasi registro modificato dalla procedura all'interno della procedura stessa. Questo esclude i registri che passano valori alla procedura: erano stati cambiati deliberatamente dal chiamante subito prima della chiamata della procedura. Considera che una procedura è definita una volta ma chiamata molte volte da molti altri posti nel tuo codice. Se cerchi di salvare registri e la procedura cambia prima di chiamare la procedura, avrai molti più inserimenti ed estrazioni rispetto a se preservi i registri che una procedura utilizza all'interno della procedura. Inoltre, se una procedura restituisce un valore al chiamante in un registro, il chiamante presume che il valore del registro cambierà e utilizzerà il nuovo valore in quel registro. Oh, c'è un altro problema: le tue procedure non sono le uniche che utilizzano—e cambiano—i registri. Anche Linux ha una parte in questo.
</p>

### Preservare i registri attraverso le chiamate di sistema Linux

<p align=justify>
Anche Linux utilizza registri. Lo fa in modo piuttosto trasparente per il tuo codice. L'unico problema serio è sapere quali registri vengono modificati durante le chiamate di sistema tramite l'istruzione SYSCALL e quali registri rimangono intatti. Purtroppo, non c'è una risposta semplice. Dipende completamente dalla chiamata di sistema che effettui. Ma prima di tutto, l'istruzione SYSCALL stessa utilizza due registri:
</p>

<ul>
	<li>
		<p align=justify>
			SYSCALL memorizza l'indirizzo di ritorno nel registro RCX
		</p>
	</li>
 	<li>
		<p align=justify>
			SYSCALL memorizza RFlags nel registro R11
		</p>
	</li>
</ul>

<p align=justify>
Questo è l'equivalente funzionale di SYSCALL che inserisce RCX e R11 nello stack. Tuttavia, salvare valori nei registri è molto più veloce che inserire valori nello stack. Rimuovere valori dallo stack è anche lento, quindi SYSCALL non ripristina nulla. Ogni volta che esegui SYSCALL, RCX e R11 saranno sovrascritti. E non è tutto il sovrascrivere coinvolto nell'effettuare una chiamata di sistema. L'uso dei registri durante una chiamata di sistema rientra in tre categorie:
</p>

<ul>
	<li>
		<p align=justify>
		Devi passare i parametri al codice della chiamata di sistema nei registri.
		</p>
	</li>
 	<li>
		<p align=justify>
		Il codice della chiamata di sistema utilizza alcuni registri aggiuntivi.
		</p>
	</li>
	 <li>
		<p align=justify>
		La chiamata di sistema può restituire valori nei registri di cui il tuo codice potrebbe aver bisogno.
		</p>
	</li>
</ul>

<p align=justify>
La definizione delle chiamate di sistema SYSCALL include le specifiche. Questa definizione fa parte dell'ABI System V x86-64. Se il corpo più ampio del tuo codice utilizza un registro che viene sovrascritto durante una chiamata di sistema, devi scegliere un altro registro da utilizzare nel corpo del programma o salvarlo nello stack con un'istruzione PUSH prima di impostare i parametri ed eseguire SYSCALL. Dopo la chiamata di sistema, devi ripristinarlo tramite un'istruzione POP. Usare lo stack in questo modo può causare problemi con l'allineamento dello stack a meno che tu non comprenda cosa rende lo stack allineato e come mantenerlo tale. C'è anche la questione dei registri volatili rispetto a quelli non volatili. Il processo di effettuare una chiamata di sistema tramite SYSCALL non è complesso. Tuttavia, l'ultima volta che ho controllato, ce n'erano 335. Ogni chiamata di sistema richiede che certe cose vengano passate in registri specifici. È molto da ricordare. Per lo più dovrai cercare i dettagli su come effettuare chiamate di sistema in un riferimento stampato o online. Dei riferimenti sono elencati sotto.
</p>

[x86-64-linux-syscalls](https://hackeradam.com/x86-64-linux-syscalls/)

[Linux_System_Call_Table_for_x86_64](https://blog.rchapman.org/posts/Linux_System_Call_Table_for_x86_64/)

<p align=justify>
Entrambi sono tavoli molto grandi che assomigliano a fogli di calcolo, con colonne per l'uso dei registri e i valori richiesti per ogni numero di chiamata di sistema. Ora, le pagine web vanno e vengono e se stai utilizzando questo libro alcuni anni dopo la sua pubblicazione nel 2023, le pagine web citate potrebbero semplicemente non esistere più. Fai una ricerca su web su "tabella delle chiamate di sistema x64" e troverai diverse. Assicurati che la tabella che usi sia per le chiamate di sistema e non per le chiamate negli spazi utente. Le chiamate negli spazi utente sono chiamate alla libreria di codice glibc utilizzata nella programmazione C, che è una questione completamente diversa. Chiamare glibc dall'assembly è possibile e spesso molto utile. Un'avvertenza seria se hai già fatto del lavoro in assembly Linux in modalità protetta a 32 bit: i parametri delle chiamate di sistema x64 non sono gli stessi di quelli in x86 a 32 bit. Nella maggior parte dei casi, non sono nemmeno vicini. In Linux x64, c'è un sistema per l'uso dei registri: il numero della chiamata di sistema (in altre parole, quale chiamata di sistema stai chiamando) è sempre in RAX. Una chiamata di sistema accetta fino a sei parametri. I registri usati per passare i parametri sono in questo ordine: RDI, RSI, RDX, R10, R8 e R9. In altre parole, il primo parametro è passato in RDI. Il secondo parametro è passato in RSI, e così via. Nessuna chiamata di sistema richiede che i parametri siano passati a essa tramite lo stack. Nota: Sia che un registro (come R9, per esempio) sia usato per passare un parametro a una chiamata di sistema, quel registro non viene preservato. Solo sette registri sono preservati da Linux durante una chiamata di sistema: R12, R13, R14, R15, RBX, RSP e RBP. Dopo una SYSCALL, RAX conterrà un valore restituito. Se RAX è negativo, indica che si è verificato un errore durante la chiamata. Per la maggior parte delle chiamate di sistema, un valore di 0 indica successo.
</p>

### PUSHAD e POPAD sono spariti

<p align=justify>
Ci sono casi in cui una procedura utilizza la maggior parte o tutti i registri a uso generale. Prima di x64, c'era una coppia di istruzioni che potevano pushare e poppare tutti i registri GP da 32 bit in una sola volta. Questi sono PUSHAD e POPAD. (Un'altra coppia di istruzioni, PUSHA e POPA, avrebbero pushato e poppato tutti i registri GP da 16 bit. Anche loro non ci sono più.) Ora che x64 ha 15 registri GP, con ogni registro che richiede otto byte nello stack, non è uno spreco di spazio nello stack? Non necessariamente. Sì, ci vuole tempo per pushare un registro nello stack, ma ricorda: in ogni caso in cui ponderi se un'istruzione richiede più tempo per essere eseguita rispetto a un'altra, devi considerare quante volte quella istruzione viene eseguita. Se un'istruzione si trova all'interno di un ciclo ristretto che viene eseguito in sequenza decine di migliaia o milioni di volte, la velocità dell'istruzione è importante. D'altra parte, se un'istruzione viene eseguita solo poche volte durante l'esecuzione di un programma, la sua velocità è al meglio una considerazione minore e di solito può essere ignorata. Sì, PUSHAD e POPAD erano scorciatoie comode. Non ci sono più. Ora devi pensare con attenzione a quali registri modifica una procedura e quindi pushare quei registri individualmente nello stack e popparli uno per uno quando la procedura restituisce. Per un buon esempio, vediamo la procedura LoadBuff mostrata in precedenza in questo capitolo in hexdump2gcc. LoadBuff preserva quattro dei registri del chiamante: RAX, RDX, RSI e RDI. Tuttavia, apporta modifiche a due altri registri, RCX e R15, senza preservarli.
</p>

<p align=justify>
Perché? Il registro RCX contiene un valore "globale": la posizione del prossimo carattere da elaborare nella variabile del buffer file Buff. LoadBuff viene chiamato quando un buffer pieno di dati è stato completamente elaborato e un nuovo caricamento di dati deve essere portato da stdin. Quando il buffer viene riempito nuovamente, il contatore del buffer deve essere resettato a 0 in modo che l'elaborazione possa ricominciare e lavorare attraverso i nuovi dati dall'inizio. LoadBuff fa questo, e l'RCX pulito viene restituito a chi lo ha chiamato. Anche R15 ha una missione: riporta il numero di byte caricati in Buff dalla chiamata SYSCALL a sys_read. La chiamata a sys_read richiede il numero di byte specificato dall'equazione BUFFLEN vicino all'inizio del programma. Tuttavia, poiché pochi file saranno esattamente multipli di BUFFLEN, il numero di byte nell'ultima serie di dati portati da stdin sarà inferiore a BUFFLEN. Questo valore è considerato anch'esso globale e viene utilizzato dal programma principale per determinare quando il buffer corrente è stato completamente elaborato. LoadBuff preserva i registri nello stack e li ripristina prima di tornare al codice che lo ha chiamato. Ora, non c'è motivo per cui il push e il pop per preservare i registri debbano sempre essere fatti all'interno della procedura. Il codice chiamante può preservare i propri registri, e questo viene occasionalmente fatto. Ad esempio, considera questa sequenza di istruzioni (fittizia):
</p>

```asm
 push rbx
 push rdx
 call CalcSpace
 pop  rdx
 pop  rbx
```

<p align=justify>
C'è solo una differenza tra la conservazione dei registri all'esterno della procedura piuttosto che all'interno: il codice che chiama la procedura può scegliere quali dei suoi registri sono in uso e quindi necessitano di preservazione. Salvare tutti i registri sarebbe uno spreco se non tutti i registri sono in uso dal codice del chiamante. Ora, potrebbero esserci più di una chiamata a CalcSpace all'interno del programma. Ciascuna di queste chiamate richiede questa sequenza di cinque istruzioni invece di una sola. Se la preservazione dei registri avviene all'interno della procedura, la preservazione richiede solo quattro istruzioni, a prescindere da quante volte il codice chiama la procedura. Con i moderni PC x64, la differenza in termini di dimensioni del codice e velocità non sarà significativa. Il vantaggio di inserire la preservazione dei registri all'interno della procedura è che il codice principale del programma sarà meno ingombro. Non ci sono regole rigide su quali registri preservare, anche se ci sono forti raccomandazioni nell'ABI System V x86-64. Alcuni registri sono volatili e non è necessario preservarli. Alcuni sono non volatili e dovrebbero essere preservati. Ancora una volta, tornerò su questo nei prossimi due capitoli, che trattano anche questioni importanti come l'allineamento dello stack. Devi sapere come i registri vengono utilizzati in un dato momento nel programma e programmare di conseguenza. (Prendere buone note sull'uso dei registri mentre progetti il programma è importante.) L'unico consiglio che offrirei è conservativo e tende a evitare bug: preserva qualsiasi registri che sai non essere usati globalmente né essere usati per restituire valori al chiamante. Il tempo impiegato per la preservazione dei registri è minimo rispetto all'aggravio di bug causati da conflitti di registri.
</p>

### Dati Locali

<p align=justify>
I dati locali, in contrapposizione ai dati globali, sono dati accessibili (diciamo "visibili") solo a una particolare procedura o, in alcuni casi, a una libreria. (Di nuovo, posticipiamo per il momento la discussione sulle librerie.) Quando le procedure hanno dati locali, sono quasi sempre dati che vengono posizionati nello stack quando viene chiamata una procedura. Le istruzioni PUSH posizionano i dati nello stack. Quando una parte del tuo codice chiama una procedura con l'istruzione CALL, può passare dati a quella procedura usando PUSH una o più volte prima dell'istruzione CALL. La procedura può quindi accedere a questi elementi di dati PUSHati nello stack. Tuttavia, un avvertimento: la procedura non può semplicemente estrarre quegli elementi di dati dallo stack nei registri, perché l'indirizzo di ritorno è in mezzo. Ricorda che la prima cosa che fa CALL è spingere l'indirizzo della prossima istruzione della macchina nello stack. Quando la tua procedura ottiene il controllo, quell'indirizzo di ritorno è in cima allo stack (TOS, come diciamo) pronto per l'inevitabile istruzione RET da utilizzare per tornare a casa. Qualsiasi cosa spinta nello stack dal chiamante prima dell'istruzione CALL si trova sopra l'indirizzo di ritorno. Questi elementi possono comunque essere accessibili usando il normale indirizzamento della memoria e il puntatore dello stack RSP. Non puoi, tuttavia, usare POP per accedervi senza estrarre e riprendere l'indirizzo di ritorno. Questo funziona, e l'ho fatto un paio di volte, ma è lento e anche superfluo, una volta che comprendi la natura di un "frame dello stack" e come indirizzare la memoria all'interno di uno. Di nuovo, affronterò la nozione di frame dello stack più avanti in questo libro, poiché è assolutamente cruciale una volta che inizi a chiamare procedure di libreria scritte in C o in altri linguaggi di alto livello. Per ora, semplicemente comprendi che i dati globali sono quasi sempre definiti nelle sezioni .data e .bss del tuo programma, mentre i dati locali vengono posizionati nello stack per l'uso "locale" di una particolare chiamata a una particolare procedura. I dati locali richiedono un po' di attenzione e disciplina per essere utilizzati in modo sicuro, per motivi che spiegherò in seguito.
</p>

### Inserire Dati Costanti nelle Definizioni delle Procedure

<p align=justify>
Ormai sei abituato a pensare al codice come qualcosa che vive nella sezione .text e ai dati come qualcosa che vive nelle sezioni .data o .bss. In quasi tutti i casi, questo è un buon modo per organizzare le cose, ma non c'è una richiesta assoluta di separare codice e dati in questo modo. È possibile definire dati all'interno di una procedura utilizzando le pseudoinstruzioni di NASM, che includono DB, DW, DD e DQ. Ho creato una procedura utile che mostra come fare e che è un buon esempio di quando farlo. La procedura newlines ti consente di emettere un certo numero di caratteri di nuova riga su stdout, specificati da un valore passato alla subroutine in RDX.
</p>

```asm
 ;--------------------------------------------------------------------
 ; Newlines: Sends between 1-15 newlines to the Linux console
 ; VERSION:  2.0
 ; UPDATED:  8/27/2022
 ; IN: EDX:  # of newlines to send, from 1 to 15
 ; RETURNS:  Nothing
 ; MODIFIES: RAX, RDI
 ; CALLS:    Kernel sys_write
 ; DESCRIPTION: The number of newline chareacters (0Ah) specified
 ; in RDX is sent to stdout using using SYSCALL sys_write.
 ; procedure demonstrates placing constant data in the
 ; procedure definition itself, rather than in the .data or
 ; .bss sections.
 newlines:
  cmp rdx,15       ; Make sure caller didn't ask for more than 15
  ja .exit         ; If so, exit without doing anything
  mov rsi,EOLs     ; Put address of EOLs table into ECX
  mov rax,1        ; Specify sys_write
  mov rdi,1        ; Specify stdout
  syscall          ; Make the kernel call
.exit:
  Ret              ; Go home!  

EOLs db 10,10,10,10,10,10,10,10,10,10,10,10,10,10,10
```

<p align=justify>
La tabella EOLs contiene 15 caratteri EOL. Se ricordi, quando il carattere EOL viene inviato a stdout, la console lo interpreta come un a capo, in cui la posizione del cursore della console viene spostata verso il basso di una riga. Il chiamante passa il numero desiderato di a capo in RDX. La procedura newlines verifica prima di assicurarsi che il chiamante non abbia richiesto più a capo di quanti caratteri EOL ci siano nella tabella e poi passa l'indirizzo della tabella EOLs e il numero richiesto in una chiamata convenzionale a sys_write utilizzando SYSCALL. Fondamentalmente, sys_write visualizza i primi caratteri RDX della tabella EOLs sulla console, che interpreta i dati come RDX a capo. Avere i dati direttamente nella procedura significa che è facile copiare e incollare la definizione della procedura da un programma all'altro senza lasciare indietro la tabella essenziale dei caratteri EOL. Poiché l'unico codice che utilizza mai la tabella EOLs è la procedura newlines stessa, non c'è vantaggio a posizionare la tabella EOLs nella sezione .data più visibile centralmente. E anche se la tabella EOLs non è locale nel senso tecnico della scienza informatica (non è posizionata nello stack da un chiamante a newlines), “sembra” locale e tiene le sezioni .data e .bss più ordinate, evitando di sovraccaricarle con dati che vengono referenziati solo all'interno di una singola procedura. C'è un file sorgente di programma completo chiamato newlinestest.asm pronto per essere assemblato nell'archivio delle liste per questo libro. (Costruiscilo con SASM.) Contiene la procedura newlines, che ti permetterà di sperimentare con essa.
</p>

### Alcuni trucchi per le Tabelle

<p align=justify>
Il programma hexdump2gcc funziona in modo molto simile al programma hexdump1gcc dell'elenco 9.1, ma ha qualche trucco in più nel suo sacco. Uno degno di nota risiede nella definizione della variabile di linea del dump esadecimale DumpLine:
</p>

```asm
 DumpLine:    db " 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 "
 DUMPLEN      EQU $-DumpLine
 ASCLine:     db "|................|",10
 ASCLEN       EQU $-ASCLine
 FULLLEN       EQU $-DumpLine
```

<p align=justify>
Quello che abbiamo qui è una variabile dichiarata in due parti. Ogni parte può essere utilizzata separatamente, o (come di solito si fa) le due parti possono essere utilizzate insieme. La prima sezione di DumpLine è la stringa contenente 16 cifre esadecimali. La sua lunghezza è definita dall'equazione DUMPLEN. (Nota che la mia convenzione personale è di scrivere i nomi delle equazioni in maiuscolo. Le equazioni non sono la stessa specie di animali delle variabili, e trovo che rendere i programmi più leggibili impostando le equazioni in modo che possano essere distinte dalle variabili a colpo d'occhio sia utile. Questo non è un requisito NASM; puoi nominare le equazioni in minuscolo o in maiuscolo misto come preferisci.) La seconda sezione di DumpLine è la colonna ASCII, e ha il proprio etichetta, ASCLine. Un programma che avesse bisogno solo della colonna ASCII potrebbe utilizzare la variabile ASCLine da sola, insieme alla sua lunghezza associata, ASCLEN. Ora, poiché le due sezioni di DumpLine sono adiacenti in memoria, fare riferimento a DumpLine ti consente di fare riferimento a entrambe le sezioni come un'unità, ad esempio, quando desideri inviare una riga a stdout tramite SYSCALL. In questo caso, l'equazione che calcola la lunghezza dell'intera riga è FULLLEN. È utile avere un nome separato per le sezioni di due righe, perché i dati non vengono scritti né letti dalle due sezioni in modi simili. Dai un'occhiata alla procedura DumpChar da hexdump2gcc:
</p>

```asm
DumpChar:
 push rbx     ; Save caller's RBX
 push rdi     ; Save caller's RDI

 ; First we insert the input char into the ASCII portion of the dump line
 mov bl,[DotXlat+rax]       ; Translate nonprintables to '.'
 mov [ASCLine+rdx+1],bl     ; Write to ASCII portion

 ; Next we insert the hex equivalent of the input char in the hex portion
 ; of the hex dump line:
 mov rbx,rax                ; Save a second copy of the input char
 lea rdi,[rdx*2+rdx]        ; Calc offset into line string (RDX X 3)
 
; Look up low nybble character and insert it into the string:
    and rax,000000000000000Fh ; Mask out all but the low nybble
    mov al,[HexDigits+rax]    ; Look up the char equiv. of nybble
    mov [DumpLine+rdi+2],al   ; Write the char equiv. to line string
 
; Look up high nybble character and insert it into the string:
    and rbx,00000000000000F0h ; Mask out all the but 2nd lowest nybble
    shr rbx,4                 ; Shift high 4 bits of byte into low 4 bits
    mov bl,[HexDigits+rbx]    ; Look up char equiv. of nybble
    mov [DumpLine+rdi+1],bl   ; Write the char equiv. to line string
 
; Done! Let's return:
    pop rdi     ; Restore caller's RDI
    pop rbx     ; Restore caller's RBX
    ret         ; Return to caller
```

<p align=justify>
Scrivere nella colonna ASCII è molto semplice, perché ogni carattere nella colonna ASCII è un singolo byte in memoria, e l'indirizzo effettivo di una qualsiasi posizione in ASCLine è facile da calcolare:
</p>

```asm
 mov [ASCLin+rdx+1],bl   ; Write to ASCII portion
```

<p align=justify>
Tuttavia, ogni posizione nella parte del dump esadecimale della linea consiste di tre caratteri: uno spazio seguito da due cifre esadecimali. Considerato come una tabella, indirizzare un'entrata specifica in DumpLine richiede una scala di 3 nel calcolo dell'indirizzo effettivo:
</p>

```asm
lea rdi,[rdx*2+rdx]   ; Calc offset into line string (RDX × 3)
```

<p align=justify>
Nota qui che RDX*2+RDX è equivalente a RDX × 3 come citato nel commento della riga. Le due parti della linea di dump esadecimale sono trattate in modo molto diverso dal punto di vista della manipolazione dei dati, e agiscono insieme solo quando vengono inviate a stdout. È quindi utile dare a ciascuna delle due sezioni la propria etichetta. Le strutture in C e i record in Pascal sono gestiti in modo molto simile "sotto il cofano". La tabella DotXlat di hexdump2gcc è un altro esempio di traduzione dei caratteri e, come per tutte le tabelle di traduzione, esprime le regole necessarie per visualizzare in modo coerente tutti i 256 valori ASCII diversi in una linea di testo.
</p>

<ul>
	<li>
		<p align=justify>
		Tutti i caratteri stampabili si traducono come se stessi
  		</p>
	</li>
 	<li>
		<p align=justify>
		Tutti i caratteri non stampabili (che includono tutti i caratteri di controllo e tutti i caratteri dal 127 in su) vengono tradotti come punti ASCII.
  		</p>
	</li>
</ul>

### Etichette locali e lunghezze dei salti

<p align=justify>
Prima o poi, man mano che i tuoi programmi diventano più lunghi e complessi, finirai per riutilizzare accidentalmente un'etichetta. Non presenterò alcun programma particolarmente lungo o complesso in questo libro, quindi non ci saranno problemi pratici con le etichette del codice che confliggono tra loro. Ma quando inizi a scrivere programmi più seri, alla fine scriverai centinaia o addirittura (con un po' di pratica e perseveranza) migliaia di righe di codice assembly in un singolo file di codice sorgente. Ti accorgerai presto che le etichette di codice duplicate diventeranno un problema. Come ricorderai sempre di aver già utilizzato l'etichetta Scan nella riga 187 di un programma di 2.732 righe? Non lo farai. E prima o poi (soprattutto se stai elaborando spesso buffer e tabelle), proverai a utilizzare nuovamente l'etichetta Scan. NASM te lo segnalerà con un errore. Questo è un problema abbastanza comune (soprattutto con etichette ovviamente utili come Scan) che gli autori di NASM hanno creato una funzione per affrontarlo: etichette locali. Le etichette locali si basano sul fatto che quasi tutte le etichette in assembly funzionano (escludendo i nomi delle subroutine e delle sezioni principali) in modo “locale”, nel senso che vengono solo reference da istruzioni di salto che sono molto vicine ad esse—forse solo due o tre istruzioni più in alto. Tali etichette sono solitamente parti di cicli stretti e non sono referenziate da lontano nel codice e spesso sono referenziate solo da un luogo. Ecco un esempio, dal corpo principale di hexdump2gcc.
</p>

```asm
; Go through the buffer and convert binary byte values to hex digits:
 Scan:
    xor rax,rax                ; Clear RAX to 0
    mov al,[Buff+rcx]          ; Get a byte from the buffer into AL
    mov rdx,rsi                ; Copy total counter into RDX
    and rdx,000000000000000Fh  ; Mask out lowest 4 bits of char counter
    call DumpChar              ; Call the char poke procedure
 
; Bump the buffer pointer to the next char and see if
 buffer's done:
    inc rsi           ; Increment total chars processed counter
    inc rcx           ; Increment buffer pointer
    cmp rcx,r15       ; Compare with # of chars in buffer
    jb .modTest       ; If we've processed all chars in buffer...
    call LoadBuff     ; ...go fill the buffer again
    cmp r15,0         ; If r15=0, sys_read reached EOF on stdin
    jbe Done          ; If we get EOF, we're done
 
; See if we're at the end of a block of 16 and need to display a line:
 .modTest:
    test rsi,000000000000000Fh ; Test 4 lowest bits in counter for 0
    jnz Scan          ; If counter is *not* modulo 16, loop back
    call PrintLine    ; ...otherwise print the line
    call ClearLine    ; Clear hex dump line to 0's
    jmp Scan          ; Continue scanning the buffer
```

<p align=justify>
Nota che l'etichetta .modTest ha un punto davanti ad essa. Questo punto la segna come un'etichetta locale. Un'etichetta locale è locale all'etichetta non locale (cioè, la prima etichetta non preceduta da un punto; chiamiamo queste globali) che la precede nel codice. In questo caso particolare, l'etichetta globale a cui appartiene .modTest è Scan. Il blocco precedente è la parte del corpo principale del programma che scansiona il buffer del file di input, formatta i dati di input in righe di 16 byte e visualizza quelle righe sulla console. In che modo un'etichetta globale 'possiede' un'etichetta locale? È una questione di visibilità all'interno del codice sorgente: un'etichetta locale non può essere referenziata a un livello superiore nel file di codice sorgente rispetto all'etichetta globale che la possiede, che, di nuovo, è la prima etichetta globale sopra di essa nel file. In questo caso, l'etichetta locale .modTest non può essere referenziata sopra l'etichetta globale Scan. Questo significa che potrebbe esistere un'altra etichetta .modTest nel programma, sul 'lato opposto' di Scan. Finché esiste un'etichetta globale tra due etichette locali con lo stesso nome, NASM non ha problemi a distinguerle. Le etichette locali possono anche esistere all'interno delle procedure. In un altro esempio da hexdump2gcc, c'è un'etichetta locale .poke nella procedura ClearLine. Appartiene all'etichetta ClearLine e pertanto non può essere referenziata da nessun'altra procedura altrove nel programma o nella libreria. (Non dimenticare che i nomi delle procedure sono etichette globali.) Questa isolamento all'interno di una singola procedura non è immediatamente ovvio, ma è vero e deriva dal fatto che 'sotto' una procedura in un programma o in una libreria c'è sempre un'altra procedura o l'etichetta _start o main che segna l'inizio del programma principale. È ovvio una volta che lo si vede disegnato, come ho fatto nella figura di sotto.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/local_labels_and_the_globals_that_own_them.png">
</div>

<p align=justify>
Ecco alcune note sulle etichette locali:
</p>

<ul>
	<li>
		<p align=justify>
		Le etichette locali all'interno delle procedure sono almeno locali alle procedure in cui sono definite. (Questo è il punto principale della figura di sopra.) Puoi, ovviamente, avere etichette globali all'interno delle procedure. Tieni presente che questo limiterà ulteriormente la visibilità delle etichette locali.
		</p>
	</li>
 	<li>
		<p align=justify>
		Può sembrare peculiare, ma è perfettamente legale e spesso utile definire etichette globali che non vengono mai reference, semplicemente per fornire proprietà delle etichette locali. Se stai scrivendo un programma utility semplice che si esegue in modo lineare senza molti salti o ritorni a lungo raggio, potresti andare molto lontano senza la necessità di inserire un'etichetta globale. Mi piace usare etichette globali per separare le principali parti funzionali di un programma, indipendentemente dal fatto che queste etichette vengano mai chiamate o meno. Questo mi consente di utilizzare liberamente le etichette locali all'interno di quei principali moduli funzionali.
		</p>
	</li>
 	<li>
		<p align=justify>
		Se stai scrivendo codice complesso con molti etichette globali e locali mescolate, fai attenzione a non cercare di JMP a un'etichetta locale dall'altra parte di un'etichetta globale. Questa è una delle ragioni per cui non avere 15 etichette locali chiamate .scan o .loopback all'interno di una parte di un programma - puoi facilmente confonderle e, cercando di saltare a una cinque istruzioni sopra, potresti inconsapevolmente saltare a una sette istruzioni sotto. NASM non ti avviserà se c'è un'etichetta locale con lo stesso nome dalla tua parte di un'etichetta globale e provi a saltare a un'etichetta locale dall'altra parte dell'etichetta globale. Bug come questo possono essere incredibilmente difficili da trovare a volte. Come qualsiasi strumento, le etichette locali devono essere utilizzate con attenzione per essere di maggior beneficio.
		</p>
	</li>
 	<li>
		<p align=justify>
		Ecco una regola empirica che uso: le etichette locali e tutti i salti ad esse dovrebbero avvenire all'interno di un unico schermo di codice. In altre parole, dovresti essere in grado di vedere sia un'etichetta locale che tutto ciò che si riferisce ad essa senza dover scorrere l'editor del tuo programma. Questa è solo una guida approssimativa per aiutarti a mantenere senso nei tuoi programmi, ma l'ho trovata molto utile nel mio lavoro.
		</p>
	</li>
</ul>

### Accesso forzato all'etichetta locale

<p align=justify>
Ogni tanto (non molto spesso), potresti sentire la necessità di accedere a un'etichetta locale dall'altra parte del suo proprietario di etichetta globale. NASM offre un modo per farlo, anche se ammetto di non averne mai avuto la necessità. La chiave per forzare l'accesso a un'etichetta locale al di fuori del suo ambito (l'area del tuo programma da cui è normalmente visibile) è comprendere come NASM tratta le etichette locali "sotto il cofano." Un'etichetta locale ha una definizione implicita che include l'etichetta globale a cui appartiene. L'etichetta locale .modTest di cui ho parlato prima in questa sezione appartiene all'etichetta globale Scan. Internamente, NASM conosce .modtest come Scan.modTest. Se ci fosse un'altra etichetta locale .modtest altrove nel programma (appartenente, diciamo, a un'etichetta globale Calc), potresti forzare un salto ad essa includendo il nome del suo proprietario nell'istruzione di salto:
</p>

```asm
 jne Calc.modTest
```

<p align=justify>
In un certo senso, sotto il tappeto, un'etichetta locale è semplicemente la "coda" di un'etichetta globale. Se ne hai bisogno, puoi accedere a un'etichetta locale anteponendo l'etichetta del suo proprietario globale e trattandola così come un'etichetta globale. Ancora una volta, non ho mai dovuto farlo e non lo considero una buona pratica, ma è bene sapere che l'opzione è lì nel caso si presentasse mai la necessità.
</p>

### Salti Corti, Vicini e Lontani

<p align=justify>
Uno degli errori di assemblaggio più strani che potresti incontrare può apparire in un programma completamente corretto, e se lavori con NASM abbastanza a lungo e crei programmi abbastanza grandi, lo incontrerai. Eccolo:
</p>

```asm
error: short jump is out of range
```

<p align=justify>
Questo errore si verifica quando un'istruzione di salto condizionale è troppo lontana dall'etichetta a cui fa riferimento, dove "troppo lontano" significa troppe posizioni in memoria. Questo si applica solo ai salti condizionali; l'istruzione di salto incondizionato JMP non è soggetta a questo errore. Il problema sorge a causa dei diversi modi in cui NASM può generare un opcode binario per una particolare istruzione di salto condizionale. Ci sono due diversi tipi di salti condizionali, a seconda di quanto lontano si trova l'etichetta di salto. Un'etichetta di salto che si trova entro 127 byte dall'istruzione di salto condizionale è chiamata. Un'etichetta di salto che è più lontana di 127 byte ma comunque all'interno del segmento di codice corrente è chiamata un salto vicino. C'è un terzo tipo di salto chiamato, che implica l'uscita totale dal segmento di codice corrente per qualsiasi motivo. Nel vecchio mondo del DOS in modalità reale, questo significava specificare sia un indirizzo di segmento che un indirizzo di offset per l'etichetta di salto. I salti lontani non venivano utilizzati molto spesso, anche se li ho usati un paio di volte nell'era del DOS. Non dimenticare che i segmenti ora appartengono al sistema operativo per il proprio utilizzo. In modalità protetta a 32 bit e in modalità estesa a 64 bit, i salti lontani sono estremamente rari e comportano tutte le complicazioni del sistema operativo che non posso trattare in questo libro. Per la programmazione nello spazio utente sono completamente non necessari. Il problema risiede davvero nella differenza tra salti brevi e salti vicini. Un'istruzione di salto condizionale breve genera un opcode binario breve—e quindi compatto. Gli opcode di salto brevi sono sempre di due byte, non di più. Gli opcode di salto vicino sono di quattro o sei byte, a seconda di vari fattori. Codice compatto significa codice veloce, e prendere un salto breve è (leggermente) più veloce nella maggior parte dei casi rispetto a un salto vicino. Inoltre, se utilizzi salti brevi per la maggior parte del tempo, i tuoi file eseguibili saranno un pochino più piccoli. Dato che il 90 percento o più delle istruzioni di salto condizionali che scriverai mirano a posizioni del programma a sole poche istruzioni di distanza, ha senso per NASM generare opcodes per salti brevi per impostazione predefinita. Infatti, NASM genera opcodes per salti brevi a meno che non gli dici esplicitamente di usare salti vicini. Un salto vicino è specificato utilizzando il qualificatore NEAR:
</p>

```asm
 jne Scan      ; Jump within 127 bytes in either direction
 jne near Scan ; Jump anywhere in the current code segment
```

<p align=justify>
I principianti tendono a imbattersi in questo modo nell'errore "salto breve fuori portata": inizi un programma e metti un'etichetta come Exit: alla fine, aspettandoti di saltare all'etichetta Exit: da diverse parti del programma. Quando il programma è nuovo e ancora abbastanza piccolo, potrebbe funzionare bene. Tuttavia, alla fine, il codice aggiunto nel mezzo del programma costringe i salti condizionali vicino all'inizio del programma a essere più di 127 byte lontani dall'etichetta Exit: alla fine. Bang! NASM ti restituisce l'errore "salto breve fuori portata". La soluzione è semplice: per ogni salto che NASM chiama "fuori portata", inserisci il qualificatore NEAR tra il mnemonico dell'istruzione di salto condizionale e l'etichetta di destinazione. Lascia stare gli altri.
</p>

### Costruzione di librerie di procedure esterne

<p align=justify>
Noterai che il programma hexdump2gcc fornito ha la maggior parte del suo codice separato in procedure. Questo è proprio come dovrebbe essere, per mantenere il programma comprensibile e manutenibile. Tuttavia, le procedure dichiarate all'interno del file hexdump2gcc.asm sono utilizzabili solo dal programma hexdump2gcc stesso. Se dovessi scrivere un programma più potente che, per qualche motivo, avesse bisogno di visualizzare un dump esadecimale/ASCII di alcuni dati, quelle procedure potrebbero essere riutilizzate, ma non finché sono all'interno del file hexdump2gcc.asm. La risposta è spostare le procedure di hexdump2gcc fuori da hexdump2gcc.asm completamente e collocarle in un file di codice sorgente separato chiamato una libreria. Potrebbe essere pieno di procedure, ma non ha alcuna porzione di programma principale e quindi nessun'etichetta _start: o main: per indicare dove inizia l'esecuzione. Contiene solo procedure (e forse alcune definizioni di dati) quindi non può essere tradotto dal linker in un suo programma eseguibile. Una volta creati i file di libreria contenenti procedure, ci sono due modi per usarli:
</p>

<ul>
	<li>
		<p align=justify>
		Un file di libreria può essere assemblato separatamente in un file .o, che a sua volta può essere collegato dal linker Linux in altri programmi che potresti scrivere in futuro.
  		</p>
	</li>
 	<li>
		<p align=justify>
		Un file di libreria può essere incluso nel file di codice sorgente del programma principale, utilizzando una direttiva chiamata %INCLUDE. (Ti dirò molto presto come utilizzare %INCLUDE.) Questo è ciò che devi fare per utilizzare le librerie da programmi scritti in SASM.
  		</p>
	</li>
</ul>

### Quando i Tool raggiungono i loro limiti

<p align=justify>
Per quanto sia facile per i principianti del linguaggio macchina imparare e utilizzare SASM (per questo SASM è stato creato), l'IDE di SASM ha le sue limitazioni, e stiamo per incorrere in una significativa: SASM non può collegare insieme più file di codice oggetto dell'assembly in un singolo file eseguibile. Fondamentalmente, tranne in casi molto rari, non può eseguire assembly separato. Un singolo programma potrebbe consistere in tre o quattro file di codice sorgente .asm separati, ognuno dei quali viene assemblato separatamente in un file .o separato. Per produrre il file eseguibile finale, il linker Linux ld intreccia tutti i file .o insieme, risolvendo tutti i riferimenti da uno all'altro, creando infine il file eseguibile. L'assembly separato non è pienamente supportato da SASM. Descriverò in dettaglio l'assembly separato dei file di libreria più avanti in questo capitolo. Gli esempi dovranno essere costruiti senza SASM, utilizzando makefile. Senza SASM, il debug sarà anche una sfida, e parleremo di questo anche. Nel frattempo, c'è un trucco che SASM ha e che ti permetterà di creare librerie separate di procedure.
</p>

### Utilizzare gli include file in SASM

<p align=justify>
NASM include una direttiva che consente di "includere" un file in un altro file durante un'operazione di assemblaggio. La direttiva %INCLUDE è seguita dal nome di un file di testo, tra virgolette doppie:
</p>

```asm
%INCLUDE "%textlibgcc.asm"
```

<p align=justify>
(Non dimenticare le virgolette!) Qui possono essere utilizzati solo file di testo contenenti codice sorgente. Non puoi includere alcun file binario di nessun tipo. Ciò che accade è che quando NASM assemblare un file di codice sorgente e incontra una direttiva %INCLUDE, apre il file nominato dalla direttiva %INCLUDE e inizia a prelevare testo dal file incluso, riga per riga. Nota che il file incluso non è inserito nel tuo file sorgente principale del linguaggio assembly. Fondamentalmente, quando NASM incontra %INCLUDE, smette di assemblare il tuo file sorgente principale e inizia ad assemblare il file incluso. Una volta che ha elaborato tutte le righe nel file incluso, riprende esattamente da dove si era fermato dopo la direttiva %INCLUDE e continua ad assemblare il tuo file sorgente principale. Molti file inclusi non sono un problema; puoi avere quante più direttive %INCLUDE in un file sorgente di programma vuoi. Puoi anche avere direttive %INCLUDE in un file di libreria che è esso stesso un file incluso, anche se fatto a sufficienza, il tuo codice sorgente diventerà molto disordinato, e non lo consiglio a meno che tu non abbia una ragione molto valida per farlo. Non sono necessarie dichiarazioni speciali in un file incluso, poiché in un senso utilitaristico è parte del file sorgente che contiene la direttiva %INCLUDE. Per un esempio di un file di inclusione, vedere il codice di sotto, che è una libreria di file di inclusione di procedure utilizzate in hexdump3gcc.asm per scrivere testo sulla console di Linux.
</p>

```asm
;  Library name    : textlibgcc
;  Version         : 2.0
;  Created date    : 5/9/2022
;  Last update     : 5/9/2023
;  Author          : Jeff Duntemann
;  Description     : A simple include library demonstrating the use of
;                  : the %INCLUDE directive within SASM
;
;  Note that this file cannot be assembled by itself, as SASM does not
;  support separate assembly. It can only be used as the target of an
;  %INCLUDE directive.
;

SECTION .bss        ; Section containing uninitialized data

    BUFFLEN  EQU 10h
    Buff     resb BUFFLEN

SECTION .data       ; Section containing initialised data

; Here we have two parts of a single useful data structure, implementing
; the text line of a hex dump utility. The first part displays 16 bytes in
; hex separated by spaces. Immediately following is a 16-character line 
; delimited by vertical bar characters. Because they are adjacent, the two
; parts can be referenced separately or as a single contiguous unit.
; Remember that if DumpLin is to be used separately, you must append an
; EOL before sending it to the Linux console.

DumpLine:  db " 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 "
DUMPLEN    EQU $-DumpLine
ASCLine:    db "|................|",10
ASCLEN     EQU $-ASCLine
FULLLEN    EQU $-DumpLine

; The HexDigits table is used to convert numeric values to their hex
; equivalents. Index by nybble without a scale: [HexDigits+eax]
HexDigits: db "0123456789ABCDEF"

; This table is used for ASCII character translation, into the ASCII
; portion of the hex dump line, via XLAT or ordinary memory lookup. 
; All printable characters "play through" as themselves. The high 128 
; characters are translated to ASCII period (2Eh). The non-printable
; characters in the low 128 are also translated to ASCII period, as is
; char 127.
DotXlat: 
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 20h,21h,22h,23h,24h,25h,26h,27h,28h,29h,2Ah,2Bh,2Ch,2Dh,2Eh,2Fh
    db 30h,31h,32h,33h,34h,35h,36h,37h,38h,39h,3Ah,3Bh,3Ch,3Dh,3Eh,3Fh
    db 40h,41h,42h,43h,44h,45h,46h,47h,48h,49h,4Ah,4Bh,4Ch,4Dh,4Eh,4Fh
    db 50h,51h,52h,53h,54h,55h,56h,57h,58h,59h,5Ah,5Bh,5Ch,5Dh,5Eh,5Fh
    db 60h,61h,62h,63h,64h,65h,66h,67h,68h,69h,6Ah,6Bh,6Ch,6Dh,6Eh,6Fh
    db 70h,71h,72h,73h,74h,75h,76h,77h,78h,79h,7Ah,7Bh,7Ch,7Dh,7Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
			
	
SECTION .text       ; Section containing code

;-------------------------------------------------------------------------
; ClearLine:    Clear a hex dump line string to 16 0 values
; UPDATED:      5/9/2023
; IN:           Nothing
; RETURNS:      Nothing
; MODIFIES:     Nothing
; CALLS:        DumpChar
; DESCRIPTION:  The hex dump line string is cleared to binary 0 by
;               calling DumpChar 16 times, passing it 0 each time.

ClearLine:
    push rax       ; Save all caller's r*x GP registers
    push rbx
    push rcx
    push rdx

    mov rdx,15     ; We're going to go 16 pokes, counting from 0
.poke:	
    mov rax,0      ; Tell DumpChar to poke a '0'
    call DumpChar  ; Insert the '0' into the hex dump string
    sub rdx,1      ; DEC doesn't affect CF!
    jae .poke      ; Loop back if RDX >= 0

    pop rdx        ; Restore all caller's GP registers
    pop rcx
    pop rbx
    pop rax
    ret	           ; Go home

;-------------------------------------------------------------------------
; DumpChar:     "Poke" a value into the hex dump line string.
; UPDATED:      5/9/2023
; IN:           Pass the 8-bit value to be poked in RAX.
;               Pass the value's position in the line (0-15) in RDX 
; RETURNS:      Nothing
; MODIFIES:     RAX, ASCLin, DumpLin
; CALLS:        Nothing
; DESCRIPTION:  The value passed in RAX will be put in both the hex dump
;               portion and in the ASCII portion, at the position passed 
;               in RDX, represented by a space where it is not a
;               printable character.

DumpChar:
    push rbx    ; Save caller's RBX
    push rdi    ; Save caller's RDI

; First we insert the input char into the ASCII portion of the dump line
    mov bl,byte [DotXlat+rax]    ; Translate nonprintables to '.'
    mov byte [ASCLine+rdx+1],bl   ; Write to ASCII portion

; Next we insert the hex equivalent of the input char in the hex portion
; of the hex dump line:
    mov rbx,rax           ; Save a second copy of the input char
    lea rdi,[rdx*2+rdx]   ; Calc offset into line string (RDX X 3)

; Look up low nybble character and insert it into the string:
    and rax,000000000000000Fh    ; Mask out all but the low nybble
    mov al,byte [HexDigits+rax]  ; Look up the char equiv. of nybble
    mov byte [DumpLine+rdi+2],al  ; Write the char equiv. to line string

; Look up high nybble character and insert it into the string:
    and rbx,00000000000000F0h    ; Mask out all the but second-lowest nybble
    shr rbx,4                    ; Shift high 4 bits of byte into low 4 bits
    mov bl,byte [HexDigits+rbx]  ; Look up char equiv. of nybble
    mov byte [DumpLine+rdi+1],bl  ; Write the char equiv. to line string

;Done! Let's go home:
    pop rdi    ; Restore caller's RDI
    pop rbx    ; Restore caller's RBX
    ret        ; Return to caller

;-------------------------------------------------------------------------
; PrintLine:   Displays DumpLin to stdout
; UPDATED:     5/9/2022
; IN:          DumpLine, FULLEN
; RETURNS:     Nothing
; MODIFIES:    Nothing
; CALLS:       Kernel sys_write
; DESCRIPTION: The hex dump line string DumpLin is displayed to stdout 
;              using syscall function sys_write. Registers used 
;              are preserved, along with RCX & R11.

PrintLine:
    ; Alas, we don't have pushad anymore.
    push rax
    push rbx
    push rcx         ; syscall clobbers
    push rdx
    push rsi
    push rdi
    push r11         ; syscall clobbers

    mov rax,1        ; Specify sys_write call
    mov rdi,1        ; Specify File Descriptor 1: Standard output
    mov rsi,DumpLine ; Pass address of line string
    mov rdx,FULLLEN  ; Pass size of the line string
    syscall          ; Make kernel call to display line string

    pop r11          ; syscall clobbers
    pop rdi
    pop rsi
    pop rdx
    pop rcx          ; syscall clobbers
    pop rbx
    pop rax
    ret              ; Return to caller


;-------------------------------------------------------------------------
; LoadBuff:    Fills a buffer with data from stdin via syscall sys_read
; UPDATED:     5/9/2023
; IN:          Nothing
; RETURNS:     # of bytes read in R15
; MODIFIES:    RCX, R15, Buff
; CALLS:       syscall sys_read
; DESCRIPTION: Loads a buffer full of data (BUFFLEN bytes) from stdin 
;              using syscall sys_read and places it in Buff. Buffer
;              offset counter RCX is zeroed, because we're starting in
;              on a new buffer full of data. Caller must test value in
;              R15: If R15 contains 0 on return, we've hit EOF on stdin.
;              Less than 0 in R15 on return indicates some kind of error.

LoadBuff:
    push rax         ; Save caller's RAX
    push rdx         ; Save caller's RDX
    push rsi         ; Save caller's RSI
    push rdi         ; Save caller's RDI

    mov rax,0        ; Specify sys_read call
    mov rdi,0        ; Specify File Descriptor 0: Standard Input
    mov rsi,Buff     ; Pass offset of the buffer to read to
    mov rdx,BUFFLEN  ; Pass number of bytes to read at one pass
    syscall          ; Call syscall's sys_read to fill the buffer
    mov r15,rax      ; Save # of bytes read from file for later
    xor rcx,rcx      ; Clear buffer pointer RCX to 0

    pop rdi          ; Restore caller's RDI
    pop rsi          ; Restore caller's RSI
    pop rdx          ; Restore caller's RDX
    pop rax          ; Restore caller's RAX
    ret              ; And return to calle
```

<p align=justify>
Un programma che utilizza una libreria di procedure sarà molto più piccolo di uno che contiene tutta la macchina nel suo singolo file di codice sorgente. Il codice di sotto è fondamentalmente hexdump2gcc.asm con le sue procedure rimosse e raccolte nel file di inclusione che ho presentato nel codice di sopra.
</p>

```asm
;  Executable name  : hexdump3gcc
;  Version          : 2.0
;  Created date     : 9/5/2022
;  Last update      : 5/9/2023
;  Author           : Jeff Duntemann
;  Description      : A simple hex dump utility demonstrating the use of
;                   : code libraries by inclusion via %INCLUDE
;
;  Build using SASM's standard x64 build setup
;
;  Type or paste some text into Input window and click Build & Run.
;

SECTION .bss        ; Section containing uninitialized data

SECTION .data       ; Section containing initialised data		
	
SECTION .text       ; Containing code
   
%INCLUDE "textlibgcc.asm"

GLOBAL main   ; You need to declare "main" here because SASM uses gcc
              ; to do builds.

;-------------------------------------------------------------------------
; MAIN PROGRAM BEGINS HERE
;-------------------------------------------------------------------------

main:
    mov rbp, rsp; for correct debugging

; Whatever initialization needs doing before loop scan starts is here:
    xor r15,r15     ; Zero out r15,rsi, and rcx
    xor rsi,rsi		
    xor rcx,rcx
    call LoadBuff   ; Read first buffer of data from stdin
    cmp r15,0       ; If r15=0, sys_read reached EOF on stdin
    jbe Exit

; Go through the buffer and convert binary byte values to hex digits:
Scan:
    xor rax,rax                ; Clear RAX to 0
    mov al,byte[Buff+rcx]      ; Get a byte from the buffer into AL
    mov rdx,rsi	               ; Copy total counter into RDX
    and rdx,000000000000000Fh  ; Mask out lowest 4 bits of char counter
    call DumpChar              ; Call the char poke procedure

; Bump the buffer pointer to the next character and see if buffer's done:
    inc rsi           ; Increment total chars processed counter
    inc rcx           ; Increment buffer pointer
    cmp rcx,r15       ; Compare with # of chars in buffer
    jb .modTest        ; If we've processed all chars in buffer...
    call LoadBuff     ; ...go fill the buffer again
    cmp r15,0         ; If r15=0, sys_read reached EOF on stdin
    jbe Done          ; If we get EOF, we're done

; See if we're at the end of a block of 16 and need to display a line:
.modTest:
    test rsi,000000000000000Fh ; Test 4 lowest bits in counter for 0
    jnz Scan                   ; If counter is *not* modulo 16, loop back
    call PrintLine             ; ...otherwise print the line
    call ClearLine             ; Clear hex dump line to 0's
    jmp Scan                   ; Continue scanning the buffer

; All done! Let's end this party:
Done:
    call PrintLine   ; Print the final "leftovers" line

Exit:	
    ret              ; Return to glibc's shutdown code
```

### Dove devono essere memorizzati i file di inclusione di SASM

<p align=justify>
Uno dei problemi in qualsiasi linguaggio di programmazione che supporta i file di inclusione è dove l'assemblatore o il compilatore cercherà quei file di inclusione. Con SASM hai due opzioni: 
</p>

1. Puoi creare e utilizzare librerie di file di inclusione nella directory di lavoro attuale, cioè la directory in cui si trova il tuo file sorgente principale. Questo è ciò che dovresti fare quando stai sviluppando la libreria che sarà successivamente utilizzata come file di inclusione.
2. Puoi utilizzare librerie di file di inclusione che si trovano in una directory creata da SASM a tale scopo quando SASM è installato.

<p align=justify>  
Ecco la directory:
</p>

```
/usr/share/sasm/include
```

<p align=justify>
Non è un grande problema, vero? Bene, c'è una complicazione: devi essere connesso come root per inserire un file di inclusione nella directory di inclusione di SASM. È al di fuori dello scopo di questo libro spiegare in dettaglio i comandi di Linux, quindi se hai dubbi su come ottenere i permessi di root, fai una ricerca su internet. L'account root viene creato automaticamente quando installi Linux; devi “rivendicarlo” dandogli una password. Ancora una volta, ci sono troppi dettagli per queste pagine, ma ci sono tutorial online, ed è un'abilità di cui avrai bisogno se intendi fare qualsiasi tipo di programmazione seria su Linux. Quindi perché preoccuparsi di quella directory di inclusione difficile da raggiungere? Semplicemente questo: se mantieni le tue librerie nelle directory di lavoro di diversi progetti, una modifica apportata alla copia di una libreria di un progetto non si rifletterà in tutte le altre copie della stessa libreria altrove tra i tuoi vari progetti. Se non fai attenzione a questo, le copie di una data libreria si “evolveranno” gradualmente l'una dall'altra, e le procedure in quella libreria inizieranno a comportarsi in modo diverso o a causare bug. La tentazione di applicare correzioni “veloci e sporche” a piccoli problemi in un file di codice sorgente è forte. Non farlo, specialmente per le librerie di file di inclusione. Crea e perfeziona una libreria di file di inclusione come progetto o parte di un progetto, e poi, con i permessi di root, inseriscila nella directory di inclusione di SASM. In questo modo, tutti i tuoi progetti utilizzeranno la stessa copia della libreria di inclusione.
</p>

### Il modo migliore per creare una libreria di file di inclusione

<p align=justify>
Se hai intenzione di sviluppare una libreria di procedure in stile include da zero con SASM, ecco un processo collaudato da utilizzare: 
</p>

1. Progetta le tue procedure. Creo semplicemente un documento di testo e scrivo le descrizioni di ciò che le procedure della biblioteca devono fare, affinando gradualmente le descrizioni fino a quando le descrizioni non sono effettivamente codificate.
2. Apri il programma sandbox che ho descritto in precedenza e inserisci il codice sorgente delle tue procedure. Se li hai già scritti come parti di altri programmi, copia/incolla il loro codice sorgente nel nuovo file.
3. Crea un semplice codice "esercizio" nel corpo del programma sandbox che chiama le tue procedure e le mette alla prova. Eseguire il debug come sempre con il debugger SASM. Questo rivelerà booboos relativamente semplici come spingere e far scoppiare i registri nell'ordine sbagliato, cestinare i registri del chiamante e così via.
4. Una volta terminato il debug semplice, includere il codice sorgente della libreria in un programma "reale" testare le procedure della libreria in modo più approfondito.
5. Quando sei soddisfatto che tutte le procedure funzionino come progettato, raccoglile in un file senza il framework sandbox e rilasciale nella directory include files di SASM.
6. Conserva una copia della nuova libreria da qualche altra parte, da qualche parte in cui esegui regolarmente il backup.
7. Se in qualsiasi momento apporti modifiche al codice sorgente della libreria, testa accuratamente le modifiche e quindi rilascia il file modificato nella directory di inclusione di SASM, sostituendo la versione precedente già presente.

<p align=justify>
A questo punto metteremo da parte SASM per un po' e parleremo dell'utilizzo di assembly separati per collegare i file di codice oggetto .o preassemblati in un singolo file eseguibile. È facile diventare "viziati" usando SASM, perché inserisce così tanti strumenti utili all'interno di un IDE, un IDE creato appositamente per i primi passi di uno studente nella programmazione in linguaggio assembly. Continuerò a presentare il codice di esempio per l'uso all'interno di SASM in questo libro, che è un'introduzione ai concetti di informatica e linguaggio assembly. Ma avrai bisogno di sapere come funziona l'assemblaggio separato, una volta che sarai "passato" da SASM a IDE più complessi e tecniche di programmazione sofisticate
</p>

### Assemblaggio e moduli separati

<p align=justify>
Dal punto di vista del processo di assemblaggio, ogni singolo file .asm è considerato un modulo, che contenga o meno un'etichetta _start: o main:, e quindi sia un programma o contenga semplicemente procedure. Ogni modulo contiene codice e possibilmente alcune definizioni di dati. Quando tutte le dichiarazioni sono fatte correttamente, tutti i moduli possono liberamente "parlare" tra loro tramite chiamate di procedura, e qualsiasi procedura può fare riferimento a qualsiasi definizione di dati presente in uno qualsiasi dei file che il linker combina. (Le etichette locali sono ancora visibili solo alle etichette globali che le possiedono.) Ogni file eseguibile può contenere solo un'etichetta _start: o main:, quindi tra i diversi moduli collegati in un file eseguibile, solo uno può contenere un'etichetta _start: o main: e quindi essere il programma vero e proprio. Questo sembra più difficile di quanto non sia. Il trucco è semplicemente ottenere tutte le dichiarazioni corrette.
</p>

### Dichiarazioni Globali ed Esterne

<p align=justify>
Ed è molto meno complicato di quanto non fosse in passato. Ai vecchi tempi del DOS, era necessario definire segmenti di codice e segmenti di dati per l'uso delle librerie assemblate separatamente e assicurarsi che tali segmenti fossero contrassegnati come PUBLIC, e così via. Per i programmi in modalità protetta a 32 bit e in modalità lunga x64 in spazio utente sotto Linux, c'è solo un segmento, contenente codice, dati e stack, letteralmente tutto ciò che un programma ha. La maggior parte della "connessione" manuale che prima dovevamo fare viene ora eseguita automaticamente da NASM, dal linker e dal caricatore Linux. Creare librerie è ora un gioco da ragazzi, non più complesso della creazione di programmi e per certi versi anche più facile. Il cuore della programmazione nei moduli è "rimandare" la risoluzione degli indirizzi fino al momento del collegamento. È possibile che si sia già riscontrato il problema della risoluzione degli indirizzi se si è iniziato a scrivere i propri programmi in assembly. Può succedere per caso: se avete intenzione di scrivere una procedura in un programma ma nel vostro entusiasmo maniacale scrivete prima il codice che fa riferimento all'etichetta di quella procedura (non ancora scritta), NASM vi darà allegramente un messaggio di errore:
</p>

```asm
 error: symbol 'MyProc' undefined
```

<p align=justify>
Nella programmazione modulare, è frequente chiamare procedure che non esistono da nessuna parte nel file di codice sorgente su cui stai effettivamente lavorando. Come superare i controlli dell'assemblatore? La risposta è dichiarare una procedura esterna. Funziona molto come suona: all'assemblatore viene detto che un determinato'etichetta dovrà essere trovata altrove nel programma, in un altro modulo, in seguito. Una volta comunicato questo, NASM è felice di darti una deroga su un'etichetta non definita, per ora. Hai promesso a NASM che la fornirai in seguito, e NASM accetta la tua promessa. (Il linker ti costringerà a mantenere quella promessa durante il passaggio di collegamento.) NASM segnalerà il riferimento come esterno e continuerà senza contestare l'etichetta non definita. La promessa che fai a NASM appare così.
</p>

```asm
EXTERN MyProc
```

<p align=justify>
Qui hai detto all'assemblatore che l'etichetta MyProc rappresenta una procedura e che sarà trovata da qualche parte esterna al modulo attuale. Questo è tutto ciò che l'assemblatore deve sapere per trattenere il suo messaggio di errore. E dopo aver fatto ciò, la parte dell'assemblatore nell'accordo è finita. Lascia in place un socket vuoto nel tuo programma dove l'indirizzo della procedura esterna può essere inserito in seguito. A volte lo penso come un occhiello dove in seguito la procedura esterna si aggancerà. Nell'altro modulo dove la procedura MyProc è effettivamente definita, non è sufficiente solo definire la procedura. Un occhiello ha bisogno di un gancio. Devi avvisare l'assemblatore che MyProc sarà referenziato da fuori dal modulo. L'assemblatore ha bisogno di forgiare il gancio che si aggancerà all'occhiello. Forgi il gancio dichiarando la procedura globale, il che significa che altri moduli in qualsiasi parte del programma possono liberamente fare riferimento alla procedura. Dichiarare una procedura globale non è più complesso che dichiararla esterna:
</p>

```asm
 GLOBAL MyProc
```

<p align=justify>
Una procedura dichiarata come GLOBAL dove è definita può essere riferita da qualsiasi parte in cui la sua etichetta è dichiarata come EXTERN. Con entrambi l'uncinetto e l'eyelet in posizione, chi li collega realmente? Il linker fa questo durante l'operazione di collegamento. Al momento del collegamento, il linker prende i due file .o generati dall'assemblatore, uno dal tuo programma e l'altro dal modulo contenente MyProc, e li combina in un unico file binario eseguibile. Il numero di file .o non è limitato a due; puoi avere quasi qualsiasi numero di moduli esterni assemblati separatamente in un unico programma. (Ancora una volta, solo uno di essi—il programma vero e proprio—può avere un'etichetta _start: o main:). Quando il file eseguibile creato dal linker viene caricato ed eseguito, il programma può chiamare MyProc in modo pulito e veloce come se entrambi fossero stati dichiarati nello stesso file di codice sorgente. Questo processo è riassunto graficamente nella figura di sotto
</p>

<div aling=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/connecting_globals_and_externals.png">
</div>

<p align=justify>
Ciò che funziona per le procedure funziona anche per i dati, e può funzionare in entrambe le direzioni. Il tuo programma può dichiarare qualsiasi variabile nominata come GLOBALE, e quella variabile può quindi essere utilizzata da qualsiasi modulo in cui lo stesso nome di variabile è dichiarato come esterno con la direttiva EXTERN. Infine, le librerie di procedure possono condividere dati e procedure tra loro in qualsiasi combinazione, a patto che tutte le dichiarazioni globali ed esterne siano gestite correttamente. Un programma o un modulo contenente procedure o variabili dichiarate come globali esporta quegli elementi. Inoltre, diciamo che un programma o un modulo che utilizza procedure o variabili che gli sono estranee importa quegli elementi.
</p>

# Il meccanismo dei Globals e Externals

<p align=justify>
Il programma hexdump2gcc contiene diverse procedure. Estraiamo quelle procedure dal modulo principale del programma e creiamo un modulo di libreria assemblato separatamente in modo da poter vedere come funziona tutto. Ho descritto in dettaglio nei capitoli precedenti i requisiti del codice sorgente dei programmi in linguaggio assembly. I moduli di libreria assemblati separatamente sono simili ai programmi e possono avere tutte e tre le sezioni (.text, .data e .bss) che i moduli di programma possono avere. Ci sono però due differenze principali riguardanti le cose di cui i moduli di libreria sono privi.
</p>

<ul>
	<li>
		<p align=justify>
		I moduli esterni non contengono un programma principale e quindi non hanno un indirizzo di avvio. Cioè, non esiste un'etichetta _start: o main: in una libreria per indicare al linker che questo è il punto da cui deve iniziare l'esecuzione del codice. I moduli di libreria non sono progettati per essere eseguiti autonomamente, quindi un'etichetta _start: o main: in un modulo di libreria è sia superflua sia causa di un errore fatale del linker se _start: esiste già nel modulo del programma principale.	
		</p>
	</li>
 	<li>
		<p align=justify>
		I moduli esterni non ritornano a Linux. Se solo il modulo del programma principale contiene un'etichetta _start: o main:, allora solo il modulo del programma principale dovrebbe contenere la necessaria SYSCALL sys_exit che arresta il programma e restituisce il controllo a Linux. Come regola generale, non chiamare mai sys_exit all'interno di una procedura, sia essa situata nello stesso modulo del programma principale o in un modulo di libreria esterna. Il programma principale ottiene il permesso di eseguire dal sistema operativo, e il programma principale dovrebbe restituirlo.
		</p>
	</li>
</ul>

<p align=justify>
Innanzitutto, dai un'occhiata al codice di sotto. È fondamentalmente lo stesso programma di hexdump2gcc, ma con le sue procedure raccolte in un file di libreria assemblato separatamente chiamato textlib.asm. Fa esattamente le stesse cose di hexdump2gcc. È più piccolo di hexdump2gcc dal punto di vista del codice sorgente, perché la maggior parte della sua meccanica è stata esternalizzata. Esternalizzata dove? Non lo sai ancora — e non devi saperlo. NASM ritarderà la risoluzione degli indirizzi delle procedure mancanti finché non elenchi tutte le procedure mancanti utilizzando la direttiva EXTERN.
</p>

```asm
;  Executable name : hexdump3
;  Version         : 2.0
;  Created date    : 9/14/2022
;  Last update     : 7/18/2023
;  Author          : Jeff Duntemann
;  Description     : A simple hex dump utility demonstrating the use of
;                  : separately assembled code libraries via EXTERN & GLOBAL
;
;  Build using these commands:
;    nasm -f elf64 -g -F dwarf hexdump3.asm
;    ld -o hexdump3 hexdump3.o <path>/textlib.o
;
SECTION .bss         ; Section containing uninitialized data

SECTION .data        ; Section containing initialised data
		
SECTION .text        ; Section containing code

EXTERN ClearLine, DumpChar, LoadBuff, PrintLine
EXTERN Buff, BuffLength

GLOBAL _start:

_start:
    push rbp
    mov rbp,rsp      ; For the benefit of gdb
;    nop              ; Ditto

; Whatever initialization needs doing before the loop scan starts is here:
    xor r15,r15
    xor rsi,rsi		
    xor rcx,rcx
    call LoadBuff    ; Read first buffer of data from stdin
    cmp r15,0        ; If r15=0, sys_read reached EOF on stdin
    jbe Exit

; Go through the buffer and convert binary values to hex digits:
Scan:
    xor rax,rax                ; Clear RAX to 0
    mov al,byte[Buff+rcx]      ; Get a char from the buffer into AL
    mov rdx,rsi                ; Copy total counter into RDX
    and rdx,000000000000000Fh  ; Mask out lowest 4 bits of char counter
    call DumpChar              ; Call the char poke procedure

; Bump the buffer pointer to the next character and see if buffer's done:
    inc rsi                    ; Increment buffer pointer
    inc rcx                    ; Increment total chars processed counter
    cmp rcx,r15                ; Compare with # of chars in buffer
    jb modTest                 ; If we've processed all chars in buffer...
    call LoadBuff              ; ...go fill the buffer again
    cmp r15,0                  ; If r15=0, sys_read reached EOF on stdin
    jbe Done                   ; If we get EOF, we're done

; See if we're at the end of a block of 16 and need to display a line:
modTest:
    test rsi,000000000000000Fh ; Test 4 lowest bits in counter for 0
    jnz Scan                   ; If counter is *not* modulo 16, loop back
    call PrintLine             ; ...otherwise print the line
    call ClearLine             ; Clear hex dump line to 0's
    jmp Scan                   ; Continue scanning the buffer

; All done! Let's end this party:
Done:
    call PrintLine             ; Print the "leftovers" line

Exit:	
    mov rax,60                 ; Code for Exit system call
    mov rdi,0                  ; Return a code of zero	
    syscall                    ; Make system call
```

<p align=justify>
Le dichiarazioni esterne di più elementi possono essere messe su una sola riga, separate da virgole, come in hexdump3:
</p>

```asm
 EXTERN ClearLine, DumpChar, PrintLine
```

<p align=justify>
Non deve esserci una sola direttiva EXTERN. Possono esisterne diverse in un modulo; ogni identificatore esterno, infatti, può avere la propria direttiva EXTERN. Sta a te decidere. Tuttavia, quando hai un elenco piuttosto lungo di identificatori esterni, non commettere questo errore, che è un errore:
</p>

```asm
EXTERN InitBlock, ReadBlock, ValidateBlock, WriteBlock,
CleanUp, ShowStats, PrintSummary            ; ERROR!
```

<p align=justify>
Le dichiarazioni EXTERN non possono estendersi oltre i confini di riga. (In effetti, quasi nulla nel linguaggio assembly può estendersi oltre i confini di riga, specialmente con NASM. I programmatori Pascal e C si imbattono in questa peculiarità abbastanza spesso quando sono alle prime armi con il linguaggio assembly.) Se hai troppe dichiarazioni esterne per adattarle a una singola riga con un singolo EXTERN, posiziona ulteriori direttive EXTERN sulle righe seguenti. Per collegare hexdump3 in un programma eseguibile funzionante, dobbiamo creare un modulo di libreria esterna per ciascuna delle sue procedure. Tutto ciò di cui abbiamo bisogno sono le procedure e i loro dati nelle sezioni corrette e le necessarie dichiarazioni GLOBAL. Questo è ciò che si trova nel codice di sotto:
</p>

```asm
;  Module name      : textlib.asm
;  Version          : 2.0
;  Created date     : 9/14/2022
;  Last update      : 7/18/2023
;  Author           : Jeff Duntemann
;  Description      : A simple procedure library demonstrating the use of
;                   : separately assembled code libraries via EXTERN
;
;  Build using this command:
;    nasm -f elf64 -g -F dwarf textlib.asm
;
;
		
SECTION .bss               ; For containing uninitialized data
	
    BUFFLEN  EQU 10h       ; We read the input file 16 bytes at a time
	Buff:    resb BUFFLEN  ; Reserve memory for the input file read buffer

SECTION .data              ; For containing initialised data

; Here we have two parts of a single useful data structure, implementing the
; text line of a hex dump utility. The first part displays 16 bytes in hex
; separated by spaces. Immediately following is a 16-character line delimited
; by vertical bar characters. Because they are adjacent, they can be
; referenced separately or as a single contiguous unit. Remember that if
; DumpLin is to be used separately, you must append an EOL before sending it
; to the Linux console.

DumpLine:   db " 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 "
DUMPLEN     EQU $-DumpLine
ASCLine:    db "|................|",10
ASCLEN      EQU $-ASCLine
FULLLEN     EQU $-DumpLine

; The equates shown above must be applied to variables to be exported:
DumpLength: dq DUMPLEN
ASCLength:  dq ASCLEN
FullLength: dq FULLLEN
BuffLength: dq BUFFLEN

; The HexDigits table is used to convert numeric values to their hex
; equivalents. Index by nybble without a scale, e.g.: [HexDigits+rax]
HexDigits:  db "0123456789ABCDEF"

; This table allows us to generate text equivalents for binary numbers. 
; Index into the table by the nybble using a scale of 4: 
; [BinDigits + rcx*4]
BinDigits:  db "0000","0001","0010","0011"
            db "0100","0101","0110","0111"
            db "1000","1001","1010","1011"
            db "1100","1101","1110","1111"

; Exported data items and procedures:            
GLOBAL  Buff, DumpLine, ASCLine, HexDigits, BinDigits
GLOBAL  ClearLine, DumpChar, NewLines, PrintLine, LoadBuff
            
; This table is used for ASCII character translation, into the ASCII
; portion of the hex dump line, via XLAT or ordinary memory lookup. 
; All printable characters "play through" as themselves. The high 128 
; characters are translated to ASCII period (2Eh). The non-printable
; characters in the low 128 are also translated to ASCII period, as is
; char 127.
    DotXlat: 
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 20h,21h,22h,23h,24h,25h,26h,27h,28h,29h,2Ah,2Bh,2Ch,2Dh,2Eh,2Fh
    db 30h,31h,32h,33h,34h,35h,36h,37h,38h,39h,3Ah,3Bh,3Ch,3Dh,3Eh,3Fh
    db 40h,41h,42h,43h,44h,45h,46h,47h,48h,49h,4Ah,4Bh,4Ch,4Dh,4Eh,4Fh
    db 50h,51h,52h,53h,54h,55h,56h,57h,58h,59h,5Ah,5Bh,5Ch,5Dh,5Eh,5Fh
    db 60h,61h,62h,63h,64h,65h,66h,67h,68h,69h,6Ah,6Bh,6Ch,6Dh,6Eh,6Fh
    db 70h,71h,72h,73h,74h,75h,76h,77h,78h,79h,7Ah,7Bh,7Ch,7Dh,7Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
    db 2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh,2Eh
		
SECTION .text              ; For code

;-------------------------------------------------------------------------
; ClearLine:   Clear a Full-Length hex dump line to 16 0 values
; UPDATED:     9/21/2022
; IN:          Nothing
; RETURNS:     Nothing
; MODIFIES:    Nothing
; CALLS:       DumpChar
; DESCRIPTION: The hex dump line string is cleared to binary 0. 

ClearLine:
    push rax        ; Save all caller's r*x GP registers
    push rbx
    push rcx
    push rdx

    mov rdx,15      ; We're going to go 16 pokes, counting from 0
.poke:	
    mov rax,0       ; Tell DumpChar to poke a '0'
    call DumpChar   ; Insert the '0' into the hex dump string
    sub rdx,1       ; DEC doesn't affect CF!
    jae .poke       ; Loop back if RDX >= 0
	
    pop rdx         ; Restore caller's r*x GP registers
    pop rcx
    pop rbx
    pop rax
    ret             ; Go home

;-------------------------------------------------------------------------
; DumpChar:     "Poke" a value into the hex dump line string DumpLine.
; UPDATED:      9/21/2022
; IN:           Pass the 8-bit value to be poked in RAX.
;               Pass the value's position in the line (0-15) in RDX 
; RETURNS:      Nothing
; MODIFIES:     RAX
; CALLS:        Nothing
; DESCRIPTION:  The value passed in RAX will be placed in both the hex dump
;               portion and in the ASCII portion, at the position passed 
;               in RCX, represented by a space where it is not a printable 
;               character.

DumpChar:
	push rbx    ; Save caller's RBX
	push rdi    ; Save caller's RDI

; First we insert the input char into the ASCII portion of the dump line
    mov bl,byte [DotXlat+rax]      ; Translate nonprintables to '.'
    mov byte [ASCLine+rdx+1],bl    ; Write to ASCII portion

; Next we insert the hex equivalent of the input char in the hex portion
; of the hex dump line:
    mov rbx,rax                    ; Save a second copy of the input char
    lea rdi,[rdx*2+rdx]            ; Calc offset into line string (RDX X 3)

; Look up low nybble character and insert it into the string:
    and rax,000000000000000Fh      ; Mask out all but the low nybble
    mov al,byte [HexDigits+rax]    ; Look up the char equivalent of nybble
    mov byte [DumpLine+rdi+2],al   ; Write the char equivalent to line string

; Look up high nybble character and insert it into the string:
    and rbx,00000000000000F0h      ; Mask out all the but second-lowest nybble
    shr rbx,4                      ; Shift high 4 bits of char into low 4 bits
    mov bl,byte [HexDigits+rbx]    ; Look up char equivalent of nybble
    mov byte [DumpLine+rdi+1],bl   ; Write the char equiv. to line string

;Done! Let's go home:
    pop rdi     ; Restore caller's EDI register value
    pop rbx     ; Restore caller's EBX register value
    ret         ; Return to caller

;-------------------------------------------------------------------------
; Newlines:     Sends between 1-15 newlines to the Linux console
; UPDATED:      5/9/2023
; IN:           # of newlines to send, from 1 to 15
; RETURNS:      Nothing
; MODIFIES:     Nothing
; CALLS:        Kernel sys_write
; DESCRIPTION:  The number of newline chareacters (0Ah) specified in RDX
;               is sent to stdout using using SYSCALL sys_write. This
;               procedure demonstrates placing constant data in the 
;               procedure definition itself, rather than in .data or .bss

Newlines:
    push rax       ; Push caller's registers
    push rsi
    push rdi
    push rcx       ; Used by syscall
    push rdx
    push r11       ; Used by syscall
        
    cmp rdx,15     ; Make sure caller didn't ask for more than 15
    ja .exit       ; If so, exit without doing anything
    mov rcx,EOLs   ; Put address of EOLs table into ECX
    mov rax,1      ; Specify sys_write call
    mov rdi,1      ; Specify File Descriptor 1: Standard output
    syscall        ; Make the system call

.exit:   
    pop r11        ; Restore all caller's registers
    pop rdx
    pop rcx
    pop rdi
    pop rsi
    pop rax
    ret            ; Go home!

EOLs db 10,10,10,10,10,10,10,10,10,10,10,10,10,10,10

;-------------------------------------------------------------------------
; PrintLine:    Displays the hex dump line string via SYSCALL sys_write
; UPDATED:      5/9/2023
; IN:           Nothing
; RETURNS:      Nothing
; MODIFIES:     RAX RCX RDX RDI RSI
; CALLS:        SYSCALL sys_write
; DESCRIPTION:  The hex dump line string DumpLine is displayed to stdout 
;               using SYSCALL sys_write.


PrintLine:
    ; Alas, we don't have pushad anymore.
    push rax            ; Push caller's registers
    push rbx
    push rcx            ; Used by syscall
    push rdx
    push rsi
    push rdi
    push r11            ; Used by syscall
        
    mov rax,1           ; Specify sys_write call
    mov rdi,1           ; Specify File Descriptor 1: Standard output
    mov rsi,DumpLine    ; Pass offset of line string
    mov rdx,FULLLEN     ; Pass size of the line string
    syscall             ; Make system call to display line string
        
    pop r11             ; Restore callers registers
    pop rdi             
    pop rsi
    pop rdx
    pop rcx
    pop rbx
    pop rax
    ret                 ; Go home!

;-------------------------------------------------------------------------
; LoadBuff:     Fills a buffer with data from stdin via syscall sys_read
; UPDATED:      5/9/2023
; IN:           Nothing
; RETURNS:      # of bytes read in R15
; MODIFIES:     RAX, RDX, RSI, RDI, RCX, R15, Buff
; CALLS:        syscall sys_read
; DESCRIPTION:  Loads a buffer full of data (BUFFLEN bytes) from stdin 
;               using syscall sys_read and places it in Buff. Buffer
;               offset counter RCX is zeroed, because we're starting in
;               on a new buffer full of data. Caller must test value in
;               R15: If R15 contains 0 on return, we've hit EOF on stdin.
;               Less than 0 in R15 on return indicates some kind of error.

LoadBuff:
	push rax        ; Save caller's RAX
	push rdx        ; Save caller's RDX
	push rsi        ; Save caller's RSI
	push rdi        ; Save caller's RDI

	mov rax,0       ; Specify sys_read call
	mov rdi,0       ; Specify File Descriptor 0: Standard Input
	mov rsi,Buff    ; Pass offset of the buffer to read to
	mov rdx,BUFFLEN	; Pass number of bytes to read at one pass
	syscall         ; Call syscall's sys_read to fill the buffer
	mov r15,rax     ; Save # of bytes read from file for later
	xor rcx,rcx     ; Clear buffer pointer RCX to 0

	pop rdi         ; Restore caller's RDI
	pop rsi         ; Restore caller's RSI
	pop rdx         ; Restore caller's RDX
	pop rax         ; Restore caller's RAX
	ret             ; And return to caller
```

<p align=justify>
Ci sono due righe di dichiarazioni di identificatori globali, ciascuna con la propria direttiva GLOBAL. Come convenzione nel mio lavoro, separo le dichiarazioni di procedure e di elementi di dati nominati e assegno a ciascuna la propria riga. (Naturalmente, poiché le dichiarazioni GLOBAL non possono attraversare una riga di testo, potresti aver bisogno di più di due righe se hai molti globali da esportare.)
</p>

```asm
 GLOBAL  Buff, DumpLine, ASCLine, HexDigits, BinDigits
 GLOBAL  ClearLine, DumpChar, NewLines, PrintLine, LoadBuff
```

<p align=justify>
Qualsiasi procedura o elemento di dati che deve essere esportato (cioè reso disponibile al di fuori del modulo) deve essere dichiarato su una riga dopo una direttiva GLOBAL. Non è necessario dichiarare tutto in un modulo come globale. Infatti, un modo per gestire la complessità e prevenire certi tipi di bug è riflettere con attenzione e limitare rigorosamente ciò che altri moduli possono "vedere" all'interno dei loro moduli. Un modulo può avere procedure "private" e elementi di dati nominati che possono essere referenziati solo all'interno del modulo. Rendere questi elementi privati è infatti l'impostazione predefinita: basta non dichiararli globali. Nota bene che tutti gli elementi dichiarati globali devono essere dichiarati globali prima di essere definiti nel codice sorgente. In pratica, questo significa che è necessario dichiarare le procedure globali nella parte superiore della sezione .text, prima che qualsiasi procedura sia effettivamente definita. Allo stesso modo, tutti gli elementi di dati nominati globali devono essere dichiarati nella sezione .data prima che gli elementi di dati siano definiti. Gli equates possono essere esportati dai moduli, sebbene questa sia un'innovazione dell'assemblatore NASM e non necessariamente vera per tutti gli assemblatori. Penso che sia rischioso e invece di esportare equates, definisco variabili nominate per contenere valori definiti da equates:
</p>

```asm
 DumpLength:     
 ASCLength:      
 FullLength:     
 BuffLength:     
 dq DUMPLEN
 dq ASCLEN
 dq FULLLEN
 dq BUFFLEN 
```

<p align=justify>
Se vuoi che vengano esportate, dichiara le variabili GLOBAL. Nota che gli esempi mostrati non sono esportati da textlib.asm e servono solo a illustrare la tecnica.
</p>

### Linkare le librerie nei tuoi programmi

<p align=justify>
Per tutti i precedenti programmi di esempio presentati in questo libro, i makefile sono abbastanza semplici. Qui, ad esempio, c'è il makefile per il programma hexdump2:
</p>

```make
 hexdump2: hexdump2.o
	 ld -o hexdump2 hexdump2.o
 hexdump2.o: hexdump2.asm
 	nasm -f elf64 -g -F dwarf hexdump2.asm
```

<p align=justify>
L'invocazione del linker converte HEXDUMP2.O nel file eseguibile hexdump2, e questo è tutto ciò che deve fare. Aggiungere un file di libreria complica leggermente le cose. Il linker ora deve fare un vero e proprio collegamento di più file. File di libreria aggiuntivi nel formato .o vengono aggiunti all'invocazione del linker dopo il nome del file collegabile del programma principale. Può esserci un numero (ragionevole) di file .o in un passaggio di collegamento. Per costruire hexdump3, ne servono solo due. Ecco il makefile per hexdump3:
</p>

```make
 hexdump3: hexdump3.o
 	ld -o hexdump3 hexdump3.o ../textlib/textlib.o
 hexdump3.o: hexdump3.asm
 	nasm -f elf64 -g -F dwarf hexdump3.asm
```

<p align=justify>
Il file textlib.o è semplicemente posizionato sulla riga di invocazione del linker dopo il file .o per il programma stesso. C'è una sottigliezza nel makefile precedente: il file della libreria si trova su un percorso relativo alla directory contenente il progetto hexdump3. Posizionare ../textlib/ davanti al nome del file textlib.o consente al linker di raggiungere "su, attraverso e giù" attraverso il file system Linux nella directory del progetto per la libreria. Altrimenti, dovresti posizionare textlib.o nella stessa directory di hexdump3.o, o copiarlo in una directory sotto usr/lib, che si trova nel percorso di ricerca predefinito. Una directory sotto usr/lib sarebbe effettivamente un ottimo posto per esso, una volta che è finito e ben testato—per grandi valori di “ben testato.” Mentre stai ancora lavorando attivamente a una libreria, è meglio tenerla in una directory di progetto a sé stante all'interno della stessa struttura di directory di tutte le tue altre directory di progetto, così puoi correggere bug e aggiungere funzionalità che non ti vengono in mente fino a quando non l'hai usata per un po' a costruire altri programmi.
</p>

### I pericoli di troppe procedure e tropte librerie

<p align=justify>
Nella programmazione assembly, come nella vita, si può avere troppo di una cosa buona. Ho visto librerie di codice costituite da centinaia di file, ciascun file contenente una singola procedura. Queste non sono neanche procedure autonome. Si chiamano l'una con l'altra a destra e a manca, in una fitta rete di esecuzione che è molto difficile da tracciare a livello di codice sorgente, specialmente se hai ereditato una tale libreria da qualcun altro e devi afferrare (spesso molto rapidamente) come funzionano effettivamente i meccanismi implementati dalla libreria. In assenza di una documentazione testuale molto dettagliata, non c'è una “vista dall'alto” che ti aiuti a capire cosa chiama cosa e da dove. Se la libreria proviene da un'altra parte ed è usata come una “scatola nera”, ciò potrebbe non essere una catastrofe, anche se mi piace comunque sapere come funzionano le librerie che utilizzo. C'è, ahimè, una ragione valida per creare librerie con singole procedure come questa: quando colleghi una libreria a un programma, l'intera libreria viene aggiunta al file eseguibile, comprese quelle procedure e definizioni di dati che non vengono mai referenziate dal programma principale. Se ogni procedura viene assemblata separatamente in un suo comodo file .o, il linker aggiungerà solo quelle procedure al tuo programma che verranno effettivamente chiamate da (e quindi eseguite da) esso. Molto dipende da dove finisce il tuo codice. Se il tuo obiettivo è il file eseguibile più piccolo possibile, questo è significativo, e ci sono alcuni continenti nel mondo del linguaggio assembly (soprattutto quelli relativi ai sistemi embedded) dove ogni byte conta e il “codice morto” che non viene mai eseguito aggiunge costi inutili all'hardware di fascia bassa su cui il codice deve girare. La dimensione del codice in linguaggio assembly non sarà un problema su normali PC Linux con 16 gigabyte di memoria e un terabyte di disco. Se è lì che il tuo codice girerà, potresti trovare più vantaggioso avere meno librerie e più codice sorgente comprensibile, anche se finisci con qualche migliaio di byte di codice nei tuoi file eseguibili che in realtà non incontrano mai la CPU faccia a faccia.
</p>

### L'arte di creare procedure

<p align=justify>
Creare delle procedure richiede un po' più di semplicemente ritagliare una sezione di codice da uno dei tuoi programmi e farne un panino CALL e RET. Lo scopo principale dell'intera idea di procedure è quello di rendere il tuo codice più manutenibile, raggruppando istruzioni che servono a uno scopo comune in entità nominate. Non dimenticare i marziani e come hanno rapito il mio sfortunato formattatore di testo APL nel 1977. La manutenibilità è probabilmente il più difficile problema da risolvere nel design software, e la manutenibilità dipende completamente dalla comprensibilità. L'intera idea nella creazione di librerie di procedure è quella di rendere il tuo codice comprensibile— principalmente per te, ma molto probabilmente anche per altre persone che potrebbero ereditare o tentare di utilizzare il tuo codice. Quindi, in questa sezione, parlerò un po' di come pensare alle procedure e al processo della loro creazione, tenendo a mente la manutenibilità del codice.
</p>

### Manutenibilità e Riutilizzo

<p align=justify>
Lo scopo più importante delle procedure è gestire la complessità nei tuoi programmi sostituendo una sequenza di istruzioni di macchina con un nome descrittivo. Il secondo scopo più importante è il riutilizzo del codice. Non ha senso riscrivere gli stessi meccanismi comuni da zero ogni volta che inizi un nuovo progetto. Scrivili una volta, scrivili bene e usali per sempre. I due scopi interagiscono. Il riutilizzo del codice aiuta la manutenibilità del codice in vari modi:
</p>

<ul>
	<li>
		<p align=justify>
		Il riutilizzo significa che c'è meno codice in totale da mantenere in tutti i tuoi progetti.
 		</p>
	</li>
 	<li>
		<p align=justify>
		Il riutilizzo mantiene il tuo tempo e sforzo investiti nella debug.
 		</p>
	</li>
  	<li>
		<p align=justify>
		Il riutilizzo ti costringe a mantenere determinate convenzioni di codifica nei tuoi progetti nel tempo (perché le tue librerie lo richiedono), il che conferisce ai tuoi progetti una "somiglianza di famiglia" che li rende più facili da comprendere dopo che sei stato lontano da essi per un po'.
 		</p>
	</li>
  	<li>
		<p align=justify>
		Il riuso significa che avrai meno sequenze di codice che fanno praticamente la stessa cosa, ma in modi leggermente diversi.
 		</p>
	</li>
 
</ul>

<p align=justify>
Questo ultimo punto è sottile ma importante. Quando stai facendo debugging, ciò a cui ti riferisci costantemente nella parte posteriore della tua mente è la comprensione di come funziona ogni sezione del tuo programma. Ti piacerebbe che questa comprensione fosse unica per ogni programma che scrivi, ma non funziona in questo modo. La memoria è imprecisa e i ricordi di cose separate ma molto simili tendono a confondersi dopo un certo periodo di tempo. (Velocemente: è una Toyota 4Runner del 2001 o una Toyota 4Runner del 2003?) Nella programmazione, i dettagli sono cruciali e nella programmazione in linguaggio assembly ci sono molti dettagli. Se hai scritto a mano una procedura RefreshText tre volte per tre programmi diversi che differiscono solo in modi minori, potresti fare affidamento su una comprensione di un'implementazione di RefreshText mentre stai guardando un'altra. Più indietro nel tempo vanno queste procedure simili ma non identiche, più è probabile che tu le confonda e perda tempo a chiarire le piccole peculiarità di come ciascuna di esse funziona. Tuttavia, se c'è solo una procedura RefreshText, c'è solo una comprensione di RefreshText da avere. Tutti i punti di vantaggio della riutilizzazione menzionati si riducono a questo: gestire la complessità semplicemente riducendo la quantità di complessità che deve essere gestita.
</p>

### Decidere cosa dovrebbe essere una procedura

Quindi, quando dovrebbe essere estratto un blocco di istruzioni e trasformato in una procedura? Non ci sono regole rigide, ma ci sono alcune euristiche utili che vale la pena discutere:

<ul>
	<li>
		<p align=justify>
		Cerca azioni che accadono frequentemente all'interno di un programma
 		</p>
	</li>
 	<li>
		<p align=justify>
		Cerca azioni che potrebbero non accadere molto frequentemente all'interno di un singolo programma, ma che tendono a verificarsi in modi simili in molti o nella maggior parte dei programmi.
 		</p>
	</li>
  	<li>
		<p align=justify>
		Quando i programmi diventano grandi (e con "grandi" intendo oltre alla classe dimostrativa del libro di tutorial; diciamo circa 1.000 righe), cerca dei blocchi funzionali che possono essere trasformati in procedure in modo che il flusso complessivo di esecuzione nel programma principale diventi più breve, semplice e quindi più facile da comprendere. (Di più su questo tra un momento.)
 		</p>
	</li>
  	<li>
		<p align=justify>
		Cerca azioni all'interno di un programma che possono cambiare nel tempo in risposta a forze fuori dal tuo controllo (specifiche dei dati, librerie di terze parti, cose del genere) e isola quelle azioni in procedure.
 		</p>
	</li>
 
</ul>

<p align=justify>
In breve: Pensa in grande e pensa a lungo termine. Non rimarrai un principianti per sempre. Cerca di anticipare i tuoi sforzi di programmazione "nel lungo periodo" e crea procedure di utilità generale. "Generale" qui significa non solo utile all'interno del singolo programma su cui stai lavorando attualmente, ma anche utile nei programmi che scriverai in futuro. Non c'è una "dimensione minima" per le procedure se vengono chiamate abbastanza frequentemente. Procedure estremamente semplici, anche quelle con sole quattro o cinque istruzioni, non nascondono di per sé una grande complessità. Forniscono nomi descrittivi per determinate azioni frequentemente utilizzate, il che è prezioso di per sé. Possono anche fornire mattoni di base standard per la creazione di procedure più grandi e potenti. Detto ciò, una breve sequenza di codice (5-10 istruzioni) che viene chiamata solo una volta o forse due volte all'interno di un programma di media grandezza di diverse centinaia di istruzioni macchina è un cattivo candidato per essere una procedura, a meno che non sia un candidato per il riutilizzo in programmi futuri. Allora appartiene a una libreria di codice, e il codice non può essere in una libreria a meno che non sia in una procedura. Non c'è neanche una "dimensione massima" per le procedure, e ci sono circostanze in cui procedure molto grandi hanno senso, se servono a uno scopo ben definito. Ricorda che le procedure non devono sempre essere in librerie. Potresti trovare utile definire procedure grandi che vengono chiamate solo una volta quando il tuo programma diventa sufficientemente grande da richiedere di essere suddiviso in parti funzionali per la comprensibilità. Un programma in linguaggio assembly di mille righe potrebbe essere suddiviso bene in una sequenza di sette o otto procedure grandi. Ogni procedura è destinata ad essere chiamata solo una volta dal programma principale, ma questo consente al tuo programma principale di essere breve, facilmente comprensibile e molto indicativo di ciò che il programma sta facendo:
</p>

```asm
 Start: call Initialize    ; Open spec files, create buffers
        call OpenFile      ; Open the target data file
 Input: call GetRec        ; Fetch a record from the open file
        cmp rax,0          ; Test for EOF on file read
	je Done            ; If we've hit EOF, time to shut'er down
        call ProcessRec    ; Crunch the rec     
        call VerifyRec     ; Validate the modified data against the spec
        call WriteRec      ; Write the modified record out to the file
        jmp Input          ; Go back and do it all again
 Done:  call CloseFile     ; Close the opened file
        call CleanUp       ; Delete the temp files
        mov rax,60         ; Code for Exit system call
        mov rdi,0          ; Return a code of zero
        syscall            ; Make system call
```

<p align=justify>
Questo corpo di programma (immaginario) è pulito e leggibile e fornisce una necessaria visione dall'alto quando inizi ad avvicinarti a un programma in linguaggio assembly di mille righe. Ricorda che i marziani si nascondono sempre da qualche parte nelle vicinanze, ansiosi di trasformare i tuoi programmi in geroglifici illeggibili. Non c'è arma contro di loro con metà della potenza delle procedure.
</p>

### Usare i commenti!

<p align=justify>
Col passare del tempo, ti renderai conto di creare dozzine o addirittura centinaia di procedure per gestire la complessità. Le librerie di procedure “pronte” che la maggior parte dei fornitori di linguaggi di alto livello fornisce con i propri compilatori non esistono affatto con NASM. Per lo più, quando hai bisogno di una funzione o di un'altra, dovrai scriverla tu stesso. Mantenere un elenco di routine ordinato non è un compito facile quando le hai scritte tutte tu. Devi documentare i fatti essenziali su ciascuna procedura individuale o le dimenticherai, oppure le ricorderai in modo errato e agirai su informazioni sbagliate. (I bug risultanti sono spesso diavolosamente difficili da trovare perché sei sicuro di ricordare tutto ciò che c'è da sapere su quella procedura! Dopotutto, l'hai scritta tu!) Raccomando vivamente di aggiungere un'intestazione di commento a ogni procedura che scrivi, non importa quanto semplice. Tale intestazione dovrebbe contenere almeno le seguenti informazioni:
</p>

* Il nome della procedura
* La data dell'ultima modifica
* Il nome di ciascun punto di entrata, se la procedura ha più punti di entrata
* Cosa fa la procedura
* Quali elementi di dati il chiamante deve passarle per farla funzionare correttamente
* Quali dati (se presenti) vengono restituiti dalla procedura e dove vengono restituiti (ad esempio, nel registro RCX)
* Quali registri o elementi di dati la procedura modifica
* Quali altre procedure, se presenti, vengono chiamate dalla procedura
* Eventuali "gotchas" che devono essere tenuti a mente mentre si scrive codice che utilizza la procedura
* Oltre a ciò, altre informazioni possono essere utili nei commenti di intestazione:
	* La versione della procedura, se si utilizza il versioning
 	* La data di creazione
  	* Il nome della persona che ha scritto la procedura, se si sta trattando di codice condiviso all'interno di un team

 ```asm
--------
; LoadBuff:     Fills a buffer with data from stdin via syscall sys_read
; UPDATED:      10/9/2022
; IN:	        Nothing          
; RETURNS:      # of bytes read in RAX
; MODIFIES:     RCX, R15, Buff
; CALLS:        syscall sys_read
; DESCRIPTION:  Loads a buffer full of data (BUFFLEN bytes) from stdin     
; 		using syscall sys_read and places it in Buff.
: 		offset counter RCX is zeroed, because we're
; 		on a new buffer full of data. Caller must test
; 		RAX: If RAX contains 0 on return, we hit EOF on stdin
; 		< 0 in RAX on return indicates some kind of
```

<p align=justify>
Un'intestazione di commento non ti solleva dalla responsabilità di commentare le singole righe di codice all'interno della procedura! Come ho detto molte volte, è una buona idea mettere un breve commento a destra di ogni riga che contiene un mnemonico di istruzione della macchina, e anche (nelle procedure più lunghe) un blocco di commento che descriva ogni blocco funzionale principale all'interno della procedura.
</p>

### Controllo semplice del cursore nella console di Linux

<p align=justify>
Come passaggio dalle procedure del linguaggio assembly ai macro del linguaggio assembly, vorrei dedicare un po' di tempo ai dettagli del controllo della visualizzazione della console di Linux all'interno dei vostri programmi. Torniamo al nostro piccolo display pubblicitario per il diner di Joe. Andiamo a migliorarlo un po', prima cancellando la console di Linux e poi centrando il testo dell'annuncio sulla visualizzazione cancellata. Presenterò lo stesso programma due volte, prima con diverse parti espresse come procedure e in seguito con le stesse parti espresse come macro. Procediamo con le procedure per prime, come mostrato nel codice di sotto.
</p>

```asm
;  Executable name : eattermgcc
;  Version         : 2.0
;  Created date    : 6/18/2022
;  Last update     : 5/17/2023
;  Author          : Jeff Duntemann
;  Description     : A simple program in assembly for Linux, using 
;                  : NASM 2.15, demonstrating the use of escape 
;                  : sequences to do simple "full-screen" text output
;                  : to a terminal like Konsole.
;
;  Build using SASM's x64 build configuration.
;
;  Run by executing the executable binary file.
;

section .data      ; Section containing initialised data

    SCRWIDTH       equ 80             ; Default is 80 chars wide
    PosTerm:       db 27,"[01;01H"    ; <ESC>[<Y>;<X>H
    POSLEN         equ $-PosTerm      ; Length of term position string
    ClearTerm:     db 27,"[2J"        ; <ESC>[2J
    CLEARLEN       equ $-ClearTerm    ; Length of term clear string
    AdMsg:         db "Eat At Joe's!" ; Ad message
    ADLEN          equ $-AdMsg        ; Length of ad message
    Prompt:        db "Press Enter: " ; User prompt
    PROMPTLEN      equ $-Prompt       ; Length of user prompt

; This table gives us pairs of ASCII digits from 0-80. Rather than 
; calculate ASCII digits to insert in the terminal control string, 
; we look them up in the table and read back two digits at once to 
; a 16-bit register like DX, which we then poke into the terminal 
; control string PosTerm at the appropriate place. See GotoXY.
; If you intend to work on a larger console than 80 X 80, you must
; add additional ASCII digit encoding to the end of Digits. Keep in
; mind that the code shown here will only work up to 99 X 99.
    Digits: db "0001020304050607080910111213141516171819"
            db "2021222324252627282930313233343536373839"
            db "4041424344454647484950515253545556575859"
            db "606162636465666768697071727374757677787980"

SECTION .bss       ; Section containing uninitialized data

SECTION .text      ; Section containing code

;-------------------------------------------------------------------------
; ClrScr:       Clear the Linux console
; UPDATED:      9/13/2022
; IN:           Nothing
; RETURNS:      Nothing
; MODIFIES:     Nothing
; CALLS:        SYSCALL sys_write
; DESCRIPTION:  Sends the predefined control Estring <ESC>[2J to the
;               console, which clears the full display

ClrScr:
    push rax          ; Save pertinent registers
    push rbx
    push rcx
    push rdx
    push rsi
    push rdi

    mov rsi,ClearTerm ; Pass offset of terminal control string
    mov rdx,CLEARLEN  ; Pass the length of terminal control string
    call WriteStr     ; Send control string to console

    pop rdi           ; Restore pertinent registers
    pop rsi
    pop rdx
    pop rcx
    pop rbx
    pop rax
    ret               ; Go home


;-------------------------------------------------------------------------
; GotoXY:       Position the Linux Console cursor to an X,Y position
; UPDATED:      9/13/2022
; IN:           X in AH, Y     nop            ; This no-op keeps gdb happy...in AL
; RETURNS:      Nothing
; MODIFIES:     PosTerm terminal control sequence string
; CALLS:        Kernel sys_write
; DESCRIPTION:  Prepares a terminal control string for the X,Y coordinates
;               passed in AL and AH and calls sys_write to position the
;               console cursor to that X,Y position. Writing text to the
;               console after calling GotoXY will begin display of text
;               at that X,Y position.

GotoXY:
    push rax                ; Save caller's registers
    push rbx
    push rcx
    push rdx
    push rsi

    xor rbx,rbx             ; Zero RBX
    xor rcx,rcx             ; Ditto RCX

; Poke the Y digits:
    mov bl,al                   ; Put Y value into scale term RBX
    mov cx,[Digits+rbx*2]  ; Fetch decimal digits to CX
    mov [PosTerm+2],cx ; Poke digits into control string

; Poke the X digits:
    mov bl,ah              ; Put X value into scale term EBX
    mov cx,[Digits+rbx*2]  ; Fetch decimal digits to CX
    mov [PosTerm+5],cx     ; Poke digits into control string

; Send control sequence to stdout:
    mov rsi,PosTerm         ; Pass address of the control string
    mov rdx,POSLEN          ; Pass the length of the control string
    call WriteStr           ; Send control string to the console

; Wrap up and go home:
    pop rsi                 ; Restore caller's registers
    pop rdx
    pop rcx			   
    pop rbx
    pop rax
    ret                     ; Go home

;-------------------------------------------------------------------------
; WriteCtr:     Send a string centered to an 80-char wide Linux console
; UPDATED:      5/10/2023
; IN:           Y value in AL, String address in RSI, string length in RDX
; RETURNS:      Nothing
; MODIFIES:     PosTerm terminal control sequence string
; CALLS:        GotoXY, WriteStr
; DESCRIPTION:  Displays a string to the Linux console centered in an
;               80-column display. Calculates the X for the passed-in 
;               string length, then calls GotoXY and WriteStr to send 
;               the string to the console

WriteCtr:
    push rbx           ; Save caller's RBX
    xor rbx,rbx        ; Zero RBX
    mov bl,SCRWIDTH    ; Load the screen width value to BL
    sub bl,dl          ; Take diff. of screen width and string length
    shr bl,1           ; Divide difference by two for X value
    mov ah,bl          ; GotoXY requires X value in AH
    call GotoXY        ; Position the cursor for display
    call WriteStr      ; Write the string to the console
    pop rbx            ; Restore caller's RBX
    ret                ; Go home


;-------------------------------------------------------------------------
; WriteStr:     Send a string to the Linux console
; UPDATED:      5/10/2023
; IN:           String address in RSI, string length in RDX
; RETURNS:      Nothing
; MODIFIES:     Nothing
; CALLS:        Kernel sys_write
; DESCRIPTION:  Displays a string to the Linux console through a 
;               sys_write kernel call

WriteStr:
    push rax    ; Save pertinent registers
    push rdi
    mov rax,1   ; Specify sys_write call
    mov rdi,1   ; Specify File Descriptor 1: Stdout
    syscall     ; Make the kernel call
    pop rdi     ; Restore pertinent registers
    pop rax
    ret         ; Go home

global  main

main:
    push rbp       ; Prolog
    mov rbp, rsp   ; for correct debugging

; First we clear the terminal display...
    call ClrScr

; Then we post the ad message centered on the 80-wide console:
    xor rax,rax    ; Zero out RAX.
    mov al,12
    mov rsi,AdMsg
    mov rdx,ADLEN
    call WriteCtr

; Position the cursor for the "Press Enter" prompt:
    mov rax,0117h  ; X,Y = 1,23 as a single hex value in AX
    call GotoXY    ; Position the cursor

; Display the "Press Enter" prompt:
    mov rsi,Prompt      ; Pass offset of the prompt
    mov rdx,PROMPTLEN   ; Pass the length of the prompt
    call WriteStr       ; Send the prompt to the console

; Wait for the user to press Enter:
    mov rax,0      ; Code for sys_read
    mov rdi,0      ; Specify File Descriptor 0: Stdin	
    syscall        ; Make kernel call

; And we're done!
Exit:
    pop rbp
    ret
   
```

<p align=justify>
C'è un nuovo macchinario qui. Tutti i programmi che ho presentato finora in questo libro inviano semplicemente righe di testo in sequenza all'output standard, e la console le visualizza sequenzialmente, ogni riga nella riga successiva, scorrendo verso l'alto dal fondo. Questo può essere molto utile, ma non è il meglio che possiamo fare. Nel Capitolo 6, descrivo brevemente il modo in cui la console di Linux può essere controllata inviando “sequenze di escape” incorporati nel flusso di testo che viaggia dal tuo programma a stdout. Sarebbe utile rileggere quella sezione “Controllo del terminale con sequenze di escape” se è passato del tempo, poiché non ricapitolerei a fondo qui. L'esempio più semplice di una sequenza di escape per controllare la console cancella l'intero display della console a spazi vuoti. (Fondamentalmente, caratteri di spazio.) Nel programma eattermgcc, questa sequenza è una variabile di stringa chiamata ClearTerm:
</p>

```
 ClearTerm:      db 27,"[2J"  ; <ESC>[2J
```

<p align=justify>
La sequenza di escape è long quattro caratteri. Inizia con ESC, un carattere non stampabile che di solito descriviamo con il suo valore decimale nella tabella ASCII, 27. (Oppure esadecimale, che è 1Bh.) Immediatamente dopo il carattere ESC ci sono i tre caratteri stampabili: [2J. Sono stampabili, ma non vengono stampati perché seguono ESC. La console controlla i caratteri ESC e interpreta qualsiasi carattere che segue ESC in un modo speciale, secondo uno schema ampio e molto complicato. Sequenze particolari rappresentano comandi particolari per la console, come questa, che svuota il display. Non c'è un marcatore alla fine di una sequenza di escape per indicare che la sequenza è finita. La console conosce ogni singola sequenza di escape a menadito, comprese le lunghezze di ciascuna e non ci sono ambiguità. Nel caso della sequenza ClearTerm, la console sa che quando vede il carattere “J”, la sequenza è completa. Poi svuota il suo display e riprende a visualizzare i caratteri che il tuo programma invia a stdout. Non è necessario fare nulla di speciale per inviare una sequenza di escape alla console. La sequenza di escape va a stdout tramite SYSCALL, proprio come tutto il testo. Puoi incorporare sequenze di escape nel mezzo di testo stampabile tramite un'attenta disposizione delle direttive DB nelle sezioni .text dei tuoi programmi. Questo è importante: anche se le sequenze di escape non vengono mostrate sul display della console, devono comunque essere contate quando passi la lunghezza di una sequenza di testo a sys_write tramite SYSCALL. La sequenza di escape per svuotare il display è facile da capire, perché è sempre la stessa e fa sempre la stessa cosa. La sequenza che posiziona il cursore è molto più complicata, perché richiede parametri che specificano la posizione X,Y a cui il cursore deve essere spostato. Ognuno di questi parametri è un numero decimale testuale a due cifre in ASCII che deve essere incorporato nella sequenza dal tuo programma prima che la sequenza venga inviata a stdout. Tutta la difficoltà nel muovere il cursore nella console Linux coinvolge l'incorporamento di quei parametri X e Y nella sequenza di escape. La sequenza predefinita come definita in eattermgcc si chiama PosTerm:
</p>

```asm
PosTerm:      db 27,"[01;01H"      ; <ESC>[<Y>;<X>H
```

<p align=justify>
Come con ClearTerm, inizia con un carattere ESC. Tra il carattere [ e il carattere H ci sono i due parametri. Il valore Y viene per primo ed è separato dal valore X da un punto e virgola. Nota bene che questi non sono numeri binari, ma due caratteri ASCII che rappresentano cifre numeriche decimali, in questo caso, ASCII 48 (0) e ASCII 49 (1). Non puoi semplicemente inserire il valore binario 1 nella sequenza di escape. La console non comprende il valore binario 1 come ASCII 49. I valori binari per le posizioni X e Y devono essere convertiti nei loro equivalenti ASCII e poi inseriti nella sequenza di escape. Questo è ciò che fa la procedura GotoXY. I valori binari vengono convertiti nei loro equivalenti ASCII consultando i caratteri ASCII in una tabella. La tabella Digits presenta rappresentazioni ASCII a due cifre di valori numerici da 0 a 80. I valori inferiori a 10 hanno zeri iniziali, come in 01, 02, 03, e così via. Ecco dove avviene la magia all'interno di GotoXY:
</p>

```asm
 ; Poke the Y digits:
 mov bl,al                ; Put Y value into scale term    
 mov cx,[Digits+rbx*2]    ; Fetch decimal digits to CX
 mov [PosTerm+2],cx       ; Poke digits into control string
 ; Poke the X digits:
 mov bl,ah   		  ; Put X value into scale term
 mov cx,[Digits+rbx*2]   ; Fetch decimal digits to CX
 mov [PosTerm+5],cx       ; Poke digits into control string
```

<p align=justify>
è posizionato in un RBX liberato che diventa un termine in un indirizzo efficace a partire da Digits. Poiché ogni elemento della tabella Digits è grande due caratteri, dobbiamo scalare l'offset per due. Il trucco (se ce n'è uno) consiste nel portare giù entrambi i numeri ASCII con un'unica referenza di memoria e collocarli nel registro a 16 bit CX. Con i due numeri ASCII in CX, poi li inseriamo simultaneamente nella loro corretta posizione nella stringa della sequenza di escape. Il valore Y inizia all'offset 2 nella stringa, e il valore X inizia all'offset 5. Una volta che la stringa PosTerm è stata modificata per una particolare coppia di coordinate X,Y, la stringa viene inviata a stdout e interpretata dalla console come una sequenza di escape che controlla la posizione del cursore. Il prossimo carattere inviato alla console apparirà nella nuova posizione del cursore, e i caratteri successivi seguiranno nelle posizioni successive finché non viene inviata un'altra sequenza di controllo del cursore alla console. Assicurati quando esegui programmi che emettono codici di controllo del cursore che la finestra della tua console sia più grande dei massimi valori X e Y che il tuo cursore assumerà, altrimenti le righe si piegheranno e nulla apparirà esattamente dove intendi. Il programma eattermgcc ha una tabella Digits valida fino a 80 × 80. Se desideri lavorare su un display più grande, dovrai espandere la tabella Digits con gli equivalenti ASCII dei valori a due cifre fino a 99. A causa del modo in cui la tabella è configurata e referenziata, puoi recuperare solo valori a due cifre, e quindi con il codice mostrato qui sei limitato a una console da 99 × 99 caratteri. Questo non è un problema serio, poiché gli schermi in modalità testo in Linux generalmente rispettano il vecchio standard dei terminali di testo di 80 × 24.
</p>

### Avvertenze per il controllo della console

<p align=justify>
Tutto ciò sembra fantastico, ma non è proprio così fantastico come sembra. Le sequenze di controllo fondamentali come cancellare il display e spostare il cursore sono probabilmente universali e funzioneranno in modo identico su qualsiasi console Linux tu possa trovare. Certamente funzionano su GNOME Terminal e Konsole, le due utility per terminale console più popolari per le distro Linux basate su Debian. Sfortunatamente, la storia dei terminal Unix e del controllo del terminale è una storia molto macchiata e, per le funzioni di controllo della console più avanzate, le sequenze potrebbero non essere supportate o potrebbero essere diverse da un'implementazione della console all'altra. Per garantire che tutto funzioni, i tuoi programmi dovrebbero sondare la console per scoprire quale specifica del terminale supporta e poi emettere le sequenze di escape di conseguenza. È un peccato. In Konsole, la seguente sequenza di escape rende lo sfondo della console verde:
</p>

```asm
 GreenBack:    db 27,"[42m"
```

<p align=justify>
Almeno lo fa in Konsole. Quanto sia universale questa sequenza e altre simili, non lo so. Stessa cosa per la moltitudine di altri comandi di controllo della console, tramite i quali puoi accendere e spegnere i LED della tastiera del PC, modificare i colori del primo piano, visualizzare con sottolineature, e così via. Maggiori informazioni su questo (nello stile conciso di Unix) possono essere trovate nelle pagine man di Linux sotto la parola chiave "console_codes". Ti invito a sperimentare, tenendo presente che diverse console (soprattutto quelle su implementazioni Unix non Linux) possono reagire in modi diversi a sequenze diverse. Tuttavia, controllare l'output della console non è la cosa peggiore. Il sacro graal della programmazione in console è creare applicazioni testuali a schermo intero che "disegnano" un modulo sulla console, completo di campi per l'inserimento dati, e poi consentire all'utente di passare da un campo all'altro, inserendo dati in ogni campo. Questo diventa diabolico in Linux a causa della necessità di accedere a singole pressioni di tasti sulla tastiera della console, attraverso qualcosa chiamato modalità raw. Anche solo spiegare come funziona la modalità raw richiederebbe la maggior parte di un capitolo e coinvolgerebbe molti argomenti Linux piuttosto avanzati, per i quali non ho spazio in questo libro. Il modo standard di Unix per trattare la console è una libreria C chiamata ncurses, e anche se ncurses può essere chiamata dall'assembly, è veramente una cosa pesante e brutta. Una scelta migliore per i programmatori in assembly è una libreria molto più recente scritta specificamente per l'assembly NASM, chiamata LinuxAsmTools. È stata originariamente scritta da Jeff Owens e fa quasi tutto ciò che fa ncurses senza le convenzioni di chiamata forzate di C e altri pesanti cruft di C. LinuxAsmTools è gratuita e open-source. Purtroppo, dovrai cercarla. Fai una ricerca su Google per "Linux ASM Tools" e dovresti trovare un link, molto probabilmente a GitHub. La libreria è stata spostata diverse volte da quando l'ho scoperta per la prima volta a metà degli anni 2000, e sospetto che si sposterà di nuovo.
</p>

### Creare ed Usare Macro

<p align=justify>
Ci sono più di un modo per suddividere un programma in linguaggio assembly in segmenti più gestibili. Le procedure sono il modo più ovvio e certamente il più facile da comprendere. Il meccanismo per chiamare e tornare dalle procedure è integrato direttamente nella CPU ed è indipendente da qualsiasi prodotto assembler specifico. I principali assemblatori odierni forniscono un altro strumento di gestione della complessità: le macro. Le macro sono tutta un'altra cosa. Mentre le procedure sono implementate tramite le istruzioni CALL e RET integrate nel set di istruzioni, le macro sono un'astuzia dell'assembler e non dipendono da nessuna istruzione particolare o gruppo di istruzioni. In termini semplici, una macro è un'etichetta che rappresenta una sequenza di righe di testo. Questa sequenza di righe di testo può essere (ma non è necessariamente) una sequenza di istruzioni. Quando l'assembler incontra l'etichetta della macro in un file di codice sorgente, sostituisce l'etichetta della macro con le righe di testo che rappresenta. Questo è chiamato macro, perché il nome della macro (che occupa una riga di testo) viene sostituito da più righe di testo, che vengono quindi assemblate come se fossero apparse nel file di codice sorgente fin dall'inizio. (Naturalmente, una macro non deve per forza consistere in più righe di testo. Può essere solo una - ma in tal caso ci sono molti meno vantaggi nell'usarle!) Le macro somigliano a file di inclusione, come quelli che ho spiegato in precedenza in questo capitolo. Potresti pensare a una macro come a un file di inclusione integrato nel file di codice sorgente. È una sequenza di righe di testo che viene definita una volta, data un nome descrittivo e poi inserita nel codice sorgente continuamente secondo necessità semplicemente utilizzando il nome della macro. Questo processo è mostrato nella figura di sotto. Il codice sorgente memorizzato su disco ha una definizione della macro, racchiusa tra le direttive %MACRO e %ENDMACRO. Più avanti nel file, il nome della macro appare più volte. Quando l'assembler elabora questo file, copia la definizione della macro in un buffer da qualche parte nella memoria. Mentre assembla il testo letto dal disco, l'assembler inserisce le istruzioni contenute nella macro nel testo ovunque compaia il nome della macro. Il file sul disco non viene influenzato; l'espansione delle macro avviene solo in memoria.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/how_macros_work.png">
</div>

### Il Meccanisco della definizione di Macro

<p align=justify>
Una definizione di macro assomiglia un po' a una definizione di procedura, racchiusa tra una coppia di direttive speciali NASM: %MACRO e %ENDMACRO. Si noti che la direttiva %ENDMACRO si trova sulla riga dopo l'ultima riga della macro. Non commettere l'errore di trattare %ENDMACRO come un'etichetta che segna l'ultima riga della macro. Una piccola mancanza delle macro rispetto alle procedure è che le macro possono avere solo un punto di entrata. Una macro, in fin dei conti, è una sequenza di righe di codice che vengono inserite nel programma nel corso dell'esecuzione. Non si chiama una macro e non si ritorna da essa. La CPU la esegue proprio come esegue qualsiasi sequenza di istruzioni. Molte o la maggior parte delle procedure possono essere espresse come macro con un po' di attenzione. Nella codice di sotto, ho preso il programma precedente e ho convertito tutte le procedure in macro affinché tu possa vedere le differenze tra i due approcci.
</p>

```asm
;  Executable name : eatmacro
;  Version         : 2.0
;  Created date    : 10/11/2022
;  Last update     : 7/18/2023
;  Author          : Jeff Duntemann
;  Description     : A simple program in assembly for Linux, using 
;                  : NASM 2.14.2, demonstrating the use of escape 
;                  : escape sequences to do simple "full-screen" text
;                  ; output through macros rather than procedures
;
;  Build using these commands:
;    nasm -f elf -g -F dwarf eatmacro.asm
;    ld -o eatmacro eatmacro.o
;
;
section .data      ; Section containing initialized data

    SCRWIDTH:   equ 80              ; By default 80 chars wide
    PosTerm:    db 27,"[01;01H"     ; <ESC>[<Y>;<X>H
    POSLEN:     equ $-PosTerm       ; Length of term position string
    ClearTerm:  db 27,"[2J"         ; <ESC>[2J
    CLEARLEN    equ $-ClearTerm     ; Length of term clear string
    AdMsg:      db "Eat At Joe's!"  ; Ad message
    ADLEN:      equ $-AdMsg         ; Length of ad message
    Prompt:     db "Press Enter: "  ; User prompt
    PROMPTLEN:  equ $-Prompt        ; Length of user prompt

; This table gives us pairs of ASCII digits from 0-80. Rather than 
; calculate ASCII digits to insert in the terminal control string, 
; we look them up in the table and read back two digits at once to 
; a 16-bit register like DX, which we then poke into the terminal 
; control string PosTerm at the appropriate place. See GotoXY.
; If you intend to work on a larger console than 80 X 80, you must
; add additional ASCII digit encoding to the end of Digits. Keep in
; mind that the code shown here will only work up to 99 X 99.
    Digits: db "0001020304050607080910111213141516171819"
	        db "2021222324252627282930313233343536373839"
            db "4041424344454647484950515253545556575859"
            db "606162636465666768697071727374757677787980"

SECTION .bss       ; Section containing uninitialized data

SECTION .text      ; Section containing code

;-------------------------------------------------------------------------
; ExitProg:     Terminate program and return to Linux
; UPDATED:      10/11/2022
; IN:           Nothing
; RETURNS:      Nothing
; MODIFIES:     Nothing
; CALLS:        Kernel sys_exit
; DESCRIPTION:  Calls syscall sys_edit to terminate the program and return
;               control to Linux

%macro  ExitProg 0
    mov rsp,rbp     ; Epilog
    pop rbp

    mov rax,60      ; 60 = exit the program
    mov rdi,0       ; Return value in rdi 0 = nothing to return
    syscall         ; Call syscall sys_exit to return to Linux
%endmacro


;-------------------------------------------------------------------------
; WaitEnter:    Wait for the user to press Enter at the console
; UPDATED:      10/11/2022
; IN:           Nothing
; RETURNS:      Nothing
; MODIFIES:     Nothing
; CALLS:        Kernel sys_read
; DESCRIPTION:  Calls sys_read to wait for the user to type a newline at
;               the console

%macro WaitEnter 0
    mov rax,0      ; Code for sys_read
    mov rdi,0      ; Specify File Descriptor 0: Stdin	
    syscall        ; Make kernel call
%endmacro


;-------------------------------------------------------------------------
; WriteStr:     Send a string to the Linux console
; UPDATED:      5/10/2023
; IN:           String address in %1, string length in %2
; RETURNS:      Nothing
; MODIFIES:     Nothing
; CALLS:        Kernel sys_write
; DESCRIPTION:  Displays a string to the Linux console through a 
;               sys_write kernel call

%macro WriteStr 2   ; %1 = String address; %2 = string length
    push r11    ; Save pertinent registers
    push rax
    push rcx
    mov rax,1   ; 1 = sys_write for syscall
    mov rdi,1   ; 1 = fd for stdout; i.e., write to the terminal window
    mov rsi,%1  ; Put address of the message string in rsi
    mov rdx,%2  ; Length of string to be written in rdx
    syscall     ; Make the system call
    pop rcx
    pop rax
    pop r11
%endmacro


;-------------------------------------------------------------------------
; ClrScr:       Clear the Linux console
; UPDATED:      5/10/2023
; IN:           Nothing
; RETURNS:      Nothing
; MODIFIES:     Nothing
; CALLS:        Kernel sys_write
; DESCRIPTION:  Sends the predefined control string <ESC>[2J to the
;               console, which clears the full display

%macro ClrScr 0
    push rax    ; Save pertinent registers
    push rbx
    push rcx
    push rdx
    push rsi
    push rdi
; Use WriteStr macro to write control string to console:
	WriteStr ClearTerm,CLEARLEN
	pop rdi     ; Restore pertinent registers
	pop rsi
	pop rdx
	pop rcx
	pop rbx
	pop rax	
%endmacro


;-------------------------------------------------------------------------
; GotoXY:       Position the Linux Console cursor to an X,Y position
; UPDATED:      10/11/2022
; IN:           X in %1, Y in %2
; RETURNS:      Nothing
; MODIFIES:     PosTerm terminal control sequence string
; CALLS:        Kernel sys_write
; DESCRIPTION:  Prepares a terminal control string for the X,Y coordinates
;               passed in AL and AH and calls sys_write to position the
;               console cursor to that X,Y position. Writing text to the
;               console after calling GotoXY will begin display of text
;               at that X,Y position.

%macro GotoXY 2 ; %1 is X value; %2 id Y value		
    push rdx          ; Save caller's registers
    push rcx
    push rbx
    push rax
    push rsi
    push rdi
    xor rdx,rdx       ; Zero EDX
    xor rcx,rcx       ; Ditto ECX
; Poke the Y digits:
    mov dl,%2                  ; Put Y value into offset term EDX
    mov cx,word [Digits+rdx*2] ; Fetch decimal digits to CX
    mov word [PosTerm+2],cx    ; Poke digits into control string
; Poke the X digits:
    mov dl,%1                    ; Put X value into offset term EDX
    mov cx,word [Digits+rdx*2]   ; Fetch decimal digits to CX
    mov word [PosTerm+5],cx	     ; Poke digits into control string
; Send control sequence to stdout:
    WriteStr PosTerm,POSLEN
; Wrap up and go home:
    pop rdi           ; Restore caller's registers
    pop rsi
    pop rbx
    pop rcx
    pop rdx
%endmacro

;-------------------------------------------------------------------------
; WriteCtr:     Send a string centered to an 80-char wide Linux console
; UPDATED:      5/10/2023
; IN:           Y value in %1, String address in %2, string length in %3
; RETURNS:      Nothing
; MODIFIES:     PosTerm terminal control sequence string
; CALLS:        GotoXY, WriteStr
; DESCRIPTION:  Displays a string to the Linux console centered in an
;               80-column display. Calculates the X for the passed-in 
;               string length, then calls GotoXY and WriteStr to send 
;               the string to the console

%macro WriteCtr 3  ; %1 = row; %2 = String addr; %3 = String length
    push rbx       ; Save caller's RBX
    push rdx       ; Save caller's RDX
    mov rdx,%3     ; Load string length into RDX
    xor rbx,rbx      ; Zero RBX
    mov bl,SCRWIDTH  ; Load the screen width value to BL
    sub bl,dl      ; Calc diff. of screen width and string length
    shr bl,1       ; Divide difference by two for X value
    GotoXY bl,%1   ; Position the cursor for display
    WriteStr %2,%3 ; Write the string to the console
    pop rdx        ; Restore caller's RDX
    pop rbx        ; Restore caller's RBX
%endmacro


global  _start     ; Linker needs this to find the entry point!

_start:
    push rbp       ; Stack alignment ptolog
    mov rbp,rsp    ; for correct debugging
    and rsp,-16

; First we clear the terminal display...
	ClrScr
; Then we post the ad message centered on the 80-wide console:
	WriteCtr 12,AdMsg,ADLEN
; Position the cursor for the "Press Enter" prompt:
	GotoXY 1,23
; Display the "Press Enter" prompt:
	WriteStr Prompt,PROMPTLEN	
; Wait for the user to press Enter:
	WaitEnter
; Aand we're done!
    ExitProg
```

<p align=justify>
Confronta i macro in eatmacro con i loro equivalenti di procedura in eattermgcc. Hanno eliminato le loro istruzioni RET (e per quei macro che invocano altri macro, le loro istruzioni CALL) ma per la maggior parte consistono quasi esattamente nello stesso codice. I macro sono invocati semplicemente nominando loro. Ancora una volta, non usare l'istruzione CALL. Basta scrivere il nome del macro su una riga.
</p>

```asm
ClrScr
```

<p align=justify>
L'assemblatore si occuperà del resto
</p>

### Definire Macron con parametri

<p align=justify>
Le macro sono per la maggior parte un semplice trucco di sostituzione del testo, ma la sostituzione del testo ha alcune caratteristiche interessanti e a volte utili. Una di queste è la possibilità di passare parametri a un macro quando il macro viene invocato. Ad esempio, in eatmacro c'è un'invocazione del macro WriteCtr con tre parametri.
</p>

```asm
 WriteCtr 12,AdMsg,ADDLEN
```

<p align=justify>
La costante letterale 12 viene passata "dentro" il macro e utilizzata per specificare la riga dello schermo su cui il testo centrato deve essere visualizzato; in questo caso, la riga 12 dall'alto. Potresti sostituire il 12 con 3 o 16 o qualsiasi altro numero inferiore al numero di righe attualmente visualizzate nella console Linux. (Se tenti di posizionare il cursore su una riga che non esiste nella console, i risultati sono difficili da prevedere. In genere, il testo appare sulla riga inferiore del display.) Gli altri due parametri ricevono l'indirizzo e la lunghezza della stringa da visualizzare. I parametri del macro sono, di nuovo, artefatti dell'assemblatore. Non vengono spinti nello stack o impostati in un'area di memoria condivisa o qualcosa del genere. I parametri sono semplicemente segnaposto per i valori effettivi (chiamati) che passi al macro attraverso i suoi parametri. Diamo un'occhiata più da vicino al macro WriteCtr per vedere come funziona:
</p>

```asm
%macro WriteCtr 3  ; %1 = row; %2 = String addr; %3 = String length
    push rbx       ; Save caller's RBX
    push rdx       ; Save caller's RDX
    mov rdx,%3     ; Load string length into RDX
    xor rbx,rbx        ; Zero RBX
    mov bl,SCRWIDTH    ; Load the screen width value to BL
    sub bl,dl      ; Calc diff. of screen width and string length
    shr bl,1       ; Divide difference by two for X value
    GotoXY bl,%1   ; Position the cursor for display
    WriteStr %2,%3 ; Write the string to the console
    pop rdx        ; Restore caller's RDX
    pop rbx        ; Restore caller's RBX
 %endmacro

```

<p align=justify>
Quindi, dove sono i parametri? Questa è un'altra area in cui NASM differisce radicalmente da MASM di Microsoft. MASM ti consente di utilizzare nomi simbolici—come la parola Row o StringLength—per rappresentare i parametri. NASM si basa su un sistema più semplice che dichiara il numero di parametri nella definizione della macro e poi fa riferimento a ciascun parametro per numero all'interno della macro, piuttosto che tramite un nome simbolico. Nella definizione della macro WriteCtr, il numero 3 dopo il nome della macro indica che l'assemblatore deve cercare tre parametri. Questo numero deve essere presente—anche come 0—anche quando hai una macro come ClrScr senza parametri. Ogni macro deve avere un conteggio dei parametri. Nella definizione della macro, i parametri sono referenziati per numero. %1 indica il primo parametro utilizzato dopo l'invocazione del nome della macro WriteCtr. %2 indica il secondo parametro, contando da sinistra a destra. %3 indica il terzo parametro, e così via. I valori effettivi passati nei parametri sono chiamati argomenti. Non confondere i valori effettivi con i parametri. Se capisci Pascal, è esattamente come la differenza tra parametri formali e parametri effettivi. I parametri di una macro corrispondono ai parametri formali di Pascal, mentre gli argomenti di una macro corrispondono ai parametri effettivi di Pascal. I parametri della macro sono le etichette che seguono il nome della macro nella riga in cui è definita. Gli argomenti sono i valori specificati sulla riga in cui la macro è invocata. I parametri delle macro sono un tipo di etichetta e possono essere referenziati ovunque all'interno della macro—ma solo all'interno della macro. In WriteCtr, il parametro %3 è referenziato come operando di un'istruzione MOV. L'argomento passato alla macro in %3 viene quindi caricato nel registro RDX. Gli argomenti delle macro possono essere passati come parametri ad altre macro. Questo è ciò che accade all'interno di WriteCtr quando WriteCtr invoca la macro WriteStr. WriteStr prende due parametri e WriteCtr passa i suoi parametri %2 e %3 a WriteStr come suoi argomenti.
</p>

### Il Meccanismo d'invocazione delle Macro

<p align=justify>
Puoi passare un valore costante letterale come argomento a una macro, proprio come il valore della riga è passato alla macro WriteCtr nel programma eatmacro. Puoi anche passare un nome di registro come argomento. Questo è legale ed è un'invocazione perfettamente ragionevole di WriteCtr:
</p>

```asm
 mov al,4
 WriteCtr al,AdMsg,ADLEN
```

<p align=justify>
All'interno del macro WriteCtr, NASM sostituisce il nome del registro AL con il parametro %1
</p>

```asm
GotoXY bl,%1  ; Position the cursor for display
```

<p align=justify>
diventa:
</p>

```asm
 GotoXY bl,al
```

<p align=justify>
Nota bene che tutte le consuete regole che governano gli operandi d'istruzione si applicano. Il parametro %1 può contenere solo un argomento a 8 bit, perché in ultima analisi %1 viene caricato in un registro a 8 bit all'interno di GotoXY. Non puoi legalmente passare il registro RBP o CX a WriteCtr nel parametro %1, perché non puoi spostare direttamente un registro a 64 bit, 32 bit o 16 bit in un registro a 8 bit. Allo stesso modo, puoi passare un indirizzo tra parentesi come argomento:
</p>

```asm
WriteCtr [RowValue],AdMsg,ADLEN
```

<p align=justify>
Questo presuppone, ovviamente, che RowValue sia una variabile nominata definita come un elemento dati a 8 bit. Se un parametro macro viene utilizzato in un'istruzione che richiede un argomento a 64 bit (come i parametri %2 e %3 di WriteCtr), puoi anche passare etichette che rappresentano indirizzi a 64 bit o valori numerici a 64 bit. Quando una macro viene invocata, i suoi argomenti sono separati da virgole. NASM inserisce gli argomenti nei parametri della macro in ordine, da sinistra verso destra. Se passi solo due argomenti a una macro con tre parametri, è probabile che tu riceva un messaggio di errore dall'assemblatore, a seconda di come hai fatto riferimento al parametro non compilato. Se passi più argomenti a una macro rispetto ai parametri disponibili per riceverli, gli argomenti superflui verranno ignorati.
</p>

### Etichette Locali all'interno di macro

<p align=justify>
I macro che ho incluso in eatmacro.asm sono stati progettati per essere semplici e piuttosto ovvi. Nessuno di essi contiene istruzioni di salto, ma il codice nelle macro può utilizzare salti condizionali e incondizionati proprio come il codice nelle procedure o nei corpi dei programmi. Tuttavia, c'è un problema importante con le etichette usate all'interno delle macro: Le etichette nei programmi in linguaggio assembly devono essere uniche, eppure una macro è essenzialmente duplicata nel codice sorgente tante volte quanto viene richiamata. Ciò significa che ci saranno messaggi di errore che segnalano etichette duplicate... a meno che le etichette di una macro non siano trattate come locali. Gli elementi locali non hanno significato al di fuori dell'immediato contesto in cui sono definiti. Le etichette locali a una macro non sono visibili al di fuori della definizione della macro, il che significa che non possono essere riferite se non dal codice all'interno dei confini %MACRO...%ENDMACRO. Tutte le etichette definite all'interno di una macro sono considerate locali alla macro e sono gestite in modo speciale dal montatore. Ecco un esempio; è un'adattamento di macro di un pezzo di codice che ho presentato in precedenza, per forzare i caratteri in un buffer da minuscole a maiuscole:
</p>

```asm
 %macro UpCase 2      ; %1 = Address of buffer; %2 = Chars in buffer
      mov rdx,%1     ; Place the offset of the buffer into rdx
      mov rcx,%2     ; Place the number of bytes in the buffer into rcx
 %%IsLC:cmp byte [rdx+rcx-1],'a'   ; Below 'a'?
      jb %%Bump                   ; Not lowercase. Skip
      cmp byte [rdx+rcx-1],'z'    ; Above 'z'?
      ja %%Bump                   ; Not lowercase. Skip
      sub byte [rdx+rcx-1],20h    ; Force byte in buffer to uppercase
 %%Bump:dec rcx                   ; Decrement character count
      jnz %%IsLC                  ; If more chars in the
 buffer, repeat
 %endmacro
```

<p align=justify>
Un'etichetta in una macro è resa locale all'inizio con due simboli di percentuale: %% . Quando si segna una posizione nella macro, l'etichetta locale deve essere seguita da un due punti. Quando è usata come operando per un'istruzione di salto o chiamata (come JA, JB e JNZ nel precedente), l'etichetta locale non è seguita da un due punti. La cosa importante è capire che a meno che le etichette IsLC e Bump non siano state rese locali alla macro aggiungendo il prefisso %% a ciascuna, ci sarebbero più istanze di un'etichetta nel programma (supponendo che la macro sia stata invocata più di una volta), e l'assemblatore genererebbe un errore di etichetta duplicata alla seconda e a ogni successiva invocazione. Poiché le etichette devono essere in effetti uniche all'interno del tuo programma, NASM prende un'etichetta locale come %%Bump e genera un'etichetta da essa che sarà unica nel tuo programma. Lo fa usando il prefisso ..@ più un numero di quattro cifre e il nome dell'etichetta. Ogni volta che la tua macro è invocata, NASM cambierà il numero e così genererà sinonimi unici per ogni etichetta locale all'interno della macro. L'etichetta %%Bump, per esempio, potrebbe diventare ..@1771.Bump per una data invocazione, e il numero sarebbe diverso ogni volta che la macro è invocata. Questo avviene in background, e raramente sarai consapevole che sta accadendo a meno che non leggi i file di elenco del dump di codice generati da NASM.
</p>

### Librerie Macro come File di Inclusione

<p align=justify>
Proprio come le procedure possono essere raccolte in moduli di libreria esterni al programma, così le macro possono essere raccolte in librerie di macro. Una libreria di macro non è altro che un file di testo che contiene il codice sorgente per le macro nella libreria. A differenza delle procedure raccolte in un modulo, le librerie di macro non sono assemblate separatamente e devono essere passate attraverso l'assemblatore ogni volta che il programma viene assemblato. Questo è un problema con le macro in generale, non solo con le macro raccolte nelle librerie. I programmi che gestiscono la complessità dividendo il codice in macro verranno assemblati più lentamente rispetto ai programmi che sono stati divisi in moduli assemblati separatamente. Data la velocità dei PC del 2020, questo è molto meno un problema oggi rispetto al 1989 quando ho scritto la prima edizione di questo libro, ma per progetti molto grandi può influire sulla velocità di costruzione. Le librerie di macro vengono utilizzate "includendole" nel file di codice sorgente del programma. Il mezzo per farlo è la direttiva %INCLUDE. La direttiva %INCLUDE precede il nome della libreria di macro:
</p>

```asm
%include "mylib.mac"
```

<p align=justify>
Tecnicamente, questa dichiarazione può trovarsi ovunque nel file di codice sorgente, ma è importante tenere presente che tutte le macro devono essere completamente definite prima di essere invocate. Per questo motivo, è una buona idea utilizzare la direttiva %INCLUDE vicino all'inizio della sezione .text del file di codice sorgente, prima di qualsiasi possibile invocazione di una delle macro della libreria. Se il file macro che desideri includere in un programma non si trova nella stessa directory del tuo programma, potrebbe essere necessario fornire un percorso completamente qualificato come parte della direttiva %INCLUDE:
</p>

```asm
 %include "../macrolibs/mylib.mac"
```

<p align=justify>
Altrimenti, NASM potrebbe non essere in grado di trovare il file macro e ti darà un messaggio di errore. (Fai un po' di ricerca se non sai come creare un percorso completamente qualificato in Linux, poiché non è davvero un argomento di programmazione.)
</p>

### Macro contro Procedure: Pro e Contro

<p align=justify>
Ci sono vantaggi nei macro rispetto alle procedure. Uno di questi è la velocità. Ci vuole tempo per eseguire le istruzioni CALL e RET che controllano l'ingresso e l'uscita da una procedura. In un macro, nessuna delle due istruzioni viene utilizzata. Vengono eseguite solo le istruzioni che svolgono il lavoro effettivo del macro, quindi il lavoro del macro viene eseguito il più rapidamente possibile. C'è un costo per questa velocità, e il costo è in memoria extra utilizzata, specialmente se il macro viene invocato un numero molto elevato di volte. Nota nella di sopra che tre invocazioni del macro WriteStr generano un totale di 18 istruzioni in memoria. Se il macro fosse stato impostato come una procedura, avrebbe richiesto le sei istruzioni nel corpo della procedura, più un'istruzione RET e tre istruzioni CALL per svolgere lo stesso lavoro. Questo richiederebbe un totale di otto istruzioni per l'implementazione della procedura e diciotto per l'implementazione del macro. E se il macro fosse chiamato cinque, sette volte o più, la differenza crescerebbe. Ogni volta che un macro viene chiamato, tutte le sue istruzioni vengono duplicate nel programma un'altra volta. Nei programmi brevi, questo potrebbe non essere un problema, e in situazioni in cui il codice deve essere il più veloce possibile—come nei driver grafici— i macro hanno molti vantaggi, eliminando il sovraccarico procedurale delle chiamate e dei ritorni. È un semplice compromesso da comprendere: pensa ai macro per la velocità e alle procedure per la compattezza.
</p>

<p align=justify>
D'altra parte, a meno che tu non stia veramente scrivendo qualcosa che dipende assolutamente dalle prestazioni—come i driver grafici—questo compromesso è minore al punto da essere insignificante. Per il software ordinario, la differenza di dimensione tra un'implementazione orientata alle procedure e un'implementazione orientata ai macro potrebbe essere di soli 2.000 o 3.000 byte, e la differenza di velocità probabilmente non sarebbe rilevabile. Su CPU moderne, è molto difficile prevedere le prestazioni di un determinato pezzo di software, e i dispositivi di archiviazione massicci e i sistemi di memoria rendono la dimensione del programma molto meno importante rispetto a un generatione fa. Se stai cercando di decidere se andare per procedure o per macro in un dato caso, fattori diversi dalla dimensione o dalla velocità prevarranno. Ad esempio, ho sempre trovato il software intensivo in macro molto più difficile da debug. Gli strumenti software non trattano necessariamente bene le macro. Ad esempio, il componente Insight del debugger Gdb non mostra il testo espanso delle macro nella sua finestra di codice sorgente. Insight non è stato progettato tenendo a mente il debug in puro assembly (Gdb, come la maggior parte degli strumenti Unix, ha un forte bias verso il C), e quando entri in una macro, l'evidenziazione del codice sorgente semplicemente si ferma, fino a quando l'esecuzione non esce dalla macro. Pertanto non puoi eseguire il passo attraverso il codice di una macro come puoi fare con il codice di procedura o programma. Gdb continuerà a fare il debug come sempre dalla finestra della console, ma il debug della console è un processo molto doloroso rispetto alla prospettiva visiva disponibile da SASM o Insight. Infine, c'è un'altra questione connessa alle macro che è molto più difficile da spiegare, ma è il motivo per cui mi sento famoso discomfort con esse: usa troppo le macro e il tuo codice non assomiglierà più al linguaggio assembly. Rivediamo la parte principale del programma eatmacro.asm, senza i suoi commenti:
</p>

```asm
 ClrScr
 WriteCtr 12,AdMsg,ADLEN
 GotoXY 1,23
 WriteStr Prompt,PROMPTLEN    
 WaitEnter
 ExitProg
```

<p align=justify>
Questo è l'intero programma principale. L'intera cosa è stata assorbita da invocazioni di macro. È questo un linguaggio assembly, o è—buon Dio!—un dialetto di BASIC? Ammetto che ho sostituito l'intero programma principale con invocazioni di macro qui per farlo notare, ma è certamente possibile creare così tante macro che i tuoi programmi assembly iniziano a sembrare un linguaggio di alto livello strano. In realtà, ho usato qualcosa di simile alla fine degli anni '70 quando ero programmatore per la Xerox. Avevano un linguaggio interno che era fondamentalmente un assemblatore 8080 con carichi di macro da utilizzare su microcomputer 8080 basati su longobarde (molto lenti; ci crederesti 1 megahertz?). Funzionava. Doveva farlo, con quella poca potenza computazionale per eseguire i suoi processi. La difficile verità è che le macro possono chiarire cosa sta facendo un programma, oppure, usate in modo eccessivo, possono oscurare completamente come funzionano le cose realmente "sotto la superficie". Nei miei progetti, uso le macro esclusivamente per ridurre il disordine di sequenze di istruzioni molto ripetitive, specialmente cose come l'impostazione dei registri prima di effettuare chiamate di sistema Linux. Del resto, l'intero obiettivo della programmazione assembly è promuovere una comprensione completa di ciò che sta accadendo dove il software incontra la CPU. Qualsiasi cosa che ostacola quella comprensione dovrebbe essere usata con cautela, abilità e (soprattutto) parsimonia—o potresti anche benissimo imparare il C.
</p>

### Le stringhe in lunguaggio Assembly

<p align=justify>
A volte le parole ci tradiscono, raccogliendo significati con la stessa facilità con cui un magnete raccoglie trucioli di ferro. La parola "string" è uno dei principali colpevoli qui. Significa grossomodo la stessa cosa in tutta la programmazione informatica, ma ci sono una moltitudine di piccole variazioni su quel tema unico. Se hai imparato a conoscere le stringhe in Pascal (come ho fatto io), scoprirai che ciò che sai non è totalmente applicabile quando programmi in C/C++, Python, BASIC o (soprattutto) assembly. Quindi ecco la Vista Generale: Una stringa è qualsiasi gruppo contiguo di byte in memoria, contenente qualsiasi tipo di dati, di qualsiasi dimensione arbitraria che il tuo sistema operativo consente. (Per un moderno Linux, questo può essere molto.) Il concetto fondamentale di una stringa in un linguaggio assembly è che i suoi byte costituenti sono tutti in fila, senza interruzioni. Questo è piuttosto fondamentale. La maggior parte dei linguaggi di alto livello si basa sul concetto di stringa in diversi modi. Le implementazioni di Pascal che discendono da UCSD (e successivamente Turbo) Pascal trattano le stringhe come un tipo di dati separato, con un contatore di lunghezza all'inizio della stringa per indicare quanti byte ci sono nella stringa. In C, una stringa non ha un byte di lunghezza davanti a sé. Invece, si dice che una stringa C finisca quando viene incontrato un byte con un valore binario di 0. Questo sarà importante nel lavoro di assembly, molto del quale si relaziona intimamente con C e la libreria standard C, dove vive il meccanismo di gestione delle stringhe di C. In BASIC, le stringhe sono memorizzate in qualcosa chiamato string space, che ha molta codifica incorporata associata, per gestire lo spazio delle stringhe e gestire la manipolazione profonda dei dati delle stringhe. Quando inizi a lavorare in assembly, devi rinunciare a tutte quelle cose dei linguaggi di alto livello. Le stringhe in assembly sono semplicemente regioni contigue di memoria. Iniziano a un indirizzo specificato, avanzano per un certo numero di byte e si fermano. Non c'è un contatore di lunghezza per dirti quanti byte ci sono nella stringa, senza caratteri di confine standard come il numero binario 0 per indicare dove inizia o finisce una stringa. Puoi certamente scrivere routine in linguaggio assembly che allocano stringhe in stile Pascal o in stile C e le manipolano. Tuttavia, per evitare confusione, devi quindi pensare ai dati elaborati dalle tue routine come stringhe Pascal o C piuttosto che come stringhe di linguaggio assembly.
</p>

<p align=justify>
Le stringhe in assembly non hanno valori di confine o indicatori di lunghezza. Possono contenere qualsiasi valore, incluso il 0 binario. Infatti, devi davvero smettere di pensare alle stringhe in termini di regioni specifiche nella memoria. Dovresti invece pensare alle stringhe in termini dei valori dei registri che le definiscono. È leggermente al contrario rispetto a come pensi alle stringhe in linguaggi come Pascal, ma funziona: hai una stringa quando imposti un registro per puntarne una. E una volta che punti a una stringa, la lunghezza di quella stringa è definita dal valore che poni nel registro RCX. Questo è fondamentale, e a rischio di ripetermi lo dirò di nuovo: le stringhe in assembly sono completamente definite dai valori che poni nei registri. C'è un insieme di presupposti sulle stringhe e sui registri integrati nel silicio della CPU. Quando esegui una delle istruzioni per le stringhe (come descriverò a breve), la CPU utilizza quei presupposti per determinare quale area di memoria legge o scrive.
</p>

### Stringa Sorgente e stringa Destinazione

<p align=justify>
Ci sono due tipi di stringhe nel lavoro in assembly x64. Le stringhe di origine sono le stringhe da cui si legge. Le stringhe di destinazione sono le stringhe su cui si scrive. La differenza tra le due è solo una questione di registri; le stringhe di origine e le stringhe di destinazione possono sovrapporsi. Infatti, la stessa regione di memoria può essere sia una stringa di origine che una stringa di destinazione, tutto allo stesso tempo. Qui ci sono le assunzioni che la CPU fa sulle stringhe quando esegue un'istruzione di stringa in modalità lunga a 64 bit:
</p>

<ul>
	<li>
		<p align=justify>
		Una stringa sorgente è puntata da RSI.
 		</p>
	</li>
 	<li>
		<p align=justify>
		Una stringa di destinazione è puntata da RDI.
 		</p>
	</li>
 	<li>
		<p align=justify>
		La lunghezza di entrambi i tipi di stringhe è il valore che inserisci in RCX. Come questa lunghezza viene utilizzata dalla CPU dipende dall'istruzione specifica e da come viene utilizzata.
 		</p>
	</li>
 	<li>
		<p align=justify>
		I dati provenienti da una stringa sorgente o destinati a una stringa di destinazione devono iniziare il viaggio da, terminare il viaggio a, o passare attraverso il registro RAX.
 		</p>
	</li>
</ul>


<p align=justify>
La CPU è in grado di riconoscere contemporaneamente sia una stringa di origine che una stringa di destinazione, perché RSI e RDI possono contenere valori indipendenti l'uno dall'altro. Tuttavia, poiché esiste un solo registro RCX, la lunghezza delle stringhe di origine e di destinazione deve essere identica quando vengono utilizzate contemporaneamente, come nella copia di una stringa di origine in una stringa di destinazione. Un modo per ricordare la differenza tra le stringhe di origine e le stringhe di destinazione è costituito dai relativi registri di offset. Il "SI" in RSI significa "indice di origine" e il "DI" in RDI significa "indice di destinazione". La "R", come ormai sapete, è la convenzione in base alla quale i registri per uso generale sono contrassegnati con una dimensione di 64 bit.
</p>

### Uno schermo virtuale di visualizzazione del testo

<p align=justify>
Il modo migliore per cementare tutte quelle informazioni di base sulle stringhe nella tua mente è vedere alcune istruzioni sulle stringhe in azione. Nel codice di soto  ho implementato un meccanismo interessante utilizzando le istruzioni sulle stringhe: un semplice display di testo virtuale per la console di Linux. Ai tempi della programmazione in modalità reale sotto DOS su macchine compatibili con PC, avevamo accesso senza restrizioni alla memoria del buffer di aggiornamento del video sullo strumento grafico del PC. Se scrivevamo un carattere ASCII o una stringa di caratteri nella regione di memoria che comprende il buffer di visualizzazione della scheda, Bam! I glifi di testo associati apparivano istantaneamente sullo schermo. Nelle edizioni precedenti di questo libro che trattavano DOS, ho sfruttato tale meccanismo di accesso diretto al display e presentato una serie di routine di visualizzazione utili che dimostravano le istruzioni sulle stringhe dell'architettura Intel. Sotto Linux, questo non è più possibile. Il buffer di visualizzazione grafica è ancora lì, ma ora è di proprietà del sistema operativo Linux, e le applicazioni in spazio utente non possono scriverci o nemmeno leggerlo direttamente. Scrivere applicazioni in modalità testo in assembly per la console di Linux non è affatto semplice come lo era sotto DOS. Nel Capitolo 10, ho spiegato come un controllo molto semplice del terminale della console potesse essere fatto scrivendo sequenze di escape sulla console tramite la SYSCALL sys_write. Tuttavia, tranne per i due o tre comandi più semplici, le variazioni nell'implementazione del terminale rendono l'uso di sequenze di escape "nude" un po' rischioso. Una determinata sequenza potrebbe significare una cosa per un terminale e qualcosa di completamente diverso per un altro. Le librerie di codice come ncurses fanno grandi sforzi per rilevare e adattarsi alla moltitudine di specifiche dei terminali esistenti. Il codice per farlo non è qualcosa che puoi assemblare in un pomeriggio e, in effetti, è un argomento troppo ampio da trattare in dettaglio in un libro introduttivo come questo.
</p>

<p align=justify>
Tuttavia... Possiamo fare qualche trucco contro lo scorbuto e imparare alcune cose facendoli. Uno consiste nell'allocare il nostro buffer di aggiornamento video di testo in memoria come variabile denominata e scrivere periodicamente l'intero buffer nella console Linux tramite una singola istruzione SYSCALL. I nostri PC sono diventati estremamente veloci dall'era DOS e i buffer video di testo non sono grandi. Un buffer di visualizzazione del testo da 25 × 80 è lungo solo 2.000 caratteri e il tutto può essere inviato alla console Linux con una singola chiamata sys_write SYSCALL. Il buffer appare sulla console istantaneamente, almeno per quanto qualsiasi osservatore umano possa discernere. L'inserimento del testo nel buffer è una semplice questione di calcolo dell'indirizzo di una data posizione di riga e colonna nel buffer e di scrittura dei valori dei caratteri ASCII nella variabile del buffer a partire da quell'indirizzo. Dopo ogni modifica della variabile buffer, è possibile aggiornare la visualizzazione della console scrivendo l'intero buffer nella console tramite SYSCALL. Gli esperti stanchi potrebbero chiamarla "forza bruta" (e sì, non è neanche lontanamente versatile come la libreria ncurses), ma è facile da capire. Non ti dà il controllo sul colore o sugli attributi del carattere (sottolineatura, lampeggiamento e così via), ma ti darà una buona comprensione di base delle istruzioni della stringa x86. Dai un'occhiata al codice. Nelle sezioni seguenti, lo esaminerò pezzo per pezzo. Si noti che è disponibile un file separato per la compilazione tramite SASM, denominato vidbuff1gcc.asm. I due file sono quasi identici e differiscono quasi interamente negli indirizzi iniziali globali _start rispetto a quelli principali, richiesti da SASM
</p>

```asm
;  Executable name : vidbuff1
;  Version         : 2.0
;  Created date    : 10/12/2022
;  Last update     : 7/18/2023
;  Author          : Jeff Duntemann
;  Description     : A simple program in assembly for Linux, using NASM 2.14.02,
;                  : demonstrating string instruction operation by "faking" 
;                  : full-screen memory-mapped text I/O.
;
;    Note that the output to the console from this program will NOT display
;    correctly unless you have enabled the IBM850 character encoding in
;    the terminal program being used to display the console! 
;

SECTION .data           ; Section containing initialized data
    EOL     equ 10      ; Linux end-of-line character
    FILLCHR equ 32      ; ASCII space character
    HBARCHR equ 196     ; Use dash char if this won't display
    STRTROW equ 2       ; Row where the graph begins

; We use this to display a ruler across the screen. 
    TenDigits   db 31,32,33,34,35,36,37,38,39,30
    DigitCount  db 10
    RulerString db "12345678901234567890123456789012345678901234567890123456789012345678901234567890" 
    RULERLEN    equ $-RulerString
                      
; The dataset is just a table of byte-length numbers:
    Dataset db 9,17,71,52,55,18,29,36,18,68,77,63,58,44,0
    Message db "Data current as of 5/13/2023"
    MSGLEN  equ $-Message

; This escape sequence will clear the console terminal and place the
; text cursor to the origin (1,1) on virtually all Linux consoles:
    ClrHome db 27,"[2J",27,"[01;01H"
    CLRLEN  equ $-ClrHome   ; Length of term clear string
	
SECTION .bss            ; Section containing uninitialized data	

    COLS    equ 81          ; Line length + 1 char for EOL
    ROWS    equ 25          ; Number of lines in display
    VidBuff resb COLS*ROWS  ; Buffer size adapts to ROWS & COLS

SECTION .text           ; Section containing code

global  _start          ; Linker needs this to find the entry point!

ClearTerminal:
    push r11            ; Save all modified registers
    push rax
    push rcx
    push rdx
    push rsi
    push rdi

    mov rax,1           ; Specify sys_write call
    mov rdi,1           ; Specify File Descriptor 1: Standard Output
    mov rsi,ClrHome     ; Pass address of the escape sequence
    mov rdx,CLRLEN      ; Pass the length of the escape sequence
    syscall             ; Make system call

    pop rdi             ; Restore all modified registers
    pop rsi
    pop rdx
    pop rcx
    pop rax
    pop r11
    ret

;-------------------------------------------------------------------------
; Show:         Display a text buffer to the Linux console
; UPDATED:      5/10/2023
; IN:           Nothing
; RETURNS:      Nothing
; MODIFIES:     Nothing
; CALLS:        Linux sys_write
; DESCRIPTION:  Sends the buffer VidBuff to the Linux console via sys_write.
;               The number of bytes sent to the console is calculated by
;               multiplying the COLS equate by the ROWS equate.

Show:	
    push r11           ; Save all registers we're going to change
    push rax
    push rcx
    push rdx
    push rsi
    push rdi
    mov rax,1          ; Specify sys_write call
    mov rdi,1          ; Specify File Descriptor 1: Standard Output
    mov rsi,VidBuff    ; Pass address of the buffer
    mov rdx,COLS*ROWS  ; Pass the length of the buffer
    syscall            ; Make system call
    pop rdi            ; Restore all modified registers
    pop rsi
    pop rdx
    pop rcx
    pop rax
    pop r11
    ret


;-------------------------------------------------------------------------
; ClrVid:       Clears a buffer to spaces and replaces overwritten EOLs
; UPDATED:      5/10/2023
; IN:           Nothing
; RETURNS:      Nothing
; MODIFIES:     VidBuff, DF
; CALLS:        Nothing
; DESCRIPTION:  Fills the buffer VidBuff with a predefined character
;               (FILLCHR) and then places an EOL character at the end
;               of every line, where a line ends every COLS bytes in
;               VidBuff.

ClrVid:
    push rax            ; Save registers that we change
    push rcx
    push rdi
    cld                 ; Clear DF; we're counting up-memory
    mov al,FILLCHR      ; Put the buffer filler char in AL
    mov rdi,VidBuff     ; Point destination index at buffer
    mov rcx,COLS*ROWS   ; Put count of chars stored into RCX
    rep stosb           ; Blast byte-length chars at the buffer

; Buffer is cleared; now we need to re-insert the EOL char after each line:
    mov rdi,VidBuff     ; Point destination at buffer again
    dec rdi             ; Start EOL position count at VidBuff char 0
    mov rcx,ROWS        ; Put number of rows in count register
.PtEOL:
    add rdi,COLS        ; Add column count to RDI
    mov byte [rdi],EOL  ; Store EOL char at end of row
    loop .PtEOL         ; Loop back if still more lines
    pop rdi             ; Restore caller's registers
    pop rcx
    pop rax
    ret                 ; and go home!


;-------------------------------------------------------------------------
; WrtLn:        Writes a string to a text buffer at a 1-based X,Y position
; UPDATED:      5/10/2023
; IN:           The address of the string is passed in RSI
;               The 1-based X position (row #) is passed in RBX
;               The 1-based Y position (column #) is passed in RAX
;               The length of the string in chars is passed in RCX
; RETURNS:      Nothing
; MODIFIES:     VidBuff, RDI, DF
; CALLS:        Nothing
; DESCRIPTION:  Uses REP MOVSB to copy a string from the address in RSI
;               to an X,Y location in the text buffer VidBuff.

WrtLn:
    push rax        ; Save registers we will change
    push rbx
    push rcx
    push rdi
    cld             ; Clear DF for up-memory write
    mov rdi,VidBuff ; Load destination index with buffer address
    dec rax         ; Adjust Y value down by 1 for address calculation
    dec rbx         ; Adjust X value down by 1 for address calculation
    mov ah,COLS     ; Move screen width to AH
    mul ah          ; Do 8-bit multiply AL*AH to AX
    add rdi,rax     ; Add Y offset into vidbuff to RDI
    add rdi,rbx     ; Add X offset into vidbuf to RDI
    rep movsb       ; Blast the string into the buffer
    pop rdi         ; Restore registers we changed
    pop rcx
    pop rbx
    pop rax
    ret             ; and go home!


;-------------------------------------------------------------------------
; WrtHB:        Generates a horizontal line bar at X,Y in text buffer
; UPDATED:      5/10/2023
; IN:           The 1-based X position (row #) is passed in RBX
;               The 1-based Y position (column #) is passed in RAX
;               The length of the bar in chars is passed in RCX
; RETURNS:      Nothing
; MODIFIES:     VidBuff, DF
; CALLS:        Nothing
; DESCRIPTION:  Writes a horizontal bar to the video buffer VidBuff, 
;               at th1e 1-based X,Y values passed in RBX,RAX. The bar is
;               "made of" the character in the equate HBARCHR. The
;               default is character 196; if your terminal won't display
;               that (you need the IBM 850 character set) change the
;               value in HBARCHR to ASCII dash or something else supported
;               in your terminal.

WrtHB:
    push rax         ; Save registers we change
    push rbx
    push rcx
    push rdi
    cld              ; Clear DF for up-memory write
    mov rdi,VidBuff  ; Put buffer address in destination register
    dec rax          ; Adjust Y value down by 1 for address calculation
    dec rbx          ; Adjust X value down by 1 for address calculation
    mov ah,COLS      ; Move screen width to AH
    mul ah           ; Do 8-bit multiply AL*AH to AX
    add rdi,rax      ; Add Y offset into vidbuff to EDI
    add rdi,rbx      ; Add X offset into vidbuf to EDI
    mov al,HBARCHR   ; Put the char to use for the bar in AL
    rep stosb        ; Blast the bar char into the buffer
    pop rdi          ; Restore registers we changed
    pop rcx
    pop rbx
    pop rax
    ret              ; And go home!


;-------------------------------------------------------------------------
; Ruler:        Generates a "1234567890"-style ruler at X,Y in text buffer
; UPDATED:      5/10/2023
; IN:           The 1-based X position (row #) is passed in RBX
;               The 1-based Y position (column #) is passed in RAX
;               The length of the ruler in chars is passed in RCX
; RETURNS:      Nothing
; MODIFIES:     VidBuff
; CALLS:        Nothing
; DESCRIPTION:  Writes a ruler to the video buffer VidBuff, at the 1-based
;               X,Y position passed in RBX,RAX. The ruler consists of a
;               repeating sequence of the digits 1 through 0. The ruler
;               will wrap to subsequent lines and overwrite whatever EOL
;               characters fall within its length, if it will not fit
;               entirely on the line where it begins. Note that the Show
;               procedure must be called after Ruler to display the ruler
;               on the console.

Ruler:
    push rax         ; Save the registers we change
    push rbx
    push rcx
    push rdx
    push rdi
    mov rdi,VidBuff  ; Load video buffer address to RDI
    dec rax          ; Adjust Y value down by 1 for address calculation
    dec rbx          ; Adjust X value down by 1 for address calculation
    mov ah,COLS      ; Move screen width to AH
    mul ah           ; Do 8-bit multiply AL*AH to AX
    add rdi,rax      ; Add Y offset into vidbuff to RDI
    add rdi,rbx      ; Add X offset into vidbuf to RDI
        
; RDI now contains the memory address in the buffer where the ruler
; is to begin. Now we display the ruler, starting at that position:
    mov rdx,RulerString ; Load address of ruler string into RDX
DoRule: 
    mov al,[rdx] ; Load first digit in the ruler to AL
    stosb             ; Store 1 char; note that there's no REP prefix!
    inc rdx           ; Increment RDX to point to next char in ruler string
    loop DoRule       ; Decrement RCX & Go back for another char until RCX=0
    pop rdi           ; Restore the registers we changed
    pop rdx
    pop rcx
    pop rbx
    pop rax
    ret               ; And go home!

;-------------------------------------------------------------------------
; MAIN PROGRAM:
	
_start:
    push rbp
    mov rbp,rsp
    and rsp,-16

; Get the console and text display text buffer ready to go:
    call ClearTerminal ; Send terminal clear string to console
    call ClrVid        ; Init/clear the video buffer

; Next we display the top ruler:
    mov rax,1        ; Load Y position to AL
    mov rbx,1        ; Load X position to BL
    mov rcx,COLS-1   ; Load ruler length to RCX
    call Ruler       ; Write the ruler to the buffer

; Thow up an informative message centered on the last line
    mov rsi,Message  ; Load the address of the message to RSI
    mov rcx,MSGLEN   ; and its length to RCX
    mov rbx,COLS     ; and the screen width to RBX
    sub rbx,rcx      ; Calc diff of message length and screen width
    shr rbx,1        ; Divide difference by 2 for X value
    mov rax,20       ; Set message row to Line 24
    call WrtLn       ; Display the centered message

; Here we loop through the dataset and graph the data:
    mov rsi,Dataset  ; Put the address of the dataset in RSI
    mov rbx,1        ; Start all bars at left margin (X=1)
    mov r15,0        ; Dataset element index starts at 0
.blast:	
    mov rax,r15      ; Add dataset number to element index
    add rax,STRTROW  ; Bias row value by row # of first bar
    mov cl,byte [rsi+r15]   ; Put dataset value in lowest byte of RCX
    cmp rcx,0        ; See if we pulled a 0 from the dataset
    je .rule2        ; If we pulled a 0 from the dataset, we're done
    call WrtHB       ; Graph the data as a horizontal bar
    inc r15          ; Increment the dataset element index
    jmp .blast       ; Go back and do another bar

; Display the bottom ruler:
.rule2:	
    mov rax,r15      ; Use the dataset counter to set the ruler row
    add rax,STRTROW  ; Bias down by the row # of the first bar
    mov rbx,1        ; Load X position to BL
    mov rcx,COLS-1   ; Load ruler length to RCX
    call Ruler       ; Write the ruler to the buffer

; Having written all that to the buffer, send the buffer to the console:
    call Show        ; Refresh the buffer to the console

; And return control to Linux:
Exit:
    mov rsp,rbp
    pop rbp
    
    mov rax,60       ; End program via Exit Syscall
    mov rdi,0        ; Return a code of zero	
    syscall          ; Return to Linux
```

### REP STOSB, la mitragliatrice software

<p align=justify>
Il nostro buffer di visualizzazione del testo virtuale non è altro che una regione di memoria grezza riservata nella sezione .bss, utilizzando la direttiva RESB. La dimensione del buffer è definita da due equazioni, che specificano il numero di righe e colonne che desideri. Per impostazione predefinita, l'ho impostato su 25 righe e 80 colonne, ma i display della console del 2023 possono visualizzare uno schermo di testo molto più grande di così. Puoi cambiare le equazioni COLS e ROWS per definire buffer grandi fino a 255 × 255, anche se se la finestra del tuo terminale non è così grande, i tuoi risultati saranno (per dirla gentilmente) imprevedibili. Cambiare le dimensioni della tua visualizzazione del testo viene fatto modificando una o entrambe quelle equazioni. Qualsiasi altro cambiamento necessario nel codice viene gestito automaticamente. Tieni presente che questo deve essere fatto al tempo dell'assemblaggio poiché molti dei calcoli sono calcoli di tempo di assemblaggio eseguiti da NASM quando costruisci il programma. Non è necessario far combaciare esattamente la dimensione della finestra del terminale ai valori ROWS e COLS scelti, purché la finestra del terminale sia più grande di ROWS × COLS. Se massimizzi la finestra del terminale (come Konsole), la tua visualizzazione del testo apparirà a partire dall'angolo in alto a sinistra dello schermo.
</p>

### Mitragliatrice sul display virtuale

<p align=justify>
Quando Linux carica i tuoi programmi in memoria, solitamente azzera le variabili non inizializzate (come VidBuff nell'elenco 11.1) a zeri binari. Questo è buono, ma gli zeri binari non vengono visualizzati correttamente sulla console di Linux. Per apparire "vuoto" sulla console, la memoria del buffer di visualizzazione deve essere azzerata al carattere spazio ASCII. Ciò significa scrivere il valore 20h nella memoria dall'inizio del buffer fino alla sua fine. Tali operazioni dovrebbero sempre essere eseguite in cicli stretti. Il modo ovvio è mettere l'indirizzo del buffer di visualizzazione in RDI, il numero di byte nel tuo buffer di aggiornamento in RCX, il valore ASCII per azzerare il buffer in AL, e poi codificare un ciclo stretto in questo modo:
</p>

```asm
Clear:  mov [rdi],al  ; Write the value in AL to memory
 	inc rdi       ; Bump RDI to next byte in the buffer
 	dec rcx       ; Decrement RCX by one position
	jnz Clear      ; And loop again until RCX is 0
```

<p align=justify>
Questo funzionerà. È anche ragionevolmente veloce, specialmente su CPU più recenti. Ma tutto il codice precedente è equivalente a quest'unica istruzione:
</p>

```asm
 rep stosb
```

<p align=justify>
Davvero. No, sul serio. L'istruzione STOSB è la più semplice delle istruzioni di stringa Intel ed è un buon punto di partenza. Ci sono due parti nell'istruzione come l'ho mostrata, una situazione che non abbiamo visto prima. REP è un nuovo tipo di elemento, chiamato prefisso, e cambia il modo in cui la CPU tratta il mnemonico dell'istruzione che lo segue. Torneremo a REP a breve. Adesso, diamo un'occhiata a STOSB. Il mnemonico significa STOrare la Stringa per Byte. Come tutte le istruzioni di stringa, STOSB fa certe assunzioni su alcuni registri della CPU. Funziona solo sulla stringa di destinazione, quindi RSI non è coinvolto. Tuttavia, queste assunzioni devono essere rispettate e affrontate:
</p>

<ul>
	<li>
		<p align=justify>
		RDI deve essere caricato con l'indirizzo della stringa di destinazione. (Pensa: RDI, per indice di destinazione.)
		</p>
	</li>
 	<li>
		<p align=justify>
		RCX deve essere caricato con il numero di volte che il valore in AL deve essere memorizzato nella stringa
		</p>
	</li>
 	<li>
		<p align=justify>
		AL deve essere caricato con il valore a 8 bit da memorizzare nella stringa.
		</p>
	</li>
 	<li>
		<p align=justify>
		Il flag di direzione DF deve essere impostato o azzerato, a seconda se si desidera che la ricerca sia verso l'alto nella memoria (azzerrato; usa CLD) o verso il basso nella memoria (impostato; usa STD). Avrò di più da dire su DF come utilizzato con STOSB un po' più tardi.
		</p>
	</li>
</ul>

### Esecuzione dell'istruzione STOSB

<p align=justify>
Una volta che hai impostato questi tre registri, puoi eseguire in sicurezza un'istruzione STOSB. Quando lo fai, ecco cosa succede: 
</p>

1. Il valore byte in AL viene copiato nell'indirizzo di memoria memorizzato in RDI.
2. RDI viene incrementato di 1, in modo che ora punti al byte successivo in memoria dopo quello appena scritto.

<p align=justify>
Nota che non stiamo sparando a raffica qui—non ancora, almeno. Una copia di AL viene copiata in una posizione di memoria. Il registro RDI viene regolato affinché sia pronto per la prossima volta che viene eseguita STOSB. Un punto molto importante da ricordare è che RCX non viene decrimentato da STOSB. RCX viene decrimentato automaticamente solo se metti il prefisso REP davanti a STOSB. Senza il prefisso REP, devi fare tu stesso il decrimento, sia esplicitamente tramite DEC o tramite l'istruzione LOOP, come spiegherò un po' più avanti in questo capitolo. Quindi, non puoi far funzionare STOSB automaticamente senza REP. Tuttavia, se vuoi, puoi eseguire altre istruzioni prima di eseguire un altro STOSB. Finché non disturbi RDI o RCX, puoi fare quello che vuoi. Poi, quando esegui di nuovo STOSB, un'altra copia di AL andrà alla posizione puntata da RDI, e RDI sarà adeguatamente aggiornato di nuovo. (Devi ricordarti di decrimentare RCX in qualche modo.) Nota che puoi cambiare il valore in AL se vuoi, ma il valore cambiato verrà copiato nella memoria. Potresti volerlo fare—non c'è legge che dice che devi riempire una stringa con solo un singolo valore. Tuttavia, questo è come la differenza tra un'arma semiautomatica (che spara un colpo ogni volta che premi e rilasci il grilletto) e un'arma completamente automatica, che spara colpi continuamente finché tieni premuto il grilletto. Per rendere STOSB completamente automatica, basta mettere il prefisso REP davanti ad essa. Ciò che fa REP è splendidamente semplice: imposta il ciclo più serrato di tutti i cicli completamente all'interno della CPU e spara copie di AL nella memoria ripetutamente (il motivo del suo nome), incrementando RDI di 1 ogni volta e decrimentando RCX di 1, fino a quando RCX non viene decrimentato a 0. Poi si ferma, e quando il fumo si dirada, vedrai che l'intera stringa di destinazione, per quanto grande, è stata riempita con copie di AL. Amico, ora questo è programmare!
</p>

<p align=justify>
Nel programma vidbuff1, il codice per cancellare il buffer di visualizzazione si trova nella procedura ClrVid. Le righe pertinenti sono quelle mostrate qui:
</p>

```asm
cld                 ; Clear DF so we're counting up-memory
mov al,FILLCHR      ; Put the buffer filler char in AL
mov rdi,VidBuff     ; Point destination index at buffer 
mov rcx,COLS*ROWS   ; Put count of chars stored into RCX
rep stosb           ; Blast chars at the buffer 
```

<p align=justify>
L'equivalente FILLCHR è impostato di default a 32, che è il carattere di spazio ASCII. Puoi impostarlo per riempire il buffer con un altro carattere, anche se quanto possa essere utile questo non è chiaro. Nota anche che il numero di caratteri da scrivere in memoria viene calcolato da NASM al momento dell'assemblaggio come COLONNE per RIGHE. Questo ti consente di modificare la dimensione del tuo display virtuale senza cambiare il codice che svuota il buffer del display.
</p>

### STOSB e il Flag di Direzione DF

<p align=justify>
A guidare la sequenza di codice breve mostrata in precedenza c'è un'istruzione di cui non ho parlato prima: CLD. Essa controlla qualcosa di fondamentale nel lavoro con le istruzioni delle stringhe: la direzione in memoria che l'operazione su stringa prende. La maggior parte del tempo in cui userai STOSB, vorrai eseguirla "verso l'alto" in memoria, cioè, da un indirizzo di memoria più basso a un indirizzo di memoria più alto. In ClrVid, metti l'indirizzo dell'inizio del buffer di aggiornamento video in RDI e poi invii caratteri in memoria a indirizzi di memoria progressivamente più alti. Ogni volta che STOSB invia un byte in memoria, RDI viene incrementato per puntare al byte successivo più alto in memoria. Questo è il modo logico di lavorare, ma non deve essere fatto in questo modo in ogni momento. STOSB può tranquillamente iniziare da un indirizzo alto e muoversi verso il basso in memoria. Ad ogni memorizzazione in memoria, RDI può essere decrementato di 1 invece. Quale direzione STOSB segua—verso l'alto verso indirizzi di memoria progressivamente più alti o verso il basso verso indirizzi progressivamente più bassi—è governato da uno dei flag nel registro RFlags. Questo è il flag di Direzione DF. Il compito principale di DF è controllare la direzione dell'azione intrapresa da istruzioni particolari che, come STOSB, possono muoversi in una delle due direzioni in memoria. La maggior parte di queste (come STOSB e i suoi simili) sono istruzioni sulle stringhe.
</p>

<p align=justify>
Il senso del DF è questo: Quando il DF è impostato (cioè, quando il DF ha il valore 1), STOSB e le sue istruzioni stringa correlate funzionano in discesa, da indirizzi più alti a indirizzi più bassi. Quando il DF è resettato (cioè, quando ha il valore 0), STOSB e i suoi simili lavorano in salita, da indirizzi più bassi a indirizzi più alti. Questo a sua volta è semplicemente la direzione in cui viene regolato il registro RDI: quando il DF è impostato, RDI viene decrementato durante l'esecuzione delle istruzioni stringa. Quando il DF è resettato, RDI viene incrementato. Il flag di Direzione predefinito è 0 (in salita) quando la CPU viene resettata. Generalmente viene cambiato in uno dei due modi: con l'istruzione CLD, o con l'istruzione STD. CLD azzera il DF a 0, e STD imposta il DF a 1. (Dovresti tenere a mente quando fai il debug che l'istruzione POPF può anche cambiare il DF estraendo un nuovo set completo di flag dallo stack nel registro RFlags.) Poiché lo stato predefinito del DF è azzerato a 0 e tutte le istruzioni stringa nel programma demo vidbuff1 lavorano in salita nella memoria, non è tecnicamente necessario includere un'istruzione CLD nella procedura ClrVid. Tuttavia, altre parti di un programma possono cambiare il DF. È sempre una buona idea inserire l'appropriato CLD o STD proprio prima di un'istruzione stringa per assicurarti che la tua mitragliatrice spari nella giusta direzione! A volte le persone si confondono e pensano che il DF governi anche se RCX viene incrementato o decrementato dalle istruzioni stringa. Non è così! Nulla in un'istruzione stringa incrementa mai RCX. RCX tiene un valore di conteggio, non un indirizzo di memoria. Inserisci un conteggio in RCX, e conta giù ogni volta che un'istruzione stringa viene eseguita fino a raggiungere 0. Il DF non ha nulla da dire al riguardo. Fondamentalmente, RDI è dove si trova l'obiettivo, e RCX è il numero di proiettili nel tuo caricatore.
</p>

### Definire le linee nel buffer di visualizzazione

<p align=justify>
Tuttavia, cancellare VidBuff per spazi vuoti non è del tutto la fine della storia. Per essere visualizzato correttamente nei programmi terminali che mostrano la console Linux, i dati di visualizzazione devono essere suddivisi in righe. Le righe sono delimitate dal carattere EOL, ASCII 10. Una riga inizia all'inizio del buffer e termina con il primo carattere EOL. La riga successiva inizia immediatamente dopo il carattere EOL e continua fino al prossimo carattere EOL, e così via. Quando il testo viene scritto a pezzi nella console, ogni riga può avere una lunghezza diversa. Nel nostro sistema di visualizzazione virtuale, tuttavia, l'intero buffer viene scritto nella console in un'unica chiamata di sistema, come una sequenza di righe tutte della stessa lunghezza. Questo significa che quando cancelliamo il buffer, dobbiamo anche inserire i caratteri EOL dove vogliamo che ciascuna riga visualizzata termini. Questo viene fatto nel resto della procedura ClrVid. Quello che dobbiamo fare è scrivere un carattere EOL nel buffer ogni COLS byte. Questo viene fatto con un ciclo molto stretto. Se guardi la seconda parte di ClrVid, potresti notare che il ciclo in questione non è del tutto ordinario. Tieni a mente questo pensiero—tornerò all'istruzione LOOP fra un po'.
</p>

### Invio del Buffer alla Console di Linux

<p align=justify>
Devo ribadire: stiamo parlando di un display virtuale qui. VidBuff è semplicemente una regione di memoria nella quale puoi scrivere caratteri e stringhe di caratteri con istruzioni di linguaggio assembly ordinarie. Tuttavia, nulla apparirà sul tuo monitor finché non invierai il buffer alla console Linux. Questo è abbastanza semplice. La procedura Show nel programma precedente effettua una sola chiamata al servizio kernel sys_write tramite SYSCALL e invia l'intero buffer alla console in una sola volta. I caratteri di fine riga (EOL) incorporati nel buffer ogni COLS byte vengono trattati come i caratteri di fine riga vengono sempre trattati dalla console e costringono a iniziare una nuova riga immediatamente dopo ciascun EOL. Poiché tutte le righe sono della stessa lunghezza, inviare VidBuff alla console crea una regione rettangolare di testo che verrà visualizzata correttamente su qualsiasi finestra del terminale che sia almeno COLS per ROWS in dimensione. (Finestra più piccole confonderanno il testo di VidBuff. Prova a eseguire il programma vidbuff1 in finestre di terminale di varie dimensioni e vedrai rapidamente cosa intendo.) Ciò che è importante è che i tuoi programmi chiamino Show ogni volta che vuoi un aggiornamento dello schermo. Questo può essere fatto ogni volta che desideri. Su PC Linux moderni, l'aggiornamento avviene così rapidamente da apparire istantaneo. Con quella velocità, non c'è motivo per cui tu non debba chiamare Show dopo ogni scrittura su VidBuff, ma dipende da te.
</p>

### L'Arma Semiautomatica: STOSB Senza REP

<p align=justify>
Tra tutte le istruzioni di stringa, ho scelto di mostrarti prima REP STOSB perché è estremamente drammatico. Ma più precisamente, è semplice: in effetti, è più semplice usare REP piuttosto che non usarlo. REP semplifica l'elaborazione delle stringhe dal punto di vista del programmatore, perché porta l'intero ciclo di istruzioni all'interno della CPU. Puoi usare l'istruzione STOSB senza REP, ma è un po' più complicato. Il lavoro comporta la preparazione del ciclo di istruzioni al di fuori della CPU e assicurarsi che sia corretto. Perché preoccuparsi? Semplicemente questo: con REP STOSB puoi ripetutamente memorizzare lo stesso valore nella stringa di destinazione. Qualunque cosa tu metta in AL prima di eseguire REP STOSB è il valore che verrà memorizzato in memoria per RCX volte. STOSB può essere utilizzato per memorizzare valori diversi nella stringa di destinazione facendolo semiautomatizzando e cambiando il valore in AL tra ciascun colpo del grilletto. Perdi un po' di tempo gestendo il ciclo da solo al di fuori della CPU. Questo perché c'è un certo tempo speso per recuperare i byte delle istruzioni del ciclo dalla memoria. Tuttavia, se mantieni il tuo ciclo il più stretto possibile, non perdi una quantità di velocità inaccettabile, specialmente sui moderni processori Intel/AMD, che fanno un uso molto efficace della cache e non recuperano le istruzioni dalla memoria esterna ogni volta che vengono eseguite.
</p>

### Chi Decrementa RCX?

<p align=justify>
All'inizio della mia esperienza con il linguaggio assembly x86, ricordo di essere stato massicciamente confuso su dove e quando il registro RCX (in realtà, molto tempo fa, era semplicemente il registro CX) venisse decrementato quando si utilizzavano le istruzioni di stringa. È una questione chiave, soprattutto quando non si utilizza il prefisso REP. Quando si usa REP STOSB (o REP con qualsiasi delle istruzioni di stringa), RCX viene decrementato automaticamente, di 1, per ogni accesso alla memoria effettuato dall'istruzione. E una volta che RCX viene decrementato a 0, REP STOSB rileva che RCX è ora 0 e smette di scrivere nella memoria. Il controllo passa quindi alla prossima istruzione in coda. Ma togli il REP, e il decremento automatico di RCX si ferma. Quindi, anche la rilevazione automatica quando RCX è stato conteggiato fino a 0. Ovviamente, qualcosa deve decrementare RCX poiché RCX governa quante volte l'istruzione di stringa accede alla memoria. Se STOSB non lo fa—hai indovinato—devi farlo in un altro posto, con un'altra istruzione. Il modo ovvio per decrementare RCX è utilizzare DEC RCX. E il modo ovvio per determinare se RCX è stato decrementato a 0 è seguire l'istruzione DEC RCX con un'istruzione JNZ (Salta se Non Zero). JNZ testa il flag Zero ZF e salta di nuovo all'istruzione STOSB fino a quando ZF diventa vero. E ZF diventa vero quando un'istruzione DEC causa che il suo operando (qui, RCX) diventi 0.
</p>

### L'Istruzione LOOP

<p align=justify>
Tenendo tutto ciò a mente, considera il seguente ciclo di istruzioni in linguaggio assembly. Questo non è tratto dal programma precedente, ma un esempio assemblato del modo "difficile" di fare le cose:
</p>

```asm
     mov al,30h  ; Put the value of character "0" in AL
 DoChar:
     stosb       ; Note that there's no REP prefix!
     inc al      ; Bump the character value in AL up by 1     
     dec rcx     ; Decrement the count by 1..
     jnz DoChar  ; ..and loop again if RCX> 0
```

<p align=justify>
Guarda come funziona il ciclo. STOSB si attiva, AL viene modificato e poi RCX viene decrementato. L'istruzione JNZ verifica se l'istruzione DEC ha forzato RCX a zero. Se sì, il flag Zero ZF viene impostato e il ciclo termina. Ma fino a quando ZF non è impostato, il salto viene effettuato di nuovo all'etichetta DoChar, dove STOSB si attiva ancora una volta. C'è un modo più semplice, usando un'istruzione di cui non ho parlato fino ad ora: LOOP. L'istruzione LOOP combina il decremento di RCX con un test e un salto basato su ZF. Si presenta così:
</p>

```asm
     mov al,30h   ; Put the value of character "0" in AL
 DoChar:
     stosb        ; Note that there's no REP prefix!
     inc al        ; Bump the character value in AL up by 1
     loop DoChar  ; Go back & do another char until RCX goes to 0
```

<p align=justify>
Quando viene eseguita, l'istruzione LOOP prima decrementa RCX di 1. Poi controlla il flag Zero per vedere se l'operazione di decremento ha portato RCX a zero. Se sì, passa all'istruzione successiva. Se no (cioè, se ZF rimane 0, indicando che RCX è ancora maggiore di 0), LOOP salta all'etichetta specificata come suo operando. Quindi, il ciclo continua a ripetere LOOP finché RCX non arriva a 0. A quel punto, il ciclo è terminato e l'esecuzione continua con l'istruzione successiva dopo LOOP.
</p>

### Visualizzare un righello sullo schermo

<p align=justify>
Come dimostrazione utile di quando ha senso utilizzare STOSB senza REP (ma con LOOP), lasciami offrirti un altro elemento per il tuo toolkit video. La procedura Ruler nel programma precedente visualizza una sequenza ripetitiva di cifre ascendenti a partire da 1, di qualsiasi lunghezza, in una posizione selezionabile sullo schermo. In altre parole, puoi visualizzare una stringa di cifre come questa ovunque tu voglia:
</p>

```
 123456789012345678901234567890123456789012345678901234567890
```

<p align=justify>
Questo potrebbe consentirti di determinare dove, nella dimensione orizzontale della finestra della console, inizia una riga o dove cade un certo carattere. La procedura Ruler ti consente di specificare quanto è lunga la riga, in cifre, e dove sullo schermo verrà visualizzata.
</p>

<p align=justify>
Una chiamata tipica a Ruler somiglierebbe a qualcosa del genere:
</p>

```asm
 mov rax,1       ; Load Y position to AL
 mov rbx,1        ; Load X position to BL
 mov rcx,COLS-1  ; Load ruler length to RCX
 call Ruler      ; Write the ruler to the buffer
````

<p align=justify>
Questa invocazione posiziona un righello nell'angolo in alto a sinistra del display, iniziando dalla posizione 1,1. La lunghezza del righello è passata in RCX. Qui, stai specificando un righello lungo un carattere in meno rispetto alla larghezza del display. Questo fornisce un righello che copre l'intera larghezza visibile del tuo display di testo virtuale. Perché un carattere in meno? Ricorda che c'è un carattere EOL alla fine di ogni riga. Questo carattere EOL non è visibile direttamente, ma è comunque un carattere e richiede un byte nel buffer per contenerlo. L'equivalente COLS deve sempre tenerne conto: se vuoi un display largo 80 caratteri, COLS deve essere impostato su 81. Se vuoi un display largo 96 caratteri, COLS deve essere impostato su 97. Se codifichi una chiamata a Ruler come mostrato in precedenza, NASM eseguirà alcuni calcoli durante l'assemblaggio e genererà sempre un righello che copre l'intera larghezza (visibile) del display di testo. Oltre all'istruzione LOOP, qui c'è una notevole quantità di nuove tecnologie di assemblaggio in gioco che meriterebbero una spiegazione. Facciamo una deviazione dalle istruzioni a stringa per un momento e diamo un'occhiata più da vicino.
</p>

### MUL non è IMUL

<p align=justify>
Ho descritto l'istruzione MUL e i suoi operandi impliciti molto tempo fa. La procedura Ruler usa anche MUL per calcolare una posizione X,Y nel buffer di memoria di visualizzazione dove STOSB può iniziare a posizionare i caratteri della riga. L'algoritmo per determinare l'offset in byte nel buffer per valori X e Y qualsiasi appare così.
</p>

```asm
 Offset = ((Y * width in characters of a screen line) + X)
```

<p align=justify>
Abbastanza ovviamente, devi spostarti Y righe verso il basso nel buffer dello schermo e poi spostarti di X byte dal margine sinistro dello schermo per raggiungere la tua posizione X,Y. Il calcolo viene fatto in questo modo all'interno della procedura Ruler:
</p>

```asm
 mov rdi,VidBuff   ; Load video buffer address to RDI
     dec rax       ; Adjust Y value down by 1 for address calculation
     dec rbx       ; Adjust X value down by 1 for address calculation
     mov ah,COLS   ; Move screen width to AH
     mul ah        ; Do 8-bit multiply AL*AH to AX
     add rdi,rax   ; Add Y offset into vidbuff to RDI
     add rdi,rbx   ; Add X offset into vidbuf to RDI
```

<p align=justify>
Le due istruzioni DEC si occupano del fatto che le posizioni X,Y in questo sistema sono basate su 1; cioè, l'angolo superiore sinistro dello schermo è la posizione 1,1 piuttosto che 0,0, come avviene in alcuni sistemi di coordinate X,Y. Pensala in questo modo: se vuoi visualizzare un righello che inizia nell'angolo superiore sinistro dello schermo, devi scrivere i caratteri del righello che partono dall'inizio del buffer, senza alcuno spostamento. A fini di calcolo, quindi, i valori X,Y devono essere basati su 0. Per una moltiplicazione a 8 bit utilizzando MUL, uno dei fattori è implicito: AL contiene il valore Y e il chiamante passa a Ruler il valore Y in RAX. Inseriamo la larghezza dello schermo in AH e poi moltiplichiamo AH per AL con MUL. (Vedi la discussione su MUL nei paragrafi precedenti se è diventato poco chiaro nel frattempo.) Il prodotto sostituisce i valori sia in AH che in AL e viene accesso come il valore in AX. Aggiungendo quel prodotto e il valore X (passato a Ruler in BL) a RDI ottieni l'indirizzo di memoria preciso in cui devono essere scritti i caratteri del righello. Ora, c'è un bug piuttosto comune di cui avvertirti: MUL non è IMUL…la maggior parte del tempo. MUL e IMUL sono istruzioni sorelle che svolgono entrambe la moltiplicazione. MUL tratta i suoi valori operandi come non firmati, mentre IMUL li tratta come firmati. Questa differenza non importa finché entrambi i fattori rimangono positivi in un contesto firmato. In termini pratici, per una moltiplicazione a 8 bit, MUL e IMUL funzionano identicamente su valori di 127 o meno. A 128 tutto cambia. I valori superiori a 127 sono considerati negativi in un contesto firmato a 8 bit. MUL considera 128 come…128. IMUL considera 128 come -1. Ops. Potresti sostituire l'istruzione MUL con IMUL in Ruler, e la procedura funzionerebbe identicamente fino a quando non le passi una dimensione dello schermo maggiore di 127. Poi, all'improvviso, IMUL calcolerebbe un prodotto che è nominalmente negativo…ma solo se stai trattando il valore come un valore firmato. Un numero negativo trattato come non firmato è un numero positivo molto grande, e un riferimento di memoria all'indirizzo rappresentato da RDI più quel valore anomalo genererà un errore di segmentazione. Provalo! Nessun danno fatto, ed è una lezione interessante. IMUL è per valori firmati. Per i calcoli degli indirizzi di memoria, lascialo perdere e assicurati di usare MUL invece.
</p>

<p align=justify>
La procedura Ruler è un buon esempio di utilizzo di STOSB senza il prefisso REP. Dobbiamo cambiare il valore in AL ogni volta che memorizziamo AL in memoria e quindi non possiamo usare REP STOSB. Nota che non viene fatto nulla a RDI o RCX mentre cambiamo la cifra da visualizzare, e quindi i valori memorizzati in quei registri vengono mantenuti per la prossima esecuzione di STOSB. Ruler è un buon esempio di come LOOP funzioni con STOSB per ridurre RCX e restituire il controllo all'inizio del ciclo. LOOP, in un certo senso, fa all'esterno della CPU ciò che REP fa all'interno della CPU: regola RCX e chiude il ciclo. Cerca di mantenere questo concetto chiaro nella tua mente quando utilizzi qualsiasi delle istruzioni di stringa!
</p>

### Le quattro dimensioni di STOS

<p align=justify>
Prima di passare ad altre istruzioni sulle stringhe, vale la pena sottolineare che ci sono quattro diverse "dimensioni" dell'istruzione di stringa STOS:
</p>

<ul>
	<li>
		<p align=justify>
		STOSB memorizza il valore a 8 bit in AL nella memoria.
		</p>
	</li>
 	<li>
		<p align=justify>
		STOSW memorizza il valore a 16 bit in AX nella memoria.
		</p>
	</li>
 	<li>
		<p align=justify>
		STOSD memorizza il valore a 32 bit in EAX nella memoria
		</p>
	</li>
 	<li>
		<p align=justify>
		STOSQ memorizza il valore a 64 bit in RAX nella memoria
		</p>
	</li>
</ul>

<p align=justify>
STOSW, STOSD e STOSQ funzionano quasi allo stesso modo di STOSB. La principale differenza risiede nel modo in cui viene modificato l'indirizzo di destinazione RDI dopo ogni operazione di trasferimento di memoria. RDI viene modificato in base alle dimensioni della quantità su cui agisce l'istruzione. Per STOSW, RDI cambia di due byte, verso l'alto o verso il basso a seconda dello stato di DF. Per STOSD, RDI cambia di quattro byte, ancora una volta verso l'alto o verso il basso a seconda dello stato di DF. STOSQ cambia RDI di otto byte, verso l'alto o verso il basso a seconda dello stato di DF. Tuttavia, in tutti i casi, con il prefisso REP davanti all'istruzione, il registro contatore (in x64, RCX) viene decrementato di uno dopo ogni operazione di trasferimento di memoria. Viene sempre decrementato, e sempre di uno. RCX conta le operazioni. Non ha nulla a che fare con gli indirizzi di memoria né con la dimensione del valore memorizzato in memoria.
</p>

### Addio Matematica BCD

<p align=justify>
Questo potrebbe sembrare un posto strano per parlare di istruzioni macchina che non sono più disponibili, ma ho un motivo. I lettori che hanno visto le edizioni precedenti di questo libro, in particolare l'edizione del 2009, potrebbero ricordare che il programma di esempio vidbuff1 utilizzava l'aritmetica BCD per generare i caratteri che compongono il righello. Per essere chiari, gli architetti di x64 hanno rimosso tutte le istruzioni di matematica BCD trovate nella definizione x86. Questo equivale a sei istruzioni: AAA, DAA, DAS, AAS, AAM, AAD. È al di fuori dell'ambito di questo libro spiegare la matematica BCD (l'edizione del 2009 ha una certa copertura se sei veramente interessato), e lo menziono solo perché nell'edizione del 2009, il programma vidbuff1 utilizzava la matematica BCD. Ci sono casi d'uso per la matematica BCD, principalmente nei calcoli finanziari, ma le istruzioni BCD di Intel risalgono a molto tempo fa, e oggi abbiamo tecniche di calcolo finanziario migliori. Fondamentalmente, la matematica BCD ti consentiva di aggiungere un carattere ASCII a un altro carattere ASCII. È complicato e lento e non è più possibile—perché le istruzioni che lo realizzano non sono più disponibili.
</p>

### MOVSB: Copie di blocco veloci

<p align=justify>
L'istruzione STOSB è un elemento affascinante, ma per pura azione racchiusa in una singola riga di codice assembly, non c'è nulla che possa eguagliare l'istruzione MOVS. Come STOS, MOVS viene in quattro "dimensioni", per gestire byte (MOVSB), parole a 16 bit (MOVSW), doppie parole a 32 bit (MOVSD) e quadruple parole a 64 bit (MOVSQ). Per lavorare con caratteri ASCII come facciamo in questo capitolo, MOVSB è quella da usare. La sostanza dell'istruzione MOVSB è questa: un blocco di dati di memoria all'indirizzo memorizzato in RSI viene copiato all'indirizzo memorizzato in RDI. Il numero di byte da spostare è posto nel registro RCX. RCX conta a rovescio di uno dopo che ogni byte è copiato, e gli indirizzi in RSI e RDI vengono regolati di uno. Per MOVSW, i registri di origine e destinazione vengono regolati di due dopo che ogni parola è copiata; per MOVSD, vengono regolati di quattro dopo che ogni doppia parola è copiata, e per MOVSQ, vengono regolati di otto byte dopo che ogni quadrupla parola è copiata. Queste regolazioni sono incrementi o decrementi, a seconda dello stato di DF. In tutti i casi, RCX viene decrementato di uno ogni volta che un elemento di dati passa dall'indirizzo sorgente all'indirizzo di destinazione. Ricorda che RCX conta le operazioni di trasferimento di memoria, non i byte di indirizzo! Il registro DF influisce su MOVSB nello stesso modo in cui influisce su STOSB. Per impostazione predefinita, DF è cancellato e le operazioni di stringa operano “in salita” dalla memoria bassa verso la memoria alta. Se DF è impostato, la direzione in cui funzionano le operazioni di stringa va in senso contrario, dalla memoria alta verso la memoria bassa. MOVSB può operare sia semiautomatica che automaticamente, proprio come con STOSB. Aggiungi il prefisso REP a MOVSB, e (presumendo che tu abbia impostato correttamente i registri) un blocco di memoria verrà copiato da qui a lì in un'unica istruzione, in un ciclo stretto all'interno della CPU. Per dimostrare MOVSB, ho aggiunto una breve procedura chiamata WrtLn. WrtLn copia una stringa in una certa posizione X,Y nel buffer di visualizzazione VidBuff. Fa un lavoro molto simile a Write in Pascal o print in C. Prima di chiamare WrtLn, posizioni l'indirizzo sorgente della stringa in RSI, le coordinate X,Y basate su 1 in RBX e RAX, e la lunghezza della stringa in byte in RCX. Il codice che fa il lavoro in WrtLn è piuttosto semplice:
</p>

```asm
 cld             ; Clear DF for up-memory write
 mov rdi,VidBuff  ; Load destination index with buffer address
 dec rax          ; Adjust Y value down by 1 for address calculation
 dec rbx          ; Adjust X value down by 1 for address calculation
 mov ah,COLS      ; Move screen width to AH
 mul ah           ; Do 8-bit multiply AL*AH to AX
 add rdi,rax      ; Add Y offset into vidbuff to RDI
 add rdi,rbx      ; Add X offset into vidbuf to RDI
 rep movsb        ; Blast the string into the buffer
```

<p align=justify>
Il codice per calcolare l'offset nel VidBuff dai valori X,Y utilizzando MUL è lo stesso utilizzato in Ruler. Nella sezione principale del programma di vidbuff1, vengono effettuati alcuni calcoli aggiuntivi per visualizzare una stringa centrata nel buffer visibile, piuttosto che in una specifica posizione X,Y:
</p>

```asm
 mov rsi,Message  ; Load the address of the message to RSI
 mov rcx,MSGLEN   ; and its length to RCX
 mov rbx,COLS     ; and the screen width to RBX
 sub rbx,rcx      ; Calc diff of message length and screen width
 shr rbx,1        ; Divide difference by 2 for X value
 mov rax,20       ; Set message row to Line 20
 call WrtLn       ; Display the centered message
```

### DF e Mosse di Blocco Sovrapposte

<p align=justify>
Il semplice programma dimostrativo vidbuff1 utilizza MOVSB per copiare un messaggio dalla sezione .data del programma nel buffer di visualizzazione. Sebbene WrtLn utilizzi MOVSB per copiare il messaggio "in salita" dalla memoria bassa a quella alta, si potrebbe sostenere che si potrebbe altrettanto facilmente copiarlo dalla memoria alta "in discesa" a quella bassa, e avresti ragione. Il flag di direzione DF non sembra essere più di una questione di preferenza... a meno che e fino a quando i tuoi blocchi di memoria sorgente e destinazione non si sovrappongano. Nulla richiede che RSI e RDI puntino a aree di memoria completamente separate. I blocchi di memoria sorgente e destinazione possono sovrapporsi e questo può spesso essere estremamente utile. Ecco un esempio: considera la sfida di modificare un testo memorizzato in un buffer di memoria. Supponiamo di avere una stringa in un buffer e di voler inserire un carattere da qualche parte a metà della stringa. Tutti i caratteri nella stringa oltre il punto di inserimento devono essere "spostati da parte" per fare spazio al nuovo carattere inserito. (Questo presuppone che ci sia spazio vuoto alla fine del buffer.) Questa è un'applicazione naturale per REP MOVSB—ma predisporla potrebbe essere più complicato di quanto sembri a prima vista. Ricordo vividamente la prima volta che ho provato, che non è coincidente, era la prima volta che ho mai tentato di usare MOVSB. Ciò che ho fatto è mostrato schematicamente nella parte sinistra della figura di sotto. L'obiettivo era spostare una stringa a destra di una posizione in modo da poter inserire un carattere spazio davanti ad essa.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/movsb_on_overlapping_memory_blocks.png">
</div>


<p align=justify>
Ho puntato RSI al primo byte della stringa e ho puntato RDI alla posizione in cui volevo spostare la stringa. Ho quindi eseguito un'istruzione REP MOVSB "in salita" e, quando la polvere si è posata, ho scoperto di aver sostituito l'intera stringa con il suo carattere iniziale. Sì, è un errore ovvio... una volta che lo vedi accadere realmente. (Sì, quando ho commesso questo errore, i registri erano di 16 bit e ero molto più giovane, ma le cose funzionano allo stesso modo in modalità long x64, e il bug è ancora molto facile da commettere.) Sul lato destro della figura c'è il modo in cui un'inserzione del genere dovrebbe essere effettivamente eseguita. Devi iniziare dalla parte alta della stringa e lavorare "in discesa" verso il punto di inserimento. Il primo spostamento del carattere deve portare l'ultimo carattere della stringa in uno spazio di buffer vuoto e fuori dal cammino del successivo spostamento del carattere, e così via. In questo modo, due aree di memoria che si sovrappongono tranne che per un byte possono essere copiate l'una nell'altra senza perdere alcun dato. Questo si mostra più facilmente di quanto si racconti. Se puoi osservare lo spostamento avvenire, diventa molto più chiaro. Ho creato una demo sandbox di un movimento di blocco sovrapposto nel codice di sotto. È progettata per SASM, motivo per cui ha il suffisso gcc.
</p>

```asm
section .data
                 ;0000000000011
                 ;0123456789012
    EditBuff: db 'abcdefghijklm '
    BUFFLEN   equ $-EditBuff
    ENDPOS    equ 12         ; 0-based number of last visible character
    INSRTPOS  equ 1
	
section .text

global main

main:
    mov rbp, rsp; for correct debugging

; Put your experiments between the two nops...
    nop

    std                        ; We're doing a "downhill" transfer
    mov rbx,EditBuff
    mov rsi,EditBuff+ENDPOS    ; Start at end of visible text
    mov rdi,EditBuff+ENDPOS+1  ; Bump text right by 1
    mov rcx,ENDPOS-INSRTPOS+2  ; # of chars to bump; not a 0-based address but a count
    rep movsb                  ; Move 'em!
    mov byte [rbx],' '         ; Write a space at insert point

; Put your experiments between the two nops...
    nop
```

<p align=justify>
Per guardare il film in SASM, devi caricare il codice, compilarlo e poi avviare il debugger. Una volta che sei in modalità di debug, seleziona Debug ➪ Mostra memoria. Nel campo Variabile o espressione, inserisci EditBuff. Nel campo Tipo, seleziona Char dal primo menu a discesa e b dal secondo menu a discesa. EditBuff è lungo 14 caratteri (incluso lo spazio finale), quindi inserisci 14 nel terzo campo. Non fare clic sulla casella di controllo Indirizzo. Ecco come funziona: ENDPOS è l'offset basato su 0 dell'ultimo carattere non spazio nella stringa. Nota che questo non è un conteggio, ma un offset dall'inizio di EditBuff. L'offset dell'ultimo carattere “m” dall'inizio del buffer è di 12 byte. Se inizi con l'indirizzo di EditBuff in RSI e aggiungi 12, RSI punterà a “m.” RDI, a sua volta, è puntato all'offset della prima posizione del buffer dopo l'ultimo carattere nella stringa, che è la ragione per il calcolo in fase di assemblaggio ENDPOS + 1, che punta al carattere di spazio alla fine di EditBuff. Derivare il conteggio da inserire in RCX deve tenere conto della natura basata su 0 degli offset degli indirizzi. Devi aggiungere 2 alla differenza tra la posizione finale della stringa (ENDPOS) e la posizione di inserimento (INSRTPOS) perché entrambe sono basate su 0, e per ottenere un conteggio corretto, devi aggiungere di nuovo i due 1 in più che avresti se ENDPOS e INSRTPOS fossero entrambi numeri basati su 1. (Ricorda che i conteggi di cose non sono basati su 0!) Nota l'istruzione STD che inizia il blocco di codice. STD imposta il Flag di Direzione DF su 1, il che costringe le istruzioni stringa a funzionare "in discesa" dalla memoria alta verso la memoria bassa. DF di default è 0, quindi per far funzionare questo codice, l'istruzione STD deve essere presente!
</p>

### Istruzioni di stringa REP con passo singolo

<p align=justify>
Dovrei menzionare qui che, anche se un'istruzione REP MOVSB sembra essere un'unica istruzione, in realtà si tratta di un ciclo estremamente ristretto implementato come un'unica istruzione. Fase per fase, la REP MOVSB in un debugger non esegue l'intero ciclo in un colpo solo! Ogni volta che fai clic sull'icona 'Step Into' di SASM, verrà eseguita solo un'operazione di trasferimento di memoria. Se RCX è caricato con un valore di conteggio di 13, ad esempio, dovrai fare clic sull'icona 'Step Into' 13 volte per avanzare attraverso l'intera istruzione. Questo ti consente di osservare i cambiamenti in memoria e nei registri mentre l'istruzione opera. Tuttavia, per valori di conteggio elevati in RCX, questo può comportare molti clic. Se sei sicuro della correttezza della configurazione della tua istruzione stringa, potresti voler inserire un break point dopo l'istruzione REP string e fare clic su 'Continue' (o premere F5) per eseguire l'istruzione stringa a piena velocità senza fermarti dopo ogni operazione di trasferimento di memoria. SASM si fermerà al break point, e potrai ispezionare lo stato finale del buffer di memoria e continuare a fare il single-stepping da lì. L'altro problema relativo all'osservazione dei trasferimenti di memoria con il debugger di SASM è il modo strano in cui SASM visualizza i buffer delle stringhe. Se selezioni 'Smart' dal primo menu a discesa, SASM visualizzerà EditBuff come una stringa di caratteri nella forma “abcdefghijklm” ma senza lo spazio finale. Puoi osservare il trasferimento avvenire con quella visualizzazione, ma non è l'intera situazione e potrebbe confonderti. La visualizzazione Char di EditBuff è in parte così perchè consente di includere caratteri non visualizzabili come EOL. Un carattere è mostrato come il suo equivalente decimale e poi il carattere reale tra apici singoli, come questo.
</p>

```asm
{97'a',98'b',99'c',100'd',101'e',102'f'103'g', ... 32''}
```

<p align=justify>
Questo formato ti mostrerà il carattere spaziatore alla fine di EditBuff, ma dovrai guardare attentamente per vedere il movimento mentre accade. La mia sincera speranza è che SASM un giorno includa una visualizzazione della memoria in stile hexdump, simile a quella di Insight.
</p>

### Memorizzare dati in stringhe discontinue

<p align=justify>
A volte devi infrangere le regole. Fino ad ora ho spiegato le istruzioni della stringa assumendo che la stringa di destinazione sia sempre una sequenza continua di byte in memoria. Questo non è necessariamente vero. Oltre a cambiare il valore in RAX tra le esecuzioni di STOSB, puoi anche cambiare l'indirizzo di destinazione. Il risultato finale è che puoi memorizzare dati in diverse aree di memoria all'interno di un singolo ciclo molto ristretto.
</p>

### Visualizzazione di una tabella ASCII

<p align=justify>
Ho creato un piccolo programma demo per SASM per mostrarvi cosa intendo. Non è utile come la procedura Ruler nel codice di prima, ma fa il suo punto ed è facile da capire se mi hai seguito finora. Il programma showchargcc utilizza molti degli stessi macchinari di base di vidbuff1, incluso il meccanismo di visualizzazione virtuale e il righello. Quindi, per risparmiare spazio sulla pagina del libro, non mostrerò l'intero programma qui. Il file completo del codice sorgente (come tutto il codice presentato in questo libro) può essere scaricato dalla mia pagina web in linguaggio assembly nel file zip dell'archivio degli elenchi. Il programma showchargcc cancella lo schermo, visualizza un righello sulla riga 1 e sotto mostra una tabella contenente 224 dei 256 caratteri ASCII, visualizzati ordinatamente in 7 righe di 32 caratteri ciascuna. La tabella include i 127 caratteri ASCII "alti", inclusi i caratteri delle lingue straniere, i caratteri di disegno delle linee e i simboli vari. Ciò che non visualizza sono i primi 32 caratteri ASCII. Linux li considera come caratteri di controllo, e anche quei caratteri per i quali sono disponibili glifi non vengono visualizzati nella console. Il programma showchargcc introduce un paio di nuovi concetti e istruzioni, tutti relativi ai cicli di programma. (Le istruzioni per stringhe come STOSB e i cicli di programma sono intimamente correlate.) Per risparmiare spazio sulla pagina, il listato di sotto presenta showchargcc senza le sue procedure. Tutte le procedure e le macro che invoca sono presenti nel codice precedente.
</p>

```asm
;  Executable name : showchargcc
;  Version         : 2.0
;  Created date    : 10/19/2022
;  Last update     : 7/15/2023
;  Author          : Jeff Duntemann
;  Description     : A simple program in assembly for Linux, 
;    demonstrating discontinuous string writes to memory using STOSB without
;    REP. The program loops through characters 32 through 255 and writes a
;    simple "ASCII chart" in a display buffer. The chart consists of 8 lines
;    of 32 characters, with the lines not continuous in memory.
;
;  Build using the standard SASM x64 build lines
;

SECTION .data       ; Section containing initialized data
    EOL 	equ 10  ; Linux end-of-line character
    FILLCHR	equ 32  ; Default to ASCII space character
    CHRTROW	equ 2   ; Chart begins 2 lines from top
    CHRTLEN	equ 32  ; Each chart line shows 32 chars

; This escape sequence will clear the console terminal and place the
; text cursor to the origin (1,1) on virtually all Linux consoles:
    ClrHome db 27,"[2J",27,"[01;01H"
    CLRLEN  equ $-ClrHome    ; Length of term clear string
    EOL     equ 10           ; Linux end-of-line character

	
; We use this to display a ruler across the screen. 
    RulerString db "12345678901234567890123456789012345678901234567890123456789012345678901234567890" 
    RULERLEN    equ $-RulerString
	
SECTION .bss                ; Section containing uninitialized data	

    COLS	equ 81          ; Line length + 1 char for EOL
    ROWS	equ 25          ; Number of lines in display
    VidBuff	resb COLS*ROWS  ; Buffer size adapts to ROWS & COLS

SECTION .text               ; Section containing code

global   main                ; Linker needs this to find the entry point!

ClearTerminal:
    push r11            ; Save all modified registers
    push rax
    push rcx
    push rdx
    push rsi
    push rdi

    mov rax,1           ; Specify sys_write call
    mov rdi,1           ; Specify File Descriptor 1: Standard Output
    mov rsi,ClrHome     ; Pass address of the escape sequence
    mov rdx,CLRLEN      ; Pass the length of the escape sequence
    syscall	            ; Make system call

    pop rdi             ; Restore all modified registers
    pop rsi
    pop rdx
    pop rcx
    pop rax
    pop r11
    ret

;-------------------------------------------------------------------------
; Show:         Display a text buffer to the Linux console
; UPDATED:      5/10/2023
; IN:           Nothing
; RETURNS:      Nothing
; MODIFIES:     Nothing
; CALLS:        Linux sys_write
; DESCRIPTION:  Sends the buffer VidBuff to the Linux console via sys_write.
;               The number of bytes sent to the console is calculated by
;               multiplying the COLS equate by the ROWS equate.

Show:	
    push r11            ; Save all registers we're going to change
    push rax
    push rcx
    push rdx
    push rsi
    push rdi

    mov rax,1           ; Specify sys_write call
    mov rdi,1           ; Specify File Descriptor 1: Standard Output
    mov rsi,VidBuff     ; Pass address of the buffer
    mov rdx,COLS*ROWS   ; Pass the length of the buffer
    syscall             ; Make system call

    pop rdi             ; Restore all modified registers
    pop rsi
    pop rdx
    pop rcx
    pop rax
    pop r11
    ret

;-------------------------------------------------------------------------
; ClrVid:       Clears a buffer to spaces and replaces overwritten EOLs
; UPDATED:      5/10/2023
; IN:           Nothing
; RETURNS:      Nothing
; MODIFIES:     VidBuff, DF
; CALLS:        Nothing
; DESCRIPTION:  Fills the buffer VidBuff with a predefined character
;               (FILLCHR) and then places an EOL character at the end
;               of every line, where a line ends every COLS bytes in
;               VidBuff.

ClrVid:	push rax        ; Save registers that we change
	push rcx
	push rdi
	cld                 ; Clear DF; we're counting up-memory
	mov al,FILLCHR      ; Put the buffer filler char in AL
	mov rdi,VidBuff     ; Point destination index at buffer
	mov rcx,COLS*ROWS   ; Put count of chars stored into RCX
	rep stosb           ; Blast byte-length chars at the buffer

; Buffer is cleared; now we need to re-insert the EOL char after each line:
	mov rdi,VidBuff     ; Point destination at buffer again
	dec rdi             ; Start EOL position count at VidBuff char 0
	mov rcx,ROWS        ; Put number of rows in count register

.PtEOL:	add rdi,COLS    ; Add column count to RDI
	mov byte [rdi],EOL  ; Store EOL char at end of row
	loop .PtEOL         ; Loop back if still more lines
	pop rdi             ; Restore caller's registers
	pop rcx
	pop rax
	ret                 ; and go home!

;-------------------------------------------------------------------------
; Ruler:        Generates a "1234567890"-style ruler at X,Y in text buffer
; UPDATED:      5/10/2023
; IN:           The 1-based X position (row #) is passed in RBX
;               The 1-based Y position (column #) is passed in RAX
;               The length of the ruler in chars is passed in RCX
; RETURNS:      Nothing
; MODIFIES:     VidBuff
; CALLS:        Nothing
; DESCRIPTION:  Writes a ruler to the video buffer VidBuff, at the 1-based
;               X,Y position passed in RBX,RAX. The ruler consists of a
;               repeating sequence of the digits 1 through 0. The ruler
;               will wrap to subsequent lines and overwrite whatever EOL
;               characters fall within its length, if it will not fit
;               entirely on the line where it begins. Note that the Show
;               procedure must be called after Ruler to display the ruler
;               on the console.

Ruler:  
    push rax         ; Save the registers we change
    push rbx
    push rcx
    push rdx
    push rdi

    mov rdi,VidBuff   ; Load video buffer address to RDI
    dec rax           ; Adjust Y value down by 1 for address calculation
    dec rbx           ; Adjust X value down by 1 for address calculation
    mov ah,COLS       ; Move screen width to AH
    mul ah            ; Do 8-bit multiply AL*AH to AX
    add rdi,rax       ; Add Y offset into vidbuff to RDI
    add rdi,rbx       ; Add X offset into vidbuf to RDI
        
; RDI now contains the memory address in the buffer where the ruler
; is to begin. Now we display the ruler, starting at that position:
    mov rdx,RulerString  ; Losd address of ruler string into RDX

DoRule: 
    mov byte al,[rdx] ; Load first digit in the ruler to AL
    stosb             ; Store 1 char; note that there's no REP prefix!
    inc rdx           ; Increment RDX to point to next char in ruler string
    loop DoRule       ; Decrement RCX & Go back for another char until RCX=0

    pop rdi           ; Restore the registers we saved
    pop rdx
    pop rcx
    pop rbx
    pop rax
    ret    

;-------------------------------------------------------------------------
; MAIN PROGRAM:
;-------------------------------------------------------------------------	
main:
    mov rbp,rsp

; Get the console and text display text buffer ready to go:
    call ClearTerminal  ; Send terminal clear string to console
    call ClrVid         ; Init/clear the video buffer

; Show a 64-character ruler above the table display:
    mov rax,1           ; Start ruler at display position 1,1
    mov rbx,1
    mov rcx,32          ; Make ruler 32 characters wide
    call Ruler          ; Generate the ruler

; Now let's generate the chart itself:
    mov rdi,VidBuff     ; Start with buffer address in RDI
    add rdi,COLS*CHRTROW    ; Begin table display down CHRTROW lines
    mov rcx,224         ; Show 256 chars minus first 32
    mov al,32           ; Start with char 32; others won't show
.DoLn:	mov bl,CHRTLEN  ; Each line will consist of 32 chars
.DoChr:	stosb           ; Note that there's no REP prefix!
    jrcxz AllDone       ; When the full set is printed, quit
    inc al              ; Bump the character value in AL up by 1
    dec bl              ; Decrement the line counter by one
    loopnz .DoChr       ; Go back & do another char until BL goes to 0
    add rdi,COLS-CHRTLEN   ; Move RDI to start of next line
    jmp .DoLn           ; Start display of the next line

; Having written all that to the buffer, send the buffer to the console:
AllDone:
    call Show           ; Refresh the buffer to the console
Exit:
    ret
```
### Cicli di istruzioni annidati

<p align=justify>
Una volta che tutti i registri sono stati impostati correttamente secondo le ipotesi fatte da STOSB, il lavoro reale di showchargcc è svolto da due cicli di istruzioni, uno dentro l'altro. Il ciclo interno visualizza una linea composta da 32 caratteri. Il ciclo esterno suddivide la visualizzazione in sette di queste linee. Il ciclo interno è di gran lunga il più interessante dei due. Ecco qui:
</p>

```asm
 .DoChr:
     stosb          ; Note that there's no REP prefix!
     jrcxz AllDone  ; When the full set is printed, quit
     inc al         ; Bump the character value in AL up by 1
     dec bl         ; Decrement the line counter by one
     loopnz .DoChr  ; Go back & do another char until BL goes to 0
```

<p align=justify>
Il lavoro qui (mettere un carattere nel buffer di visualizzazione) è nuovamente svolto da STOSB. Ancora una volta, STOSB lavora da solo, senza REP. Senza REP per tirare il ciclo all'interno della CPU, devi impostare tu stesso il ciclo. Tieni presente cosa accade ogni volta che STOSB si attiva: il carattere in AL viene scritto nella posizione di memoria puntata da RDI, e RDI viene incrementato di 1. All'altra estremità del ciclo, l'istruzione LOOPNZ decrementa RCX di 1 e chiude il ciclo. Durante l'impostazione dei registri, abbiamo caricato RCX con il numero di caratteri che volevamo visualizzare - in questo caso, 224. (Sono 224 caratteri perché i primi 32 caratteri dell'elenco completo di 256 sono principalmente caratteri di controllo e non possono essere visualizzati.) Ogni volta che STOSB si attiva, inserisce un altro carattere nel buffer di visualizzazione VidBuff, e ci sono un carattere in meno da visualizzare. RCX funge da master counter, tenendo traccia di quando finalmente visualizziamo l'ultimo carattere rimanente. Quando RCX arriva a zero, abbiamo visualizzato il sottoinsieme appropriato del set di caratteri ASCII e il lavoro è completato.
</p>

### Salto quando RCX arriva a 0

<p align=justify>
JRCXZ è un'istruzione di salto speciale creata specificamente per aiutare con i cicli come questo. Ho spiegato come sia possibile effettuare un salto usando una delle molte variazioni dell'istruzione JMP, basata sullo stato di uno o più flag della CPU. All'inizio di questo capitolo, ho spiegato l'istruzione LOOP, che è una sorta di JMP con uno scopo speciale, combinata con un'istruzione DEC RCX implicita. JRCXZ è un'altra varietà di istruzione JMP, ma una che non osserva alcun flag o diminuisce alcun registro. Invece, JRCXZ osserva il registro RCX. Quando vede che RCX è appena andato a zero, salta all'etichetta specificata. Se RCX è ancora diverso da zero, l'esecuzione passa all'istruzione successiva in linea. Nel caso del ciclo interno mostrato in precedenza, JRCXZ salta al codice 'chiudiamo bottega' quando vede che RCX è finalmente arrivato a 0. Questo è il modo in cui termina il programma showchar. La maggior parte delle altre istruzioni JMP ha partner che saltano quando il flag di controllo non è vero. Cioè, JC (Jump on Carry) salta quando il flag di riporto è uguale a 1. Il suo partner, JNC (Jump on Not Carry), salta se il flag di riporto non è 1. Tuttavia, JRCXZ è un solitario. Non c'è istruzione JRCXNZ, quindi non cercarne una nel riferimento delle istruzioni!
</p>

### Chiusura del ciclo interno

<p align=justify>
Si supponga che RCX non sia ancora stato decrementato a 0 dall'istruzione STOSB (una condizione monitorata da JRCXZ), il ciclo continua. AL viene incrementato. In questo modo viene selezionato il successivo carattere ASCII in linea. Il valore in AL viene inviato alla posizione memorizzata in RDI da STOSB. Se incrementi il valore in AL, cambi il carattere visualizzato con il successivo nella linea. Ad esempio, se AL contiene il valore per il carattere A (65), incrementando AL cambia il carattere A in un B (66). Nella successiva esecuzione del ciclo, STOSW invierà un B allo schermo invece di un A. Dopo che il codice del carattere in AL è stato incrementato, BL viene decrementato. Ora, BL non è direttamente correlato alle istruzioni della stringa. Nulla in nessuna delle assunzioni fatte dalle istruzioni della stringa coinvolge BL. Stiamo usando BL per qualcos'altro completamente qui. BL funge da contatore che governa la lunghezza delle righe di caratteri visualizzate sullo schermo. BL è stato caricato in precedenza con il valore rappresentato dall'equazione CHRTLEN, che ha il valore 32. Ad ogni passaggio attraverso il ciclo, l'istruzione DEC BL decrementa il valore di BL di 1. Quindi, l'istruzione LOOPNZ ottiene il suo momento di gloria. LOOPNZ è leggermente diverso dal nostro amico LOOP che abbiamo esaminato in precedenza. È solo abbastanza diverso da metterti nei guai se non capisci veramente come funziona. Sia LOOP che LOOPNZ decrementano il registro RCX di 1. LOOP monitora lo stato del registro RCX e chiude il ciclo finché RCX non arriva a 0. LOOPNZ osserva sia lo stato del registro RCX sia lo stato del flag zero ZF. (LOOP ignora ZF.) LOOPNZ chiuderà il ciclo solo se RCX <> 0 e ZF = 0. In altre parole, LOOPNZ chiude il ciclo solo se RCX ha ancora qualcosa al suo interno e se il flag Zero ZF non è impostato. Quindi, cosa sta esattamente osservando LOOPNZ qui? Ricorda che immediatamente prima dell'istruzione LOOPNZ, stiamo decrementando BL di 1 attraverso un'istruzione DEC BL. L'istruzione DEC influisce sempre su ZF. Se l'operando di DEC arriva a zero per effetto dell'istruzione DEC, ZF diventa 1 (è impostato). Altrimenti, ZF rimane 0 (rimane azzerato). Quindi, effettivamente, LOOPNZ sta monitorando lo stato del registro BL. Finché BL non viene decrementato a 0 (impostando ZF), LOOPNZ chiude il ciclo. Dopo che BL è arrivato a zero, il ciclo interno è terminato e l'esecuzione passa attraverso LOOPNZ all'istruzione successiva. E per quanto riguarda RCX? Bene, LOOPNZ sta infatti osservando RCX, ma anche JRCXZ. JRCXZ è in realtà l'interruttore che governa quando l'intero ciclo —sia le porzioni interne che quelle esterne—ha svolto il suo lavoro e deve fermarsi. Quindi, mentre LOOPNZ osserva RCX, qualcun altro sta svolgendo quel compito e quel qualcun altro agirà su RCX prima che LOOPNZ possa farlo. Il compito di LOOPNZ è quindi quello di decrementare RCX ma di monitorare BL. Governa il ciclo interno dei due.
</p>

### Chiusura del ciclo esterno

<p align=justify>
Ma significa questo che JRCXZ chiude il ciclo esterno? No. JRCXZ ci dice quando entrambi i cicli sono terminati. La chiusura del ciclo esterno viene eseguita in modo leggermente diverso rispetto alla chiusura del ciclo interno. Dai un'altra occhiata ai due cicli nidificati:
</p>

```asm
 .DoLn:
 	mov bl,CHRTLEN        ; Each line will consist of 32 chars

 .DoChr:
 	stosb                 ; Note that there's no REP prefix!
	jrcxz AllDone         ; When the full set is printed, quit
	inc al                ; Bump the character value in AL up by 1
 	dec bl                ; Decrement the line counter by one
	loopnz .DoChr         ; Go back & do another char until BL = 0
	add rdi,COLS-CHRTLEN  ; Move RDI to start of next line
	jmp .DoLn             ; Start display of the next line
```

<p align=justify>
Il ciclo interno si considera completato quando abbiamo visualizzato un'intera riga della tabella ASCII sullo schermo. BL governa la lunghezza di una riga e quando BL arriva a zero (cosa che l'istruzione LOOPNZ rileva), una riga è finita. LOOPNZ quindi passa all'istruzione ADD che modifica RDI. Modifichiamo RDI per saltare dall'indirizzo della fine di una riga completata nel buffer di visualizzazione all'inizio della riga successiva al margine sinistro. Questo significa che dobbiamo "avvolgere" un certo numero di caratteri dalla fine della riga della tabella ASCII alla fine dello schermo visibile. Il numero di byte richiesto è dato dall'espressione a tempo di assemblaggio COLS-CHRTLEN. Questo è fondamentalmente la differenza tra la lunghezza di una riga della tabella ASCII e la larghezza dello schermo virtuale. (Non la larghezza della finestra del terminale a cui lo schermo virtuale è visualizzato!) Il risultato dell'espressione è il numero di byte che dobbiamo muovere ulteriormente nel buffer di visualizzazione per arrivare all'inizio della riga successiva al margine sinistro dello schermo. Ma dopo che quell'avvolgimento è stato realizzato modificando RDI, il lavoro del ciclo esterno è finito e chiudiamo il ciclo. Questa volta lo facciamo incondizionatamente tramite un semplice JMP. L'obiettivo dell'istruzione JMP è l'etichetta locale .DoLn. Nessun se, nessun argomento. Alla cima del ciclo esterno (rappresentato dall'etichetta .DoLn), ricarichiamo la lunghezza di una riga della tabella nel registro BL ora vuoto e poi torniamo nel ciclo interno. Il ciclo interno inizia a lanciare caratteri di nuovo nel buffer e continuerà a farlo finché JRCXZ non rileva che RCX è arrivato a 0. A quel punto, sia i cicli interno che esterno sono finiti e l'intera tabella ASCII è stata scritta in VidBuff. Con questo completato, il buffer può essere inviato alla console Linux chiamando la procedura Show.
</p>

###  Showchar Recap

<p align=justify>
Rivisitiamo ciò che abbiamo appena passato, poiché è indubbiamente piuttosto complesso. Il programma showchar contiene due cicli annidati: il ciclo interno invia caratteri allo schermo tramite STOSB. Il ciclo esterno invia righe di caratteri allo schermo, ripetendo il ciclo interno un certo numero di volte. (Qui, 7.) Il ciclo interno è governato dal valore nel registro BL, che è inizialmente impostato per prendere la lunghezza di una riga di caratteri. (Qui, 32.) Il ciclo esterno non è esplicitamente governato dal numero di righe da visualizzare. Cioè, non si carica il numero 7 in un registro e lo si decrementa. Invece, il ciclo esterno continua fino a quando il valore in RCX non scende a 0, indicando che l'intero lavoro—visualizzare tutti i 224 caratteri che vogliamo mostrare—è completato. Entrambi i cicli, interno ed esterno, modificano i registri con cui lavora STOSB. Il ciclo interno modifica AL dopo ogni carattere inviato allo schermo. Questo rende possibile visualizzare un carattere diverso ogni volta che STOSB viene eseguito. Il ciclo esterno modifica RDI (il registro dell'indice di destinazione) ogni volta che una riga di caratteri è completata. Questo ci consente di suddividere la stringa di destinazione in sette righe separate, non contigue e non identiche.
</p>

### Argomenti da linea di comando, ricerche di stringhe e lo stack di Linux

<p align=justify>
Quando avvii un programma al prompt dei comandi della console Linux, hai la possibilità di includere un numero ragionevole di argomenti dopo il percorso del programma eseguibile. In altre parole, puoi eseguire un programma chiamato showargs1 in questo modo:
</p>

```
$./showargs1 time for tacos
```

<p align=justify>
I tre argomenti seguono il nome del programma e sono separati da caratteri di spazio. Nota che questi non sono gli stessi dei parametri di reindirizzamento I/O, che richiedono l'uso degli operatori di reindirizzamento “>” o “<” e sono gestiti separatamente da Linux. Quando uno dei tuoi programmi inizia a essere eseguito, qualsiasi argomento della riga di comando che è stato inserito al momento del lancio del programma viene passato al programma nello stack di Linux. In questo capitolo, vedremo come accedere agli argomenti della riga di comando di un programma da un programma in linguaggio assembly. Nel processo, vedremo un'altra istruzione di stringa x86 in azione: SCASB.
</p>

### Visualizzazione degli argomenti della riga di comando da SASM

<p align=justify>
Il fatto che Linux posizioni gli argomenti della riga di comando nello stack non significa che tu debba accedere direttamente allo stack per ottenerli. Dai programmi scritti all'interno dell'IDE SASM, l'accesso agli argomenti ti arriva nei registri RSI e RDI. Funziona in questo modo:
</p>

<ul>
	<li>
		<p align=justify>
		All'avvio del programma, il registro RDI contiene un valore, 1 o maggiore, che indica il numero di argomenti della riga di comando. Il valore è sempre almeno 1 perché Linux posiziona sempre il testo di invocazione della riga di comando del programma come primo elemento nella sua lista di argomenti della riga di comando.
		</p>
	</li>
 		<p align=justify>
		All'avvio, il registro RSI contiene l'indirizzo del primo elemento nella lista degli argomenti della riga di comando. Ricorda che quel primo elemento è sempre l'invocazione della riga di comando del programma. Se non ci sono argomenti della riga di comando, il testo di invocazione è l'unica cosa a cui puoi accedere da RSI. Se ci sono argomenti della riga di comando, ci sarà un elenco di indirizzi in memoria, con ogni indirizzo che punta a uno degli argomenti.
		</p>
	</li>
</ul>

<p align=justify>
Ricorda che questo vale per i programmi che crei con SASM utilizzando i parametri di build predefiniti, o per i programmi non SASM che colleghi con gcc. Perché? SASM utilizza il compilatore Gnu C gcc come linker e richiede l'etichetta main: come inizio del programma. Tutti i programmi C hanno quella che viene chiamata la funzione principale, main(), che è la parte del programma che scrivi. In sostanza, ciò che SASM costruisce è un programma C per il quale si scrive la funzione main(). La parte difficile è che gcc si collega a un blocco di codice che viene eseguito prima che la funzione main() inizi l'esecuzione. Questo codice di "avvio" fa una serie di cose. Per questa discussione, ciò che conta è che copi il conteggio degli argomenti e il puntatore alla tabella degli argomenti dallo stack e nei registri RSI e RDI. Vedere la Figura di sotto. Si noti che i programmi collegati a glibc ma costruiti al di fuori di SASM hanno le stesse informazioni utili in RSI e RDI, per gentile concessione del codice di avvio di glibc. Più avanti spiegherò come i programmi assembly compilati senza collegarsi con gcc possono leggere le stesse informazioni dallo stack. Per ora date un'occhiata al listato di sotto, un programma che visualizza i parametri della riga di comando, scritto per SASM.
</p>

```asm
;  Executable name : showargs1gcc
;  Version         : 2.0
;  Created date    : 10/17/2022
;  Last update     : 7/18/2023
;  Author          : Jeff Duntemann
;  Description     : A simple program in assembly for Linux, using NASM 2.14.02,
;                    demonstrating how to access command line arguments from
;                    programs written/built in SASM.
;
;                Build using SASM standard x64 build setup
;
SECTION .data                   ; Section containing initialised data

    ErrMsg db "Terminated with error.",10
    ERRLEN equ $-ErrMsg
        
    MAXARGS equ 5               ; More than 5 arguments triggers an error
	
SECTION .bss                    ; Section containing uninitialized data	

SECTION .text                   ; Section containing code

global 	main                    ; Linker needs this to find the entry point!
	
main:
    mov rbp, rsp            ; for correct SASM debugging
    nop                     ; This no-op keeps gdb happy...

    mov r14,rsi             ; Put offset of arg table in r14
    mov r15,rdi             ; Put argument count in r15

    cmp qword r15,MAXARGS   ; Test for too many arguments
    ja Error                ; Show error message if too many args & quit
              
; Use SCASB to find the 0 at the end of the single argument
    xor rbx,rbx             ; RBX contains the 0-based # (not address) of current arg 
Scan1:
    xor rax,rax             ; Searching for string-termination 0, so clear AL to 0
    mov rcx,0000ffffh       ; Limit search to 65535 bytes max
    mov rdi,qword [r14+rbx*8] ; Put address of string to search in RDI, for SCASB     
    mov rdx,rdi             ; Copy string address into RDX for subtraction
                                                                                                                                                                                                                                                                                                                    
    cld                     ; Set search direction to up-memory
    repne scasb             ; Search for null (0) in string at RDI
    jnz Error               ; Jump to error message display if null not found.

    mov byte [rdi-1],10     ; Store an EOL where the null used to be
    sub rdi,rdx             ; Subtract position of 0 in RDI from start address in RDX
    mov r13,rdi             ; Put calculated arg length into R13

; Display the argument to stdout:
    mov rax,1               ; Specify sys_write call
    mov rdi,1               ; Specify File Descriptor 1: Standard Output
    mov rsi,rdx             ; Pass offset of the arg in RSI
    mov rdx,r13             ; Pass length of arg in RDX
    syscall                 ; Make kernel call

    inc rbx                 ; Increment the argument counter
    cmp rbx,r15             ; See if we've displayed all the arguments
    jb Scan1                ; If not, loop back and do another
    jmp Exit                ; We're done! Let's pack it in!

Error:
    mov rax,1               ; Specify sys_write call
    mov rdi,1               ; Specify File Descriptor 2: Standard Error
    mov rsi,ErrMsg          ; Pass offset of the error message
    mov rdx,ERRLEN          ; Pass the length of the message
    syscall                 ; Make kernel call

Exit:
    ret
```

<div aling=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/how_to_access_parameters_from_within_SASM.png">
</div>

### Ricerche di stringhe con SCASB

<p align=justify>
Poiché il codice di avvio di glibc copia il conteggio degli argomenti e il puntatore alla tabella nei registri per te, accedere agli argomenti della riga di comando è facile. Hai quello che equivale a una tabella di indirizzi nello stack, e ogni indirizzo punta a un argomento. L'unica parte complicata è determinare quanti byte appartengono a ciascun argomento in modo da poter copiare i dati degli argomenti altrove se necessario, o passarli a una chiamata di sistema Linux come sys_write. Poiché ogni argomento termina con un singolo byte 0, la sfida è chiara: dobbiamo cercare quel 0. Questo può essere fatto nel modo ovvio, in un ciclo che legge un byte da un indirizzo in memoria, e poi confronta quel byte con 0 prima di incrementare un contatore e leggere il byte successivo in memoria. Tuttavia, la buona notizia è che il set di istruzioni x64 implementa un tale ciclo in un'istruzione di stringa che non memorizza dati (come STOSB) o copia dati (come MOVSB) ma cerca invece in memoria un valore di dato particolare. Questa istruzione è SCASB (Scan String by Byte), e se hai seguito la mia presentazione sulle altre istruzioni di stringa finora, capirla dovrebbe essere un gioco da ragazzi. Il codice di sopra dimostra SCASB esaminando gli argomenti della riga di comando nello stack e costruendo una tabella delle lunghezze degli argomenti. Successivamente, restituisce gli argomenti (insieme al testo di invocazione del file eseguibile) a stdout tramite una chiamata a sys_write. La prima cosa da fare è copiare il conteggio degli argomenti e il puntatore della tabella in registri differenti, in questo caso R14 e R15. Perché? I registri RSI e RDI hanno entrambi agende segrete: RDI fa parte dell'uso di SCASB (ne parlerò tra poco) e RSI è utilizzato per effettuare chiamate sys_write. Vuoi mantenere il conteggio degli argomenti e il puntatore della tabella degli indirizzi al sicuro in registri che non saranno utilizzati per altre cose. Stiamo usando un prefisso qui per la prima volta in questo libro: REPNE. Questo può essere letto come “Ripeti finché non è uguale.” Spiegherò questo in maggior dettaglio tra poco. Quando REPNE è usato insieme a SCASB, l'istruzione REPNE SCASB può trovare il byte 0 alla fine di ogni argomento. Configurare SCASB è grossomodo lo stesso che configurare STOSB:
</p>

<ul>
	<li>
		<p align=justify>
		Per le ricerche in memoria avanzata (come questa), viene utilizzata l'istruzione CLD per garantire che il flag di Direzione DF sia resettato.
		</p>
	</li>
 	<li>
		<p align=justify>
		L'indirizzo del primo byte della stringa da cercare è collocato in RDI. Qui, è l'indirizzo di un argomento della riga di comando memorizzato da qualche parte nello stack.
		</p>
	</li>
 	<li>
		<p align=justify>
		Il valore da cercare è posizionato nel registro a 8 bit AL. (Qui, il numero binario 0.)
		</p>
	</li>
 	<li>
		<p align=justify>
		Un conteggio massimo è impostato in RCX. Questo viene fatto per evitare di cercare troppo lontano nella memoria nel caso in cui il byte che stai cercando non sia effettivamente presente.
		</p>
	</li>
</ul>

<p align=justify>
Con tutto ciò in atto, REPNE SCASB può essere eseguito. Come con STOSB, questo crea un ciclo stretto all'interno della CPU. Ad ogni passaggio nel ciclo, il byte a [RDI] viene confrontato con il valore in AL. Se i valori sono uguali, il ciclo è soddisfatto e REPNE SCASB smette di essere eseguito. Se i valori non sono uguali, RDI viene incrementato di 1, RCX viene decrementato di 1 e il ciclo continua con un altro test del byte a [RDI]. Quando REPNE SCASB trova il carattere in AL e termina, RDI punterà al byte dopo la posizione del carattere trovato nella stringa di ricerca. Se vuoi accedere al carattere trovato, devi sottrarre 1 da RDI, come fa il programma quando sostituisce il carattere terminatore 0 con un carattere EOL:
</p>

```asm
mov byte [rdi-1],10 ; Store an EOL where the 0 used to be
```

### REPNE vs. REPE

<p align=justify>
Vale la pena dare un'occhiata più da vicino al prefisso REPNE qui, insieme al suo partner con il senso opposto, REPE. L'istruzione SCASB è un po' diversa da STOSB e MOVSB in quanto è un'istruzione di stringa condizionale. STOSB e MOVSB ripetono entrambi la loro azione incondizionatamente quando sono preceduti dal prefisso REP. Non ci sono test in corso se non il test di RCX per vedere se il ciclo è continuato per il numero di iterazioni predeterminato. Al contrario, SCASB esegue un test separato ogni volta che viene attivato, e ogni test può andare in due modi. Ecco perché non utilizziamo il prefisso REP incondizionato con SCASB, ma il prefisso REPNE oppure il prefisso REPE. Quando stiamo cercando un byte nella stringa di ricerca che corrisponde al byte in AL, usiamo il prefisso REPNE, come viene fatto nel programma showargs1gcc. Quando stiamo cercando un byte nella stringa di ricerca che non corrisponde al byte in AL, usiamo REPE. Potresti pensare che suoni all'incontrario in qualche modo, e lo è. Tuttavia, il senso del prefisso REPNE è questo: Ripeti SCASB finché [RDI] non è uguale ad AL. Allo stesso modo, il senso del prefisso REPE è questo: Ripeti SCASB finché [RDI] è uguale ad AL. Il prefisso indica per quanto tempo l'istruzione SCASB dovrebbe continuare a scattare, non quando dovrebbe fermarsi. È importante ricordare che REPNE SCASB può terminare per due motivi: trova una corrispondenza con il byte in AL, oppure conta RCX fino a 0. Nella quasi totalità dei casi, se RCX è zero quando REPNE SCASB finisce, significa che il byte in AL non è stato trovato nella stringa di ricerca. Tuttavia, c'è la possibilità casuale che RCX sia semplicemente conteggiato fino a zero quando [RDI] conteneva una corrispondenza con AL. Questo non è molto probabile, ma ci sono alcune combinazioni di dati in cui potrebbe verificarsi. Ogni volta che SCASB scatta, esegue un confronto, e quel confronto imposta o cancella il flag Zero ZF. REPNE terminerà l'istruzione quando il suo confronto imposta ZF a 1. REPE terminerà l'istruzione quando il suo confronto cancella ZF a 0. Tuttavia, per essere assolutamente sicuro di catturare il risultato "ricerca fallita", devi testare immediatamente ZF dopo la fine dell'istruzione SCASB.
</p>

<p align=justify>
Per REPNE SCASB: Usa JNZ. 
</p>

<p align=justify>
Per REPE SCASB: Usa JZ
</p>

### Non puoi passare argomenti da linea di comando ai programmi all'interno di SASM

<p align=justify>
Se costruisci e poi esegui il Listato codice di sopra all'interno di SASM, ciò che verrà mostrato sarà il primo elemento nell'elenco, che è il testo di invocazione per il programma. Tuttavia, questo testo di invocazione non includerà il nome showargs1gcc. Quello che vedrai sarà questo o qualcosa di molto simile a questo:
</p>

```
/tmp/SASM/SASMprog.exe
```

<p align=justify>
Perché? Quando esegui un programma all'interno di SASM, ciò che stai eseguendo è un file binario temporaneo chiamato SASMprog.exe. SASM genera questo file quando costruisce un programma per te. È lo stesso nome del file per qualsiasi programma tu scriva in SASM. Il file eseguibile showargs1gcc non esiste finché non lo crei salvando l'eseguibile su disco. E non puoi eseguirlo fino a quando non apri una finestra del terminale, non navighi nella cartella in cui esiste il programma eseguibile, e poi lo esegui dalla riga di comando. Questo ci porta a uno dei principali difetti di SASM: per quanto ne so, non esiste un meccanismo in SASM per memorizzare gli argomenti della riga di comando che verranno passati a un programma eseguito all'interno di SASM. Per far sì che showargs1gcc mostri effettivamente gli argomenti, devi salvarlo come file eseguibile ed eseguirlo dalla riga di comando del terminale.
</p>

<p align=justify>
Se esegui showargs1gcc dalla riga di comando in questo modo:
</p>

```
$ ./showargs1gcc time for tacos
```

<p align=justify>
vedrai il seguente nella finestra del terminale:
</p>

```
./showargs1gcc
 time
 for
 tacos
```

<p align=justify>
Ogni argomento della riga di comando è su una riga separata perché il programma sostituisce il byte 0 alla fine di ogni argomento con un carattere EOL. Solo un rapido promemoria: salva un file eseguibile selezionando l'elemento di menu File ➪ Salva .exe in SASM e poi inserendo il nome che vuoi dare al file del programma eseguibile. Il nome non deve essere necessariamente quello del file del codice sorgente meno il .asm. Non è necessario usare il suffisso .exe. La maggior parte degli eseguibili Linux sono semplicemente un nome senza alcun suffisso. Puoi chiamarlo come vuoi. Tuttavia, ti consiglio vivamente di salvare il file eseguibile nella stessa cartella in cui si trovano il suo file di codice sorgente e il makefile.
</p>

### Lo Stack, la sua struttura e come usarlo

<p align=justify>
Lo stack è molto più grande e complesso di quanto tu possa pensare. Quando Linux carica il tuo programma, posiziona una grande quantità di informazioni nello stack prima di permettere l'esecuzione del codice del programma. Questo include il testo di invocazione dell'eseguibile in esecuzione, eventuali argomenti della riga di comando inseriti dall'utente durante l'esecuzione del programma e lo stato corrente dell'ambiente Linux, che è una grande collezione di stringhe di configurazione testuali che definiscono come è impostato Linux. Tutto questo è organizzato secondo un piano, e ho riassunto il piano nella figura di sotto. Prima, alcune rinfrescate di gergo: la parte superiore dello stack è (controintuitivamente) in fondo al diagramma. È il luogo di memoria indicato da RSP quando il tuo programma inizia a essere eseguito. La parte inferiore dello stack è in cima al diagramma. È l'indirizzo più alto nello spazio degli indirizzi virtuali che Linux assegna al tuo programma quando lo carica e lo esegue. Questa distinzione tra “alto” e “basso” è una convenzione antica che confonde molte persone. I diagrammi di memoria solitamente iniziano con la memoria bassa in fondo alla pagina e raffigurano la memoria più alta sopra di essa, anche se questo significa che la parte inferiore dello stack si trova in cima al diagramma. Abituati, se vuoi comprendere la letteratura, non hai scelta. Linux costruisce lo stack dalla memoria alta verso la memoria bassa, iniziando dalla parte inferiore dello stack e proseguendo verso la memoria più bassa. Quando il codice del tuo programma inizia effettivamente a essere eseguito, RSP punta alla parte superiore dello stack. Ecco una descrizione più dettagliata di ciò che troverai nello stack all'avvio:
</p>

<ul>
	<li>
		<p align=justify>
		In RSP (cioè, la cima dello stack) c'è un numero a 64 bit che indica il numero di argomenti della riga di comando presenti nello stack. Questo valore è sempre almeno 1, anche se non sono stati inseriti argomenti. Il testo digitato dall'utente durante l'esecuzione del programma viene conteggiato insieme a eventuali parametri della riga di comando, e questo "testo di invocazione" è sempre presente, motivo per cui il conteggio è sempre almeno 1.
		</p>
	</li>
 	<li>
		<p align=justify>
		Il prossimo elemento a 64 bit in memoria a partire da RSP è l'indirizzo del testo di invocazione con cui è stato eseguito il file eseguibile. Il testo può essere completamente qualificato, il che significa che il percorso include il percorso della directory al file dalla tua directory /home; ad esempio, /home/asmstuff/asm4ecode/showargs2/showargs2. Questo è come appare il testo di invocazione quando esegui il tuo programma dal debugger Insight. (Ulteriori informazioni su Insight nell'Appendice A.) Se utilizzi il metodo "punto slash" per invocare un eseguibile dalla directory corrente, vedrai il nome dell'eseguibile preceduto da ./.
		</p>
	</li>
 	<li>
		<p align=justify>
		Se sono stati inseriti dei parametri da riga di comando, i loro indirizzi a 64 bit si trovano sopra la memoria rispetto a RSP, con l'indirizzo del primo (più a sinistra) parametro seguito dall'indirizzo del secondo, e così via. Il numero di parametri è ovviamente variabile, anche se raramente avrai bisogno di più di quattro o cinque.
		</p>
	</li>
 	<li>
		<p align=justify>
		La lista degli indirizzi degli argomenti della riga di comando è terminata da un puntatore nullo, che è gergo per 64 bit di zero binario.
		</p>
	</li>
 	<li>
		<p align=justify>
		La memoria superiore dal puntatore nullo inizia un lungo elenco di indirizzi a 64 bit. Quanti siano dipende dal tuo particolare sistema Linux, ma può essere vicino a 200. Ognuno di questi indirizzi punta a una stringa terminata da nullo (ne parleremo tra poco) contenente una delle definizioni appartenenti all'ambiente Linux.
		</p>
	</li>
 	<li>
		<p align=justify>
		Alla fine dell'elenco degli indirizzi delle variabili ambientali di Linux c'è un altro puntatore nullo a 64 bit, e questo segna la fine della "directory" dello stack. Oltre questo punto, utilizzi gli indirizzi trovati in precedenza nello stack per accedere a elementi ancora più in alto nella memoria.
		</p>
	</li>
</ul>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/linux_stack_at_program_execution.png">
</div>

### Accedere allo Stack direttamente

<p align=justify>
Il Listato di sopra viene eseguito in SASM, e il codice di avvio C copia utilmente il conteggio degli argomenti e l'indirizzo della tabella degli argomenti nei registri. Se non stai usando SASM, quel passaggio utile non avverrà. Devi accedere direttamente allo stack. Il Listato di sotto mostra come ciò può essere fatto.
</p>

```asm
;  Executable   : showargs2
;  Version      : 2.0
;  Created date : 11/3/2022
;  Last update  : 5/11/2023
;  Author       : Jeff Duntemann
;  Description  : A simple program in assembly for Linux, using NASM 2.15.05,
;                 demonstrating the way to access command line arguments on 
;                 the stack. This version accesses the stack "nondestructively"
;                 by using memory references calculated from RBP rather than
;                 POP instructions.
;
;    Use this makefile to build:
;    showargs2: showargs2.o
;        ld -o showargs2 -g showargs2.o
;    showargs2.o: showargs2.asm
;        nasm -f elf64 -g -F dwarf showargs2.asm -l showargs2.lst 
;

SECTION .data           ; Section containing initialized data

    ErrMsg db "Terminated with error.",10
    ERRLEN equ $-ErrMsg
	
SECTION .bss            ; Section containing uninitialized data	

; This program handles up to MAXARGS command-line arguments. Change the
; value of MAXARGS if you need to handle more arguments than the default 10.
; Argument lengths are stored in a table. Access arg lengths this way:
;     [ArgLens + <index reg>*8]
; Note that when the argument lengths are calculated, an EOL char (10h) is
; stored into each string where the terminating null was originally. This
; makes it easy to print out an argument using sys_write. 

    MAXARGS   equ  10       ; Maximum # of args we support
    ArgLens:  resq MAXARGS	; Table of argument lengths

SECTION .text       ; Section containing code

global  _start      ; Linker needs this to find the entry point!
	
_start:
    push rbp        ; Standard prolog
    mov rbp, rsp
    and rsp,-16    


; Copy the command line argument count from the stack and validate it:
    mov r13,[rbp+8]         ; Copy argument count from the stack
    cmp qword r13,MAXARGS   ; See if the arg count exceeds MAXARGS
    ja Error                ; If so, exit with an error message

; Here we calculate argument lengths and store lengths in table ArgLens:
    mov rbx,1               ; Stack address offset starts at RBX*8

ScanOne:
    xor rax,rax     ; Searching for 0, so clear AL to 0
    mov rcx,0000ffh ; Limit search to 65535 bytes max
    mov rdi,[rbp+8+rbx*8] ; Put address of string to search in RDI
    mov rdx,rdi     ; Copy starting address into RDX

    cld	            ; Set search direction to up-memory
    repne scasb     ; Search for null (binary 0) in string at RDI
    jnz Error       ; REPNE SCASB ended without finding AL

    mov byte [rdi-1],10	; Store an EOL where the null used to be
    sub rdi,rdx     ; Subtract position of 0 from start address
    mov [ArgLens+rbx*8],rdi    ; Put length of arg into table
    inc rbx         ; Add 1 to argument counter
    cmp rbx,r13     ; See if arg counter exceeds argument count
    jbe ScanOne     ; If not, loop back and scan another one

; Display all arguments to stdout:
    mov rbx,1 ; Start (for stack addressing reasons) at 1
Showem:
    mov rax,1       ; Specify sys_write call
    mov rdi,1       ; Specify File Descriptor 1: Standard Output
    mov rsi,[rbp+8+rbx*8]   ; Pass offset of the argument
    mov rdx,[ArgLens+rbx*8] ; Pass the length of the argument
    syscall         ; Make kernel call
    inc rbx         ; Increment the argument counter
    cmp rbx,r13     ; See if we've displayed all the arguments
    jbe Showem      ; If not, loop back and do another
    jmp Exit        ; We're done! Let's pack it in!

Error:
    mov rax,1       ; Specify sys_write call
    mov rdi,1       ; Specify File Descriptor 2: Standard Error
    mov rsi,ErrMsg  ; Pass offset of the error message
    mov rdx,ERRLEN  ; Pass the length of the message
    syscall         ; Make kernel call

Exit:
    mov rsp,rbp
    pop rbp
    
    mov rax,60      ; Code for Exit Syscall
    mov rdi,0       ; Return a code of zero	
    syscall         ; Make kernel call
```

### Stack Alignment Prolog

```asm
 push rbp        ; Alignment prolog
 mov rbp, rsp
 and rsp,-16
```

<p align=justify>
Va all'inizio dei programmi che non si collegano con la libreria glibc. (Questi sono programmi che iniziano con l'etichetta _start: I programmi creati con make di solito usano il prologo di allineamento.) Lo standard x64 ABI richiede che lo stack sia allineato su un confine di 16 byte (non bit!). L'istruzione AND RSP,-16 è quella che garantisce l'allineamento dello stack. Ho già parlato dell'AND prima; dovresti afferrare rapidamente che questa istruzione costringe i quattro bit inferiori del puntatore dello stack a 0. Ora è allineato su un confine di 16 byte, anche se prima non lo era. Il push di RBP nello stack ti fornisce un'ancora da cui indirizzare elementi di dati come i parametri della riga di comando esistenti “più in basso” (il che significa veramente “in memoria più alta”) nello stack. Aiuta anche a mantenere lo stack allineato, anche se come funziona dovrà aspettare il prossimo capitolo. La conseguenza pratica di avere RBP in cima allo stack è che contiene il valore originale del puntatore dello stack. Lo svantaggio è che devi saltarlo per arrivare agli argomenti della riga di comando. C'è anche qualcosa chiamato epilogo, che arriva alla fine del programma, proprio prima che restituisca il controllo a Linux. L'epilogo (di nuovo, solo per programmi non-SASM) arriva giusto prima che il programma esca usando SYSCALL.
</p>

```asm
 mov rsp,rbp
 pop rbp
```

<p align=justify>
Lo scopo dell'epilogo è ripristinare lo stack allo stato in cui si trovava all'ingresso nella funzione. Ora, potreste chiedere qui perché abbiamo utilizzato il prologo di allineamento in questo esempio e non in quelli precedenti. Per i programmi collegati con il compilatore gcc e la libreria glibc, lo stack sarà già allineato. Quindi, i programmi SASM non hanno bisogno del prologo di allineamento. SASM richiede istruzione MOV RBP,RSP all'inizio della funzione MAIN:, altrimenti la sua interfaccia di debug potrebbe non funzionare correttamente. Ancora, parlerò dell'allineamento dello stack in modo più dettagliato successivamente. Per programmi semplici che non utilizzano molto lo stack (come la maggior parte degli esempi in questo libro), il disallineamento dello stack potrebbe non causare molti o nessun problema. Tuttavia, è una buona idea prendere l'abitudine di inserire il prologo di allineamento all'inizio dei vostri programmi non-SASM.
</p>

### Indirizzamento dei dati nello Stack

<p align=justify>
Il "dove" inizia da quello che chiamiamo la cima dello stack, che è l'indirizzo presente nel puntatore dello stack RSP quando il programma inizia a essere eseguito. Nota che subito dopo aver spinto RBP nello stack, il prologo copia RSP in RBP. Questo ti fornisce un puntatore solido allo stack così come esisteva quando Linux ha iniziato a eseguire il tuo programma. Con la cima originale dello stack a disposizione in RBP, il puntatore dello stack RSP può spostarsi verso l'alto o verso il basso man mano che le procedure vengono chiamate e restituite. (Il programma showargs2 non fa nulla di questo, per semplificare.) Inoltre, puoi spingere valori temporanei nello stack per un uso successivo, anche se, con il doppio dei registri generali nell'architettura x64, questo viene fatto sempre meno man mano che viene scritto nuovo codice. RBP era un tempo BP nell'era a 16 bit, e il nome significava "puntatore di base". È stato creato per contenere il valore iniziale del puntatore dello stack, fornendo una "base" da cui fare riferimento ad altri elementi nello stack. Allora, cosa c'è nello stack mentre lo erediti da Linux? L'ho disegnato nella figura di sopra. Questo è il suo stato prima che il prologo spinga RBP su di esso. In cima allo stack c'è un valore di 8 byte che rappresenta il numero di argomenti della riga di comando. C'è sempre almeno 1 elemento nello stack: il testo di invocazione del programma. In altre parole, se il valore in [RBP] è 5, ci sono quattro argomenti reali della riga di comando. Il quinto elemento è il testo di invocazione, che appare per primo nello stack. Il programma visualizzerà un messaggio di errore se vengono inseriti più di MAXARGS argomenti (qui, 10). Immediatamente dopo il conteggio degli argomenti c'è una tabella di indirizzi a 64 bit che puntano agli argomenti reali. Quanti indirizzi ci sono dipende da quanti argomenti sono stati inseriti sulla riga di comando. C'è sempre almeno uno. Il primo indirizzo nella tabella è l'indirizzo del testo inserito dall'utente per invocare il programma. Dopo di ciò, gli indirizzi puntano agli argomenti della riga di comando nell'ordine in cui sono stati inseriti dall'utente. Tutto ciò che viene letto dallo stack in showargs2 è letto in base all'indirizzo in RBP. Il test del numero di argomenti rispetto a un valore massimo viene effettuato in questo modo:
</p>

```asm
 mov r13,[rbp+8]   ; Copy argument count from the stack into R13
 cmp r13,MAXARGS   ; See if the arg count exceeds MAXARGS
 ja Error          ; If so, exit with an error message
```

<p align=justify>
Qui, il conteggio degli argomenti si trova all'indirizzo contenuto in RBP più otto byte, perché RBP è stato inserito nello stack dal prologo e deve essere "superato" per raggiungere il conteggio degli argomenti. Il fatto che RBP contenga l'indirizzo informa l'assemblatore che il valore rappresentato da MAXARGS deve essere trattato come una parola quad di 64 bit, anche se il suo valore è solo 10. Ricorda che le equazioni sono valori, non posizioni in memoria. Se il conteggio degli argomenti è superiore a 10, il programma si interrompe con un breve messaggio di errore. La scansione di ciascuno degli argomenti per localizzare il suo carattere zero di terminazione è effettuata utilizzando il calcolo dell'indirizzo efficace più complesso possibile in x64: <code>Base + (Indice x Scala) + Dislocamento</code>. (Vedi la discussione sugli effective address, specialmente le figure)
</p>

```asm
 mov rsi,qword [rbp+8+rbx*8]
```

<p align=justify>
I termini dell'indirizzo efficace qui sono mostrati in un ordine diverso nel codice per renderlo un po' più facile da capire come funziona questo particolare riferimento alla memoria. Leggilo in questo modo:
</p>

1. Inizi con l'indirizzo "base" per il riferimento allo stack, in RBP.
2. Aggiungi 8 alla base per "superare" RBP in cima allo stack. Questo è il termine di "spostamento" dell'indirizzo efficace.
3. Moltiplichi il numero ordinale a partire da 1 dell'indirizzo a cui si accede per 8, che è la dimensione (in byte) di tutti gli indirizzi in x64. In altre parole, per il secondo elemento nella lista degli argomenti, moltiplicheresti il numero ordinale memorizzato in RBX per 8, la dimensione degli indirizzi in x64. Il valore più piccolo aggiunto è almeno 8, che ti porta oltre il conteggio degli argomenti.
4. Aggiungi il prodotto di RBX e 8 alla base più lo spostamento, e avrai l'indirizzo del primo argomento nella tabella. Questo indirizzo è copiato in RDI, per essere utilizzato con l'istruzione REPNE SCASB.

<p align=justify>
Se questo non ti è completamente chiaro, torna indietro e leggilo di nuovo. L'indirizzamento della memoria è il concetto più importante nel lavoro con il linguaggio assembly. Se non comprendi l'indirizzamento della memoria, conoscere le istruzioni della macchina e i registri ti aiuterà poco, se non del tutto.
</p>

<p align=justify>
Accedere agli elementi nello stack estraendoli con pop nei registri funziona sicuramente, ma ora nel 2023 ti consiglio di evitare di estrarre cose dallo stack a meno che il tuo codice non le abbia inserite lì. Come puoi immaginare, estrarre il conteggio degli argomenti in un registro come RAX modifica i contenuti originali dello stack spostando RSP. Se puoi fare riferimento ai contenuti dello stack tramite un singolo indirizzo di memoria basato su RBP, non dovrai preoccuparti tanto dei bug che possono verificarsi una volta che RSP non punta più alla cima dello stack come lo hai ricevuto originalmente da Linux.
</p>


### Usare gcc per l'assembly

<p align=justify>
Perché usare un compilatore C per lavorare in assembly? Principalmente questo: gcc fa molto di più che semplicemente compilare il codice C. È una sorta di strumento di sviluppo multiuso. Infatti, potrei caratterizzare meglio ciò che fa come costruire software piuttosto che semplicemente compilarlo. Oltre a compilare il codice C in codice oggetto, gcc governa sia il passaggio di assembly che il passaggio di linking. Passaggio di assembly? Sì, proprio così. Esiste un assemblatore GNU chiamato gas, anche se è una cosa strana che non è realmente destinata ad essere utilizzata da programmatori umani. Ciò che fa gcc è controllare gas e il linker GNU ld (che stai già usando nei makefile) come marionette sui fili. Se usi gcc, specialmente a livello principiante, non devi fare molto direttamente con gas o ld. Parliamo di più di questo.
</p>

<p align=justify>
Il lavoro con il linguaggio assembly è un distacco dal lavoro in C, e gcc è prima di tutto un compilatore C. Pertanto, dobbiamo prima esaminare il processo di costruzione del codice C. A prima vista, costruire un programma C per Linux utilizzando gli strumenti GNU è piuttosto semplice. Tuttavia, dietro le quinte, è un affare seriamente complicato. Anche se sembra che gcc faccia tutto il lavoro, ciò che gcc fa veramente è agire come un controllore principale per diversi strumenti GNU, supervisionando una catena di assemblaggio del codice che non è necessario vedere a meno che non lo desideri specificamente. Teoricamente, questo è tutto ciò che devi fare per generare un file binario eseguibile dal codice sorgente C:
</p>

```
gcc eatc.c –o eatc

```

<p align=justify>
Qui, gcc prende il file eatc.c (che è un file di codice sorgente C) e lo elabora per produrre il file eseguibile eatc. (L'opzione -o dice a gcc come nominare il file di output eseguibile.) Tuttavia, c'è di più in corso qui di quanto sembri a prima vista. Dai un'occhiata alla figura di sotto mentre la esaminiamo. Nella figura, le frecce in ombra indicano il movimento delle informazioni. Le frecce vuote indicano il controllo del programma.
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/how_gcc_builds_linux_executables.png">
</div>

<p align=justify>
Il programmatore invoca gcc dalla riga di comando della shell, di solito in una finestra del terminale. Poi gcc prende il controllo del sistema e invoca immediatamente un'utilità chiamata preprocessore C, cpp. Il preprocessore prende il file sorgente C originale e gestisce determinati elementi come #includes e #defines. Può essere considerato come una sorta di passaggio di espansione macro sul file sorgente C. Quando cpp ha finito il suo lavoro, gcc prende il comando in modo serio. Dal file sorgente C preprocessato, gcc genera un file di codice sorgente in linguaggio assembly con un'estensione .s. Questo è letteralmente il codice assembly equivalente delle dichiarazioni C nel file .c originale, in forma leggibile dagli esseri umani. Se sviluppi qualche abilità nella lettura della sintassi e dei mnemonici dell'assembly AT&T (di cui parleremo tra poco), puoi imparare molto ispezionando i file .s prodotti da gcc. Quando gcc ha completato la generazione dell'equivalente in linguaggio assembly del file sorgente C, invoca l'assemblatore GNU, gas, per assemblare il file .s in codice oggetto. Questo codice oggetto viene scritto in un file con estensione .o. L'ultimo passaggio coinvolge il linker, ld. Il file .o contiene codice binario, ma è solo il codice binario generato dalle dichiarazioni nel file .c originale. Il file .o non contiene il codice delle librerie C standard che sono così importanti nella programmazione C. Quelle librerie sono già state compilate e devono semplicemente essere collegate all'applicazione. Il linker ld svolge questo lavoro sotto la direzione di gcc. La cosa positiva è che gcc sa esattamente quali librerie C standard devono essere collegate alla tua applicazione per farla funzionare e include sempre le librerie giuste nelle loro versioni corrette. Quindi, anche se gcc non fa effettivamente il collegamento, sa cosa deve essere collegato e questa è veramente una conoscenza preziosa, man mano che i tuoi programmi diventano sempre più complessi. Infine, ld restituisce il file del programma completamente collegato ed eseguibile. A quel punto, la compilazione è completata e gcc restituisce il controllo alla shell di Linux. Nota che tutto ciò è generalmente fatto con un semplice comando a gcc!
</p>

### SAMSusa GCC

<p align=justify>
Alcuni di questi concetti potrebbero iniziare a suonare familiari. Abbiamo utilizzato SASM per diversi capitoli ormai, e SASM ha un modo di lavorare fondamentalmente diverso da quello che abbiamo imparato con i makefile e l'utility make di Linux. Ho accennato all'inizio al fatto che ciò che SASM produce è in realtà un programma C scritto in linguaggio assembly. Se guardi la scheda Build nel menu delle Impostazioni di SASM, nota che gcc (e non ld) è mostrato nel percorso del linker. Questo non significa che ld non venga utilizzato, come accade quando usiamo i makefile. Significa che gcc ha il pieno controllo del processo di collegamento, chiamando ld quando necessario per collegare librerie precompilate di codice C binario.
</p>

### Come usare GCC in assembly

<p align=justify>
Il processo che ho appena descritto, e che ho illustrato per voi nella figura precedente, è come un programma C viene costruito sotto Linux utilizzando gli strumenti GNU. Sono andato nei dettagli qui perché useremo parte—anche se solo parte—di questo processo per rendere più facile la nostra programmazione in assembly. È vero che non abbiamo bisogno di convertire il codice sorgente C in codice assembly—e infatti, non abbiamo bisogno di gas per convertire il codice sorgente assembly gas in codice oggetto. Tuttavia, abbiamo bisogno dell'esperienza di gcc nel collegamento. Ci atterremo al processo di costruzione del codice GNU nella fase di collegamento in modo che gcc possa coordinare per noi il passo di collegamento. Quando assembliamo un programma .asm per Linux utilizzando NASM, NASM genera un file .o contenente codice oggetto binario. Come abbiamo visto, invocare NASM sotto Linux a 64 bit si fa tipicamente in questo modo:
</p>

```
nasm –f elf64 -g -F dwarf eatclib.asm
```

<p align=justify>
Questo comando indirizzerà NASM a assemblare il file eatclib.asm e a generare un file chiamato eatclib.o. La parte -f elf64 indica a NASM di generare codice oggetto nel formato ELF a 64 bit piuttosto che in uno dei numerosi altri formati di codice oggetto che NASM è in grado di produrre. La parte -g -F dwarf abilita la generazione di informazioni di debug nel file di output, nel formato DWARF. Il file eatclib.o non è eseguibile da solo. Deve essere linkato. Quindi, chiamiamo gcc e lo istruiamo a collegare il programma per noi.
</p>

```
gcc eatclib.o –o eatclib –no-pie
```

<p align=justify>
Cosa di tutto ciò dice a gcc di linkare e non compilare? L'unico file di input menzionato nel comando è un file .o contenente codice oggetto. Questo fatto da solo dice a gcc che tutto ciò che deve essere fatto è collegare il file .o con la libreria runtime C per produrre l'eseguibile finale. La parte –o eatclib dice a gcc che il nome del file eseguibile finale deve essere eatclib. Includere il delimitatore –o è importante. Se non dici a gcc con precisione come nominare il file eseguibile finale, si fermerà e darà al file il nome predefinito per un eseguibile, a.out. L'argomento della riga di comando -no-pie dice a gcc di non collegare l'eseguibile per la tecnologia degli eseguibili indipendenti dalla posizione (PIE). Spiegherò questo in dettaglio più avanti in questo capitolo. Si tratta di ridurre la vulnerabilità di un eseguibile a determinati exploit. È accettabile utilizzare l'opzione –no-pie in programmi semplici e didattici come quelli in questo libro. Per il codice di produzione, hai bisogno di PIE.
</p>

### Perchè no GAS?

<p align=justify>
Potresti chiederti perché, se c'è un assemblatore perfettamente funzionante installato automaticamente con ogni copia di Linux, mi sia preoccupato di mostrarti come installarne e utilizzarne un altro. Due motivi:
</p>

<ul>
	<li>
		<p align=justify>
		L'assemblatore GNU gas utilizza una sintassi peculiare che è completamente diversa da quella di tutti gli altri assemblatori familiari utilizzati nel mondo x86/x64, incluso NASM. Ha un insieme intero di mnemonici di istruzione unici. Li trovo brutti, non intuitivi e difficili da leggere. Questa è la sintassi AT&T, così chiamata perché è stata creata da AT&T come una notazione di assembly portatile per rendere più facile il porting di Unix da una CPU sottostante a un'altra. È brutta in parte perché è stata progettata per essere generica e può essere riconfigurata per qualsiasi architettura CPU ragionevole che potrebbe apparire.
		</p>
	</li>
		<li>
		<p align=justify>
		Più specificamente, il concetto di un "linguaggio assembly portatile" è, a mio avviso, una contraddizione in termini. Un linguaggio assembly dovrebbe essere un riflesso diretto, completo, uno-a-uno dell'architettura della macchina sottostante. Qualsiasi tentativo di rendere un linguaggio assembly generico allontana il linguaggio dalla macchina e limita la capacità di un programmatore assembly di dirigere la CPU come è stata progettata per essere diretta. L'organizzazione che crea e evolve un'architettura CPU è nella posizione migliore per definire i mnemonici delle istruzioni di una CPU e la sintassi del linguaggio assembly senza compromessi. È per questo che utilizzerò sempre e insegnerò i mnemonici Intel.
		</p>
	</li>
</ul>

<p align=justify>
Se fosse così semplice, non menzionerei affatto il gas, poiché non è necessaria l'unità di gas per scrivere in linguaggio assembly Linux in NASM. Tuttavia, uno dei principali modi per imparare molte delle chiamate standard della libreria C è utilizzarle in brevi programmi C e poi ispezionare i file di output assembly .s generati da gcc. Pertanto, avere una certa capacità di leggere le mnemotecniche AT&T può essere utile mentre ti senti a tuo agio con le convenzioni di chiamata C utilizzate sotto Linux. Fornirò una panoramica della sintassi AT&T un po' più avanti in questo capitolo.
</p>

### Linking alla libreria standand del C

<p align=justify>
Quando scrivi un programma interamente in assembly utilizzando un makefile e l'utility make, scrivi tutto. A parte un'occasionale immersione nei servizi del kernel Linux, tutto il codice che viene eseguito è solo il codice che scrivi. L'integrazione di librerie di procedure in linguaggio assembly esterno complica un po' questo quadro, soprattutto se non sei tu a aver scritto quelle librerie. L'integrazione di funzioni nella libreria standard C (che per Linux si chiama glibc) complica ulteriormente la situazione. Può essere un conforto sapere che l'integrazione delle routine di glibc è più semplice nel linguaggio assembly x64 rispetto a quanto lo fosse nell'assembly x86 a 32 bit. Come ho accennato in precedenza, scrivere un programma in assembly in SASM è molto simile a scrivere un programma C nel quale scrivi il corpo principale del programma in assembly. I programmi generati da SASM sono una sorta di ibrido tra C e linguaggio assembly. Se crei un programma in linguaggio assembly per Linux che integra le funzioni di glibc, stai facendo praticamente la stessa cosa. La struttura di questo ibrido è mostrata nella figura di sotto
</p>

<div align=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/structure_of_hybrid_C_assembly.png">
</div>

<p align=justify>
Il tuo programma non è più il semplice affare di iniziare dall'alto e scendere come lo erano i tuoi precedenti programmi di assemblaggio. glibc non è solo una raccolta di funzioni disgiunte. È la libreria di runtime standard C e, come parte della sua standardità, impone una certa struttura a tutti i programmi che si collegano ad essa. Questa struttura include un blocco di codice che viene eseguito prima che il tuo programma inizi e un altro blocco di codice che viene eseguito dopo che il tuo programma è terminato. Il tuo programma è chiamato dal codice di avvio come se fosse una procedura (con l'istruzione CALL) e restituisce il controllo al codice della libreria C utilizzando un'istruzione RET. Tecnicamente, il tuo programma è una procedura (ancora una volta, chiamata funzione nel mondo C) e aiuta pensarlo come tale. È così che l'ho rappresentato nella figura di sopra. Quando Linux inizia a eseguire il tuo programma, in realtà inizia, non dall'inizio del codice che hai scritto, ma dall'inizio del blocco di codice di avvio. Quando il codice di avvio ha fatto ciò che deve, esegue un'istruzione CALL che porta l'esecuzione nel tuo codice di assemblaggio. Quando il tuo programma in linguaggio assembly restituisce il controllo al suo chiamante tramite RET, inizia l'esecuzione del codice di chiusura, ed è il codice di chiusura che restituisce effettivamente il controllo a Linux tramite la necessaria chiamata di sistema al kernel. Una volta che colleghi codice C ai tuoi programmi di assemblaggio, non è una buona idea utilizzare il servizio SYSCALL 60 per terminare un programma e tornare a Linux. Ci sono alcune operazioni di gestione da fare, che possono includere lo svuotamento dei buffer e la chiusura dei file o delle connessioni di rete. Il codice di chiusura C fa tutto questo, e se lo salti, possono succedere brutte cose. Quelle brutte cose probabilmente non accadranno quando stai lavorando su semplici esempi di codice come quelli presentati in questo libro, ma una volta che inizi a diventare ambizioso e scrivere programmi di mille righe, tutto ciò diventa possibile e ti causerà non poca disperazione. Fondamentalmente, quando lavori con C, fai le cose nel modo C. Tra il codice di avvio e il codice di chiusura, puoi fare quante più chiamate a glibc desideri. Quando colleghi il tuo programma usando gcc, il codice contenente le routine della libreria C che chiami è collegato al tuo programma. Nota bene che il codice di avvio e di chiusura, così come tutto il codice per le funzioni della libreria che il tuo programma chiama, è tutto fisicamente presente nel file eseguibile che generi con gcc.
</p>

### Convensioni di chiamata C

<p align=justify>
La libreria glibc non tratta in modo speciale i programmi in linguaggio assembly. I programmi in puro C funzionano quasi esattamente allo stesso modo, ed è per questo che la parte principale di un programma C è chiamata funzione main. È davvero una funzione, il codice standard della libreria C per l'avvio la chiama con un'istruzione CALL, e restituisce il controllo al codice di chiusura eseguendo un'istruzione RET. Il modo in cui il programma principale ottiene il controllo è quindi il primo esempio che vedrai di un insieme di regole che chiamiamo convenzioni di chiamata C. La libreria standard C non è niente se non coerente, e questo è il suo maggiore pregio. Tutte le funzioni della libreria C implementate su processori x64 seguono queste regole. Incidentalmente, fissale nei tuoi sinapsi sin dall'inizio, e perderai molto meno capelli di quanto ho fatto io cercando di capirle sbattendo la testa contro di esse. Prima di tutto, il tuo programma deve iniziare con l'etichetta globale main:. Usare _start: non funzionerà. La funzione main è etichettata come main:, punto. I programmi SASM iniziano sempre con main: perché SASM usa gcc per collegare il codice da glibc. Questa è la partenza. Il resto diventa piuttosto complicato piuttosto rapidamente.
</p>

### Chiamanti, Chiamati e Sovrascrittori

<p align=justify>
Se hai mai studiato la programmazione assembly per Linux a 32 bit, hai appreso che passare parametri a funzioni in stile C avveniva spingendo i parametri nello stack prima di effettuare la chiamata. Tutto scomparso. (Ok, quasi tutto scomparso. Ci tornerò.) La maggiore differenza singola tra le convenzioni di chiamata a 32 bit e quelle a 64 bit risiede nel modo in cui si passano i parametri alle funzioni. Passare i primi sei parametri a una funzione x64 avviene tramite registri piuttosto che nello stack. Se una funzione ha più di sei parametri (cosa poco comune e spesso una cattiva progettazione) i parametri rimanenti vengono passati nello stack. Questo è stato fatto perché abbiamo molti più registri ora di quanti ne avessimo nell'era a 32 bit. Spingere e sollevare dallo stack tocca la memoria e quindi è lento. Scrivere e leggere dai registri rimane all'interno della CPU e quindi è molto più veloce. La tecnologia moderna della cache della CPU rende l'uso dello stack più veloce rispetto ai tempi antichi, è vero, ma anche l'accesso alla cache della memoria è più lento rispetto all'accesso ai registri. Potresti ricordare che nei capitoli precedenti i programmi passavano parametri alle chiamate di funzione di Linux utilizzando l'istruzione x64 SYSCALL. Tutti i parametri del genere (almeno nei semplici programmi con cui abbiamo lavorato) vengono passati nei registri. Inoltre, c'è un sistema in questo: i primi sei parametri vengono passati in registri specifici in un ordine molto specifico. Questo ordine è il seguente:
</p>

1. RDI
2. RSI
3. RDX
4. RCX
5. R8
6. R9

<p align=justify>
Il primo parametro passato a una funzione è sempre passato in RDI. Se ci sono due parametri da passare a una funzione, il primo è passato in RDI e il secondo in RSI, e così via. Questo è vero per le chiamate tramite SYSCALL, ed è anche vero per la chiamata delle funzioni della libreria C. L'ordine dei parametri nei registri è semplice. La parte successiva è sottile: quali registri può utilizzare internamente una funzione e quindi modificare, e quali registri devono rimanere invariati dopo l'esecuzione della funzione? Per dirlo in gergo da programmatore: quali registri possiamo sovrascrivere? Ancora una volta, c'è un sistema. Questi sette registri non possono essere sovrascritti da una funzione: RSP, RBP, RBX, R12, R13, R14 e R15. Questo gruppo di registri è chiamato registri non volatili, il che significa fondamentalmente registri che devono essere preservati (o lasciati non utilizzati) dall'ebitente. Aspetta—cosa? Maggiore gergo. Le funzioni possono chiamare altre funzioni. Una funzione che chiama un'altra funzione è il chiamante. La funzione che viene chiamata è l'ebitente. C'è una sorta di rapporto di fiducia tra il chiamante e l'ebitente: l'ebitente promette al chiamante che i valori di RSP, RBP, RBX, R12, R13, R14 e R15 saranno gli stessi quando l'ebitente termina l'esecuzione rispetto a quando l'ebitente inizia l'esecuzione. L'ebitente può utilizzare i registri non volatili, ma quelli che utilizza devono prima essere salvati (spinti nello stack) e ripristinati (estratti dallo stack) prima che l'ebitente torni al chiamante. Gli altri registri sono chiamati volatili, il che significa che l'ebitente può usarli e modificarli senza problemi. Questi sono RAX, RCX, RDX, RSI, RDI, R8, R9, R10 e R11. Se sei sveglio, noterai che tutti e sei i registri utilizzati nella convenzione di chiamata C sono registri volatili. Questo ha senso poiché il chiamante li sta già utilizzando per passare valori all'ebitente. Ma cosa succede se il chiamante sta già utilizzando alcuni dei registri volatili? Se il chiamante desidera che uno dei registri volatili sopravviva a un viaggio attraverso l'ebitente, il chiamante deve salvarli prima di chiamare la funzione dell'ebitente. Dopo che l'ebitente è tornato al chiamante, il chiamante ripristina quindi i registri volatili che aveva salvato nello stack estraendo i valori salvati nei registri.
</p>

<p align=justify>
Questo implica molto più push e pop di quanto accada di solito. Una delle sfide che un buon programmatore di linguaggio assembly deve affrontare è semplicemente rimanere fuori dalla memoria, il che include il push e il pop dello stack. Abbiamo più registri da utilizzare ora e l'ingegnosità nell'uso di quei registri ripaga, rendendo l'accesso allo stack meno frequente. 
</p>

<p align=justify>
<i>Salva solo i registri che devi salvare, dopo aver esaurito tutte le altre opzioni.</i> 
</p>

<p align=justify>
Ci sono state ragioni per cui il set di istruzioni x64 ha eliminato PUSHA e POPA.
</p>

### Impostare lo Stack Frame

<p align=justify>
Nonostante ci siano più registri, lo stack è ancora estremamente importante nel lavoro di linguaggio assembly, e questo è doppiamente vero nei programmi che si interfacciano con il C, perché nel C (e in verità nella maggior parte degli altri linguaggi di alto livello a codice nativo, inclusi Pascal) lo stack ha un ruolo centrale. Un meccanismo di basso livello che ha a che fare con il lavoro in assembly su Linux è quello del frame dello stack. I compilatori si basano sui frame dello stack per creare variabili locali nelle funzioni, e mentre i frame dello stack sono meno utili nel lavoro di puro assembly, devi comprenderli se intendi chiamare funzioni scritte da un compilatore di linguaggio di alto livello. Un frame dello stack è una posizione nello stack contrassegnata come appartenente a una particolare funzione, inclusa la funzione main(). È fondamentalmente la regione tra gli indirizzi contenuti in due registri: il puntatore base RBP e il puntatore dello stack RSP. Questo si spiega meglio di quanto non si disegni; vedi figura di sotto. Un frame dello stack viene creato spingendo una copia di RBP nello stack e poi copiando il puntatore dello stack RSP nel registro RBP. Le prime due istruzioni in qualsiasi programma assembly che rispetti le convenzioni di chiamata del C devono essere queste:
</p>

```asm
 push rbp
 mov  rbp,rsp
```

<p align=justify>
Molte persone chiamano questo il prologo del programma, poiché deve essere incluso all'inizio di qualsiasi programma che rispetti le convenzioni di chiamata C. A meno che il prologo non sia presente, il debugger gdb e le sue interfacce come Insight non opereranno correttamente. Una volta che RBP è ancorato come un capo del tuo frame dello stack, il puntatore dello stack RSP è libero di muoversi su e giù nello stack come il tuo codice richiede per la memoria temporanea. Chiamare funzioni in glibc sotto x64 richiede meno push e pop rispetto a quanto non fosse nel vecchio mondo a 32 bit, ora che la maggior parte dei parametri viene passata alle funzioni in registri.
</p>

<div aling=center>
<img src"https://github.com/TheBitPoets/2cornot2c/blob/main/images/stack_frame.png">
</div>

### Distruggere lo Stack Frame (in the Epilog - epilogo)

<p align=justify>
Prima che il tuo programma termini la sua esecuzione restituendo il controllo al codice di avvio/chiusura (fai riferimento alla penultima figura se questa relazione non è chiara), il suo frame dello stack deve essere distrutto. Questo sembra a molte persone come se stesse accadendo qualcosa di sbagliato, ma non è così: il frame dello stack deve essere distrutto, altrimenti il tuo programma andrà in crash. (“Riporre” potrebbe essere un termine migliore di “distruggere”... ma i programmatori preferiscono linguaggio colorito, come imparerai una volta che trascorrerai del tempo significativo tra loro.) Il tuo stack deve essere pulito prima di distruggere il frame dello stack e restituire il controllo al codice di chiusura. Questo significa semplicemente che eventuali registri salvati dal chiamato e valori temporanei che potresti aver inviato nello stack durante l'esecuzione del programma devono essere eliminati. Pop quello che pushi! Una volta fatto ciò, annulliamo la logica seguita nella creazione del frame dello stack: estraiamo il valore RBP del chiamante dallo stack e usciamo, tramite due istruzioni che insieme vengono spesso chiamate epilogo.
</p>

```asm
 pop rbp
 ret
```

<p align=justify>
Ecco! Il frame dello stack è scomparso e lo stack è ora nello stesso stato in cui si trovava quando il codice di avvio ha passato il controllo al tuo programma. L'istruzione RET invia il controllo al codice di chiusura della libreria C, in modo che possa fare qualsiasi operazione di pulizia necessaria prima di restituire il controllo a Linux.
</p>

### Allineamento dello Stack

<p align=justify>
Lo scopo del prologo e dell'epilogo non è immediatamente ovvio, specialmente se si arriva a x64 per la prima volta dopo aver lavorato nel mondo Linux a 32 bit. Si riduce a un nuovo requisito: lo stack x64 deve essere allineato su un confine di 16 byte. Ciò significa che quando si ritorna da una funzione (inclusa main:), il puntatore dello stack deve puntare a un indirizzo divisibile uniformemente per 16. Perché è un problema? Ricorda che quando viene chiamata una procedura (una funzione nel gergo C), il chiamante spinge l'indirizzo di ritorno nello stack. Un indirizzo di ritorno è di 8 byte. Ma se accedi allo stack dopo aver aggiunto 8 byte ad esso (anziché 16), possono succedere cose cattive. Non è una garanzia, ma può succedere, specialmente quando il tuo codice diventa più ambizioso degli esempi semplici in questo libro. Il prologo spinge RBP nello stack. Questo aggiunge altri 8 byte allo stack, per un totale di 16. Lo stack è quindi ancora allineato. Nell'epilogo, riprendi il valore di RBP dallo stack. L'istruzione RET che termina l'epilogo preleva l'indirizzo di ritorno dallo stack nel puntatore delle istruzioni, quindi hai rimosso un totale di 16 byte dallo stack. Lo stack era allineato quando la tua funzione main: ha preso il controllo, grazie al codice di avvio della glibc, e sarebbe meglio se continuasse a essere allineato quando il tuo programma esegue l'istruzione RET che restituisce il controllo al codice di spegnimento della glibc. L'allineamento dello stack è richiesto anche quando la glibc non è coinvolta, come nei programmi che utilizzano un'etichetta _start: invece di main:. Questa volta la glibc non ti aiuterà perché non è presente. Un prologo e un epilogo devono comunque essere presenti, anche se c'è un po' più da fare rispetto a quando colleghi la glibc nel tuo programma. Il prologo richiesto è chiamato il prologo di allineamento dello stack:
</p>

```asm
 push rbp
 mov rbp,rsp
 and rsp,-16
```

<p align=justify>
La differenza risiede nell'istruzione AND RSP,-16. Questa istruzione azzera i quattro bit più bassi del puntatore dello stack RSP. L'ultima cifra esadecimale dell'indirizzo diventa quindi 0 e lo stack è allineato su un confine di 16 byte. Se sei attento nel tuo utilizzo dello stack, esso rimarrà allineato, come vedremo tra poco. Ecco l'epilogo dell'allineamento dello stack.
</p>

```asm
 mov rsp,rbp
 pop rbp
```

<p align=justify>
Un'altra differenza quando si utilizza _start è che l'epilogo non può restituire il controllo a Linux eseguendo un'istruzione RET. Devi usare il servizio Exit tramite SYSCALL, come ho spiegato nei capitoli precedenti. Dopo aver eseguito POP RBP, puoi utilizzare il servizio SYSCALL 60 per restituire il controllo a Linux. E per quanto riguarda le procedure che scrivi da solo? Idealmente, tutte le procedure dovrebbero iniziare con il prologo e finire con l'epilogo. Spesso puoi fare a meno di utilizzare il prologo/epilogo nelle tue funzioni, specialmente se sono semplici e non fanno molto con lo stack. Ho omesso il prologo/epilogo in alcuni dei programmi esempio di questo libro per semplificare. Inoltre, non approfondisco i frame dello stack in dettaglio fino a questo capitolo finale, ed è impossibile dare senso all'allineamento dello stack senza sapere come funziona lo stack. Più avanti , nell'esempio, randtest, il programma passa un settimo parametro a printf() mettendo il parametro nello stack. Mantenere lo stack allineato su un confine di 16 byte viene fatto in un altro modo: mettendo un elemento "dummy" nello stack (qui, RAX; il suo contenuto è ininfluente) e poi, dopo aver chiamato printf(), aggiungendo 16 a RSP invece di 8. Ecco dove viene fatto; non preoccuparti se non capisci tutto nel seguente frammento.
</p>

```asm
shownums:
    mov r12,qword [Pulls]    ; Put pull count into r12
    xor r13,r13
 .dorow:
    mov rdi,ShowArray        ; Pass address of base string
    mov rsi,[Stash+r13*8+0]  ; Pass first element
    mov rdx,[Stash+r13*8+8]  ; Pass second element
    mov rcx,[Stash+r13*8+16] ; Pass third element
    mov r8,[Stash+r13*8+24]  ; Pass fourth element
    mov r9,[Stash+r13*8+32]  ; Pass fifth element
    push rax                 ; To keep the stack 16 bytes
 aligned
    push qword [Stash+r13*8+40] ; Pass sixth element on the
 stack.
    xor rax,rax         ; Tell printf() no vector values
 coming
    call printf         ; Display the random numbers
    add rsp,16          ; Stack cleanup: 2 item X 8 bytes = 16
```

<p align=justify>
In questa parte del codice, il push di RAX decrementa lo stack di 8. Il push del settimo parametro sullo stack decrementa ulteriormente lo stack di altri 8, per un totale di 16, mantenendo lo stack allineato. Finora tutto bene. Ma questo è solo metà del lavoro. Quindi, dopo che la chiamata a printf() è stata effettuata, 'ripuliamo' lo stack con un po' di aritmetica veloce: aggiungiamo di nuovo le dimensioni sia del parametro sia della copia fittizia di RAX al puntatore dello stack. Nel frammento, il push di due valori QWORD sullo stack ha spostato l'indirizzo in RSP in direzione della memoria verso il basso di 16 byte. Per ripulire, aggiungiamo di nuovo questi 16 byte con un'istruzione ADD RSP,16. Lo stack sarà quindi di nuovo sia allineato che 'pulito'.
</p>

<p align=justify>
In precedenza ti ho detto di "pop what you push". A volte il pop non è pratico. Finché ripristini il puntatore dello stack al valore che aveva prima del push, tutto funzionerà. Se metti valori nello stack come memoria locale, assicurati di aggiungere alla RSP la dimensione totale di tutti quei valori per rendere di nuovo "pulito" lo stack. E se non stai mettendo un multiplo di 16 byte nello stack, riempilo spingendo valori fittizi fino a quando il totale non è un multiplo di 16. Ora, perché gli autori dell'ABI System V x86-64 hanno imposto uno stack allineato a 16 byte? Mantenere lo stack allineato su confini di 16 byte in ogni momento semplifica il codice per diversi aspetti, incluso l'uso dei vettori SSE quando vengono memorizzati nello stack. Non tratterò SSE o gli altri sottosistemi matematici nei processori Intel in questo libro, quindi non preoccuparti se non ha senso per ora. Una volta che avrai acquisito esperienza nel linguaggio assembly, ti incoraggio a esplorare le istruzioni matematiche x64 e i registri dei vettori. Una nota finale sull'allineamento dello stack: SASM ha problemi con il prologo e l'epilogo che mostro qui. Ha bisogno dell'istruzione mov rbp, rsp all'inizio, ma nulla oltre a questo. L'epilogo di SASM è semplicemente il RET finale.
</p>

### Caratteri via Puts()

<p align=justify>
Una delle funzioni più semplici e utili in glibc è puts(), che invia caratteri all'output standard. Effettuare una chiamata a puts() dal linguaggio assembly è così semplice che può essere fatto in tre righe di codice. Il programma di sotto dimostra puts(). Il programma eatlibc include il prologo e l'epilogo. Se rimuovi le tre istruzioni che impostano e fanno la chiamata a puts(), puoi trattare il resto come boilerplate per creare nuovi programmi che chiamano funzioni in glibc. Chiamare puts() in questo modo è un buon esempio, in miniatura, del processo generale che utilizzerai per chiamare la maggior parte delle routine delle librerie C. Ancora una volta, in conformità con le convenzioni di chiamata x64 generali, posizioniamo l'indirizzo della stringa da visualizzare in RDI. Non è necessario passare un valore della lunghezza della stringa. La funzione puts() inizia all'inizio della stringa all'indirizzo passato in RDI e invia caratteri a stdout fino a quando non incontra un carattere 0 (null). Qualunque sia il numero di caratteri che si trova tra il primo byte della stringa e il primo null, è il numero di caratteri che la console riceve.
</p>

```asm
;  Executable name : eatlibc
;  Version         : 3.0
;  Created date    : 11/12/2022
;  Last update     : 5/13/2023
;  Author          : Jeff Duntemann
;  Description     : Demonstrates calls made into libc, using NASM 2.14.02 
;                    to send a short text string to stdout with puts().
;
;  Build using these commands:
;    nasm -f elf64 -g -F dwarf eatlibc.asm
;    gcc eatlibc.o -o eatlibc


SECTION .data           ; Section containing initialised data
	
EatMsg: db "Eat at Joe's!",0	
	
SECTION .bss            ; Section containing uninitialized data

SECTION .text           ; Section containing code
	
extern puts             ; The simple "put string" routine from libc
global main             ; Required so the linker can find the entry point
	
main:
    push rbp            ; Set up stack frame for debugger
	mov rbp,rsp
;;; Everything before this is boilerplate; use it for all ordinary apps!
		
    mov rdi,EatMsg      ; Put address of string into rdi	
    call puts           ; Call libc function for displaying strings
    xor rax,rax         ; Pass a 0 as the program's return value.

;;; Everything after this is boilerplate; use it for all ordinary apps!
	mov rsp,rbp	        ; Destroy stack frame before returning
    pop rbp

    mov rax,60
    mov rdi,0
    syscall             ; Return control to Linux
```
### Testo formattato con printf()

<p align=justify>
La routine della libreria puts() può sembrare piuttosto utile, ma rispetto ad alcuni dei suoi più sofisticati "fratelli", è roba da bambini. Con puts() puoi inviare solo una semplice stringa di testo a un file (per impostazione predefinita, stdout), senza alcun tipo di formattazione. Peggio ancora, puts() include sempre un carattere EOL alla fine della sua visualizzazione, sia che tu ne includa uno nei tuoi dati di stringa o meno. Questo ti impedisce di utilizzare più chiamate a puts() per stampare più stringhe di testo tutte sulla stessa riga nel terminale. Circa il meglio che puoi dire per puts() è che ha la virtù della semplicità. Per quasi tutte le tue necessità di output di caratteri, è molto meglio usare una funzione di libreria molto più potente chiamata printf(). La funzione printf() ti consente di fare un numero di cose davvero utili, il tutto con una sola chiamata di funzione:
</p>

<ul>
	<li>
		<p align=justify>
		Output testo con o senza un EOL terminante
		</p>
	</li>
 	<li>
		<p align=justify>
		Convertire i dati numerici in testo in numerosi formati, fornendo i codici di formattazione insieme ai dati.
		</p>
	</li>
 	<li>
		<p align=justify>
		Scrivi il testo in un file che include più stringhe memorizzate separatamente.
		</p>
	</li>
</ul>

<p align=justify>
Se hai lavorato con C per più di mezz'ora, printf() ti sarà perfettamente ovvio, ma per le persone che provengono da altri linguaggi potrebbe prendere un po' di spiegazioni. La routine printf() mostrerà volentieri una stringa semplice come "Mangia da Joe!"—ma puoi unire altre stringhe di testo e dati numerici convertiti con quella stringa base mentre viaggia verso l'output standard, e mostrarle tutte insieme senza problemi. Questo viene fatto inserendo i codici di formattazione nella stringa base e poi passando un elemento dati a printf() per ciascuno di quei codici di formattazione, insieme alla stringa base. Un codice di formattazione inizia con un segno di percento e include informazioni relative al tipo e alla dimensione dell'elemento dati che viene unito con la stringa base, così come a come quelle informazioni devono essere presentate. Diamo un'occhiata a un esempio molto semplice per cominciare. Ecco una stringa base contenente un codice di formattazione:
</p>

```c
 "The answer is %d, and don't you forget it!"
```

<p align=justify>
Il codice di formattazione %d indica semplicemente a printf() di convertire un valore intero firmato in testo e sostituire quel testo per il codice di formattazione nella stringa base. Ovviamente, ora devi passare un valore intero a printf() (e ti mostrerò come si fa a breve), ma quando lo fai, printf() convertirà l'intero in testo e lo fonderà con la stringa base mentre invia testo allo stream. Se il valore decimale passato è 42, sulla console vedrai questo:
</p>

```c
 The answer is 42, and don't you forget it!
```

<p align=justify>
Un codice di formattazione ha in realtà una buona quantità di struttura, e il meccanismo printf() nel suo insieme ha più complessità di quante ne possa descrivere in dettaglio in questo libro. Qualsiasi buona guida C spiegherà tutto in dettaglio. Il trattamento su Wikipedia è eccellente.
</p>

[https://en.wikipedia.org/wiki/Printf](https://en.wikipedia.org/wiki/Printf)

<p align=justify>
Il miglioramento più significativo che puoi apportare ai codici di formattazione è inserire un valore intero tra il simbolo % e la lettera del codice:
</p>

```c
 %5d
```

<p align=justify>
Questo codice dice a printf() di visualizzare il valore allineato a destra all'interno di un campo largo cinque caratteri. Se non inserisci un valore per la larghezza del campo, printf() semplicemente darà al valore tanto spazio quanto richiedono le sue cifre. Ricorda che se hai bisogno di visualizzare un simbolo percentuale, devi includere due simboli percentuali consecutivi nella stringa: il primo è un codice di formattazione che dice a printf() di visualizzare il secondo come se stesso, e non come l'inizio di un codice di formattazione.
</p>

### Passaggio di parametri a printf()

<p align=justify>
Passare valori a printf() segue le convenzioni di chiamata x64. Se stai visualizzando una stringa con codici di formato incorporati, la stringa base dovrebbe essere il primo parametro, con il suo indirizzo passato in RDI. Dopo, il primo valore da unire alla stringa viene passato in RSI, il secondo in RDX e così via, nell'ordine standard dei registri dei parametri. I valori vengono inseriti nei codici della stringa in ordine, da sinistra a destra. Il programma di sotto presenta una dimostrazione molto semplice del formato di printf(). Una cosa interessante da notare è che puoi passare numeri sia per riferimento che per valore. Il primo intero viene passato posizionando il suo indirizzo in RSI. Il secondo intero viene passato copiando un valore letterale in RDX. Il terzo intero è anch'esso passato come letterale in RCX. Il terzo valore è mostrato in notazione esadecimale, anche se il letterale era un semplice valore intero decimale caricato in RCX. La funzione printf() può effettuare molte conversioni di questo tipo. Puoi unire stringhe di testo alla stringa base in modo simile caricando gli indirizzi delle stringhe da unire nei registri e utilizzando il codice %s che istruisce printf() su dove inserire le stringhe secondarie. Ho eliminato l'intestazione del commento per risparmiare spazio sulla pagina. Il makefile per answer.asm è questo:
</p>

```make
answer: answer.o
     gcc answer.o –o answer –no-pie
answer.o: answer.asm
     nasm –f elf64 –g –F dwarf answer.asm
```

<p align=justify>
Non dimenticare di inserire le tabulazioni richieste se digiti e salvi il makefile
</p>

```asm
section .data
        answermsg db    "The answer is %d ... or is it %d? No! It's 0x%x!",10,0
        answernum dd    42

section .bss

section .text

extern  printf

global  main

main:
    push rbp            ; Prolog
    mov rbp,rsp

    mov rax,0           ; Count of floating point args..here, 0

    mov rdi,answermsg   ; Message/format string goes in RDI
    mov rsi,[answernum] ; Second arg in RSI
    mov rdx,43          ; Third arg in RDX. You can use a numeric literal
    mov rcx,42          ; Fourth arg in RCX. Show this one in hex
    call printf         ; Call printf()

    mov rsp,rbp         ; Epilog
    pop rbp

    ret                 ; Return from main() to shutdown code
```

<p align=justify>
Quando esegui la risposta, questo è ciò che vedrai
</p>

```
The answer is 42 ... or is it 43? No! It's 0x2a!
```

### Printf() necessita di uno 0 precedente in RAX

<p align=justify>
C'è un'altra piccola sottigliezza nell'uso di printf(). In quasi tutti i casi (e certamente mentre stai appena iniziando con l'assembly), dovresti posizionare l'istruzione MOV RAX,0 prima della chiamata a printf(). Lo 0 in RAX dice alla funzione printf() che non ci sono parametri in virgola mobile nei registri vettoriali che le vengono passati. Una volta che inizi a usare valori vettoriali, devi inserire il conteggio di quei parametri in RAX prima di chiamare printf(). Spiegare i registri in virgola mobile e vettoriali va oltre l'ambito di questo libro, quindi se sei interessato, fai delle ricerche online. Questo stesso requisito si applica anche a scanf().
</p>

### Gcc --no-pie

<p align=justify>
Nei makefile per i programmi di questo capitolo che usano gcc come linker, vedrai l'opzione gcc –no-pie. Lo scopo di questa opzione è impedire a gcc di collegare il tuo programma come un PIE. Spiegare in dettaglio il PIE sarebbe un argomento avanzato ben oltre lo scopo di questo libro. In breve: il PIE è un modo per prevenire certi tipi di exploit del codice, collocando porzioni del file eseguibile in posizioni casuali quando l'eseguibile viene caricato. Questo rende impossibile prevedere dove una determinata sezione di codice verrà eseguita. Gli attacchi di programmazione orientata al ritorno (ROP) dipendono dalla conoscenza di dove si trovano alcune porzioni di un programma nel sistema di memoria virtuale di Linux. I programmi PIE sono meno vulnerabili agli attacchi ROP. L'opzione –no pie indica che il linker non genererà un PIE. Questo rende teoricamente vulnerabili ai attacchi i programmi di esempio –no-pie di questo libro. Teoricamente. Una volta che sei un programmatore esperto che produce software per uso generale (e non semplicemente apprendendo la programmazione), dovresti sapere abbastanza per comprendere le problematiche e dovresti informarti online. Il PIE complica qualche aspetto del debugging, motivo per cui non uso il PIE nei miei esempi qui. Ma una volta che un programma che stai scrivendo è stato debuggato e funziona bene, ricompilalo come PIE, che è il valore predefinito quando gcc funge da linker.
</p>

### Dati in con fgets() e scanf()

<p align=justify>
Leggere i caratteri dalla tastiera Linux utilizzando l'istruzione SYSCALL e la chiamata di sistema sys_read è semplice ma non molto versatile. La libreria standard C ha un modo migliore. Infatti, le funzioni della libreria C per leggere dati dalla tastiera (che è la sorgente di dati predefinita assegnata all'input standard) sono quasi l'inverso di quelle che visualizzano dati sull'output standard. Se fai un po' di ricerche in un riferimento della libreria C (e dovresti - ci sono una moltitudine di routine interessanti che puoi chiamare dai programmi in assembly), potresti scoprire la routine gets(). Potresti esserti chiesto (se non ho scelto di dirti qui) perché non l'ho trattata. La routine gets() è di una semplicità disarmante: gli passi il nome di un array di stringhe in cui posizionare i caratteri, e poi l'utente digita i caratteri sulla tastiera, che vengono collocati nell'array. Quando l'utente preme Invio, gets() aggiunge un null alla fine del testo inserito e restituisce. Cosa c'è da non amare? Ebbene, quanto è grande l'array? E quanto è stupido il tuo utente? Ecco il problema: non c'è modo di dire a gets() quando smettere di accettare caratteri. Se l'utente digita più caratteri di quanti ne hai allocato nello spazio per accettarli in un array, gets() continuerà felicemente ad accettare caratteri e sovrascriverà qualsiasi dato sia seduto accanto al tuo array in memoria. Se quel qualcosa è qualcosa di importante, il tuo programma malfunzionerà quasi certamente e potrebbe semplicemente bloccarsi. È per questo che, se provi a usare gets(), gcc ti avviserà che gets() è pericoloso. È un'antica routine, e molto meglio è stata creata negli (innumerevoli) decenni trascorsi da quando Unix e la libreria standard C furono progettati per la prima volta. Il successore designato di gets() è fgets(), che ha alcuni elementi di sicurezza incorporati - e anche alcune complicazioni. Le complicazioni derivano dal fatto che devi passare un handle di file a fgets(). In generale, le routine della libreria standard C i cui nomi iniziano con f agiscono su file. (Spiegherò come lavorare con i file su disco un po' più avanti in questo capitolo.) Puoi usare fgets() per leggere testo da un file su disco - ma ricorda, in termini Unix, la tua tastiera è già collegata a un file, il file chiamato input standard, stdin. Se possiamo collegare fgets() all'input standard, possiamo leggere testo dalla tastiera, che è ciò che la vecchia e pericolosa funzione gets() fa automaticamente.
</p>

<p align=justify>
Il vantaggio nell'uso di fgets() è che ci consente di specificare un numero massimo di caratteri che la routine può accettare dalla tastiera. Qualsiasi altra cosa che l'utente digita sarà troncata e scartata. Se questo valore massimo non è maggiore del buffer di stringa che definisci per contenere i caratteri inseriti dall'utente, non c'è possibilità che l'uso di fgets() faccia crashare il tuo programma. Collegare fgets() all'input standard è facile. Come ho spiegato in precedenza in questo libro, Linux predefinisce tre gestori di file standard, e questi gestori sono collegati automaticamente al tuo programma. I tre sono stdin (input standard), stdout (output standard) e stderr (errore standard). Per accettare input dalla tastiera attraverso fgets(), vogliamo usare l'identificatore stdin. È già lì; devi semplicemente dichiararlo come EXTERN per riferirlo all'interno dei tuoi programmi in linguaggio assembly. Quindi, ecco come utilizzare la funzione fgets().
</p>

1. Assicurati di aver dichiarato EXTERN fgets e EXTERN stdin insieme alle tue altre dichiarazioni esterne nella parte superiore della sezione .text del tuo programma.
2. Dichiara una variabile buffer abbastanza grande da contenere i dati della stringa che vuoi che l'utente inserisca. Usa la direttiva RESB nella sezione .bss del tuo programma.
3. Carica l'indirizzo del buffer in RDI.
4. Successivamente, carica il valore che indica il numero massimo di caratteri che vuoi che fgets() accetti in RSI. Assicurati che non sia maggiore della variabile buffer che dichiari in .bss!
5. Carica il valore di stdin in RDX. Nota bene: Non passare l'indirizzo del valore esterno stdin. Passa il valore reale che l'elemento esterno stdin contiene, usando le parentesi: [stdin]
6. Chiama fgets.

<p align=justify>
Come sempre, i parametri che passi a fgets() vengono inseriti nei registri nell'ordine specificato nella convenzione di chiamata x64. Questo è molto più comodo rispetto a spingerli nello stack, come avveniva nel mondo a 32 bit. Il codice sotto è un semplice programma che dimostra come ottenere testo dall'input standard tramite fgets(). Di nuovo, per brevità ho omesso l'intestazione dei commenti.
</p>

```asm
;  Executable name : fgetstest
;  Version         : 3.0
;  Created date    : 11/19/2022
;  Last update     : 7/18/2022
;  Author          : Jeff Duntemann
;  Description     : Demonstrates calls made into libc, using NASM 2.14.02 
;                    to enter a short text string with gets() and display 
;                    with printf().
;
;                  : Build with this makefile, being midful of the required tabs:
;   fgetstest: fgetstest.o
;       gcc fgetstest.o -o fgetstest -no-pie
;   fgetstest.o: fgetstest.asm
;       nasm -f elf64 -g -F dwarf fgetstest.asm

SECTION .data           ; Section containing initialized data	

message: db "You just entered: %s."	
	
SECTION .bss            ; Section containing uninitialized data

testbuf: resb 20 
BUFLEN   equ $-testbuf

SECTION .text           ; Section containing code

extern printf
extern stdin	
extern fgets

global main             ; Required so the linker can find the entry point
	
main:
    push rbp             ; Set up stack frame for debugger
	mov rbp,rsp
    and rsp,-16
;;; Everything before this is boilerplate; use it for all ordinary apps!

; Get a number of characters from the user:		
    mov rdi,testbuf      ; Put address of buffer into RDI
    mov rsi,BUFLEN       ; Put # of chars to enter in RSI
    mov rdx,[stdin]
    call fgets           ; Call libc function for entering data

;Display the entered characters:
    mov rdi,message      ; Base string's address goes in RDI
    mov rsi,testbuf      ; Data entry buffer's address goes in RSI
    xor rax,rax          ; 0 in RAX tells printf no SSE registers are coming    
    call printf          ; Call libc function to display entered chars

;;; Everything after this is boilerplate; use it for all ordinary apps!
	mov rsp,rbp          ; Destroy stack frame before returning
    pop rbp

    ret                  ; Return to glibc shutdown code
```

<p align="justify">
Il programma fgetstest dimostra come incorporare un codice stringa %s nella stringa base. Non è necessario fare altro che posizionare %s nella stringa base e poi copiare l'indirizzo della stringa da inserire nel prossimo registro disponibile secondo la convenzione di chiamata x64. Qui, si tratta di RSI. Dal lato dell'utente dello schermo, fgets() accetta semplicemente caratteri fino a quando l'utente non preme Invio. Non ritorna automaticamente dopo che l'utente ha digitato il numero massimo di caratteri consentiti. (Questo impedirebbe all'utente di correggere l'input.) Tuttavia, qualsiasi cosa digitata dall'utente oltre il numero di caratteri consentiti viene scartata.
</p>

### Utilizzando scanf() per l'inserimento di valori numerici

<p align="justify">
In un modo peculiare, la funzione scanf() della libreria C è printf() che funziona all'indietro: invece di produrre dati formattati in un flusso di caratteri, scanf() prende un flusso di dati carattere dalla tastiera e lo converte in dati numerici memorizzati in una variabile numerica. La funzione scanf() funziona molto bene e comprende molti formati che non sarò in grado di spiegare qui, specialmente per l'inserimento di numeri in virgola mobile. (I valori in virgola mobile rappresentano un problema speciale nel lavoro in assembly e non li tratterò in questo libro.) La voce di Wikipedia è molto buona.
</p>

[https://en.wikipedia.org/wiki/Scanf_format_string](https://en.wikipedia.org/wiki/Scanf_format_string)

<p align="justify">
Per la maggior parte dei programmi semplici che potresti scrivere mentre prendi confidenza con l'assembly, inserirai numeri interi semplici, e scanf() è molto utile per questo. Passi a scanf() il nome di una variabile numerica in cui memorizzare il valore inserito e un codice di formato che indica quale forma avrà quel valore all'ingresso dei dati. La funzione scanf() prenderà i caratteri digitati dall'utente e li convertirà nel valore intero che i caratteri rappresentano. Cioè, scanf() prenderà i due caratteri ASCII "4" e "2" inseriti consecutivamente e li convertirà nel valore numerico in base 10 42 dopo che l'utente preme Invio. E per quanto riguarda una stringa di richiesta, che istruisce l'utente su cosa digitare? Bene, molti nuovi arrivati hanno l'idea che puoi combinare la richiesta con il codice di formato in un'unica stringa passata a scanf(), ma purtroppo, questo non funzionerà. Sembra che dovrebbe funzionare—dopo tutto, puoi combinare i codici di formato con la stringa base da visualizzare usando printf(). E in scanf(), teoricamente puoi usare una stringa base contenente codici di formato ... ma poi l'utente dovrebbe digitare sia la richiesta che i dati numerici! Quindi, in termini pratici, l'unica stringa utilizzata da scanf() è una stringa contenente i codici di formato. Se vuoi una richiesta, devi visualizzarla usando printf() prima di chiamare scanf(). Per mantenere la richiesta e l'inserimento dei dati sulla stessa riga, assicurati di non avere un carattere EOL alla fine della tua stringa di richiesta! La funzione scanf() acquisisce automaticamente input di caratteri da input standard. Non devi passarle il gestore di file stdin, come fai con fgets(). Esiste una funzione glibc separata chiamata fscanf() a cui devi passare un gestore di file, ma per l'inserimento di dati interi non c'è rischio nell'usare scanf(). Ecco come utilizzare la routine scanf(): 
</p>

1. Assicurati di aver dichiarato EXTERN scanf insieme alle tue altre dichiarazioni esterne nella parte superiore della sezione .TEXT.
2. Dichiarare una variabile di memoria del tipo appropriato per contenere i dati numerici letti e convertiti da scanf(). I miei esempi qui saranno per dati interi, quindi dovresti creare tale variabile con la direttiva DQ o la direttiva RESQ. Ovviamente, se intendi mantenere diversi valori separati, dovrai dichiarare una variabile per ogni valore inserito.
3. Per chiamare scanf() per l'inserimento di un singolo valore, prima copia l'indirizzo della stringa di formato che specifica in quale formato arriveranno i dati in RDI. Per i valori interi, questa è tipicamente la stringa %d.
4. Copia l'indirizzo della variabile di memoria che conterrà il valore in RSI. (Vedi la seguente discussione sull'inserimento di più valori in una sola chiamata.)
5. Azzerare RAX, dicendo a scanf() che nessun parametro di registro vettoriale viene passato nella chiamata di funzione.
6. Chiama scanf().

<p align="justify">
È possibile presentare a scanf() una stringa contenente più codici di formattazione in modo che l'utente possa inserire più valori numerici con una sola chiamata a scanf(). L'ho provato e risulta in un'interfaccia utente piuttosto peculiare. Questa funzionalità è meglio utilizzata se stai scrivendo un programma per leggere un file di testo contenente righe di valori interi espressi come testo e convertirli in variabili intere reali in memoria. Per ottenere semplicemente valori numerici dall'utente tramite la tastiera, è meglio accettare solo un valore per ogni chiamata a scanf(). Il programma charsin.asm (vedi sotto) mostra come impostare messaggi insieme a un campo di inserimento dati per accettare sia dati stringa che dati numerici dall'utente attraverso la tastiera. Dopo aver accettato i dati, il programma visualizza ciò che è stato inserito, utilizzando printf()
</p>

```asm

;  Executable name : charsin
;  Version         : 3.0
;  Created date    : 11/19/2022
;  Last update     : 11/20/2022
;  Author          : Jeff Duntemann
;  Description     : A character input demo for Linux, using NASM 2.14.02,
;                  : incorporating calls to both fgets() and scanf().
;
;  Build using these commands:
;    nasm -f elf64 -g -F dwarf charsin.asm
;    gcc charsin.o -o charsin -no-pie
;	

[SECTION .data]         ; Section containing initialised data
	
SPrompt  db 'Enter string data, followed by Enter: ',0		
IPrompt  db 'Enter an integer value, followed by Enter: ',0
IFormat  db '%d',0
SShow    db 'The string you entered was: %s',10,0
IShow    db 'The integer value you entered was: %5d',10,0
	
[SECTION .bss]          ; Section containing uninitialized data

IntVal   resq 1         ; Reserve an uninitialized double word
InString resb 128       ; Reserve 128 bytes for string entry buffer
		
[SECTION .text]         ; Section containing code

extern stdin            ; Standard file variable for input
extern fgets
extern printf	
extern scanf		

global main             ; Required so linker can find entry point
	
main:
    push rbp            ; Set up stack frame
    mov rbp,rsp

;;; Everything before this is boilerplate; use it for all ordinary apps!

; First, an example of safely limited string input using fgets:
    mov rdi,SPrompt	    ; Load address of the prompt string into RDI
    call printf         ; Display it

    mov rdi,InString    ; Copy address of buffer for entered chars
    mov rsi,72          ; Accept no more than 72 chars from keybd
    mov rdx,[stdin]     ; Load file handle for standard input into RDX
    call fgets          ; Call fgets to allow user to enter chars

    mov rdi,SShow       ; Copy address of the string prompt into RSI
    mov rsi,InString    ; Copy address of entered string data into RDI
    call printf         ; Display it

; Next, use scanf() to enter numeric data:
    mov rdi,IPrompt     ; Copy address of integer input prompt into RDI
    call printf         ; Display it

    mov rdi,IFormat     ; Copy address of the integer format string into RDI
    mov rsi,IntVal      ; Copy address of the integer buffer into RSI
    call scanf          ; Call scanf to enter numeric data

    mov rdi,IShow       ; Copy address of base string into RDI
    mov rsi,[IntVal]    ; Copy the integer value to display into RSI
    call printf         ; Call printf to convert & display the integer

;;; Everything after this is boilerplate; use it for all ordinary apps!

    mov rsp,rbp         ; Destroy stack frame before returning
    pop rbp
	
    ret                 ; Return control to Linux
```

### Essere un Signore del Tempo Linux

<p align="justify">
Le librerie standard C contengono un gruppo piuttosto sostanzioso di funzioni che manipolano date e orari. Sebbene queste funzioni siano state originariamente progettate per gestire valori di data generati dall'orologio in tempo reale nell'hardware dei minicomputer AT&T dell'antichità, che era attuale negli anni '70, sono ormai diventate un'interfaccia standard per il supporto dell'orologio in tempo reale di qualsiasi sistema operativo. Le persone che programmando in C per Windows utilizzano lo stesso gruppo di funzioni e funzionano più o meno allo stesso modo indipendentemente dal sistema operativo su cui si sta lavorando. Comprendendo come chiamare queste funzioni come procedure in linguaggio assembly, sarai in grado di leggere la data corrente, esprimere i valori di tempo e data in numerosi formati, applicare timestamp ai file e fare molte altre cose molto utili. Diamo un'occhiata a come funziona.
</p>

### La macchina del tempo della libreria C

<p align="justify">
Da qualche parte nel profondo della libreria standard C, c'è un blocco di codice che, quando invocato, guarda all'orologio in tempo reale del computer, legge la data e l'ora correnti e traduce questo in un valore intero firmato standard. Questo valore è (teoricamente) il numero di secondi trascorsi nell'“epoca Unix”, (o negli ambienti di programmazione, semplicemente “l'epoca”), che è iniziata il 1 gennaio 1970, 00:00:00 ora universale. Ogni secondo che passa aggiunge 1 a questo valore. Quando leggi l'ora o la data corrente tramite la libreria C, ciò che recupererai è il valore attuale di questo numero. Il numero si chiama time_t. Per quasi tutta la sua storia, time_t era un intero firmato a 32 bit. Col passare degli anni, la gente ha iniziato a chiedersi cosa sarebbe successo quando un intero firmato a 32 bit non sarebbe stato abbastanza grande per contenere il numero di secondi dal 1970. Alle 3:14:07 UTC del 19 gennaio 2038, i computer che considerano time_t come un intero firmato a 32 bit lo vedranno azzerarsi a 0, perché un intero firmato a 32 bit può esprimere quantità solo fino a 2.147.483.647. Sono un sacco di secondi (e un tempo ragionevolmente lungo per prepararsi), ma io avrò solo 86 anni e mi aspetto di essere qui quando accadrà. (Ricordo tutta la panico del Y2K, eh.) In verità, non succederà, proprio come il famigerato fenomeno Y2K non ha fatto crollare la civiltà, come certa gente che avrebbe dovuto saperlo ha affermato all'epoca. Una libreria C implementata correttamente non presuppone affatto che time_t sia una quantità a 32 bit. Quindi, quando il time_t firmato a 32 bit scoppierà nel 2038, avremo utilizzato valori a 64 bit per tutto e il problema sarà rimandato per altri 292 miliardi di anni o giù di lì. Se non lo avremo risolto una volta per tutte entro allora, meriteremo di andare giù con l'intero universo nel Big Crunch che i cosmologi prevedono poco dopo. Certamente il problema non esiste più in Linux. Tutti i sistemi Linux a 64 bit utilizzano un time_t a 64 bit e, dalla versione 5.6 di Linux nel 2020, anche le versioni a 32 bit del sistema operativo utilizzano un time_t a 64 bit.
</p>

<p align="justify">
Il valore time_t è semplicemente un conteggio arbitrario dei secondi e di per sé non ti dice molto, anche se può essere utile per calcolare i tempi trascorsi in secondi. Un altro tipo di dato standard implementato dalla libreria standard C è molto più utile. Una struttura tm (che viene spesso chiamata struct, e tra le persone del Pascal un record) è un raggruppamento di nove valori numerici a 32 bit che esprimono l'ora e la data attuali in segmenti utili separatamente, come riassunto nella figura di sotto. Nota che, sebbene una struct (o record) sia nominalmente un raggruppamento di valori dissimili, nell'attuale implementazione x64 di Linux, un valore tm è più simile a un array o a una tabella dati, poiché tutti e nove gli elementi hanno la stessa dimensione, che è 32 bit, o 4 byte. L'ho descritto in questo modo nella figura di sotto, includendo un valore che rappresenta l'offset dall'inizio della struttura per ciascun elemento della struttura. Questo ti consente di utilizzare un puntatore all'inizio della struttura e un offset dall'inizio per creare l'indirizzo effettivo di un dato elemento della struttura. Nota che anche in un'istanza Linux a 64 bit, i campi tm sono di dimensioni 32 bit. Perché ancora 32 bit? Facile: nessuno degli elementi in tm ha bisogno di qualcosa vicino a 8 byte per essere espresso. Il valore più grande possibile è tm_yday, che contiene il numero ordinale del giorno corrente, ovvero un numero da 1 a 366, con 1 che è il primo giorno di gennaio. Naturalmente, tra alcuni secoli, il numero di anni dal 1900 supererà 366, ma ancora una volta, non aspettarti.
</p>

<div aling=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/values_contained_in_the_tm_structure.png">
</div>

<p align="justify">
L'unico elemento che necessita di una spiegazione un po' più dettagliata è tm_isdst. Il valore in tm_isdst è positivo se l'ora legale (DST) è in vigore e zero se l'ora legale non è in vigore. Se il sistema non riesce a determinare se l'ora legale è in vigore, il valore in tm_isdst è negativo. Esistono funzioni della libreria C che convertono i valori time_t in valori tm e viceversa. Ne tratto alcune in questo capitolo, ma sono tutte piuttosto semplici e, una volta che hai assimilato a fondo le convenzioni di chiamata C, dovresti essere in grado di elaborare un protocollo di chiamata in assembly per ciascuna di esse. Un'altra nota precauzionale: il valore time_t non è il numero esatto e preciso di secondi dall'inizio dell'epoca Unix. Ci sono problemi nel modo in cui Unix conta i secondi e il time_t non è corretto per gli errori astronomici accumulati come fa il tempo reale NIST, attraverso i "secondi intercalari". Quindi, su brevi intervalli (idealmente, meno di un anno), il time_t può essere considerato accurato. Oltre a questo, si deve presumere che sarà impreciso di alcuni secondi o più, senza un modo semplice per capire come compensare gli errori.
</p>

### Recupero valori time_t dall'orologio di sistema

<p align="justify">
Ogni singolo secondo di tempo (almeno quei secondi dopo il 1 gennaio 1970) può essere rappresentato come un intero con segno a 64 bit in un sistema compatibile con Unix. Il recupero del valore per l'ora corrente viene eseguito chiamando la funzione time(). Come tutte le funzioni progettate in conformità con le convenzioni di chiamata x64, time() restituisce il suo valore time_t in RAX. Tuttavia, c'è un problema che a volte fa inciampare i principianti: time() può prendere un parametro. Come tutti i primi parametri, viene passato a time() in RDI. Il trucco: è facoltativo. Più o meno. Quando si chiama time(), se RDI contiene 0, il valore time_t verrà restituito in RAX. Se RDI contiene qualcosa di diverso da 0, time() presumerà che il valore in RDI sia un indirizzo e tenterà di scrivere il valore time_t in memoria a quell'indirizzo. Se RDI contiene "avanzi" che non sono indirizzi validi, la chiamata time() di solito causa un errore di segmentazione. Dico "di solito" perché ho sentito dire che su alcuni sistemi, l'implementazione di time() contiene alcuni macchinari extra per rilevare gli indirizzi spazzatura, e se un indirizzo in RDI è spazzatura, tornerà a restituire il valore in RAX. Tuttavia, non puoi contare su questo. Non è necessario passare altri parametri a time(). Al ritorno, avrai il valore time_t corrente in RAX. Questo è tutto quello che c'è da fare. Data la possibilità di differenze di implementazione, non consiglio di consegnare a time() un indirizzo. Quello che consiglio è di avere il valore time_t restituito in RAX. Ciò richiede che si cancelli RDI su 0 prima di chiamare time().
</p>

### Convertire un valore time_t in una stringa formattata

<p align="justify">
Ancora una volta, da solo, un valore time_t non ti dice molto. La libreria C contiene una funzione che restituirà un puntatore a una rappresentazione di stringa formattata di un dato valore time_t. Questa è la funzione ctime(). Restituisce un puntatore a una stringa sepolta da qualche parte nella libreria di runtime. Questa stringa ha il seguente formato:
</p>

```
 Wed Nov 28 12:13:21 2022
```

<p align="justify">
Il primo campo è un codice di tre caratteri per il giorno della settimana, seguito da un codice di tre caratteri per il mese e un campo di due spazi per il giorno del mese. L'ora segue, in formato 24 ore, e l'anno chiude il tutto. Per completezza (anche se a volte può essere una seccatura), la stringa restituita da ctime termina con una nuova linea. Ecco come chiamare ctime e visualizzare la stringa di data/ora che genera:
</p>

```asm
mov rdi,TimeValue   ; Copy *address* of time_t value into rdi
call ctime          ; Returns pointer to ASCII time string in rax
mov rdi,rax         ; Copy the address in rax into rdi
call puts           ; Call puts to display the ASCII time string
```

<p align="justify">
Questo sembra piuttosto convenzionale, ma c'è qualcosa di cui devi essere consapevole, poiché si discosta dalla nostra recente esperienza con glibc: devi passare a ctime() l'indirizzo di un valore time_t, non il valore stesso! Sei abituato a passare valori interi alle funzioni copiando quei valori in RDI, RSI e così via. Non è così qui. Un valore time_t è attualmente, sotto Linux, rappresentato come un intero a 8 byte, ma non c'è alcuna garanzia che rimanga sempre così. Le versioni più vecchie di Linux potrebbero utilizzare un time_t a 32 bit. Altre implementazioni di Unix potrebbero variare notevolmente. Quindi, per mantenere aperte le sue opzioni (e per assicurarsi che Unix possa essere utilizzato per migliaia o addirittura miliardi di anni a venire, eh), la funzione della libreria C ctime() richiede un puntatore al valore time_t corrente piuttosto che un valore time_t stesso. Passa l'indirizzo del valore time_t che vuoi rappresentare come stringa in RDI, e poi chiama ctime(). Ciò che ctime() restituisce in RAX è un puntatore alla stringa, che mantiene da qualche parte all'interno della libreria di runtime. Puoi usare quel puntatore per visualizzare la stringa sullo schermo tramite puts o printf o scriverla su un file di testo.
</p>

### Generazione di valori locali di tempo separati

<p align="justify">
La libreria glibc ti offre anche una funzione per separare i vari componenti di data e ora in valori distinti in modo da poterli utilizzare separatamente o in varie combinazioni. Questa funzione è localtime(), e dato un valore time_t, separerà la data e l'ora nei campi di una struttura tm, come descritto nella figura di sopra. Ecco il codice per chiamarla:
</p>

```asm
 mov rdi,TimeValue    ; Pass address of calendar time value in rdi
 call localtime       ; Returns pointer to static time structure in rax
```

<p align="justify">
Qui, TimeValue è un valore time_t. Data questo valore, localtime() restituisce in RAX—molto come ctime()—un puntatore a una struttura tm all'interno della libreria C da qualche parte. Utilizzando questo puntatore come indirizzo base, puoi accedere ai singoli campi nella struttura. Il trucco sta nel conoscere l'offset dentro tm per il singolo campo data/ora che desideri, e utilizzare quell'offset come uno spostamento costante dall'indirizzo base.
</p>

```asm
 mov rdi, yrmsg           ; Pass address of the base string in rdi
 mov rsi, dword [rax+20]  ; Year value tm_year is 20 bytes offset into tm
 mov rax,0                ; Count of vector regs..here, 0
 call printf              ; Display string and year value with printf
```

<p align="justify">
Utilizzando gli spostamenti mostrati nella figura di sopra, è possibile accedere a tutti gli altri componenti dell'ora e della data nella struttura tm, ciascuno memorizzato come un valore intero a 32 bit.
</p>

### Creare una copia della struttura tm di glibc con MOVSD

<p align="justify">
A volte è utile mantenere una copia separata di una struttura tm, soprattutto se stai lavorando con diversi valori di data/ora contemporaneamente. Quindi, dopo aver usato localtime() per riempire la struttura tm nascosta della libreria C con valori di data/ora, puoi copiare quella struttura in una struttura allocata nella sezione .bss o .data del tuo programma. Effettuare una tale copia è un uso diretto dell'istruzione REP MOVSD (Ripeti Copia Stringa Doppia), una delle istruzioni che ho introdotto nei pragrafi precedenti. MOVSD è una cosa quasi magica: una volta impostati i puntatori sull'area dati che vuoi copiare e sul luogo in cui vuoi copiarla, memorizzi la dimensione dell'area in RCX e lasci che REP MOVSD faccia il resto. In un'unica operazione copierà un intero buffer da un luogo nella memoria a un altro. Per usare REP MOVSD, posizioni l'indirizzo dei dati sorgente—cioè, i dati da copiare—nell'RSI. Sposti l'indirizzo della posizione di destinazione—dove i dati devono essere posizionati—nell'RDI. Il numero di elementi da spostare viene posto in RCX. Ti assicuri che il flag di Direzione DF sia resettato (per ulteriori dettagli, vedi paragrafi precedenti) e poi esegui REP MOVSD:
</p>

```asm
 mov rsi,rax    ; Copy address of static tm from rax to rsi
 mov rdi,tmcopy ; Put the address of the local tm vartiable in rdi
 mov rcx,9      ; A tm struct is 9 dwords in size under Linux
 cld            ; Clear df to 0 so we move up-memory
 rep movsd      ; Copy static tm struct to local tm copy
```

<p align="justify">
Perché usare MOVSD invece del suo fratello maggiore MOVSQ a 64 bit? La struttura tm è fondamentalmente un array di nove elementi da 4 byte, non da 8 byte. Qui, stiamo trasferendo la struttura tm della libreria C in un buffer allocato nella sezione .bss del programma. La struttura tm è composta da nove parole doppie—36 byte—di dimensione. Quindi, dobbiamo riservare tanto spazio e dargli un nome.
</p>

```asm
 TmCopy resd 9 ; Reserve 9 32-bit fields for time struct tm
```

<p align="justify">
Il codice precedente presuppone che l'indirizzo della struttura tm già compilata della libreria C sia in RAX e che sia stata allocata una struttura tm TmCopy. Una volta eseguito, copierà tutti i dati tm dal suo nascondiglio all'interno della libreria di esecuzione C nel tuo buffer appena allocato TmCopy.
</p>

<p align="justify">
Il prefisso REP mette MOVSD in modalità fucile automatico, come ho spiegato nei paragrafi precedenti. Cioè, MOVSD continuerà a spostare dati dall'indirizzo in RSI all'indirizzo in RDI, decrementando RCX di uno ad ogni spostamento, fino a quando RCX non arriva a zero. Poi si ferma. Un errore facile da evitare è dimenticare che il conteggio in RCX è il conteggio degli elementi di dati da spostare, non il numero di byte da spostare! In virtù della D alla fine del suo mnemonico, MOVSD sposta doppie parole, e il valore che inserisci in RCX deve essere il numero di elementi da 4 byte da spostare. Quindi, spostando nove doppie parole, MOVSD trasporta effettivamente 36 byte da una posizione a un'altra - ma stai contando doppie parole qui, non byte. Il programma nell'Elenco 12.5 unisce tutti questi frammenti di codice in una demo delle principali funzionalità di cronologia di Unix. Ci sono molte altre funzioni temporali da studiare nella libreria C, e con ciò che ora sai sulle chiamate di funzione C, dovresti essere in grado di elaborare protocolli di chiamata per ognuna di esse.
</p>

```asm
;  Executable name : timetest
;  Version         : 3.0
;  Created date    : 11/28/2022
;  Last update     : 11/28/2022
;  Author          : Jeff Duntemann
;  Description     : A demo of time-related functions for Linux, using
;                    NASM 2.14.02
;
;  Build using these commands:
;    nasm -f elf64 -g -F stabs timetest.asm
;    gcc timetest.o -o timetest -no-pie
;

[SECTION .data]         ; Section containing initialised data

TimeMsg  db "Hey, what time is it?  It's %s",10,0
YrMsg	 db "The year is %d.",10,10,0
PressEnt db "Press enter after a few seconds: ",0
Elapsed  db "A total of %d seconds has elapsed since program began running.",10,0	
	
[SECTION .bss]          ; Section containing uninitialized data

OldTime	 resq 1         ; Reserve 3 quadwords for time_t values
NewTime  resq 1
TimeDiff resq 1	
TimeStr  resb 40        ; Reserve 40 bytes for time string
TmCopy	 resd 9         ; Reserve 9 integer fields for time struct tm			

[SECTION .text]         ; Section containing code

extern ctime
extern difftime
extern getchar
extern printf
extern localtime	
extern strftime	
extern time
									
global main             ; Required so linker can find entry point
	
main:
    push rbp            ; Set up stack frame
    mov rbp,rsp
    
;;; Everything before this is boilerplate; use it for all ordinary apps!	

; Generate a time_t calendar time value with clib's time function
    xor rdi,rdi         ; Clear rdi to 0
    call time           ; Returns calendar time in rax
    mov [OldTime],rax   ; Save time value in memory variable

; Generate a string summary of local time with clib's ctime function
    mov rdi,OldTime     ; Push address of calendar time value
    call ctime          ; Returns pointer to ASCII time string in rax

    mov rdi,TimeMsg     ; Pass address of base string in rdi
    mov rsi,rax         ; Pass pointer to ASCII time string in rsi
    call printf         ; Merge and display the two strings

; Generate local time values into libc's static tm struct
    mov rdi,OldTime     ; Push address of calendar time value
    call localtime      ; Returns pointer to static time structure in rax

; Make a local copy of libc's static tm struct
    mov rsi,rax         ; Copy address of static tm from rax to rsi
    mov rdi,TmCopy      ; Put the address of the local tm copy in rdi
    mov rcx,9           ; A tm struct is 9 dwords in size under Linux
    cld                 ; Clear DF so we move up-memory
    rep movsd           ; Copy static tm struct to local copy

; Display one of the fields in the tm structure
	mov rdx,[TmCopy+20] ; Year field is 20 bytes offset into tm
	add rdx,1900        ; Year field is # of years since 1900
	mov rdi,YrMsg       ; Put address of the base string into rdi
    mov rsi,rdx
	call printf         ; Display string and year value with printf

; Display the 'Press Enter: ' prompt
    mov rdi,PressEnt    ; Put the address of the base string into rdi
    call printf

; Wait a few seconds for user to press Enter so we have a time difference:
    call getchar        ; Wait for user to press Enter

; Calculating seconds passed since program began running:
    xor rdi,rdi         ; Clear rdi to 0
    call time           ; Get current time value; return in EAX
    mov [NewTime],rax   ; Save new time value

    sub rax,[OldTime]   ; Calculate time difference value
    mov [TimeDiff],rax  ; Save time difference value

    mov rsi,[TimeDiff]  ; Put difference in seconds rdi
    mov rdi,Elapsed     ; Push addr. of elapsed time message string
    call printf         ; Display elapsed time
		
;;; Everything after this is boilerplate; use it for all ordinary apps!

    mov rsp,rbp         ; Destroy stack frame before returning
    pop rbp

    ret                 ; Return to glibc shutdown code
```

<p align="justify">
Se mai ti trasferisci in altre implementazioni di Unix al di fuori della sfera GNU, tieni presente che il valore di time_t potrebbe già avere una definizione diversa da un intero a 32 bit. In questo momento, glibc definisce time_t come un intero a 64 bit, e puoi calcolare le differenze di tempo tra due valori di time_t semplicemente sottraendoli. Per altre implementazioni di Unix non GNU, è meglio utilizzare la funzione difftime() nella libreria libc per restituire una differenza tra due valori di time_t.
</p>

### Comprendere i mnemonici di istruzione AT&T

<p align="justify">
Esistono più di un insieme di mnemoniche per le istruzioni delle CPU x86, e questo è stato fonte di molta confusione. Una mnemonica di istruzione è semplicemente un modo per gli esseri umani di ricordare cosa significa per la CPU il modello binario 1000100111000011. Invece di scrivere 16 uno e zero in fila (o anche l'equivalente esadecimale leggermente più comprensibile 89C3h), diciamo MOV BX,AX. Tieni presente che le mnemoniche sono proprio questo: stimolatori della memoria per gli esseri umani, e sono creature sconosciute alla CPU stessa. Gli assemblatori traducono le mnemoniche in istruzioni macchina. Anche se possiamo concordare tra di noi che MOV BX,AX si tradurrà in 1000100111000011, non c'è nulla di magico nella stringa MOV BX,AX. Avremmo potuto anche concordare su COPY AX TO BX o STICK GPREGA INTO GPREGB. Usamo MOV BX,AX perché è stata l'indicazione suggerita da Intel, e poiché Intel ha progettato e produce i chip per CPU, potrebbe sapere meglio come descrivere i dettagli interni dei propri prodotti. L'insieme alternativo di mnemoniche per istruzioni x86 che chiamiamo mnemoniche AT&T è emerso dal desiderio di rendere Unix il più facile possibile da portare su diverse architetture di computer. Tuttavia, gli obiettivi degli implementatori dell'insieme di istruzioni non sono gli stessi di quelli dei programmatori in linguaggio assembly, e se il tuo obiettivo è avere un comando completo e ottimale delle CPU x86/x64, è meglio scrivere codice con l'insieme Intel, come ho insegnato in questo libro. In verità, le mnemoniche AT&T appaiono strane e un po' opache, anche per me. Il motivo è che non sono mai state progettate per essere utilizzate dagli esseri umani per scrivere programmi in linguaggio assembly. Sono state progettate per essere un linguaggio intermedio facilmente portabile, cioè un linguaggio scritto da un pezzo di software per essere elaborato da un pezzo di software completamente diverso. In Linux, questo sarebbe generalmente il compilatore di linguaggio C gcc e l'assemblatore Gnu, gas. Infatti, il linguaggio C era originariamente considerato un 'assemblatore di alto livello', e rispetto ad altri linguaggi di programmazione come COBOL, FORTRAN o Pascal, lo è. Anche se ci sono buone ragioni per saper leggere le mnemoniche e la sintassi AT&T, è diventato abbastanza complesso che non posso giustificare di insegnarlo in modo approfondito in un libro per principianti come questo.
</p>

### Convezioni mnemoniche di AT&T

<p align="justify">
Quindi ecco un riepilogo: quando gcc compila un file di codice sorgente C in codice macchina, ciò che fa realmente è tradurre il codice sorgente C in codice sorgente assembly, utilizzando i mnemonici AT&T. Torna alla figura su gcc. Il compilatore gcc prende come input un file di codice sorgente .c e genera un file di codice sorgente assembly .s, che viene poi passato all'assemblatore GNU gas per l'assemblaggio. Questo è il modo in cui gli strumenti GNU funzionano su tutte le piattaforme, con tutti i linguaggi GNU, dei quali ce ne sono diversi oltre a C e C++. Il passaggio assembly è generalmente invisibile per il programmatore, con il file .s scartato dopo che gas lo converte in codice macchina e ld lo collega. Puoi far salvare a gcc il file di codice sorgente assembly AT&T su disco utilizzando l'opzione -S:
</p>

```
gcc eatc.c –S –o eatc
```

<p align="justify">
Nota che l'opzione –S utilizza una S maiuscola. Quasi tutto in Linux e in altri discendenti di Unix è sensibile al maiuscolo e minuscolo. Ora, se hai intenzione di affrontare la libreria standard C e le moltitudini di altre librerie di funzioni scritte in C e per C, ha senso diventare almeno vagamente familiari con i mnemotecnici AT&T. Ci sono alcune regole generali che, una volta metabolizzate, rendono tutto molto più facile. Ecco l'elenco in breve.
</p>

<ul>
	<li>
		<p align="justify">
		Le mnemoniche e i nomi dei registri AT&T sono invariabilmente in minuscolo. Questo è in linea con la convenzione Unix di sensibilità al maiuscolo e al minuscolo. Ho mescolato maiuscole e minuscole nel testo e negli esempi per farti abituare a vedere il codice assembly in entrambi i modi, ma devi ricordare che mentre la sintassi di Intel (e quindi NASM) suggerisce l'uso delle maiuscole ma accetterà le minuscole, la sintassi AT&T richiede l'uso delle minuscole.
   		</p>
	</li>
 	<li>
		<p align="justify">
		I nomi dei registri sono sempre preceduti dal simbolo di percentuale, %. Cioè, ciò che Intel scriverebbe come AX o RBX, AT&T lo scriverebbe come %ax e %rbx. Questo aiuta l'assemblatore a riconoscere i nomi dei registri.
   		</p>
	</li>
 	<li>
		<p align="justify">
		Ogni mnemonico di istruzione macchina AT&T che ha operandi ha un suffisso di un singolo carattere che indica la grandezza dei suoi operandi. Le lettere del suffisso sono b, w, l e q che indicano byte (8 bit), parola (16 bit), lungo (32 bit) e quad (64 bit). Ciò che Intel scriverebbe come MOV RBX,RAX, AT&T lo scriverebbe come movq %rax,%rbx.
   		</p>
	</li>
 	<li>
		<p align="justify">
		Quando un'istruzione non prende operandi (call, leave, ret), non ha un suffisso di dimensione dell'operando. Le chiamate e i ritorni sembrano praticamente uguali sia nella sintassi Intel che in quella AT&T.
   		</p>
	</li>
 	<li>
		<p align="justify">
		Nella sintassi AT&T, gli operandi sorgente e destinazione sono posti nell'ordine opposto rispetto alla sintassi Intel. Cioè, ciò che Intel scriverebbe come MOV RBX,RAX, AT&T lo scriverebbe come movq %rax,%rbx. In altre parole, nella sintassi AT&T, l'operando sorgente viene prima, seguito dall'operando di destinazione.
   		</p>
	</li>
 	<li>
		<p align="justify">
		Nella sintassi AT&T, gli operandi immediati sono sempre preceduti dal simbolo del dollaro, $. Ciò che Intel scriverebbe come PUSH 42, AT&T lo scriverebbe come pushq $42. Questo aiuta l'assemblatore a riconoscere gli operandi immediati.
   		</p>
	</li>
 	<li>
		<p align="justify">
		Non tutte le mnemoniche di istruzione AT&T sono generate da gcc. Gli equivalenti di JCXZ, JECXZ, LOOP, LOOPZ, LOOPE, LOOPNZ e LOOPNE di Intel sono stati aggiunti al set di mnemoniche AT&T non molto tempo fa e, in alcune versioni, gcc non genera codice che le utilizza.
   		</p>
	</li>
 	<li>
		<p align="justify">
		Nella sintassi AT&T, gli spostamenti nelle riferimenti di memoria sono quantità con segno posizionate all'esterno delle parentesi contenenti i valori di base, indice e scala. Tratterò questo separatamente un po' più tardi, poiché lo vedrai spesso nei file .s, e dovresti essere in grado di leggere e comprendere la sintassi degli indirizzi di memoria di ATT.
   		</p>
	</li>
 	<li>
		<p align="justify">	
		Quando viene citato, il nome di una stringa di messaggio è preceduto da un simbolo di dollaro ($) nello stesso modo in cui lo sono i letterali numerici. In NASM, una variabile di stringa nominata è considerata una variabile e non un letterale. Questo è solo un altro peccadillo di AT&T di cui essere a conoscenza.
   		</p>
	</li>
 	<li>
		<p align="justify">
		Si noti che il delimitatore dei commenti nello schema AT&T è il cancelletto (#) piuttosto che il punto e virgola utilizzato in quasi tutti gli assemblatori in stile Intel, compreso NASM.
   		</p>
	</li>
</ul>

### Sintassi di riferimento della memoria AT&T

<p align="justify">
Come ricorderai dai capitoli precedenti, fare riferimento a una posizione di memoria (a differenza di fare riferimento al suo indirizzo) avviene racchiudendo la posizione dell'indirizzo tra parentesi quadre, in questo modo:
</p>

```asm
 mov rax,[rbp]
```

<p align="justify">
Qui, stiamo prendendo qualsiasi quantità a 64 bit che si trova all'indirizzo contenuto in RBP e caricandola nel registro RAX. Un indirizzamento della memoria più complesso può apparire così:
</p>

```asm
 mov rax,[rbx-8]         ; Base minus displacement
 mov ax, word [bx+di+28] ; Base plus index plus displacement
 mov al, byte [bx+di*4]  ; Base plus index times scale
```

<p align="justify">
la sintassi per l'indirizzamento della memoria è considerevolmente diversa. In vece delle parentesi quadre, le mnemoniche AT&T usano le parentesi tonde per racchiudere i componenti di un indirizzo di memoria:
</p>

```asm
 movb (%rbx),%al     # mov byte al,[rbx] in Intel syntax
```

<p align="justify">
Qui, stiamo spostando la quantità di byte in [rbx] in AL. (Non dimenticare che l'ordine degli operandi è invertito rispetto a come fa la sintassi Intel!) All'interno delle parentesi metti la base, l'indice e il fattore di scala, quando presente. (La base deve esserci sempre.) Lo spostamento, quando esiste, deve andare davanti e all'esterno delle parentesi:
</p>

```asm
 movl –8(%rbx),%rax       # mov dword rax,[rbx-8] (Intel)
 movb 28(%rbx,%rdi),%eax  # mov byte rax,[rbx+edi+28] (Intel)
```

<p align="justify">
Si noti che nella sintassi AT&T, non si esegue il calcolo all'interno delle parentesi. La base, l'indice e il fattore di scala sono separati da virgole, e i segni più e gli asterischi non sono consentiti. Lo schema per interpretare un riferimento di memoria AT&T è il seguente:
</p>

```asm
 ±disp(base,index,scale)
```

<p align="justify">
Il simbolo ± che uso nell'esempio schematico precedente indica che lo spostamento è firmato; cioè, può essere sia positivo che negativo per indicare se il valore dello spostamento viene aggiunto o sottratto al resto dell'indirizzo. Di solito, vedi il segno solo come esplicitamente negativo; senza il simbolo meno, il predefinito è che lo spostamento sia positivo. I valori di spostamento e scala sono facoltativi. Tuttavia, ciò che vedrai la maggior parte delle volte è un tipo molto semplice di riferimento alla memoria:
</p>

```asm
-16(%rbp)
```

<p align="justify">
Gli spostamenti varieranno, ovviamente, ma ciò che questo significa quasi sempre è che un'istruzione fa riferimento a un elemento dati da qualche parte nello stack. Il codice C alloca le sue variabili nello stack, in un frame dello stack, e poi fa riferimento a quelle variabili tramite offset letterali rispetto al valore in RBP. RBP funge da punto di partenza per l'indirizzo, e gli elementi nello stack possono essere referenziati in termini di offset (sia positivi che negativi) rispetto a RBP. Il riferimento precedente indicherebbe a un'istruzione macchina di lavorare con un elemento all'indirizzo in RBP meno 16 bytes.
</p>

### Generazione di numeri casuali

<p align="justify">
assemblaggio, facciamo qualcosa di seriamente casuale. (O modestamente pseudocasuale, perlomeno.) La libreria standard C ha un paio di funzioni che consentono ai programmi di generare numeri pseudocasuali. Il pseudo è significativo qui. Le ricerche suggeriscono che non esiste un modo provabile per generare un numero veramente casuale esclusivamente tramite software. In effetti, l'intero concetto di ciò che significa veramente casuale è inquietante e tiene molti matematici lontani dalle strade. Teoreticamente, avresti bisogno di ottenere attivatori da qualche fenomeno quantistico (la radioattività è quello più spesso menzionato) per raggiungere la vera casualità. Creature di questo tipo esistono. Ma mancando un generatore di numeri casuali attivato dalla radiazione, dovremo tornare al pseudo e imparare a viverci. Una definizione semplificata di pseudocasuale sarebbe qualcosa del genere: un generatore di numeri pseudocasuali produce una sequenza di numeri senza un modello riconoscibile, ma la sequenza può essere ripetuta passando lo stesso valore di seme al generatore. Un valore di seme è semplicemente un numero intero che funge da valore di input per un algoritmo arcano che crea la sequenza di numeri pseudocasuali. Passa lo stesso seme al generatore e ottieni la stessa sequenza. Tuttavia, all'interno della sequenza, la distribuzione dei numeri all'interno dell'intervallo del generatore è ragionevolmente dispersa e casuale. La libreria standard C contiene due funzioni relative ai numeri pseudocasuali:
</p>

<ul>
	<li>
		<p align="justify">
		La funzione srand() passa un nuovo valore di seme al generatore di numeri casuali. Questo valore deve essere un intero a 32 bit. Se non viene passato alcun valore di seme, il valore di seme predefinito è 1.
   		</p>
	</li>
 	<li>
		<p align="justify">
		La funzione rand() restituisce un numero pseudorandom di 31 bit. Il bit più alto è sempre 0 e quindi il valore è sempre positivo se trattato come un intero con segno di 32 bit.
   		</p>
	</li>
</ul>

<p align="justify">
Una volta che capisci come funzionano, usarli è quasi banale.
</p>

### Inizializzare il generatore con srand()

<p align="justify">
Inserire il valore del seme nel generatore è in realtà più complesso rispetto a effettuare la chiamata che estrae il prossimo numero pseudocasuale nella sequenza corrente. E non è che la chiamata a srand() sia così difficile: carichi il valore del seme in RDI e poi chiami srand(). È tutto quello che devi fare! La funzione srand() non restituisce un valore. Ma... cosa utilizzi come valore del seme? Ecco il problema. Se è importante che i tuoi programmi non funzionino con la stessa esatta sequenza di numeri pseudocasuali ogni volta che vengono eseguiti, chiaramente non vuoi usare un intero ordinario codificato nel programma. Idealmente, vorresti ottenere un valore del seme diverso ogni volta che esegui il programma. Il modo più semplice per farlo (anche se ce ne sono altri) è di utilizzare il conteggio dei secondi dal 1 gennaio 1970, come restituito dalla funzione time(), per alimentare le chiamate a srand(). Questo valore, chiamato time_t, è un intero firmato che cambia ogni secondo, quindi con ogni secondo che passa hai un nuovo valore del seme a tua disposizione, uno che per definizione non si ripeterà mai. (Sto assumendo qui che il problema del rollover di time_t di cui ho parlato nella sezione precedente sarà risolto entro l'anno 2038.) Quasi tutti fanno così, e l'unico avvertimento è che devi essere certo di non chiamare srand() per rinfrescare la sequenza più spesso di una volta al secondo. Nella maggior parte dei casi, per programmi che vengono eseguiti, fanno il loro lavoro e terminano in pochi minuti o ore, devi chiamare srand() solo una volta, quando il programma inizia l'esecuzione. Se stai scrivendo un programma che rimarrà in esecuzione per giorni o settimane o più a lungo senza terminare (come un server), potrebbe essere una buona idea ripristinare il generatore di numeri casuali una volta al giorno. Ecco un breve frammento di codice che chiama time() per recuperare il valore attuale di time_t e poi passa il valore del tempo a srand() in RDI:
</p>

```asm
 xor rdi,rdi  ; Make sure rdi is set to 0 before calling time()
 call time    ; Returns time_t value (32-bit integer) in rax
 mov rdi,rax  ; Pass the seed value to srand in rdi
 call srand   ; Time_t is the seed value for random # generator
```

<p align="justify">
Impostare RDI a 0 prima di chiamare time() informa la funzione time() che non stai passando una variabile per accettare il valore del tempo. Il valore time_t che desideri mantenere viene restituito in RAX.
</p>

### Generazione di numeri pseudocasuali

<p align="justify">
Una volta che hai seminato il generatore, ottenere numeri nella sequenza pseudocasuale è facile: estrai il numero successivo nella sequenza con ogni chiamata a rand(). E la funzione rand() è facile da usare come qualsiasi altra cosa nella libreria C: non prende parametri (quindi non devi passare nulla alla funzione) e il numero pseudocasuale viene restituito in RAX. Il programma randtest.asm (vedi sotto) dimostra come funzionano srand() e rand(). Mostra anche un paio di altri trucchi interessanti in assembly, e trascorrerò il resto di questa sezione a discuterne.
</p>

```asm
;  Executable name : randtest
;  Version         : 3.0
;  Created date    : 11/29/2022
;  Updated date    : 7/18/2023
;  Author          : Jeff Duntemann
;  Description     : A demo of Unix rand & srand using NASM 2.14.02
;
;  Build using these commands or the makefile:
;    nasm -f elf64 -g -F dwarf randtest.asm
;    gcc randtest.o -o randtest
;

section .data

Pulls      dq 36 ; How many numbers do we pull? (Must be a multiple of 6!)
Display    db 10,'Here is an array of %d %d-bit random numbners:',10,0
ShowArray  db '%10d %10d %10d %10d %10d %10d',10,0
NewLine    db 0		
CharTbl    db '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-@'

section .bss

[SECTION .bss]          ; Section containing uninitialized data

BUFSIZE  equ 70         ; # of randomly chosen chars
RandVal  resq 1         ; Reserve an integer variable
Stash    resq 72        ; Reserve an array of 72 integers for randoms
RandChar resb BUFSIZE+5 ; Buffer for storing randomly chosen characters

section .text

extern printf	
extern puts
extern rand
extern scanf	
extern srand
extern time	

;------------------------------------------------------------------------------
;  Random number generator procedures  --  Last update 5/13/2023
;
;  This routine provides 6 entry points, and returns 6 different "sizes" of
;  pseudorandom numbers based on the value returned by rand. Note first of 
;  all that rand pulls a 31-bit value. The high 16 bits are the most "random"
;  so to return numbers in a smaller range, you fetch a 31-bit value and then
;  right-shift it to zero-fill all but the number of bits you want. An 8-bit
;  random value will range from 0-255, a 7-bit value from 0-127, and so on.
;  Respects RBP, RSI, RDI, RBX, and RSP. Returns random value in RAX.
;------------------------------------------------------------------------------
pull31: mov rcx,0       ; For 31 bit random, we don't shift
	jmp pull
pull20: mov rcx,11      ; For 20 bit random, shift by 11 bits
    jmp pull
pull16: mov rcx,15      ; For 16 bit random, shift by 15 bits
	jmp pull
pull8:  mov rcx,23      ; For 8 bit random, shift by 23 bits
	jmp pull
pull7:  mov rcx,24      ; For 7 bit random, shift by 24 bits
	jmp pull
pull6:  mov rcx,25      ; For 6 bit random, shift by 25 bits
	jmp pull
pull4:  mov rcx,27      ; For 4 bit random, shift by 27 bits

pull:	
    push rcx            ; rand trashes rcx; save shift value on stack
    call rand           ; Call rand for random value; returned in RAX
    pop rcx             ; Pop stashed shift value back into RCX
    shr rax,cl          ; Shift the random value in RAX by the chosen factor
                        ;  keeping in mind that part we want is in CL
    ret                 ; Go home with random number in RAX

;; This subroutine pulls random values and stuffs them into an
;; integer array.  Not intended to be general purpose.  Note that
;; the address of the random number generator entry point must
;; be loaded into r13 before this is called, or you'll seg fault!

puller:
    mov r12,[Pulls]     ; Put pull count into R12
.grab:
    dec r12             ; Decrement counter in RSI
    call r13            ; Pull the value; it's returned in RAX
    mov [Stash+r12*8],rax   ; Store random value in the array
    cmp r12,0           ; See if we've pulled all STASH-ed numbers yet
    jne .grab           ; Do another if R12 <> 0 
    ret                 ; Otherwise, go home!

    ;; This subroutine displays numbers six at a time
    ;; Not intended to be general-purpose...
shownums:	
    mov r12,qword [Pulls]    ; Put pull count into r12
    xor r13,r13
.dorow:	
    mov rdi,ShowArray        ; Pass address of base string
    mov rsi,[Stash+r13*8+0]  ; Pass first element
    mov rdx,[Stash+r13*8+8]  ; Pass second element
    mov rcx,[Stash+r13*8+16] ; Pass third element
    mov r8,[Stash+r13*8+24]  ; Pass fourth element
    mov r9,[Stash+r13*8+32]  ; Pass fifth element
    push qword [Stash+r13*8+40] ; Pass sixth element on the stack.
    call printf              ; Display the random numbers
    add rsp,8                ; Stack cleanup: 1 item X 8 bytes = 8
	
    add r13,6       ; Point to the next group of six randoms in Stash 
    sub r12,6       ; Decrement pull counter
    cmp r12,0       ; See if pull count has gone to 0
    ja .dorow       ; If not, we go back and do another row!
    ret             ; Done, so go home!

; MAIN PROGRAM:
					
global main         ; Required so linker can find entry point
	
main:
    push rbp        ; Set up stack frame
	mov rbp,rsp
	
;;; Everything before this is boilerplate; 

; Begin by seeding the random number generator with a time_t value:	

Seedit:	
    xor rdi,rdi		; Mske sure rdi starts out with a 0
    call time	    ; Returns time_t value (64-bit integer) in rax
    mov rdi,rax	    ; Pass srand a time_t seed in rdi
    call srand	    ; Seed the random number generator

; All of the following code blocks are identical except for the size of
; the random value being generated:
	
; Create and display an array of 31-bit random values
    mov r13,pull31  ; Copy address of random # subroutine into RDI
    call puller     ; Pull as many numbers as called for in [Pulls]
	
    mov rdi,Display ; Display the base string
    mov rsi,[Pulls] ; Display the number of randoms displayed
    mov rdx,32      ; Display the size of the randoms displayed
    call printf     ; Display the label
    call shownums   ; Display the rows of random numbers

; Create and display an array of 20-bit random values
    mov r13,pull20  ; Copy address of random # subroutine into RDI
    call puller     ; Pull as many numbers as called for in [Pulls]
		
    mov rdi,Display ; Display the base string
    mov rsi,[Pulls] ; Display the number of randoms displayed
    mov rdx,20      ; Display the size of the randoms displayed
    call printf     ; Display the label
    call shownums   ; Display the rows of random numbers

; Create and display an array of 16-bit random values
    mov r13,pull16  ; Copy address of random # subroutine into RDI
    call puller     ; Pull as many numbers as called for in [Pulls]
	
    mov rdi,Display ; Display the base string
    mov rsi,[Pulls] ; Display the number of randoms displayed
    mov rdx,16      ; Display the size of the randoms displayed
    call printf     ; Display the label
    call shownums   ; Display the rows of random numbers

; Create and display an array of 8-bit random values
    mov r13,pull8   ; Copy address of random # subroutine into RDI
    call puller     ; Pull as many numbers as called for in [Pulls]
    	
    mov rdi,Display ; Display the base string
    mov rsi,[Pulls] ; Display the number of randoms displayed
    mov rdx,8       ; Display the size of the randoms displayed
    call printf     ; Display the label
    call shownums   ; Display the rows of random numbers

; Create and display an array of 7-bit random values
    mov r13,pull7   ; Copy address of random # subroutine into RDI
    call puller     ; Pull as many numbers as called for in [Pulls]
	
    mov rdi,Display ; Display the base string
    mov rsi,[Pulls] ; Display the number of randoms displayed
    mov rdx,7       ; Display the size of the randoms displayed
    call printf     ; Display the label
    call shownums   ; Display the rows of random numbers

; Create and display an array of 6-bit random values
    mov r13,pull6   ; Copy address of random # subroutine into RDI
    call puller     ; Pull as many numbers as called for in [Pulls]
	
    mov rdi,Display ; Display the base string
    mov rsi,[Pulls] ; Display the number of randoms displayed
    mov rdx,6       ; Display the size of the randoms displayed
    call printf     ; Display the label
    call shownums   ; Display the rows of random numbers

; Create and display an array of 4-bit random values
    mov r13,pull4   ; Copy address of random # subroutine into RDI
    call puller     ; Pull as many numbers as called for in [Pulls]
	
    mov rdi,Display ; Display the base string
    mov rsi,[Pulls] ; Display the number of randoms displayed
    mov rdx,4       ; Display the size of the randoms displayed
    call printf     ; Display the label
    call shownums   ; Display the rows of random numbers

; Clear a buffer to nulls:
Bufclr:	
    mov rcx, BUFSIZE+5  ; Fill whole buffer plus 5 for safety
.loop:	
    dec rcx             ; BUFSIZE is 1-based so decrement first!
    mov byte [RandChar+rcx],0     ; Mov null into the buffer
    cmp rcx,0           ; Are we done yet?
    jnz .loop           ; If not, go back and stuff another null

; Create a string of random alphanumeric characters:
Pulchr:	
    mov rbx, BUFSIZE    ; BUFSIZE tells us how many chars to pull
.loop:	
    dec rbx             ; BUFSIZE is 1-based, so decrement first!
    mov r13,pull6       ; For random in the range 0-63
    call r13
    mov cl,[CharTbl+rax]  ; Use random # in rax as offset into table
                          ;  and copy character from table into CL
    mov [RandChar+rbx],cl ; Copy char from CL to character buffer
    cmp rbx,0           ; Are we done having fun yet?
    jne .loop           ; If not, go back and pull another

; Display the string of random characters:
    mov rdi,NewLine     ; Output a newline
    call puts           ;  using the newline procedure
    mov rdi,RandChar    ; Push the address of the char buffer 
    call puts           ; Call puts to display it
    mov rdi,NewLine     ; Output a newline
    call puts

;;; Everything after this is boilerplate; use it for all ordinary apps!

    mov rsp,rbp         ; Destroy stack frame before returning
    pop rbp

    ret                 ; Return to glibc shutdown code
```

### Alcuni bit sono più casuali di altri

<p align="justify">
Sotto Linux x64, la funzione rand() restituisce un valore senza segno a 31 bit in RAX come un intero a 64 bit. (Il bit di segno dell'intero - il più alto di tutti i 64 bit - è sempre azzerato a 0.) La documentazione Unix per rand() e srand() indica che i bit a bassa ordine di un valore generato da rand() sono meno casuali rispetto ai bit ad alta ordine. Questo significa che se stai per usare solo alcuni dei bit del valore generato da rand(), dovresti usare i bit ad alta ordine che puoi. Onestamente, non so perché dovrebbe essere così, né quanto sia grave il problema. Non sono un esperto di matematica profonda e accetterò la parola delle persone che hanno scritto la documentazione di rand(). Ma questo riguarda la questione di come limitare l'intervallo dei numeri casuali che generi. La questione è piuttosto ovvia: supponi di voler estrarre un certo numero di caratteri alfanumerici ASCII casuali. Non hai bisogno di numeri che vanno da 0 a 2 miliardi. Ci sono solo 127 caratteri ASCII e in effetti solo 62 sono lettere e numeri. (Gli altri sono segni di punteggiatura, spazi bianchi, caratteri di controllo o caratteri non stampabili come le faccine.) Quello che vuoi fare è estrarre numeri casuali tra 0 e 61. Estrarre numeri che vanno da 0 a 2 miliardi finché non ne trovi uno inferiore a 62 richiederà molto tempo. Chiaramente, hai bisogno di un approccio diverso. Quello che ho preso tratta il valore a 31 bit restituito da rand() come una collezione di bit casuali. Estraggo un sottoinsieme di quei bit appena grande abbastanza da soddisfare le mie esigenze. Sei bit possono esprimere valori da 0 a 63, quindi prendo i 6 bit ad alta ordine dal valore originale a 31 bit e li uso per specificare caratteri casuali. È facile: semplicemente sposto il valore a 31 bit verso destra finché tutti i bit tranne i 6 bit ad alta ordine non sono stati spostati via dal lato destro del valore nell'oblio. Lo stesso trucco funziona con qualsiasi numero (ragionevole) di bit. Tutto ciò che devi fare è selezionare di quanti bit spostare.
</p>

```
pull31: mov rcx,0   ; For 31 bit random, we don't shift
    jmp pull
 pull20: mov rcx,11  ; For 20 bit random, shift by 11 bits
    jmp pull
 pull16: mov rcx,15  ; For 16 bit random, shift by 15 bits
    jmp pull
 pull8:  mov rcx,23  ; For 8 bit random, shift by 23 bits
    jmp pull
 pull7:  mov rcx,24  ; For 7 bit random, shift by 24 bits
    jmp pull
 pull6:  mov rcx,25  ; For 6 bit random, shift by 25 bits
    jmp pull
 pull4:  mov rcx,27  ; For 4 bit random, shift by 27 bits
 
pull:
    push rbp            ; Prolog: Create stack frame
    mov rbp,rsp
 
    mov r15,rcx         ; rand trashes rcx; save shift value in R15         
    call rand           ; Call rand for random value;
 returned in RAX
    mov rcx,r15         ; Restore shift value back into RCX
    shr rax,cl          ; Shift the value in RAX by the chosen factor
                        ; keeping in mind that part we want is in CL
    pop rbp             ; Epilog: Destroy stack frame
    ret                 ; Go home with random number in RAX
```

<p align="justify">
Per estrarre un numero casuale a 16 bit, chiama pull16. Per estrarre un numero casuale a 8 bit, chiama pull8, e così via. Ho scoperto che i numeri più piccoli non sono così casuali come quelli più grandi, e i numeri restituiti da pull4 probabilmente non sono abbastanza casuali da essere utili. (Ho lasciato il codice di pull4 così puoi vedere da solo eseguendo randtest.) La logica qui dovrebbe essere facile da seguire: selezioni un valore di spostamento, lo metti in RCX, copi RCX in R15, chiami rand(), copi RCX di nuovo da R15, e poi sposti il numero casuale (che rand() restituisce in RAX) per il valore in CL—che, ovviamente, è i 8 bit più bassi di RCX. Perché RCX deve essere salvato in R15? RCX non è uno dei registri preservati dal chiamato nelle convenzioni di chiamata C, e praticamente tutte le routine della libreria C usano RCX internamente e quindi ne danneggiano il valore. Se vuoi mantenere un valore in RCX attraverso una chiamata a una funzione di libreria, devi salvare il tuo valore da qualche parte prima della chiamata e ripristinarlo dopo che la chiamata è completata. C'era un solo posto per salvare un registro: lo stack. Ora, con i nuovi registri a uso generale di x64, potresti essere in grado di svolgere tutto il tuo lavoro con registri che le routine di glibc non danneggiano e quindi non devono essere salvate nello stack. Uso la routine pull6 per estrarre numeri casuali a 6 bit per selezionare caratteri da una tabella di caratteri, creando così una stringa di caratteri alfanumerici casuali. Riempio la tabella a 64 elementi con due caratteri aggiuntivi (- e @) in modo da non dover testare ogni numero estratto per vedere se è minore di 62. Se devi limitare i valori casuali a un intervallo che non è una potenza di 2, scegli la potenza di 2 più grande successiva—ma cerca di progettare il tuo programma in modo da non dover scegliere valori casuali in un intervallo come 0 a 65. Molto è stato scritto sui numeri casuali nei libri di algoritmi, quindi se il concetto ti affascina, ti indirizzo lì per ulteriori studi.
</p>

### Chiamate a indirizzi nei registri

<p align="justify">
Utilizzo una tecnica in randtest che a volte viene dimenticata dai principianti dell'assemblaggio: puoi eseguire un'istruzione CALL a un indirizzo di procedura memorizzato in un registro. Non è sempre necessario utilizzare CALL con un'etichetta immediata. In altre parole, le seguenti due istruzioni CALL sono entrambe completamente legali ed equivalenti:
</p>

```asm
  mov r13,pull8  ; Copy the address represented by label pull8 into r13
  call pull8     ; Call the address represented by pull8
  call r13        ; Call the address stored in r13
```

<p align="justify">
Perché fare questo? Troverai le tue ragioni col passare del tempo, ma in generale ti permette di trattare le chiamate di procedura come parametri. In randtest, ho estratto molto codice in una procedura chiamata puller e poi ho chiamato puller diverse volte per diverse dimensioni di numeri casuali. Ho passato a puller l'indirizzo della corretta procedura per il numero casuale da chiamare caricando l'indirizzo di quella procedura in RDI:
</p>

```asm
 ; Create and display an array of 8-bit random values:
 mov r13,pull8 ; Copy address of random # subroutine into r13
 call puller   ; Pull as many numbers as called for in [pulls]
```
<p align="justify">
Nella procedura di estrazione, il codice chiama la procedura di numero casuale richiesta in questo modo:
</p>

```asm
 puller:
 	mov r12,[Pulls]      ; Put pull count into R12

.grab:
 	dec r12              ; Decrement counter in RSI

	call r13             ; Pull the value; it's returned in RAX
	mov [Stash+r12*8],rax   ; Store random value in the array

	cmp r12,0            ; See if we've pulled all STASH-ed numbers yet
	jne .grab            ; Do another if R12 <> 0
	ret                  ; Otherwise, go home!

```

<p align="justify">
Vedi l'istruzione CALL R13? In questa situazione (dove R13 era precedentemente caricato con l'indirizzo della procedura pull8), ciò che viene chiamato è pull8—anche se l'etichetta pull8 non è presente nella procedura puller. Lo stesso codice in puller può essere usato per riempire un buffer con tutte le diverse dimensioni di numeri casuali, chiamando l'indirizzo della procedura passato a esso in R13. Chiamare un indirizzo in un registro ti dà molta potenza per generalizzare il codice—assicurati solo di documentare ciò che stai facendo, poiché l'etichetta che stai chiamando non è contenuta nell'istruzione CALL.
</p>

### Usare puts() per inviare una linea vuota alla console

<p align="justify">
Il programma randtest dimostra anche qualcosa di semplice ma non ovvio: come inviare una newline "nuda" alla console di Linux. Ho spiegato prima che la funzione puts() di libc termina sempre quello che visualizza con una newline, anche se preferiresti che non ne visualizzasse affatto. Per visualizzare le cose sulla console senza una newline, devi usare printf(). Quindi cosa fare se vuoi inviare un linefeed alla console, ma nient'altro? Facile: definisci una variabile (la chiamo NewLine) come un singolo byte e metti un 0 al suo interno. Poi copia l'indirizzo della variabile NewLine in RDI e poi chiama puts():
</p>

```asm
  mov rdi,NewLine  ; Output a newline
  call puts
```

<p align="justify">
Ricorda che puts() visualizza tutto a partire dall'indirizzo passato ad esso in RDI fino al primo null (cioè, uno 0) che incontra. Se l'unica cosa a quell'indirizzo è un null, puts() invierà una nuova riga alla console e nient'altro.
</p>

### Come passare più di sei parametri a una funzione libc

<p align="justify">
Se ti ricordi, nella convenzione di chiamata x64, i primi sei parametri passati a una funzione vengono passati in RDI, RSI, RDX, RCX, R8 e R9. Quindi, cosa succede se vuoi passare a printf() sette parametri o più? Qualsiasi cosa oltre sei parametri deve andare nello stack. Ho progettato appositamente randtest per passare sette parametri a printf(). L'azione avviene nella procedura chiamata shownums:
</p>

```asm
    mov r12,qword [Pulls]    ; Put pull count into r12
    xor r13,r13
 .dorow:
    mov rdi,ShowArray        ; Pass address of base string
    mov rsi,[Stash+r13*8+0]  ; Pass first element
    mov rdx,[Stash+r13*8+8]  ; Pass second element
    mov rcx,[Stash+r13*8+16] ; Pass third element
    mov r8,[Stash+r13*8+24]  ; Pass fourth element
    mov r9,[Stash+r13*8+32]  ; Pass fifth element
    push rax                 ; To keep the stack 16 bytes
 aligned
    push qword [Stash+r13*8+40] ; Pass sixth element on the
 stack.
    xor rax,rax         ; Tell printf() no vector values
 coming
    call printf         ; Display the random numbers
    add rsp,16          ; Stack cleanup: 2 item X 8 bytes = 16
 
```

<p align="justify">
All'etichetta dorow: c'è una sequenza di sei istruzioni MOV, tutte le quali passano parametri da utilizzare con printf(). L'indirizzo della stringa base va prima (in RDI) seguito dai sei numeri casuali che costituiscono una riga. Una volta arrivati al sesto numero, non abbiamo più registri per passare ulteriori valori. Quindi, l'ultimo valore del parametro viene spinto nello stack, immediatamente prima di chiamare printf(). Beh, quasi immediatamente. In precedenza in questo capitolo ho trattato questo stesso codice da una direzione diversa: l'allineamento dello stack. Anche se il codice di avvio glibc allinea lo stack a un valore di 16 byte, spingere solo un elemento nello stack aggiunge solo 8 byte al puntatore dello stack, e quindi disallinea lo stack. Per risolvere questo problema, spingi RAX nello stack proprio prima di spingere quel settimo parametro nello stack. RAX aggiunge altri 8 byte allo stack, riportandolo a un allineamento di 16 byte. (Ciò che è effettivamente in RAX non importa. Sono solo 8 byte di riempimento.) Se ci fossero otto parametri, l'ottavo sarebbe spinto nello stack immediatamente dopo il settimo senza necessità di alcuna istruzione PUSH RAX. Ecco perché: L'essenza dell'allineamento dello stack è far crescere o ridurre lo stack solo in blocchi di 16 byte, anche se metà di uno di quei blocchi è un registro “fittizio”. Spingere due valori di parametro nello stack fa crescere lo stack di 16 byte, quindi non è necessario alcun valore fittizio. Infatti, se dimentichi e aggiungi comunque un PUSH RAX, disallineerai lo stack! La funzione printf() sa dove guardare e troverà e utilizzerà tutti i parametri passati ad essa. Tuttavia, printf() non pulisce dopo se stessa. Se spingi valori nello stack per una chiamata a printf(), una volta che printf() ha finito di usarli, devi pulire lo stack. Questo non viene fatto con un pop (almeno non in questo caso particolare) ma aggiungendo la dimensione dell'elemento che hai spinto nello stack a RSP. Ricorda che lo stack cresce “in giù” (verso indirizzi più bassi). Se spingiamo qualcosa, RSP diventa più piccolo della dimensione del valore spinto, in questo caso, un intero a 64 bit. Per pulire lo stack, aggiungiamo la dimensione di ciò che abbiamo spinto di nuovo in RSP. In questo caso, abbiamo spinto un registro di 8 byte più un intero di 8 byte per un totale di 16 byte di dimensione, quindi aggiungiamo 16 a RSP. Voilà! Lo stack è ora pulito, almeno dalla chiamata a printf(). Tieni traccia del tuo stack: per pop ciò che spingi, oppure aggiungi la dimensione di un elemento spinto di nuovo in RSP. Fai attenzione: se mescoli lo stack, un errore di segmentazione è quasi inevitabile.
</p>

### Come C vede gli argomenti della riga di comando

<p align="justify">
Ho spiegato come accedere agli argomenti della riga di comando da un programma Linux come parte di una discussione più generale sui frame dello stack. Una delle cose più strane riguardo il collegamento e la chiamata alle funzioni della libreria standard C in glibc è che il modo di accedere agli argomenti della riga di comando cambia e cambia in modo significativo. Gli argomenti sono ancora sullo stack, così come la tabella degli indirizzi degli argomenti. Tuttavia, non è più necessario frugare su e giù nello stack per trovarli. La chiave è questa: main() è una funzione. È solo una parte di un programma C. Ci sono anche il codice di avvio e il codice di spegnimento. Una volta che il codice di avvio ha completato il suo lavoro, chiama main() proprio come chiamerebbe qualsiasi altra funzione. Quando main() è finita, restituisce il controllo al codice di spegnimento, che svolge il suo lavoro e poi restituisce il controllo a Linux. Ciò che rende più facile il processo di trovare gli argomenti della riga di comando è che il codice di avvio segue le convenzioni di chiamata x64 quando chiama main(). I primi sei parametri vengono passati a una funzione nei registri. Il primo registro a ricevere un parametro è RDI. Quando il codice di avvio chiama main(), pone il conteggio degli argomenti (argc nel gergo C) in RDI. L'unico altro parametro normalmente passato a main() è l'indirizzo della tabella dei puntatori nello stack, nel gergo C argv. Ogni indirizzo nella tabella argv punta al suo testo di argomento effettivo. Il puntatore alla tabella dei puntatori viene passato nel secondo registro della convenzione di chiamata, RSI. Il codice si sotto è funzionalmente equivalente al programma showargs2 presentato precedentemente. Tuttavia, è significativamente più semplice. Diamo un'occhiata e lo esamineremo insieme.
</p>

```asm
;  Executable name : showargs3
;  Version         : 3.0
;  Created date    : 10/1/1999
;  Last update     : 7/18/2023
;  Author          : Jeff Duntemann
;  Description     : A demo that shows how to access command line arguments
;                    stored on the stack by addressing them relative to rbp.
;
;  Build using these commands:
;    nasm -f elf64 -g -F dwarf showargs3.asm
;    gcc showargs3.o -o showargs3
;

[SECTION .data]    ; Section containing initialised data
		
ArgMsg db "Argument %d: %s",10,0

[SECTION .bss]     ; Section containing uninitialized data
	
[SECTION .text]    ; Section containing code
				
global main        ; Required so linker can find entry point
extern printf      ; Notify linker that we're calling printf

main:
    push rbp       ; Set up stack frame for debugger
    mov rbp,rsp

;;; Everything before this is boilerplate; use it for all ordinary apps!

    mov r14,rdi    ; Get arc count (argc) from RDI
    mov r13,rsi    ; Put the pointer to the arg table argv from RSI
    xor r12,r12    ; Clear r12 to 0

.showit:

    mov rdi,ArgMsg ; Pass address of display string in rdi
    mov rsi,r12    ; Pass argument number in rsi
    mov rdx,qword [r13+r12*8]   ; Pass address of an argument in RDX
    call printf    ; Display the argument # and argument

    inc r12        ; Bump argument # to next argument
    dec r14        ; Decrement argument counter by 1
    jnz .showit    ; If argument count is 0, we're done

;;; Everything after this is boilerplate; use it for all ordinary apps!

    mov rsp,rbp    ; Destroy stack frame before returning
    pop rbp

	ret            ; Return to glibc shutdown code
```

<p align="justify">
Dopo il prologo, il valore del conteggio argc è copiato in R14. L'indirizzo della tabella argv è copiato in R13. R12 è azzerato a 0. Ad ogni passaggio attraverso il ciclo .showit, i valori vengono passati alla funzione printf(), tutto secondo la convenzione di chiamata x64. L'indirizzo della stringa di visualizzazione è passato in RDI e il numero dell'argomento è passato in RSI, numerato da 0. L'indirizzo del testo di ogni argomento è passato in RDX, utilizzando un indirizzo effettivo calcolato in questo modo:
</p>

```asm
 mov rdx,qword  [r13+r12*8]
```

<p align="justify">
Il termine base è R13, che è l'indirizzo dell'inizio della tabella. Ogni indirizzo nella tabella occupa 8 byte, quindi si tratta la posizione ordinaria delle voci della tabella (cioè l'elemento 0, 1, 2, 3, ecc.) come l'indice e lo si moltiplica per il fattore di scala, 8 poiché gli indirizzi in x64 sono tutti di 8 byte. Quando il calcolo è completato, l'indirizzo effettivo dell'elemento scelto nella tabella viene copiato in RDX. RDX quindi porta l'indirizzo dell'elemento argv da visualizzare in printf(). (Si noti che non c'è termine di spostamento in questo particolare calcolo dell'indirizzo effettivo.) Durante il ciclo .showit, R14 conta all'indietro il numero di argomenti, mentre R12 assegna a ciascun argomento il proprio numero ordinario. In altre parole, R14 conta quanti argomenti abbiamo ancora da visualizzare e per ogni argomento R12 gli assegna un numero ordinario che aumenta, da visualizzare con printf(). Tutto ciò dovrebbe essere chiaro dalla figura di sotto
</p>

<div aling=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/accessing_command_line_arguments_from_main.png">
</div>

### Semplici operazioni di I/O sui file

<p align="justify">
L'ultimo programma di esempio che presento qui è nominalmente dedicato al lavoro con file di testo su disco. Tuttavia, raccoglie molti trucchi e funzionalità di assembly che ho spiegato in precedenza e ne aggiunge alcuni altri. È il programma più grande e complesso che ti ho mostrato, e se riesci a leggerlo e seguire il flusso della logica, hai appreso tutto ciò che mi ero ripromesso di insegnarti in questo libro. È più simile a un programma 'reale' rispetto a qualsiasi altra cosa in questo libro, in quanto lavora con argomenti da riga di comando, scrive l'output in un file su disco e fa altre cose utili che qualsiasi utility che intendi costruire richiederà probabilmente. Il programma textfile.asm (vedi sotto) crea e riempie un file di testo con del testo. Puoi specificare il numero di righe da riempire nel file, così come il testo per le righe. Se non specifichi il testo per il file, il programma genererà una riga di caratteri scelti casualmente e userà quella al suo posto. L'invocazione del programma avviene in questo modo: 
</p>

```
$./textfile 50 Tempo per i tacos!
```

<p align="justify">
Questa invocazione crea un nuovo file (il cui nome è fissato nel programma come testeroo.txt) e scrive il testo "Tempo per i tacos!" nel file 50 volte prima di chiudere il file. Se il file testeroo.txt esiste già, verrà sovrascritto dall'inizio. Se non digiti nulla dopo il numero di righe, il programma riempirà il file con caratteri alfanumerici casuali. Se non digiti un intero come primo argomento (ad esempio, la lettera Q), textfile visualizzerà un messaggio di errore su una riga. Se digiti solo il nome del programma e premi Invio, textfile visualizzerà diverse righe che spiegano cos'è e come usarlo.
</p>

### Convertire le stringhe in numeri con sscanf()

<p align="justify">
Quando digiti un numero nella riga di comando mentre invochi un programma, puoi accedere a quel numero come uno degli argomenti della riga di comando, attraverso i meccanismi che ho descritto poco prima in questo capitolo. Tuttavia, c'è un problema: il numero è presente come testo, e non puoi semplicemente prendere la stringa testuale “751” e caricarla in un registro o in una variabile intera. Per utilizzare gli argomenti numerici come numeri, devi prima convertire la loro espressione testuale in forma numerica. La libreria standard C ha diverse funzioni per affrontare questa sfida. Alcune di esse, come strtod(), sono abbastanza specifiche e limitate e convertono il testo solo in un tipo numerico. Tuttavia, una di esse ha la capacità di convertire quasi qualsiasi espressione testuale di un valore numerico legale in una forma numerica appropriata. Questa è sscanf(), e sarà quella che useremo nel programma di sotto
</p>

<p align="justify">
La funzione sscanf() accetta tre parametri, che è necessario caricare nei registri dei parametri standard, nel seguente ordine:
</p>

1. Il primo parametro è l'indirizzo della stringa di testo da convertire nel valore numerico che rappresenta. In textfile.asm, carichiamo RDI con l'indirizzo di arg(1), che è il primo argomento della riga di comando che digiti quando invochi il programma.
2. Successivamente carichiamo RSI con l'indirizzo di una stringa di codice di formattazione che indica a sscanf() quale formato numerico desideri che il testo di input venga convertito. Qui la stringa di codice è %d, che, come potresti ricordare dalla nostra discussione su printf(), è il codice per gli interi.
3. Il terzo parametro è l'indirizzo di una variabile numerica che conterrà il valore numerico generato da sscanf(). Questo va in RDX. Qui stiamo generando un intero a 64 bit. Quindi, in textfile.asm, passiamo l'indirizzo della variabile IntBuffer, che è dichiarata come intero a 64 bit.
4. Come con printf() e scanf(), azzera RAX a 0 immediatamente prima di effettuare la chiamata a sscanf().

<p align="justify">
Una volta che questi tre elementi sono stati caricati nei registri appropriati e RAX è stato azzerato, chiama sscanf(). Restituisce il valore convertito nella variabile numerica il cui indirizzo hai passato come terzo parametro. Restituisce anche un codice in RAX per indicare se la conversione è stata riuscita. Se il valore restituito in RAX è 0, allora si è verificato un errore e non dovresti presumere di avere qualcosa di significativo nella tua variabile numerica. Se la conversione è andata a buon fine, vedrai il valore 1 in RAX. Questo è il modo più semplice per utilizzare sscanf(). Può convertire interi array di numeri contemporaneamente, ma questo è un uso più specializzato di cui probabilmente non hai bisogno quando stai appena iniziando. Fare queste cose specializzate richiede spesso registri vettoriali, che non sto trattando in questo libro. Tuttavia, è importante azzerare RAX a 0 prima di chiamare sscanf() nel programma di esempio per dire alla funzione che non verranno utilizzati registri vettoriali. La stringa passata a sscanf() come secondo parametro può contenere più codici di formattazione e in tal caso la stringa il cui indirizzo passi come primo parametro dovrebbe avere del testo che descrive i valori numerici per ciascun codice di formattazione presente nella stringa di formato. Nel codice di sotto, il testo di formato specifica solo un valore, utilizzando il codice di formato %d. L'intero processo appare così:
</p>

```ams
 xor rax,rax         ; Clear rax to 0
 mov rdi,qword [r13+8] ; Pass address of an argument in rdi
 mov rsi,IntFormat   ; Pass address of integer format code in rsi
 mov rdx,IntBuffer   ; Pass address of integer buffer for sscanf output
 mov rax,0           ; Tell sscanf() that there are no vector arguments
 call sscanf         ; Convert string arg to number with sscanf()    
 cmp rax,1           ; Return value of 1 says we got a number
 je chkdata          ; If we got a number, go on; else abort

 mov rdi,Err1        ; Pass address of error 1-line message in rdi
 mov rax,0           ; Tell printf() that there are no vector arguments
 call printf         ; Show the error message
 jmp gohome          ; Exit the program
```

<p align="justify">
Assumendo che l'utente abbia inserito almeno un argomento nella riga di comando (e il programma abbia già verificato questo prima dell'estratto sopra), un puntatore a quell'argomento iniziale si trova a un offset di 8 dall'inizio della tabella dei puntatori degli argomenti della riga di comando. (Il primo elemento della tabella, che chiamiamo arg(0), punta al nome del programma così come l'utente l'ha digitato nella riga di comando.) Ecco perché carichiamo il contenuto dell'argomento a [R13+8] nello stack; avevamo già caricato R13 con l'indirizzo della tabella dei puntatori degli argomenti. Quello che si trova a [R13+8] è il puntatore a arg(1), il primo vero argomento della riga di comando. (Il primo argomento, arg(0), è il testo con cui hai invocato il programma.) Vedi la figura precedente se questo è ancora poco chiaro.
</p>

### Creare ed Aprire i File

<p align="justify">
A questo punto dovresti essere abbastanza a tuo agio con il meccanismo generale per effettuare chiamate alle librerie C dall'assembly. E che tu te ne renda conto o meno, sei già abbastanza a tuo agio con alcuni dei meccanismi per manipolare i file di testo. Hai già usato printf() per visualizzare testo formattato sullo schermo tramite l'output standard. Lo stesso meccanismo viene utilizzato per scrivere testo formattato nei file di testo su disco: stai praticamente sostituendo un file su disco reale con l'output standard. Quindi, capire l'I/O dei file di testo non dovrebbe essere un grande salto concettuale. Ma, a differenza dell'output standard, che è predefinito per te dalla libreria C ed è sempre disponibile, devi creare o aprire un file di testo su disco per usarlo. La funzione fopen() è quella che svolge il lavoro. Ci sono tre modi generali per aprire un file: per leggere, per scrivere e per aggiungere. Quando apri un file per la lettura, puoi leggere il testo da esso tramite funzioni come fgets(), ma non puoi scrivere nel file. Quando apri un file per scrivere, qualsiasi cosa ci fosse nel file prima viene scartata e nuovo materiale viene scritto all'inizio del file. Quando apri un file per aggiungere, puoi scrivere nel file, ma nuovo materiale viene scritto dopo qualsiasi materiale esistente e qualsiasi cosa fosse originariamente nel file viene mantenuta.
</p>

<p align="justify">
Di solito, quando apri un file per la scrittura non puoi leggerci, ma ci sono modalità speciali che consentono sia la lettura che la scrittura su un file. Per i file di testo in particolare (di cui stiamo parlando qui) questo introduce alcune complicazioni, quindi per la maggior parte, i file di testo vengono aperti o per la lettura o per la scrittura, ma non per entrambi contemporaneamente. Nel sistema di file Unix, se apri un file per la scrittura o per l'aggiunta e il file non esiste già, il file viene creato. Se non sai se un file esiste e devi scoprirlo, prova ad aprirlo per la lettura e non per la scrittura, altrimenti otterrai un file che sia realmente esistito prima o meno! Per usare fopen(), devi impostare i seguenti parametri nei registri prima della chiamata:
</p>

1. Inserire l'indirizzo della stringa di caratteri contenente il nome del file da aprire in RDI.
2. Inserire l'indirizzo di un codice che indica in quale modalità il file deve essere aperto in RSI. Le varie modalità disponibili per Linux sono elencate nella figura di sotto. Quelli che userai tipicamente per i file di testo sono r, w e a. Questi dovrebbero essere definiti come brevi stringhe di caratteri, seguite da un null:

```asm
 WriteCode  db 'w',0
 OpenCode   db 'r',0
```

<p align="justify">
Con questi due elementi nei registri, fai la chiamata a fopen(). Se il file è stato aperto con successo, fopen() restituirà un handle del file in RAX. Un handle del file è un numero a 64 bit assegnato da Linux a un file durante la chiamata a fopen(). Se l'apertura non ha avuto successo, RAX conterrà il valore 0 invece di un handle del file. Ecco come appare l'apertura di un file per la lettura nel codice:
</p>

```
mov rdi,Filename     ; Pass filename to fopen in RDI
mov rsi,ReadCode     ; Pass pointer to write/create code ('r') in rsi
call fopen           ; Open file for reading
cmp rax,0            ; Test for successful file open: failed if 0
je OpenErr           ; Jump to error handling code if open failed
<use opened file>
```

<p align="justify">
Il processo di creazione di un file e poi di scrittura su di esso è identico, tranne per il fatto che devi usare il codice w invece del codice r. Vedremo come funziona questo nel programma textfile.asm.
</p>

<div aling=center>
<img src="https://github.com/TheBitPoets/2cornot2c/blob/main/images/fopen_file_access_mode.png">
</div>

### Leggere testo dai file con fgets()

<p align="justify">
Quando fopen() crea o apre con successo un file per te, restituisce un handle del file in RAX. Tieni al sicuro quell'handle del file da qualche parte: ti consiglio di copiarlo in una variabile di memoria allocata per questo scopo o di metterlo in un registro che sai non verrà utilizzato per nient'altro. Questo è importante: se lo memorizzi in RAX, RCX o RDX e poi chiami quasi qualsiasi funzione della libreria C, l'handle del file nel registro verrà danneggiato e lo perderai. Una volta che un file è aperto per la lettura, puoi leggere le righe di testo da esso sequenzialmente con la funzione fgets(). Ogni volta che chiami fgets() su un file di testo aperto, leggerà una riga del file, che è definita come tutti i caratteri fino al prossimo carattere EOL (“newline”) (ASCII 10), che nel mondo Unix indica sempre la fine di una riga di testo. Ora, in un dato file non c'è modo di sapere quanti caratteri ci saranno fino al prossimo newline, quindi sarebbe pericoloso lasciare semplicemente fgets() libero di riportare i caratteri fino a quando non incontra un newline. Se tenti di aprire il tipo sbagliato di file (un file di codice binario è una possibilità, o un file di dati compressi), potresti portare dentro migliaia di byte prima di imbattersi nel valore binario 10 che il file system considera un newline. Qualunque buffer tu abbia allocato per contenere il testo in arrivo traboccherà e fgets() potrebbe forse distruggere dati adiacenti e/o far crashare il tuo programma.
</p>

<p align="justify">
Per questo motivo, devi anche passare un valore limite a fgets(). Quando fgets() inizia a leggere una riga, tiene traccia di quanti caratteri ha estratto dal file e quando arriva a uno meno del valore limite, smette di leggere i caratteri. Aggiunge quindi un carattere EOL al buffer per l'ultimo carattere e restituisce. Configura le chiamate a fgets() in questo modo:
</p>

1. Prima, carica RDI con l'indirizzo del buffer di caratteri in cui fgets() memorizzerà i caratteri letti dal file.
2. Successivamente, carica RSI con il valore limite del conteggio dei caratteri. Questo deve essere il valore intero effettivo, e non un puntatore al valore!
3. Infine, carica RDX con il gestore del file restituito da fopen() quando il file è stato aperto.

<p align="justify">
Con tutto ciò fatto, chiama fgets(). Se fgets() restituisce 0 in RAX, significa che hai raggiunto la fine del file oppure si è verificato un errore di lettura durante il caricamento. In entrambi i casi, non ci sono ulteriori dati provenienti dal file. Ma senza un 0 restituito in RAX, puoi presumere che ci sia testo valido presente nel buffer all'indirizzo che hai passato a fgets() in RDI. Ho usato fgets() per creare un sistema di aiuto molto semplice basato su disco per textfile.asm. Quando l'utente non inserisce affatto argomenti da riga di comando, il programma textfile legge un breve file di testo dal disco e lo visualizza in uscita standard. Se il file di aiuto basato su disco non può essere aperto, textfile visualizza un breve messaggio a tal riguardo. Questo è un modo comune e cortese di fare con i programmi da riga di comando, e consiglio che tutte le utility che costruisci per l'uso quotidiano funzionino in questo modo. Il codice per il sistema di aiuto è relativamente semplice e dimostra sia fopen() che fgets():
</p>

```asm
 diskhelp:
    mov rdi,DiskHelpNm ; Pointer to name of help file is passed in rdi
    mov rsi,OpenCode   ; Pointer to open-for-read code "r" gpes in rsi
    call fopen         ; Attempt to open the file for reading
    cmp rax,0          ; fopen returns null if attempted open failed
    jne .disk          ; Read help info from disk, else from memory
    call memhelp
    ret
 
.disk:
    mov rbx,rax        ; Save handle of opened file in ebx
 .rdln:
    mov rdi,HelpLine   ; Pass pointer to buffer in rdi
    mov rsi,HELPLEN    ; Pass buffer size in rsi
    mov rdx,rbx        ; Pass file handle to fgets in rdx
    call fgets         ; Read a line of text from the file
    cmp rax,0          ; A returned null indicates error or EOF
    jle .done          ; If we get 0 in rax, close up &
 return
    mov rdi,HelpLine   ; Pass address of help line in rdi
    mov rax,0          ; Tell printf() there are no vector
 arguments
    call printf        ; Call printf to display help line
    jmp .rdln
 
.done:
    mov rdi,rbx        ; Pass the handle of the file to be
 closed in rdi
    call fclose        ; Close the file
    jmp gohome         ; Go home
```

<p align="justify">
Prima che venga chiamata la procedura diskhelp, il chiamante passa un puntatore al nome del file di aiuto da leggere in RBX. Il codice tenta poi di aprire questo file. Se il tentativo di aprire il file di aiuto fallisce, viene visualizzato un messaggio di aiuto "fail safe" molto breve, proveniente da stringhe memorizzate nella sezione .data del programma. (Questa è la chiamata a memhelp, che è un'altra breve procedura in textfile.asm.) Non lasciare mai l'utente a fissare un cursore muto, chiedendosi cosa stia succedendo! Una volta che il file di aiuto basato su disco è stato aperto, iniziamo a scorrere una sequenza che legge righe di testo dal file aperto con fgets() e poi scrive quelle righe sull'output standard con printf(). La lunghezza massima delle righe da leggere è definita dall'equazione HELPLEN. Perché un'equazione? Invece di essere specificata in diversi posti nel tuo codice sorgente, la lunghezza massima delle righe del file di aiuto è definita in un solo posto, eliminando le possibilità di posizionare accidentalmente valori multipli in diverse parti del tuo codice sorgente. Se hai bisogno di cambiarla, utilizzando un'equazione, puoi cambiare il valore ovunque venga utilizzato modificando solo quella singola equazione. Le equazioni combattono i bug. Usale ogni volta che puoi. Ogni volta che una riga viene letta dal file, l'indirizzo della riga viene passato a printf() in RDI e visualizzato. Quando non ci sono più righe disponibili da leggere nel file di aiuto, fgets() restituisce un 0 in RAX, e il programma si dirama alla chiamata della funzione che chiude il file. Nota la funzione fclose(), che in uso è piuttosto semplice: copi l'handle del file di un file aperto in RDI e chiami fclose(). È tutto ciò che serve per chiudere il file!
</p>

### Scrivere testo su file con fprintf()

<p align="justify">
In precedenza in questo capitolo, ho spiegato come scrivere testo formattato sul display tramite l'output standard, utilizzando la funzione printf(). La libreria standard C fornisce una funzione che scrive lo stesso testo formattato su qualsiasi file di testo aperto. La funzione fprintf() fa esattamente ciò che fa printf(), ma richiede un parametro aggiuntivo nello stack: il gestore del file di un file di testo aperto. Lo stesso flusso di testo che printf() invierebbe all'output standard viene inviato da fprintf() a quel file aperto. Quindi non mi prenderò la briga di riesplorare come formattare il testo per printf() utilizzando codici di formattazione e stringhe di base. Si fa nello stesso modo, con gli stessi identici codici. Invece, semplicemente riassumerò come impostare una chiamata a fprintf():
</p>

1. Prima (e qui è dove fprintf() si differenzia da printf()), copia il gestore del file del file a cui il testo dovrebbe essere scritto in RDI.
2. Successivamente, copia l'indirizzo della stringa base contenente i codici di formattazione in RSI. Ancora una volta, proprio come per printf().
3. Infine, passa i puntatori ai valori controllati dalla stringa base nei registri, secondo l'ordine specificato nella convenzione di chiamata C. Non c'è differenza rispetto al modo in cui viene fatto per una chiamata a printf(). Come con printf(), possono esserci più di uno. Nel file textfile.asm, il primo è il numero della riga (passato in RDX), e il secondo è la riga di testo inserita dall'utente, passata in RCX.
4. Come con printf(), azzera RAX a 0 prima di chiamare fprintf().

<p align="justify">
Quindi chiama fprintf(). Il tuo testo verrà scritto nel file aperto. Nota che per utilizzare fprintf(), il file di destinazione deve essere stato aperto per scrittura o appending. Se tenti di utilizzare fprintf() su un file aperto per lettura, genererai un errore e fprintf() restituirà senza scrivere alcun dato. In tal caso, verrà restituito un codice di errore in RAX. Tuttavia, a differenza delle altre funzioni di cui abbiamo parlato finora, il codice di errore è un numero negativo, non 0! Quindi, sebbene tu debba confrontare il valore restituito con 0, in realtà devi saltare su un valore inferiore a 0—anziché 0 stesso. Tipicamente, per saltare su una condizione di errore di fprintf(), utilizzeresti l'istruzione JL (Jump if Less), che salterà su un valore inferiore a 0.
</p>

<p align="justify">
Ecco la chiamata fprintf() da textfile.asm:
</p>

```asm
 writeline:
    cmp qword r15,0     ; Has the line count gone to 0?
    je closeit          ; If so, close the file and exit
    mov rdi,rbx         ; Pass the file handle in rdi
    mov rsi,WriteBase   ; Pass the base string in rsi
    mov rdx,r14         ; Pass the line number in rdx
    mov rcx,Buff        ; Pass the pointer to the text buffer in rcx
    mov rax,0           ; Tell fprintf that there are no vector arguments     
    call fprintf        ; Write the text line to the file
    dec r15             ; Decrement the count of lines to be written
    inc r14             ; Increment the line number
    jmp writeline       ; Loop back and do it again
 
    ;; We're done writing text; now let's close the file:
 closeit:
    mov rdi,rbx         ; Pass the handle of the file to be closed in rdi
    call fclose         ; Closes the file
```

### Note sulla raccolta delle procedure in librerie

<p align="justify">
Ecco un riassunto su come raccogliere le procedure in librerie:
</p>

<ul>
	<li>
		<p align="justify">
		Crea un nuovo file di codice sorgente e incolla il codice sorgente della procedura nel file, che deve avere un'estensione di file .ASM.
   		</p>
	</li>
 	<li>
		<p align="justify">
		Dichiarare i punti di ingresso chiamabili per tutte le procedure nella libreria, così come qualsiasi altro identificatore che possa essere utilizzato da altri programmi e librerie, come globale. Questo rende quegli item visibili (e quindi utilizzabili) da altri programmi o librerie collegate con la nuova libreria.
   		</p>
	</li>
 	<li>
		<p align="justify">
		Se le procedure richiamano funzioni della libreria C o procedure in altre librerie di tua proprietà o che hai creato, o utilizzano variabili o altri identificatori definiti al di fuori della libreria, dichiara tutti questi identificatori esterni come extern.
   		</p>
	</li>
 	<li>
		<p align="justify">
		Quando si chiamano le procedure della libreria da un programma, aggiorna il makefile per quel programma in modo che l'eseguibile finale abbia una dipendenza dalla libreria.
   		</p>
	</li>
</ul>

<p align="justify">
Questo ultimo punto è l'unico che richiede ulteriori discussioni. Il file make mostrato di seguito costruisce il programma demo textfile.asm, che collega una libreria chiamata linlib.asm. Si noti che c'è una nuova riga che specifica come il file oggetto linlib.o venga assemblato e anche che il file binario finale textfile dipende sia da textfile.o che da linlib.o. Poiché l'eseguibile textfile dipende sia da textfile.o che da linlib.o, ogni volta che apporti modifiche a textfile.asm o linlib.asm, l'utility make ricompilerà completamente il file eseguibile tramite gcc. Tuttavia, a meno che tu non cambi entrambi i file .asm, solo il file .asm che viene modificato sarà assemblato nuovamente. La magia di make è che non fa nulla che non sia necessario.
</p>

```make
 textfile: textfile.o linlib.o
	 gcc textfile.o linlib.o -o textfile –no-pie
 textfile.o: textfile.asm
 	nasm -f elf64 -g -F dwarf textfile.asm
 linlib.o: linlib.asm
	 nasm -f elf64 -g -F dwarf linlib.asm
```

<p align="justify">
Il file completo linlib.asm è presente nell'archivio degli elenchi per questo libro. Le procedure che contiene sono state raccolte da altri programmi mostrati in questo capitolo, quindi sarebbe ripetitivo ristamparle tutte qui. Infine, segue il programma textfile.asm, nella sua interezza. Assicurati di poterlo leggere tutto - non c'è nulla qui che non abbia già trattato da qualche parte in questo libro. E se vuoi una sfida, eccone una per il tuo prossimo progetto: Adatta textfile.asm per leggere un file di testo e riscriverlo di nuovo con i numeri di linea preceduti davanti a ciascuna riga di testo. Permetti all'utente di inserire da riga di comando il nome di un nuovo file per contenere il testo modificato. Mantieni il sistema di aiuto e scrivi un nuovo file di testo di aiuto per esso. Se ci riesci, puoi inchinarti: sarai un programmatore di linguaggio assembly!
</p>

```asm
;  Executable name : textfile
;  Version         : 3.0
;  Created date    : 11/21/1999
;  Last update     : 7/18/2023
;  Author          : Jeff Duntemann
;  Description     : A text file I/O demo for Linux, using NASM 2.14.02
;
;  Build executable using these commands:
;    nasm -f elf64 -g -F dwarf textfile.asm
;    nasm -f elf64 -g -F dwarf linlib.asm
;    gcc textfile.o linlib.o -o textfile -no-pie
;
;  Note that the textfile program requires several procedures
;  in an external library named LINLIB.ASM.

[SECTION .data]     ; Section containing initialized data
		
IntFormat   dq '%d',0
WriteBase   db 'Line # %d: %s',10,0	
NewFilename db 'testeroo.txt',0			
DiskHelpNm  db 'helptextfile.txt',0
WriteCode   db 'w',0
OpenCode    db 'r',0			
CharTbl     db '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-@'	
Err1        db 'ERROR: The first command line argument must be an integer!',10,0
HelpMsg     db 'TEXTTEST: Generates a test file.  Arg(1) should be the # of ',10,0
HELPSIZE    EQU $-HelpMsg
            db 'lines to write to the file.  All other args are concatenated',10,0
            db 'into a single line and written to the file.  If no text args',10,0
            db 'are entered, random text is written to the file.  This msg  ',10,0
            db 'appears only if the file HELPTEXTFILE.TXT cannot be opened. ',10,0
HelpEnd     dq 0

[SECTION .bss]             ; Section containing uninitialized data

LineCount   resq 1         ; Reserve integer to hold line count
IntBuffer   resq 1         ; Reserve integer for sscanf's return value
HELPLEN     EQU 72         ; Define length of a line of help text data
HelpLine    resb HELPLEN   ; Reserve space for disk-based help text line
BUFSIZE     EQU 64         ; Define length of text line buffer buff
Buff        resb BUFSIZE+5 ; Reserve space for a line of text 
		
[SECTION .text]            ; Section containing code

;; These externals are all from the glibc standard C library:	 
extern fopen
extern fclose
extern fgets	
extern fprintf
extern printf		
extern sscanf
extern time

;; These externals are from the associated library linlib.asm:
extern seedit           ; Seeds the random number generator
extern pull6            ; Generates a 6-bit random number from 0-63

global main             ; Required so linker can find entry point
	
main:
    push rbp            ; Prolog: Set up stack frame
    mov rbp,rsp
    and rsp,-16

    mov r12,rdi         ; Save the argument count in r12
    mov r13,rsi         ; Save the argument pointer table to r13

    call seedit         ; Seed the random number generator

    ;; First test is to see if there are command-line arguments at all.
    ;; If there are none, we show the help info as several lines.  Don't
    ;; forget that the first arg is always the program name, so there's
    ;; always at least 1 command-line argument, even if we don't use it!

    cmp r12,1           ; If count in r12 is 1, there are no arguments
    ja chkarg2          ; Continue if arg count is > 1
    mov rbx,DiskHelpNm  ; Put address of help file name in rbx 
    call diskhelp       ; If only 1 arg, show help info...
    jmp gohome          ; ...and exit the program

    ;; Next we check for a numeric command line argument 1:

chkarg2:
    mov rdi,qword [r13+8] ; Pass address of an argument in rdi
    mov rsi,IntFormat   ; Pass address of integer format code in rsi
    mov rdx,IntBuffer   ; Pass address of integer buffer for sscanf output
    xor rax,rax         ; 0 says there will be no vector parameters
    call sscanf         ; Convert string arg to number with sscanf()    
    cmp rax,1           ; Return value of 1 says we got a number
    je chkdata          ; If we got a number, go on; else abort

    mov rdi,Err1        ; Pass address of error 1-line message in rdi
    xor rax,rax         ; 0 says there will be no vector parameters
    call printf         ; Show the error message
    jmp gohome          ; Exit the program

    ;; Here we're looking to see if there are more arguments.  If there
    ;; are, we concatenate them into a single string no more than BUFSIZE
    ;; chars in size.  (Yes, I DO know this does what strncat does...)

chkdata:
    mov r15,[IntBuffer] ; Store the # of lines to write in r15
    cmp r12,3           ; Is there a second argument?
    jae getlns          ; If so, we have text to fill a file with
    call randline       ; If not, generate a line of random text for file
                        ; Note that randline returns ptr to line in rsi
    jmp genfile         ; Go on to create the file

    ;; Here we copy as much command line text as we have, up to BUFSIZE
    ;; chars, into the line buffer Buff. We skip the first two args
    ;; (which at this point we know exist) but we know we have at least
    ;; one text arg in arg(2). Going into this section, we know that
    ;; r13 contains the pointer to the arg table. All other bets are off.

getlns:
    mov r14,2           ; We know we have at least arg(2), start there
    mov rdi,Buff        ; Destination pointer is start of char buffer
    xor rax,rax         ; Clear rax to 0 for the character counter
    cld                 ; Clear direction flag for up-memory movsb

grab:
    mov rsi,qword [r13+r14*8]   ; Copy pointer to next arg into rsi
.copy:
    cmp byte [rsi],0    ; Have we found the end of the arg?
    je .next            ; If so, bounce to the next arg
    movsb               ; Copy char from [rsi] to [rdi]; inc rdi & rsi
    inc rax             ; Increment total character count
    cmp rax,BUFSIZE     ; See if we've filled the buffer to max count
    je addnul           ; If so, go add a null to Buff & we're done
    jmp .copy

.next:	
    mov byte [rdi],' ' ; Copy space to Buff to separate the args
    inc rdi            ; Increment destination pointer for space
    inc rax            ; Add one to character count too
    cmp rax,BUFSIZE    ; See if we've now filled Buff
    je addnul          ; If so, go down to add a nul and we're done
    inc r14            ; Otherwise, increment the arg processed count
    cmp r14,r12        ; Compare against argument count in r12
    jae addnul         ; If r14 = arg count in r12, we're done
    jmp grab           ; Otherwise, go back and copy it

addnul:
    mov byte [rdi],0   ; Tack a null on the end of Buff
    mov rsi,Buff       ; File write code expects ptr to text in rsi

    ;; Now we create a file to fill with the text we have:	
genfile:
    mov rdi,NewFilename ; Pass filename to fopen in RDI
    mov rsi,WriteCode   ; Pass pointer to write/create code ('w') in rsi
    call fopen          ; Create/open file
    mov rbx,rax         ; rax contains the file handle; save in rbx

    ;; File is open.  Now let's fill it with text:
    mov r14,1           ; R14 now holds the line # in the text file

writeline:
    cmp qword r15,0     ; Has the line count gone to 0?
    je closeit          ; If so, close the file and exit
    mov rdi,rbx         ; Pass the file handle in rdi
    mov rsi,WriteBase   ; Pass the base string in rsi
    mov rdx,r14         ; Pass the line number in rdx
    mov rcx,Buff        ; Pass the pointer to the text buffer in rcx
    xor rax,rax         ; 0 says there will be no vector parameters  
    call fprintf        ; Write the text line to the file
    dec r15             ; Decrement the count of lines to be written
    inc r14             ; Increment the line number
    jmp writeline       ; Loop back and do it again

    ;; We're done writing text; now let's close the file:
closeit:
    mov rdi,rbx         ; Pass the handle of the file to be closed in rdi
    call fclose         ; Closes the file

gohome:	                ; End program execution
	mov rsp,rbp         ; Epilog: Destroy stack frame before returning
	pop rbp
	ret                 ; Return control to to the C shutdown code


;;; SUBROUTINES================================================================

;------------------------------------------------------------------------------
;  Disk-based mini-help subroutine  --  Last update 12/16/2022
;
;  This routine reads text from a text file, the name of which is passed by
;  way of a pointer to the name string in ebx. The routine opens the text file,   
;  reads the text from it, and displays it to standard output.  If the file   
;  cannot be opened, a very short memory-based message is displayed instead.          
;------------------------------------------------------------------------------	
diskhelp:
    mov rdi,DiskHelpNm  ; Pointer to name of help file is passed in rdi
    mov rsi,OpenCode    ; Pointer to open-for-read code "r" gpes in rsi
    call fopen          ; Attempt to open the file for reading
    cmp rax,0           ; fopen returns null if attempted open failed
    jne .disk           ; Read help info from disk, else from memory
    call memhelp		
    ret

.disk:
    mov rbx,rax         ; Save handle of opened file in ebx
.rdln:	
    mov rdi,HelpLine    ; Pass pointer to buffer in rdi
    mov rsi,HELPLEN     ; Pass buffer size in rsi
    mov rdx,rbx         ; Pass file handle to fgets in rdx
    call fgets          ; Read a line of text from the file
    cmp rax,0           ; A returned null indicates error or EOF
    jle .done           ; If we get 0 in rax, close up & return
    mov rdi,HelpLine    ; Pass address of help line in rdi
    xor rax,rax         ; Passs 0 to show there will be no fp registers    
    call printf         ; Call printf to display help line
    jmp .rdln

.done:	
    mov rdi,rbx         ; Pass the handle of the file to be closed in rdi
    call fclose         ; Close the file 
    jmp gohome          ; Go home

memhelp:
    mov rax,5           ; rax contains the number of newlines we want 
    mov rbx,HelpMsg     ; Load address of help text into rbx
.chkln:	
    cmp qword [rbx],0   ; Does help msg pointer point to a null?
    jne .show           ; If not, show the help lines
    ret                 ; If yes, go home
.show:
    mov rdi,rbx         ; Pass address of help line in rdi
    xor rax,rax         ; 0 in RAX says there will be no vector parameters
    call printf         ; Display the line
    add rbx,HELPSIZE    ; Increment address by length of help line
    jmp .chkln          ; Loop back and check to see if we're done yet

showerr:
    mov rdi,rax         ; On entry, rax contains address of error message
    xor rax,rax         ; 0 in RAX says there will be no vector parameters
    call printf         ; Show the error message
    ret                 ; Pass control to shutdown code; no returned values

randline:
    mov rbx,BUFSIZE     ; BUFSIZE tells us how many chars to pull
    mov byte [Buff+BUFSIZE+1],0 ; Put a null at the end of the buffer first
.loopback:
    dec rbx             ; BUFSIZE is 1-based, so decrement
    call pull6          ; Go get a random number from 0-63
    mov cl,[CharTbl+rax]  ; Use random # in rax as offset into char table
                          ;  and copy character from table into cl
    mov [Buff+rbx],cl   ; Copy char from cl to character buffer
    cmp rbx,0           ; Are we done having fun yet?
    jne .loopback       ; If not, go back and pull another
    mov rsi,Buff        ; Copy address of the buffer into rsi
    ret                 ;   and go home
```

## Controllo dei processi

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.01.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.02.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.03.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.04.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.05.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.06.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.07.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.08.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.09.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.10.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.11.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.12.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.13.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.14.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.15.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.16.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.17.png)

![](https://github.com/kinderp/2cornot2c/blob/main/images/controllo_dei_processi/controllo_dei_processi.18.png)

## Linux Programming

### Processi

<p align="justify">
Un processo è un instanza di un programma (un file eseguibile presente sul disco) che è stato caricato in memoria.
</p>
<p align="justify">
Quando dalla riga di comando invochiamo il nome di un programma o clicchiamo sull'icona presente sulla scrivania, il file eseguibile viene caricato in memoria ed ha inizio la sua esecuzione in un nuovo processo. Un singolo programma può far uso di più processi contemporaneamente per fare più cose contemporaneamente. La maggior parte dell funzioni per la manipolazione dei processi richiedono l'inclusione del file header <code>unistd.h></code>
</p>
	
#### Process IDs

<p align="justify">
Ciascun processo in Linux è identificato da un id univoco detto <b>process ID</b> anche detto <b>PID</b>. Un <b>PID</b> è lungo 16 bit ($s^{16}=65536$). Ciascun processo ha un processo padre (tranne il processo che viene creato per primo all'avvio del sistema operativo detto processo <b>init</b> che ha <b>PID</b> 1 e nessun padre).
Il process ID del processo padre è anche detto <b>PPID</b>. I processi sui sistemi Linux sono quindi rappresentabili attraverso un albero dove la radice è il processo <b>init</b>.
Quando in C si vuole rappresentare il <b>PID</b> di un processo si usa il tipo <code>pid_t</code> definito in <code>sys/types.h</code>. Per ottenere il proprio <b>PID</b> si richiama la system call <code>getpid()</code>, allo stesso modo per ottenere il <b>PPID</b> si richiama la <code>getppid()</code>. Vediamo un esempio:
</p>

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <stdio.h>
#include <unistd.h>

int main ()
{
  printf ("The process id is %d\n", (int) getpid ());
  printf ("The parent process id is %d\n", (int) getppid ());
  return 0;
}
```

### Vedere i processi attivi

Il comando **ps** mostra i processi attivi sul sistema.

```bash
vagrant@ubuntu2204:/lab2/0_processes$ ps
    PID TTY          TIME CMD
   1331 pts/0    00:00:00 bash
   1421 pts/0    00:00:00 ps
 ```

<p align=justify>
Sembra ci siano due processi attivi sul sistema, il primo è <b>bash</b> ed il secondo è <b>ps</b> che abbiamo lanciato. La prima colonna mostra il </>PID</b> dei processi attivi. Per maggiori dettagli possiamo digitare
</p>

```bash
ps -e -o pid,ppid, command
```

<div align=center>
	
| Opzione  | Significato |
| ------------- | ------------- |
| `-e`  | mostra tutti i processi attivi sul sistema non solo quelli dell'utente corrente  |
| `-o`  | specifica quali informazioni mostrare per il singolo processo  |
| `pid`  | mostra il **pid**  |
| `ppid`  | mostra il **ppid**  |
| `ppid`  | mostra il programma eseguito all'interno del processo |

</div>

```bash
vagrant@ubuntu2204:/lab2/0_processes$ ps -e -o pid,ppid,command
    PID    PPID COMMAND
      1       0 /sbin/init =
      2       0 [kthreadd]
      3       2 [rcu_gp]
      4       2 [rcu_par_gp]
      5       2 [slub_flushwq]
      6       2 [netns]
      8       2 [kworker/0:0H-events_highpri]
     10       2 [mm_percpu_wq]
     11       2 [rcu_tasks_rude_]
     12       2 [rcu_tasks_trace]
     13       2 [ksoftirqd/0]
     14       2 [rcu_sched]
     15       2 [migration/0]
     16       2 [idle_inject/0]
     18       2 [cpuhp/0]
     19       2 [cpuhp/1]
     20       2 [idle_inject/1]
     21       2 [migration/1]
     22       2 [ksoftirqd/1]
     24       2 [kworker/1:0H-events_highpri]
     25       2 [kdevtmpfs]
     26       2 [inet_frag_wq]
     27       2 [kauditd]
     28       2 [khungtaskd]
     29       2 [oom_reaper]
     30       2 [writeback]
     31       2 [kcompactd0]
     32       2 [ksmd]
     33       2 [khugepaged]
     80       2 [kintegrityd]
     81       2 [kblockd]
     82       2 [blkcg_punt_bio]
     83       2 [tpm_dev_wq]
     84       2 [ata_sff]
     85       2 [md]
     86       2 [edac-poller]
     87       2 [devfreq_wq]
     88       2 [watchdogd]
     90       2 [kworker/0:1H-kblockd]
     92       2 [kswapd0]
     93       2 [ecryptfs-kthrea]
     95       2 [kthrotld]
     96       2 [acpi_thermal_pm]
     98       2 [scsi_eh_0]
     99       2 [scsi_tmf_0]
    100       2 [scsi_eh_1]
    101       2 [scsi_tmf_1]
    103       2 [vfio-irqfd-clea]
    104       2 [kworker/u4:4-events_unbound]
    105       2 [mld]
    106       2 [ipv6_addrconf]
    115       2 [kstrp]
    118       2 [zswap-shrink]
    119       2 [kworker/u5:0]
    124       2 [charger_manager]
    148       2 [kworker/1:1H-kblockd]
    165       2 [kworker/0:2-events]
    166       2 [cryptd]
    175       2 [scsi_eh_2]
    178       2 [scsi_tmf_2]
    217       2 [kdmflush]
    243       2 [raid5wq]
    291       2 [jbd2/dm-0-8]
    292       2 [ext4-rsv-conver]
    354       1 /lib/systemd/systemd-journald
    379       2 [kaluad]
    382       2 [kmpath_rdacd]
    385       2 [kmpathd]
    386       2 [kmpath_handlerd]
    387       1 /sbin/multipathd -d -s
    391       1 /lib/systemd/systemd-udevd
    440       2 [kworker/u4:6-events_power_efficient]
    504       2 [jbd2/sda2-8]
    505       2 [ext4-rsv-conver]
    524       2 [kworker/0:4-events]
    526       1 /lib/systemd/systemd-networkd
    534       1 /usr/sbin/haveged --Foreground --verbose=1
    538       1 /lib/systemd/systemd-resolved
    602       1 /usr/sbin/cron -f -P
    603       1 @dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-acti
    610       1 /usr/sbin/irqbalance --foreground
    611       1 /usr/bin/python3 /usr/bin/networkd-dispatcher --run-startup-triggers
    612       1 /usr/libexec/polkitd --no-debug
    614       1 /usr/sbin/rsyslogd -n -iNONE
    620       1 /usr/lib/snapd/snapd
    624       1 /lib/systemd/systemd-logind
    629       1 /usr/libexec/udisks2/udisksd
    644       1 /usr/sbin/ModemManager
    658       1 /usr/sbin/ifplugd -i eth0 -q -f -u0 -d10 -w -I
    666       1 /sbin/agetty -o -p -- \u --noclear tty1 linux
    696       1 sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups
    704       1 /usr/sbin/VBoxService
   1279     696 sshd: vagrant [priv]
   1282       1 /lib/systemd/systemd --user
   1283    1282 (sd-pam)
   1330    1279 sshd: vagrant@pts/0
   1331    1330 -bash
   1427       2 [kworker/1:0-events]
   1429       2 [kworker/1:3-events]
   1453       2 [kworker/u4:0-events_unbound]
   1455    1331 ps -e -o pid,ppid,command
```

### Uccidere un processo

<p align=justify>
Tu puoi uccidere un processo con il comando <code>kill</code>. Semplicemente indica sulla riga di comando il pid del processo che deve essere ucciso. Il comando kill invia al processo un signale <code>SIGTERM</code>. La ricezione di questo segnale determina (a meno che il processo non gestisca il signale o lo ignori) la terminazione del processo.
</p>

### Creare un processo

<p align=justify>
Ci sono due modi per crare un processo; il primo è relativamente semplice ma è inefficiente e rischioso da un punto di vista di sicurezza, il secondo è più complesso ma fornisce maggiore sicurezza e flessibilità.
</p>

#### `system()`

<p align=justify>
La funzione <code>system()</code> è fornita nella libreria standard del linguaggio C e fornisce un modo semplice per eseguire un comando all'interno di un programma come se il comando fosse stato digitato all'interno di una shell. La funzione <code>system()</code> crea un sottoprocesso  lanciando <code>/bin/sh</code>. Per esempio il codice di sotto invoca il comando <code>ls</code> per mostrare il contenuto della root directory come se si fosse digitato <code>ls -l /</code> direttamente dalla shell
</p>

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <stdlib.h>

int main ()
{
  int return_value;
  return_value = system ("ls -l /");
  return return_value;
}
```

### `fork()` `exec()`

<p align=justify>
La system call <code>fork()</code> crea un nuovo processo che è la copia identica del processo padre. La <code>exec()</code> permette di sostituire il processo padre con un nuovo programma nel processo appena creato con la <code>fork()</code>.
</p></b>

<p align=justify>
Per distinguire il padre del figlio la funzione <code>fork()</code> restituisce un intero: in particolare restituisce zero  al processo figlio ed il <b>pid</b> del processo figlio al padre. 
</p>

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <stdio.h>
#include <sys/types.h>
#include <unistd.h>

int main ()
{
  pid_t child_pid;

  printf ("the main program process id is %d\n", (int) getpid ());

  child_pid = fork ();
  if (child_pid != 0) {
    printf ("this is the parent process, with id %d\n", (int) getpid ());
    printf ("the child's process id is %d\n", (int) child_pid);
  }
  else 
    printf ("this is the child process, with id %d\n", (int) getpid ());

  return 0;
}
```
<p align=justify>
Nota che il codice all'interno del blocco <code>if</code> è eseguito solo dal processo padre, mentre il codice dentro il blocco <code>else</code> è eseguito dal processo figlio.
</p>

<p align=justify>
La systam call <code>exec()</code> sostituisce il programma eseguito all'interno del processo con un nuovo programma. Quando un programma richiama la <code>exec()</code> il processo smette immediatamente di eseguire il programma e ed inizio l'esecuzione del nuovo programma richiamato dalla <code>exec()</code>.
</p>

Ci sono diverse versioni della <code>exec()</code>:

* Funzioni che contengono la lettera `p` nel nome (`exexcvp`, `execlp`) accettano il nome del programma e lo cercano nel sistema; le funzioni che non contengono la `p` nel nome necessitano del percorso assoluto del programma da eseguire
* Funzioni che contengono la lettera `v` nel nome (`execv`, `execvp`, `execve`) accettano una  lista di argomenti da passare in ingresso al nuovo programma come un array di puntatori a caratteri terminati da `NULL`. Le funzioni invece che contengono la lettra `l` (`execl` `execlp`, `execle`) accettano una lista di argomenti in ingresso secondo il meccanismo delle `vargargs` del lingugiaggio C
* Funzioni che contengono la lettera `e` nel nome (`execve`, `execle`) accettano un argomento in più, un array di variabili d'ambiente. L'argomento dovrebbe essere un array di puntatori a caratteri terminato da `NULL`, ciascun stringa dovrebbe essere nella forma `VARIABILE=valore`

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <stdio.h>
#include <stdlib.h>
#include <sys/types.h>
#include <unistd.h>

/* Spawn a child process running a new program.  PROGRAM is the name
   of the program to run; the path will be searched for this program.
   ARG_LIST is a NULL-terminated list of character strings to be
   passed as the program's argument list.  Returns the process id of
   the spawned process.  */

int spawn (char* program, char** arg_list)
{
  pid_t child_pid;

  /* Duplicate this process.  */
  child_pid = fork ();
  if (child_pid != 0)
    /* This is the parent process.  */
    return child_pid;
  else {
    /* Now execute PROGRAM, searching for it in the path.  */
    execvp (program, arg_list);
    /* The execvp function returns only if an error occurs.  */
    fprintf (stderr, "an error occurred in execvp\n");
    abort ();
  }
}

int main ()
{
  /* The argument list to pass to the "ls" command.  */
  char* arg_list[] = {
    "ls",     /* argv[0], the name of the program.  */
    "-l", 
    "/",
    NULL      /* The argument list must end with a NULL.  */
  };

  /* Spawn a child process running the "ls" command.  Ignore the
     returned child process id.  */
  spawn ("ls", arg_list); 

  printf ("done with main program\n");

  return 0;
}
```

<p align=justify>
Eseguendo il programma ti accorgerai che il processo padre termina immediatamente ("done with the main program") successivamente viene stampato il prompt e poco dopo l'output del processo figlio sporca il terminale perchè continua a scrivere sullo stdout. In generale non è possibile sapere quale processo tra il padre ed il figlio concluda per primo ma vedremo che è possibile sincronizzare l'esecuzione dei due processi facendo in modo che il processo padre attenda la terminazione dei suoi figli prima di concludere la propria esecuzione.
</p>

```bash
vagrant@ubuntu2204:/lab2/0_processes$ bin/3_fork_exec
done with main program
vagrant@ubuntu2204:/lab2/0_processes$ total 2097224
lrwxrwxrwx   1 root    root             7 Aug 10  2023 bin -> usr/bin
drwxr-xr-x   4 root    root          4096 Jan 11  2024 boot
drwxr-xr-x  19 root    root          3980 Aug 12 08:33 dev
drwxr-xr-x 104 root    root          4096 Aug 12 08:33 etc
drwxr-xr-x   3 root    root          4096 Jan 10  2024 home
drwxrwxrwx   1 vagrant vagrant       4096 Aug  9 07:23 lab
drwxrwxrwx   1 vagrant vagrant          0 Aug 12 08:30 lab2
lrwxrwxrwx   1 root    root             7 Aug 10  2023 lib -> usr/lib
lrwxrwxrwx   1 root    root             9 Aug 10  2023 lib32 -> usr/lib32
lrwxrwxrwx   1 root    root             9 Aug 10  2023 lib64 -> usr/lib64
lrwxrwxrwx   1 root    root            10 Aug 10  2023 libx32 -> usr/libx32
drwx------   2 root    root         16384 Jan 10  2024 lost+found
drwxr-xr-x   2 root    root          4096 Aug 10  2023 media
drwxr-xr-x   2 root    root          4096 Aug 10  2023 mnt
drwxr-xr-x   2 root    root          4096 Aug 10  2023 opt
dr-xr-xr-x 162 root    root             0 Aug 12 08:32 proc
drwx------   5 root    root          4096 Jan 11  2024 root
drwxr-xr-x  28 root    root           840 Aug 12 10:37 run
lrwxrwxrwx   1 root    root             8 Aug 10  2023 sbin -> usr/sbin
drwxr-xr-x   6 root    root          4096 Jul  7 07:31 snap
drwxr-xr-x   2 root    root          4096 Aug 10  2023 srv
-rw-------   1 root    root    2147483648 Jan 10  2024 swap.img
dr-xr-xr-x  13 root    root             0 Aug 12 08:32 sys
drwxrwxrwt  12 root    root          4096 Aug 12 16:36 tmp
drwxr-xr-x  14 root    root          4096 Aug 10  2023 usr
drwxr-xr-x  13 root    root          4096 Aug 10  2023 var
```

#### Segnali

<p align=justify>
I segnali sono un meccanismo per comunicare e manipolare i processi in Linux. Un segnale è semplicemente un messaggio inviato ad un processo. I segnali sono definiti il linux in <code>/usr/include/bits/signum.h</code> ma per usarli basta includere <code>signal.h</code> nel tuo sorgente.
<p>

<p align=justify>
Quando un processo riceve un segnale può comportarsi in modi differenti sulla base della disposizione di default che determina che cosa accade se il programma non specifica qualche altre comportamente specifico per il segnale. Per ciascun segnale, un programma può:
</p>

1. Specificare un diverso comportamente dalla disposizione di default
2. Ignora il segnale
3. Chiamare una funzione, detta **signal-handler** per rispondere in modo personalizzato al segnale

<p align=justify>
Se una funzione <b>signal-handler</b> è usata, l'esecuzione del programma è messa in pausa e la funzione è immeditamente eseguita e solo dopo che questa termina l'esecuzione del programma riprende nel punto dove si era interrotta.
</p>

Alcuni esempi di segnali sono 

<div align=center>
	
| First Header  | Significato | Disposizione
| ------------- | ------------- |------------- |
| `SIGSEGV`  | segmentation fault  | termina il processo
| `SIGTERM`  | chiede al processo di terminare, il processo potrebbe ignorare il segnale di terminazione  | termina il processo
| `SIGKILL`  | termina il processo immediatamente, il processo non può ignorare questo segnale  | termina il processo 
| `SIGUSR1`  | Definito dall'utente  |
| `SIGUSR2`  | Definito dall'utente  |
| `SIGHUP`   | Risveglia un processo o lo mette in sleep o lo costringe e rileggere la sua configurazione |

</div>

#### sigaction

La **sigaction** può essere usata per settare la disposizione per un segnale (per modificare la disposizione di default).
Questa riceva in ingresso tre parametri:

1. `int`: il numero del segnale
2. `const struct sigaction *`: la disposizione desiderata per il segnale
3. `struct sigaction *`: la precedente disposizione per il segnale
   
```c
int sigaction(int signum,
                     const struct sigaction *_Nullable restrict act,
                     struct sigaction *_Nullable restrict oldact);
```

La struct `sigaction` ha questa forma:

```c
struct sigaction {
               void     (*sa_handler)(int);
               void     (*sa_sigaction)(int, siginfo_t *, void *);
               sigset_t   sa_mask;
               int        sa_flags;
               void     (*sa_restorer)(void);
           };
```

Il campo più importante in questa struttura è `sa_handler` che può assumere uno di questi tre valori:

* **SIG_DFL**
* **SIG_IGN**
* Un puntatore alla funzione **signal-handler**. La funzione dovrebbe accettare un paraemtre (il numero del segnale) e ritornare `void`.

Quando il segnale viene processata dal programma questo può essere in uno stato altamente instabile (quindi durante l'esecuzione di un **signal-hadler**). Quindi all'interno di una funzione **signal-hanlder** bisogna svolgere solo i task strettamente necessari per gestire/rispondere il/al segnale ed evitare operazione di I/O o richiamare librerie esterne o del linguaggio. Può accadere che un **signal-handler** sia interrotto a causa della ricezione di un altro segnale e questo è un problema molto complicato da diagnosticare e debuggare e per questo bisogna essere molto cauti su cosa fare dentro un **signal-handler**.

Un altro aspetto da tenere in considerazione è rendere le prorpie istruzioni (variabili globali) atomiche usando il tipo `sig_atomic_t`. Linux garantisce che l'assegnazione di variabili di questo tipo avvenga in modo atomico e non possa essere interrotto dall'arrivo di un nuovo segnale.

Vediamo un esempio di **signal-handler** per la gestione del segnale **SIGUSR1** uno dei due segnale riservati all'uso da parte dei programmi applicativi.

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <signal.h>
#include <stdio.h>
#include <string.h>
#include <sys/types.h>
#include <unistd.h>
#include <time.h>

#define SOME_MINUTES 5
#define SECONDS_PER_MINUTE 60

sig_atomic_t sigusr1_count = 0;

void handler (int signal_number)
{
  ++sigusr1_count;
}

int main ()
{
  struct sigaction sa;
  memset (&sa, 0, sizeof (sa));
  sa.sa_handler = &handler;
  sigaction (SIGUSR1, &sa, NULL);

  time_t start = time(NULL);
  while (time(NULL) - start < (time_t) (SOME_MINUTES * SECONDS_PER_MINUTE)) {
    printf("*");
  }
  printf ("SIGUSR1 was raised %d times\n", sigusr1_count);
  return 0;
}
```

In un primo terminale esegui il programma che resterà in esecuzione per 5 minuti, alla fine dell'esecuzione stamperà il numero di volte che il segnale `SIGUSR1` è stato ricevuto.

```bash
vagrant@ubuntu2204:/lab2/0_processes$ bin/4_sigusr1
***************************************************
**************************SIGUSR1 was raised 6 times
```

Per inviare il segnale `SIGUSR1` basta usare il comando `kill` usando il **PID** del processo (che puoi recuperare con il comando `ps` come mostrato sotto)

```bash
vagrant@ubuntu2204:~$ ps -e|grep 4_sigusr1
   1642 pts/0    00:01:17 4_sigusr1

vagrant@ubuntu2204:~$ kill -SIGUSR1 1642
vagrant@ubuntu2204:~$ kill -SIGUSR1 1642
vagrant@ubuntu2204:~$ kill -SIGUSR1 1642
vagrant@ubuntu2204:~$ kill -SIGUSR1 1642
vagrant@ubuntu2204:~$ kill -SIGUSR1 1642
vagrant@ubuntu2204:~$ kill -SIGUSR1 1642
```

#### Terminare un processo

Un processo termina o attraverso la chiamata alla funzione `exit()` o quando termina la funzione `main()` del programma (attraverso `return` o perchè raggiunge l'ultima istruzione del blocco della funzione `main()`). Il valore intero ritornato attraverso `return` o come parametro in input alla `exit()` è detto **exit code**. Un processo può anche terminare in risposta ad un segnale (`SIGSEGV`, `SIGKILL` etc). Altri segnali per terminare un processo sono `SIGINT` inviato quando si preme la combinazione di tast `CTRL+C` nel terminale occupato del programma. Un altro segnale che termina un processo è `SIGABRT` che oltre che terminare il processo genera un core file, è possibile inviare questo segnale attraverso la chiamata `abort()`. Il modo più brutale per terminare un processo è quello di inviare il segnale `SIGKILL` che termina immediatamente il processo e non può essere ignorato o bloccato.
Tutti questi segnale ed anche altri possono essere inviati con il comando `kill` specificando quale segnale inviare come parametro, per inviare un `SIGKILL` fai in questo modo:

```bash
kill -KILL pid
```

Esiste anche la funzione `kill()` per inviare un segnale dal codice ed ha questo prototipo:

```c
int kill(pid_t pid, int sig);
```

1. `pid_t pid`: il pid del processo
2. `int sig`: segnale da inviare

Devi includere `<sys/types.h>` e `<signal.h` per utilizzare la funzione `kill()`.

> [!IMPORTANT]
> Per convenzione, **exit code** è usato per indicare se il programma ha terminato la sua esecuzione correttamente o con degli errir. Un valore pari a zero indica una corretta esecuzione mentre valori diversi da zero indicano che il processo ha terminato con qualche errore. E' importante seguire questa convezione se vuoi usare gli operatori logici della shell (`&&` `||`) per concatenare più programma tra loro.

Puoi leggere l'**exit code** dell'ultimo programma lanciato sulla shell stampando il contenuto della variabile `$?` per esempio

```bash
vagrant@ubuntu2204:/lab2/0_processes$ ls
0_print_pid.c  1_system.c  2_fork.c  3_fork_exec.c  4_sigusr1.c  bin
vagrant@ubuntu2204:/lab2/0_processes$ echo $?
0
```

#### Aspettare la terminazione di un processo

Quando si esegue la coppia di chiamate `fork()` ed `exec()` per creare un processo figlio siamo in grado, all'interno dello stesso codice, di differenziare quali istruzioni saranno eseguite dal padre e quali dal processo figlio sfruttando l'intero di ritorno della chiamata `fork()`. Nulla però ci assicura che il padre terminerà prima del figlio, l'ordine di terminazione dipende dal numero di istruzioni dei due processi e soprattutto da come il sistema operativo andrà a schedulare i due processi nell'assegnazione dei tempi di CPU. Quando è necessario che per la correttezza del nostro programma il padre termini soltanto al termine dell'esecuzione del processo figlio è obbligo usare la funzione `wait()`.

#### wait()

La `wait()` l'esecuzione del processo padre finchè uno dei suoi figli ha terminato (anche con un errore, non importa). Inoltre la `wait()` ritorna uno status code (**exit code**) dal quale estrarre informazioni su come il processo figlio ha terminato l'esecuzione. Per esempio la macro `WEXITSTATUS` contiene l'**exit code** del processo figlio.

Vediamo un esempio:

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <stdio.h>
#include <stdlib.h>
#include <sys/types.h>
#include <sys/wait.h>
#include <unistd.h>

/* Spawn a child process running a new program.  PROGRAM is the name
   of the program to run; the path will be searched for this program.
   ARG_LIST is a NULL-terminated list of character strings to be
   passed as the program's argument list.  Returns the process id of
   the spawned process.  */

int spawn (char* program, char** arg_list)
{
  pid_t child_pid;

  /* Duplicate this process.  */
  child_pid = fork ();
  if (child_pid != 0)
    /* This is the parent process.  */
    return child_pid;
  else {
    /* Now execute PROGRAM, searching for it in the path.  */
    execvp (program, arg_list);
    /* The execvp function returns only if an error occurs.  */
    fprintf (stderr, "an error occurred in execvp\n");
    abort ();
  }
}

int main ()
{
  int child_status;
  /* The argument list to pass to the "ls" command.  */
  char* arg_list[] = {
    "ls",     /* argv[0], the name of the program.  */
    "-l",
    "/",
    NULL      /* The argument list must end with a NULL.  */
  };

  /* Spawn a child process running the "ls" command.  Ignore the
     returned child process id.  */
  spawn ("ls", arg_list);

  /* Wait for the child process to complete. */
  wait(&child_status);
  if (WIFEXITED(child_status))
   printf("the child process exited normally, with exit code %d\n", WEXITSTATUS(child_status));
  else
    printf("the child process exited abnormally\n");

  printf("done with main program\n");

  return 0;
}                                                                    
```

Come puoi vedere sotto, prima il terminale è occupato dell'output del processo figlio (`ls -l`) e successivamente il processo padre termina stampando a schermo (`done with the main program`).

```bash
vagrant@ubuntu2204:/lab2/0_processes$ bin/5_fork_exec_wait
total 2097224
lrwxrwxrwx   1 root    root             7 Aug 10  2023 bin -> usr/bin
drwxr-xr-x   4 root    root          4096 Jan 11  2024 boot
drwxr-xr-x  19 root    root          3980 Aug 12 08:33 dev
drwxr-xr-x 104 root    root          4096 Aug 12 08:33 etc
drwxr-xr-x   3 root    root          4096 Jan 10  2024 home
drwxrwxrwx   1 vagrant vagrant       4096 Aug  9 07:23 lab
drwxrwxrwx   1 vagrant vagrant          0 Aug 12 08:30 lab2
lrwxrwxrwx   1 root    root             7 Aug 10  2023 lib -> usr/lib
lrwxrwxrwx   1 root    root             9 Aug 10  2023 lib32 -> usr/lib32
lrwxrwxrwx   1 root    root             9 Aug 10  2023 lib64 -> usr/lib64
lrwxrwxrwx   1 root    root            10 Aug 10  2023 libx32 -> usr/libx32
drwx------   2 root    root         16384 Jan 10  2024 lost+found
drwxr-xr-x   2 root    root          4096 Aug 10  2023 media
drwxr-xr-x   2 root    root          4096 Aug 10  2023 mnt
drwxr-xr-x   2 root    root          4096 Aug 10  2023 opt
dr-xr-xr-x 163 root    root             0 Aug 12 08:32 proc
drwx------   5 root    root          4096 Jan 11  2024 root
drwxr-xr-x  28 root    root           840 Aug 12 10:37 run
lrwxrwxrwx   1 root    root             8 Aug 10  2023 sbin -> usr/sbin
drwxr-xr-x   6 root    root          4096 Jul  7 07:31 snap
drwxr-xr-x   2 root    root          4096 Aug 10  2023 srv
-rw-------   1 root    root    2147483648 Jan 10  2024 swap.img
dr-xr-xr-x  13 root    root             0 Aug 12 08:32 sys
drwxrwxrwt  12 root    root          4096 Aug 12 16:36 tmp
drwxr-xr-x  14 root    root          4096 Aug 10  2023 usr
drwxr-xr-x  13 root    root          4096 Aug 10  2023 var
the child process exited normally, with exit code 0
done with main program
```

#### Processi zombie

Quando un processo figlio termina ed il processo padre ha chiamato la `wait()` le informazioni circa la terminazione della propria esecuzione sono passati attraverso la `wait()` al padre. Se il padre non chiama la `waiit()` queste informazioni vanno perse? No, perchè in questo caso il processo figlio diventa un processo **zombie**.
Un processo **zombie** è un processo che ha terminato la propria esecuzione ma non è stato ancora pulito, è compito del processo padre ripulire il processo proprio processo figlio zombie. Il compito della `wait()` è appunto questo: una volta che il processo figlio termina questo diventa una zombio poi la `wait()` andrà ad estrarre lo status di uscita del figlio zombie e finalmente il processo figlio può essere eliminato. Se il processo padre non chiama la `wait()` il figlio resta nello stato di zombie, vediamo un esempio:

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <stdlib.h>
#include <sys/types.h>
#include <unistd.h>

int main ()
{
  pid_t child_pid;

  /* Create a child process.  */
  child_pid = fork ();
  if (child_pid > 0) {
    /* This is the parent process.  Sleep for a minute.  */
    sleep (60);
  }
  else {
    /* This is the child process.  Exit immediately.  */
    exit (0);
  }
  return 0;
}
```

Lancia il programma da un terminale in questo modo:

```bash
vagrant@ubuntu2204:/lab2/0_processes$ bin/6_zombie
```
Ed usa, su un altro terminale, il comando `ps` in questo modo:

```bash
vagrant@ubuntu2204:~$ ps -e -o pid,ppid,stat,cmd|grep 6_zombie
   2317    1331 S+   bin/6_zombie
   2318    2317 Z+   [6_zombie] <defunct>
   2325    2301 S+   grep --color=auto 6_zombie
```

Il processo padre ha pid `2317` ed è in sleep `S+` il processo figlio è `<defunct>` ed è uno zombio `Z+`
Quando il processo padre termina prima del figlio senza chiamare la `wait()`, chi si occupa di ripulire il processo figlio e portarlo dallo stato di zombie a terminato? Il processo **init** che è il padre di tutti i processi (init infatti ha PID=1) ed eredita tutti i figli rimasti orfani del proprio padre. Se rilanci `ps` dopo un po' di tempo vedrai che il processo figlio con pid `2318` non esiste più in quanto è stato ripulito da init. 



### Ripulire il figlio in modo asincrono

La `wait()` ci permette di attendere (nel codice del padre) la terminazione del figlio. Il problema è che la chiamata alla `wait()` è bloccante quindi il codice del padre rimane (appeso) bloccata all'istruzione di wait fino a quando il figlio non termina. Se si vuole che il padre continui la propria elaborazione mentre si attende che il figlio completi è possibile controllare periodicamente la terminazione del figlio chiamando `wait3()` o `wait4()` (flag `WNOHANG`) in modo asincrono ogni tanto nel codice del padre. Una soluzione migliore è usare il segnale `SIGCHLD` che Linux invia al padre ogni volta che uno dei suoi figli termina. Vediamo un esempio:

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <signal.h>     // sigaction
#include <string.h>     // memset()
#include <stdio.h>      // fprintf()
#include <stdlib.h>     // abort()
#include <sys/types.h>  // pid_t
#include <sys/wait.h>   // wait()
#include <unistd.h>     // fork() exec()
#include <time.h>       // time()

#define N_CHILDS 10

#define SOME_MINUTES 2
#define SECONDS_PER_MINUTE 60

sig_atomic_t child_exit_status;

void clean_up_child_process (int signal_number)
{
  /* Clean up the child process.  */
  int status;
  wait (&status);
  /* Store its exit status in a global variable.  */
  child_exit_status = status;
  fprintf (stdout, "Child exit with %d status\n", status);
}


int spawn (char* program, char** arg_list)
{
  pid_t child_pid;

  /* Duplicate this process.  */
  child_pid = fork ();
  if (child_pid != 0){
    /* This is the parent process.  */
    fprintf (stdout, "Child %d created\n", child_pid);
  } else {
    /* Now execute PROGRAM, searching for it in the path.  */
    execvp (program, arg_list);
    /* The execvp function returns only if an error occurs.  */
    fprintf (stderr, "an error occurred in execvp\n");
    abort ();
  }
}

int main ()
{
  /* Handle SIGCHLD by calling clean_up_child_process.  */
  struct sigaction sigchld_action;
  memset (&sigchld_action, 0, sizeof (sigchld_action));
  sigchld_action.sa_handler = &clean_up_child_process;
  sigaction (SIGCHLD, &sigchld_action, NULL);

  /* Now do things, including forking a child process.  */
  /* The argument list to pass to the "ls" command.  */
  char* arg_list[] = {
    "sleep",     /* argv[0], the name of the program.  */
    "60",
    NULL      /* The argument list must end with a NULL.  */
  };

  for(int i=0; i<N_CHILDS; i++)
     spawn ("sleep", arg_list);

  time_t start = time(NULL);
  while (time(NULL) - start < (time_t) (SOME_MINUTES * SECONDS_PER_MINUTE));
  fprintf (stdout, "Father's quitting\n");

  return 0;
}
```

```bash
vagrant@ubuntu2204:/lab2/0_processes$ bin/7_sigchld
Child 3099 created
Child 3100 created
Child 3101 created
Child 3102 created
Child 3103 created
Child 3104 created
Child 3105 created
Child 3106 created
Child 3107 created
Child 3108 created

Child exit with 0 status
Child exit with 0 status
Child exit with 0 status
Child exit with 0 status
Child exit with 0 status
Child exit with 0 status
Child exit with 0 status
Child exit with 0 status

Father's quitting
```

### I Thread

I thread come i processi sono un meccanismo per permettere ad un programma di svolgere più compiti contemporaneamenente. Come i processi anche i thread si contengono la CPU per l'esecuzione. Da un punsto di vista teorico un threada esiste all'interno di un processo: quando un programma viene invocato, Linux crea un nuovo processo ed al suo interno crea anche un singolo thread che esegue il programma in modo sequenziale. Questo thread può creare altri thread che eseguono lo stesso programma nello stesso processo ma ciascun thread potrebbe eseguire una parte diversa del programma in un qualsiasi momento.
Abbiamo visto come un processo può forkare un processo figlio. Il processo figlio inizialmente esegue il programma del padre come una copia della memoria virtuale del processo padre, i descrittori dei file e così via. Il processo figlio può modificare la sua memoria, chiudere i descrittori dei file etc senza alterare quelli del padre. Quando un thread crea un nuovo thread nulla è copiato. Il thread padre ed il thread figlio condividono la stessa memoria, i descrittori dei file e tutte le altre risorse. Se un thread cambia il valore di una variabile anche l'altro thread vedrà questa modifica; se un thread chiude un descrittore di un file gli altri thread potrebbero non poter più leggere o scrivere su quel descrittore. Siccome un processo e tutti i suoi thread possono eseguire un solo programma alla volta se un thread richiama la `exec()` tutti i thread saranno terminati.
Linux implementa le API POSIX per i thread (conosciuto come **pthread**). Tutte le funzioni per i thread sono definite nel file d'intestazione `<pthread.h>` che non è inclusa nella librearia standard fornita dal linguaggio C. La librearia è fornita in `libpthread.so` ed è necessario passare il parametro `-lpthread` a gcc per linkarla al momento della compilazione.

#### Creazione di un thread

Ad ogni thread è associato un id univoco di tipo `pthread_t`.
Una volta creato un thread esegue un semplice funzione che contiene il codice che il thread dovrà eseguire, quando questa funzione termina anche il thread termina la propria esecuzione. Questa funzione riceva in ingresso un puntatore a void `void *` e ritorna sempre un altro puntatore a void `void *`.
Per creare un nuovo thread bisogna usare la funzione `pthread_create()`, questo è il suo prototipo:

```c
int pthread_create(pthread_t *restrict thread,
                          const pthread_attr_t *restrict attr,
                          void *(*start_routine)(void *),
                          void *restrict arg);
```

1. `pthread *t`: un puntatore al thread id
2. `const pthread_attr_t *`: un puntatore all'oggetto contenente gli attributi del thread: questo oggetto controlla i dettagli di ocme il thread interagisce con il resto del programma. Se passi `NULL` come attributo del thread, il thread sarà creato con gli attributi di default.
3. `void* (*) (void*)`: un puntore alla funzione del thread, questo è un semplice puntatore a funzione
4. `void *`: l'argomento in ingresso da passare alla funzione del thread di tipo `void *`

Vediamo un esempio di creazione di un thread:

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <pthread.h>
#include <stdio.h>

/* Prints x's to stderr.  The parameter is unused.  Does not return.  */

void* print_xs (void* unused)
{
  while (1)
    fputc ('x', stderr);
  return NULL;
}

/* The main program.  */

int main ()
{
  pthread_t thread_id;
  /* Create a new thread.  The new thread will run the print_xs
     function.  */
  pthread_create (&thread_id, NULL, &print_xs, NULL);
  /* Print o's continuously to stderr.  */
  while (1)
    fputc ('o', stderr);
  return 0;
}
```

Il thread termina quando termina la funzione del thread `print_xs`, un thread può ritornare anche richiamando la funzione `pthread_exit()`

#### Passare dati ad un thread

Per passare argomenti ad un thread basta usare il quarto argomento della `pthread_create()`. Per farlo basta solo dichiarare una struttura o un array e passare il puntatore alla `pthread_create`.
L'unica accortezza da tenere in considerazione è quella di ricastare il parametro in ingresso alla funzone del thread al tipo corretto.
Vediamo un esempio:

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <pthread.h>
#include <stdio.h>

/* Parameters to print_function.  */

struct char_print_parms
{
  /* The character to print.  */
  char character;
  /* The number of times to print it.  */
  int count;
};

/* Prints a number of characters to stderr, as given by PARAMETERS,
   which is a pointer to a struct char_print_parms.  */

void* char_print (void* parameters)
{
  /* Cast the cookie pointer to the right type.  */
  struct char_print_parms* p = (struct char_print_parms*) parameters;
  int i;

  for (i = 0; i < p->count; ++i)
    fputc (p->character, stderr);
  return NULL;
}

/* The main program.  */

int main ()
{
  pthread_t thread1_id;
  pthread_t thread2_id;
  struct char_print_parms thread1_args;
  struct char_print_parms thread2_args;

  /* Create a new thread to print 30000 x's.  */
  thread1_args.character = 'x';
  thread1_args.count = 30000;
  pthread_create (&thread1_id, NULL, &char_print, &thread1_args);

  /* Create a new thread to print 20000 o's.  */
  thread2_args.character = 'o';
  thread2_args.count = 20000;
  pthread_create (&thread2_id, NULL, &char_print, &thread2_args);

  return 0;
}
```

Il problema in questo codice è che le due variabili locali (automatiche) `thread1_args` e `thread1_args` che contengono i parametri da passare ai due thread sono dichiarate nel processo padre, il processo padre termina immediatamente e tutte le sue variabili verranno deallocata comprese quelle passate come argomenti alle funzoni dei thread che accederanno quindi a locazioni di memoria non valide. Per risolvere questo problema dovremmo fare in modo che il processo padre attenda la terminazione dei thread nello stesso modo con cui attraverso la `wait()` attendeva la terminazione del processo figlio.

#### Attendere la terminazione dei thread

Per fare in modo che il `main()` attenda la terminazione dei thread è possibile usare la funzione `pthread_join()`. Questo è il suo prototipo:

```c
int pthread_join(pthread_t thread, void **retval);
```

1. `pthread_t`: id del thread di cui si vuole attendere il completamento
2. `void *`: puntatore a void per il valore di ritorno del thread. Se non sei interessato al valore di ritorno passa `NULL` a questo parametro.

Vediamo come risolvere il bug dell'esempio predente usando la `pthread_join()` per attendere il completamento dei thread creati nel `main()`

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <pthread.h>
#include <stdio.h>

/* Parameters to print_function.  */

struct char_print_parms
{
  /* The character to print.  */
  char character;
  /* The number of times to print it.  */
  int count;
};

/* Prints a number of characters to stderr, as given by PARAMETERS,
   which is a pointer to a struct char_print_parms.  */

void* char_print (void* parameters)
{
  /* Cast the cookie pointer to the right type.  */
  struct char_print_parms* p = (struct char_print_parms*) parameters;
  int i;

  for (i = 0; i < p->count; ++i)
    fputc (p->character, stderr);
  return NULL;
}

/* The main program.  */

int main ()
{
  pthread_t thread1_id;
  pthread_t thread2_id;
  struct char_print_parms thread1_args;
  struct char_print_parms thread2_args;

  /* Create a new thread to print 30000 x's.  */
  thread1_args.character = 'x';
  thread1_args.count = 30000;
  pthread_create (&thread1_id, NULL, &char_print, &thread1_args);

  /* Create a new thread to print 20000 o's.  */
  thread2_args.character = 'o';
  thread2_args.count = 20000;
  pthread_create (&thread2_id, NULL, &char_print, &thread2_args);

  /* Make sure the first thread has finished.  */
  pthread_join (thread1_id, NULL);
  /* Make sure the second thread has finished.  */
  pthread_join (thread2_id, NULL);

  /* Now we can safely return.  */
  return 0;
}
```

#### Il valore di ritorno dei thread

Se il secondo parametro in ingresso alla `pthread_join()` non è `NULL` allora il valore di ritorno del thread verrà salvato nella locazione di memoria puntata da quell'argomento. Il valore di ritorno del thread è di tipo puntatore a void: `void *` quindi è necessario castare l'indrizzo della variabile intera `prime` ad `void *` nella chiamata alla `pthread_join()`.

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <pthread.h>
#include <stdio.h>

/* Compute successive prime numbers (very inefficiently).  Return the
   Nth prime number, where N is the value pointed to by *ARG.  */

void* compute_prime (void* arg)
{
  int candidate = 2;
  int n = *((int*) arg);

  while (1) {
    int factor;
    int is_prime = 1;

    /* Test primality by successive division.  */
    for (factor = 2; factor < candidate; ++factor)
      if (candidate % factor == 0) {
        is_prime = 0;
        break;
      }
    /* Is this the prime number we're looking for?  */
    if (is_prime) {
      if (--n == 0)
        /* Return the desired prime number as the thread return value.  */
        return (void*) candidate;
    }
    ++candidate;
  }
  return NULL;
}

int main ()
{
  pthread_t thread;
  int which_prime = 5000;
  int prime;

  /* Start the computing thread, up to the 5000th prime number.  */
  pthread_create (&thread, NULL, &compute_prime, &which_prime);
  /* Do some other work here...  */
  /* Wait for the prime number thread to complete, and get the result.  */
  pthread_join (thread, (void*) &prime);
  /* Print the largest prime it computed.  */
  printf("The %dth prime number is %d.\n", which_prime, prime);
  return 0;
}
```

```bash
vagrant@ubuntu2204:/lab2/1_threads$ bin/3_primes
The 5000th prime number is 48611.
```

#### `pthread_self()` e `pthread_equal()`

`pthread_self()` ritorna il thread id del thread corrente che la sta eseguendo. Questo è il suo prototipo:

```c
pthread_t pthread_self(void);
```

`pthread_equal()` confronta due thread id(s): ritorna zero se i due ID sono uguali. Questo è il suo prototipo:

```c
int pthread_equal(pthread_t t1, pthread_t t2);
```

Queste due funzioni possonoe essere utlili per controllare se un certo ID corrisponde a quello del thread corrente per esempio prima di chiamare una `pthread_join()` in quanto aspettare la terminazione di se stessi è un grosso errore. Sotto un esempio:

```c
if (!pthread_equal (pthread_self (), other_thread))
  pthread_join (other_thread, NULL);
```

#### Gli attributi dei thread

Gli attributi del thread forniscono un meccanismo per la messa a punto del comportamento dei singoli thread. Abbiamo visto come la `pthread_create()` accetta un argomento che è un puntatore a un oggetto attributo del thread. Se passi un puntatore nullo a questo argomento, gli attributi predefiniti vengono utilizzati per configurare il nuovo thread. Tuttavia, puoi creare e personalizzare un oggetto attributo thread per specificare altri valori per gli attributi. Per specificare attributi thread personalizzati, devi seguire questi passaggi: 

1. Crea un oggetto `pthread_attr_t`. Il modo più semplice per farlo èdichiarare una variabile automatica di questo tipo.
2. Chiama la funzione `pthread_attr_init()`, passando un puntatore a questo oggetto. Ciò inizializza gli attributi ai loro valori predefiniti.
3. Modifica l'oggetto attributo per contenere i valori attributo desiderati.
4. Passa un puntatore all'oggetto attributo che hai valorizzato al punto di sopra quando ruchiami la `pthread_create()`.
5. Chiama la `pthread_attr_destroy()` per rilasciare l'oggetto attributo. La variabile `pthread_attr_t` non viene deallocata; può essere reinizializzata con `pthread_attr_init()`
  
Un singolo oggetto attributo thread può essere utilizzato per inizializzare diversi thread. Non è necessario mantenere l'oggetto attributo thread dopo che i thread sono stati creati.
Per la maggior parte delle attività di programmazione delle applicazioni GNU/Linux, un solo attributo thread è in genere di interesse (gli altri attributi disponibili sono principalmente per la programmazione in tempo reale).
Questo attributo è il **detach state** del thread. Un thread può essere creato come un thread **joinable** (l'impostazione predefinita) o come un **detached** thread. Un joinable thread, come un processo, non viene automaticamente ripulito da GNU/Linux quando termina e lo stato di uscita del thread rimane sospeso nel sistema (un po' come un processo zombie) finché un altro thread non richiama la `pthread_join()` per ottenere il suo valore di ritorno. **Solo allora le sue risorse vengono rilasciate**. Un **detached** thread, al contrario, viene ripulito automaticamente quando termina. Poiché un detache thread viene immediatamente ripulito, un altro thread potrebbe non sincronizzarsi al suo completamento tramite `pthread_join()` o ottenere il suo valore di ritorno.

Per impostare lo stato detacjed in un oggetto attributo thread, basta utilizzare `pthread_attr_setdetachstate()`.
Questo è il suo prototipo:

```c
int pthread_attr_setdetachstate(pthread_attr_t *attr, int detachstate);
```

Il primo argomento è un puntatore all'oggetto attributo thread (`pthread_attr_t *`) e il secondo è lo stato detached desiderato. Poiché lo stato joinable è quello predefinito, è necessario chiamare questo solo per creare detached thread passando `PTHREAD_CREATE_DETACHED` come secondo argomento.
Il codice di sotto crea un detached thread impostando l'attributo thread a `PTHREAD_CREATE_DETACHED`.

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <pthread.h>

void* thread_function (void* thread_arg)
{
  /* Do work here...  */
  return NULL;
}

int main ()
{
  pthread_attr_t attr;
  pthread_t thread;

  pthread_attr_init (&attr);
  pthread_attr_setdetachstate (&attr, PTHREAD_CREATE_DETACHED);
  pthread_create (&thread, &attr, &thread_function, NULL);
  pthread_attr_destroy (&attr);

  /* Do work here...  */

  /* No need to join the second thread.  */
  return 0;
}
```

Anche se un thread è stato creato con stato joinable può essere imopstato in un secondo momento nello stato detached, per fare questo basta usare la funzione `pthread_detach()`. Questo è il suo prototipo:

```c
int pthread_detach(pthread_t thread);
```

#### Cancellazione del thread

In circostanze normali, un thread termina quando esce normalmente, sia tornando dalla sua funzione thread o chiamando la `pthread_exit()`. Tuttavia, è possibile che un thread richieda che un altro thread termini. Questo è chiamato cancellamento di un thread. Per cancellare un thread, chiama la `pthread_cancel()`, passando l'ID del thread da cancellare. E' possibile richiamre la pthread_join() su un thread cancellato (di tipo joinable, non è possibile per un thread in stato detaced) per liberarne le risorse, Il valore di ritorno di un thread cancellato è il valore speciale `PTHREAD_CANCELED`.

Spesso un thread può essere in un codice che deve essere eseguito in modalità tutto o niente. Ad esempio, il thread può allocare alcune risorse, usarle e quindi deallocarle. Se il thread viene annullato nel mezzo di questo codice, potrebbe non avere l'opportunità di deallocare le risorse, e quindi le risorse saranno perse. Per contrastare questa possibilità, è possibile che un thread controlli se e quando può essere annullato. Un thread può trovarsi in uno dei tre stati per quanto riguarda la cancellazione del thread:

* Il thread può essere **cancellabile in modo asincrono**. Il thread può essere annullato in qualsiasi momento della sua esecuzione.
* Il thread può essere **cancellabile in modo sincrono**. Il thread può essere annullato, ma non in qualsiasi momento della sua esecuzione. Invece, le richieste di annullamento vengono messe in coda e il thread viene cancellato solo quando raggiunge punti specifici della sua esecuzione.
* Un thread può essere **non cancellabile**. I tentativi di cancellare 	il thread vengono ignorati silenziosamente.

**Quando viene creato inizialmente, un thread è cancellabile in modo sincrono**

#### Thread sincroni ed asincroni

Un thread cancellabile in modo asincrono può essere annullato in qualsiasi momento della sua esecuzione. Un thread cancellabile in modo sincrono, al contrario, può essere cancellato solo in determinati punti della sua esecuzione. Questi punti sono chiamati punti di annullamento. Il thread metterà in coda una richiesta di annullamento finché non raggiunge il punto di annullamento successivo. Per rendere un thread cancellabile in modo asincrono, utilizzare `pthread_setcanceltype()`. Questo è il suo prototipo:

```c
int pthread_setcanceltype(int type, int *oldtype);
```

Il primo argomento dovrebbe essere `PTHREAD_CANCEL_ASYNCHRONOUS` per rendere il thread cancellabile in modo asincrono o `PTHREAD_CANCEL_DEFERRED` per riportarlo allo stato cancellabile in modo sincrono. Il secondo argomento, se non è nullo, è un puntatore a una variabile che riceverà il tipo di annullamento precedente per il thread. Questa chiamata, ad esempio, rende il thread chiamante cancellabile in modo asincrono.

```c
pthread_setcanceltype (PTHREAD_CANCEL_ASYNCHRONOUS, NULL);
```

Cosa costituisce un punto di annullamento e dove dovrebbero essere posizionati? Il modo più diretto per creare un punto di annullamento è chiamare `pthread_testcancel()`. 

```c
void pthread_testcancel(void);
```
Questa funzione non fa altro che elaborare un annullamento in sospeso in un thread cancellabile in modo sincrono. Dovresti chiamare `pthread_testcancel()` periodicamente durante i calcoli lunghi in una funzione thread, nei punti in cui il thread può essere annullato senza perdere risorse o produrre altri effetti negativi. Anche alcune altre funzioni sono implicitamente punti di annullamento. Sono elencate nella pagina man di `pthread_cancel()`. Nota che altre funzioni possono utilizzare queste funzioni internamente e quindi saranno indirettamente punti di annullamento.		


#### Sezioni critiche non cancellabili

Un thread può disabilitare del tutto la cancellazione di se stesso con la funzione `pthread_setcancelstate()`. 

```c
int pthread_setcancelstate(int state, int *oldstate);
```

Il primo argomento è `PTHREAD_CANCEL_DISABLE` per disabilitare la cancellazione o `PTHREAD_CANCEL_ENABLE` per riabilitare la cancellazione. Il secondo argomento, se non è nullo,
punta a una variabile che riceverà lo stato di cancellazione precedente. Questa chiamata, ad esempio, disabilita l'annullamento del thread nel thread chiamante.

```c
pthread_setcancelstate (PTHREAD_CANCEL_DISABLE, NULL);
```

**L'utilizzo di `pthread_setcancelstate()` consente di implementare sezioni critiche**. Una **sezione critica** è una sequenza di codice che deve essere eseguita per intero o per niente; in altre parole, se un thread inizia a eseguire la sezione critica, deve continuare fino alla fine della sezione critica senza essere annullato. Ad esempio, supponiamo che tu stia scrivendo una routine per un programma bancario che trasferisce denaro da un conto a un altro. Per fare ciò, devi aggiungere valore al saldo di un conto e detrarre lo stesso valore dal saldo di un altro conto. Se il thread che esegue la tua routine venisse annullato proprio nel momento sbagliato tra queste due operazioni, il programma avrebbe aumentato in modo ingiusto i depositi totali della banca non riuscendo a completare la transazione. Per evitare questa possibilità, inserisci le due operazioni in una sezione critica. Potresti implementare il trasferimento con una funzione come `process_transaction()`, mostrata sotto. Questa funzione disabilita l'annullamento del thread per avviare una sezione critica prima che modifichi il saldo di uno dei due conti.

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <pthread.h>
#include <stdio.h>
#include <string.h>
#include <stdlib.h>

/* Parameters to process_transaction function.  */

struct thread_params {
 int from;
 int to;
 float dollars;
};

/* An array of balances in accounts, indexed by account number.  */

float* account_balances;

/* Transfer DOLLARS from account FROM_ACCT to account TO_ACCT.  Return
   0 if the transaction succeeded, or 1 if the balance FROM_ACCT is
   too small.  */

void* process_transaction (void *args)
{
  struct thread_params *p= (struct thread_params *)args;
  int from_acct = p->from;
  int to_acct = p->to;
  float dollars = p->dollars;

  int old_cancel_state;

  /* Check the balance in FROM_ACCT.  */
  if (account_balances[from_acct] < dollars)
    return (void *)1;

  /* Begin critical section.  */
  pthread_setcancelstate (PTHREAD_CANCEL_DISABLE, &old_cancel_state);
  /* Move the money.  */
  account_balances[to_acct] += dollars;
  account_balances[from_acct] -= dollars;
  /* End critical section.  */
  pthread_setcancelstate (old_cancel_state, NULL);

  return NULL;
}

int main() {
  pthread_t thread_id;
  int thread_return_value;

  struct thread_params p;
  p.from = 0;
  p.to = 5;
  p.dollars = 9;

  account_balances = (float *)malloc(10*sizeof(float));
  account_balances[0] = 100;
  account_balances[1] = 67;
  account_balances[2] = 78;
  account_balances[3] = 10;
  account_balances[4] = 93;
  account_balances[5] = 1;
  account_balances[6] = 46;
  account_balances[7] = 90;
  account_balances[8] = 34;
  account_balances[9] = 13;

  for(int i=0; i< 10; i++)
    printf("[%d] %1.f$\n", i, account_balances[i]);

  pthread_create (&thread_id, NULL, &process_transaction, &p);
  pthread_join (thread_id, (void *) &thread_return_value);

  printf("\n");
  for(int i=0; i< 10; i++)
    printf("[%d] %1.f$\n", i, account_balances[i]);

  return 0;
}
```

```bash
vagrant@ubuntu2204:/lab2/1_threads$ bin/5_critical_section
[0] 100$
[1] 67$
[2] 78$
[3] 10$
[4] 93$
[5] 1$
[6] 46$
[7] 90$
[8] 34$
[9] 13$

[0] 91$
[1] 67$
[2] 78$
[3] 10$
[4] 93$
[5] 10$
[6] 46$
[7] 90$
[8] 34$
[9] 13$
```

Si noti che è importante ripristinare il vecchio stato di annullamento alla fine della sezione critica piuttosto che impostarlo incondizionatamente su `PTHREAD_CANCEL_ENABLE`. Ciò consente di chiamare la funzione `process_transaction()` in modo sicuro da un'altra sezione critica, in quel caso la funzione setterà lo stato di annullamento nello stesso modo in cui lo ha trovato.


#### Quando usare la cancellazione del thread

In generale, è una buona idea non usare la cancellazione del thread per terminare l'esecuzione di un thread, tranne in circostanze insolite. Durante il normale funzionamento, una strategia migliore è quella di indicare al thread che dovrebbe uscire e quindi attendere che il thread esca da solo in modo ordinato. Per far questo è necessario conoscere le tecniche di IPC (Interprocess Communication).

### Dati specifici del thread

A differenza dei processi, **tutti i thread in un singolo programma condividono lo stesso spazio di indirizzamento**. Ciò significa che se un thread modifica una posizione nella memoria (ad esempio, una variabile globale), la modifica è visibile a tutti gli altri thread. Ciò consente a più thread di operare sugli stessi dati senza utilizzare meccanismi di comunicazione tra processi. Tuttavia, ogni thread ha il proprio stack di chiamate. Ciò consente a ogni thread di eseguire codice diverso e di chiamare e restituire da subroutine nel modo consueto. Come in un programma a thread singolo, ogni invocazione di una subroutine in ogni thread ha il proprio set di variabili locali, che vengono memorizzate nello stack per quel thread. A volte, tuttavia, è desiderabile duplicare una determinata variabile in modo che ogni thread abbia una copia separata. GNU/Linux supporta ciò **fornendo a ogni thread un'area dati specifica per il thread**. Le variabili memorizzate in quest'area vengono duplicate per ogni thread e ogni thread può modificare la propria copia di una variabile senza influenzare gli altri thread. Poiché tutti i thread condividono lo stesso spazio di memoria, **i dati specifici del thread potrebbero non essere accessibili tramite normali riferimenti alle variabili**. GNU/Linux fornisce funzioni speciali per impostare e recuperare valori dall'area dati specifica del thread.

Puoi creare tutti gli elementi dati specifici del thread che vuoi, ognuno di tipo void*.
Ogni elemento è referenziato da una chiave. Per creare una nuova chiave, e quindi un nuovo elemento dati per ogni thread, usa **pthread_key_create()**. 

```c
int pthread_key_create(pthread_key_t *key, void (*destructor)(void*));
```

Il primo argomento è un puntatore a una variabile di tipo **pthread_key_t**. Quel valore chiave può essere usato da ogni thread per accedere alla propria copia dell'elemento dati corrispondente. 
Il secondo argomento dopo pthread_key_t è una funzione di pulizia (cleanup function). Se passi un puntatore a funzione qui, GNU/Linux chiama automaticamente quella funzione quando il thread esce, passando il valore specifico del thread corrispondente
a quella chiave. Ciò è particolarmente utile perché la funzione di pulizia viene chiamata anche se il thread viene annullato in un punto arbitrario della sua esecuzione. Se il valore specifico del thread è null, la funzione di pulizia del thread non viene chiamata. Se non hai bisogno di una funzione di pulizia, puoi passare null invece di un puntatore a funzione. **Dopo aver creato una chiave**, **ogni thread può impostare il suo valore specifico del thread corrispondente a quella chiave** chiamando **pthread_setspecific()**.

```c
int pthread_setspecific(pthread_key_t key, const void *value);
```

Il primo argomento è la chiave e il secondo è il valore specifico del thread (di tipo void*) da memorizzare. Per recuperare un elemento dati specifico del thread, chiama **pthread_getspecific()**, passando la chiave come argomento. 

```c
void *pthread_getspecific(pthread_key_t key);
```

Supponiamo, ad esempio, che l'applicazione divida un'attività tra più thread. Ogni thread deve avere un file di registro separato, in cui vengono registrati i messaggi di avanzamento per le attività di quel thread. L'area dati specifica del thread è un posto comodo in cui memorizzare il puntatore del file per il file di registro per ogni singolo thread. 


```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <malloc.h>
#include <pthread.h>
#include <stdio.h>

/* The key used to assocate a log file pointer with each thread.  */
static pthread_key_t thread_log_key;

/* Write MESSAGE to the log file for the current thread.  */

void write_to_thread_log (const char* message)
{
  FILE* thread_log = (FILE*) pthread_getspecific (thread_log_key);
  fprintf (thread_log, "%s\n", message);
}

/* Close the log file pointer THREAD_LOG.  */

void close_thread_log (void* thread_log)
{
  fclose ((FILE*) thread_log);
}

void* thread_function (void* args)
{
  char thread_log_filename[20];
  FILE* thread_log;

  /* Generate the filename for this thread's log file.  */
  sprintf (thread_log_filename, "thread-%d.log", (int) pthread_self ());
  /* Open the log file.  */
  thread_log = fopen (thread_log_filename, "w");
  /* Store the file pointer in thread-specific data under thread_log_key.  */
  pthread_setspecific (thread_log_key, thread_log);

  write_to_thread_log ("Thread starting.");
  char string_log[20];
  sprintf (string_log, "My ID is %d", (int) pthread_self ());
  write_to_thread_log (string_log);


  return NULL;
}

int main ()
{
  int i;
  pthread_t threads[5];

  /* Create a key to associate thread log file pointers in
     thread-specific data.  Use close_thread_log to clean up the file
     pointers.  */
  pthread_key_create (&thread_log_key, close_thread_log);
  /* Create threads to do the work.  */
  for (i = 0; i < 5; ++i)
    pthread_create (&(threads[i]), NULL, thread_function, NULL);
  /* Wait for all threads to finish.  */
  for (i = 0; i < 5; ++i)
    pthread_join (threads[i], NULL);
  return 0;
}
```


La funzione principale in questo programma di esempio crea una chiave per memorizzare il puntatore del file specifico del thread e quindi lo memorizza in **thread_log_key**. Poiché si tratta di una variabile globale, è condivisa da tutti i thread. Quando ogni thread inizia a eseguire la sua funzione thread, apre un file di registro e memorizza il puntatore del file sotto quella chiave. In seguito, uno qualsiasi di questi thread può chiamare **write_to_thread_log()** per scrivere un messaggio nel file di registro specifico del thread. Tale funzione recupera il puntatore del file per il file di registro del thread dai dati specifici del thread e scrive il messaggio.

Si noti che **thread_function()** non ha bisogno di chiudere il file di registro. Questo perché quando è stata creata la chiave del file di registro, **close_thread_log()** è stato specificato come funzione di pulizia per quella chiave. Ogni volta che un thread esce, GNU/Linux chiama quella funzione, passando il valore specifico del thread per la chiave del registro del thread. Questa funzione si occupa di chiudere il file di registro.

### Gestori di pulizia (Cleanup Handler)

Le funzioni di pulizia per chiavi dati specifiche del thread possono essere molto utili per garantire che le risorse non vengano perse quando un thread esce o viene annullato. A volte, tuttavia, è utile poter specificare funzioni di pulizia senza creare un nuovo elemento dati specifico del thread duplicato per ogni thread. GNU/Linux fornisce gestori di pulizia a questo scopo. **Un gestore di pulizia è semplicemente una funzione che dovrebbe essere chiamata quando un thread esce**. Il gestore accetta un singolo parametro void* e il suo valore di argomento viene fornito quando il gestore viene registrato, il che semplifica l'utilizzo della stessa funzione del gestore per gestire più istanze di risorse. **Un gestore di pulizia è una misura temporanea**, **utilizzata per deallocare una risorsa solo se il thread esce o viene annullato** anziché terminare l'esecuzione di una particolare regione di codice. **In circostanze normali, quando il thread non esce e non viene annullato, la risorsa dovrebbe essere deallocata in modo esplicito** e il gestore di pulizia dovrebbe essere rimosso. Per registrare un gestore di pulizia, chiama **pthread_cleanup_push()**, passando un puntatore alla funzione di pulizia e il valore del suo argomento void*. La chiamata a pthread_cleanup_push deve essere bilanciata da una chiamata corrispondente a pthread_cleanup_pop, che annulla la registrazione del gestore di pulizia. 

```c
void pthread_cleanup_push(void (*routine)(void *), void *arg);
```

```c
void pthread_cleanup_pop(int execute);
```

Per comodità, pthread_cleanup_pop accetta un argomento flag int; se il flag è diverso da zero, l'azione di pulizia viene effettivamente eseguita in quanto annullata. Il frammento di programma di sotto mostra come è possibile utilizzare un gestore di pulizia per assicurarsi che un buffer allocato dinamicamente venga ripulito se il thread termina.

```c
***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/
#include <stdio.h>
#include <malloc.h>
#include <pthread.h>

/* Allocate a temporary buffer.  */

void* allocate_buffer (size_t size)
{
  return malloc (size);
}

/* Deallocate a temporary buffer.  */

void deallocate_buffer (void* buffer)
{
  printf("Called cleanup handler function\n");
  free (buffer);
}

void* do_some_work ()
{
  /* Allocate a temporary buffer.  */
  void* temp_buffer = allocate_buffer (1024);
  /* Register a cleanup handler for this buffer, to deallocate it in
     case the thread exits or is cancelled.  */
  pthread_cleanup_push (deallocate_buffer, temp_buffer);

  /* Do some work here that might call pthread_exit or might be
     cancelled...  */
  pthread_exit(0);
  /* Unregister the cleanup handler.  Since we pass a non-zero value,
     this actually performs the cleanup by calling
     deallocate_buffer.  */
  pthread_cleanup_pop (1);

  return NULL;
}

int main(void){
  pthread_t allocator_thread;
  pthread_create(&allocator_thread, NULL, do_some_work, NULL);
  pthread_join(allocator_thread, NULL);
  return 0;

}
```

### Sincronizzazione e Sezioni Critiche

La programmazione con i thread è molto complicata perché la maggior parte dei programmi con thread sono programmi concorrenti. In particolare, non c'è modo di sapere quando il sistema pianificherà l'esecuzione di un thread e quando ne eseguirà un altro. Un thread potrebbe essere eseguito per un tempo molto lungo o il sistema potrebbe passare da un thread all'altro molto rapidamente. Su un sistema con più processori, il sistema potrebbe persino pianificare l'esecuzione di più thread letteralmente nello stesso momento. Il debug di un programma con thread è difficile perché non è sempre possibile riprodurre facilmente il comportamento che ha causato il problema. Potresti eseguire il programma una volta e far funzionare tutto correttamente; la volta successiva che lo esegui, potrebbe bloccarsi. Non c'è modo di far pianificare i thread esattamente nello stesso modo in cui lo faceva prima.

La causa ultima della maggior parte dei bug che coinvolgono i thread è che **i thread accedono agli stessi dati**. Come accennato in precedenza, questo è uno degli aspetti più potenti dei thread, ma può anche essere pericoloso. Se un thread è solo a metà dell'aggiornamento di una struttura dati quando un altro thread accede alla stessa struttura dati, è probabile che si verifichi il caos. Spesso, i programmi con thread buggati contengono un codice che funzionerà solo se un thread viene pianificato più spesso, o prima, di un altro thread. Questi bug sono chiamati **race conditions**; i thread sono in competizione tra loro per modificare la stessa struttura dati.

#### Race Conditions

Supponiamo che il tuo programma abbia una serie di lavori in coda che vengono elaborati da diversi thread simultanei. La coda dei lavori è rappresentata da una lista di oggetti struct job. Dopo che ogni thread termina un'operazione, controlla la coda per vedere se è disponibile un lavoro aggiuntivo. Se job_queue è diverso da null, il thread rimuove la testa dell'elenco collegato e imposta job_queue sul lavoro successivo nell'elenco.

Ora supponiamo che due thread finiscano un lavoro più o meno nello stesso momento, ma che solo un lavoro rimanga nella coda. Il primo thread controlla se job_queue è nullo; scoprendo che non lo è, il thread entra nel ciclo e memorizza il puntatore all'oggetto lavoro in next_job. A questo punto, Linux interrompe il primo thread e pianifica il secondo. Anche il secondo thread controlla job_queue e, trovandolo non nullo, assegna lo stesso puntatore lavoro a next_job. Per una sfortunata coincidenza, ora abbiamo due thread che eseguono lo stesso lavoro. A peggiorare le cose, un thread scollegherà l'oggetto lavoro dalla coda, lasciando job_queue contenente null. Quando l'altro thread valuta job_queue->next, si verificherà un errore di segmentazione. Questo è un esempio di condizione di gara. In circostanze "fortunate", questa particolare pianificazione dei due thread potrebbe non verificarsi mai e la condizione di gara potrebbe non manifestarsi mai. Solo in circostanze diverse, magari quando si esegue su un sistema pesantemente caricato (o sul nuovo server multiprocessore di un cliente importante!) il bug può manifestarsi. Per eliminare le **race conditions**, è necessario un modo per **rendere le operazioni atomiche**. **Un'operazione atomica è indivisibile e ininterrotta; una volta avviata, non verrà messa in pausa o interrotta fino al suo completamento e nel frattempo non verrà eseguita nessun'altra operazione**. In questo particolare esempio, si desidera controllare job_queue; se non è vuoto, rimuovere il primo lavoro, il tutto come un'unica operazione atomica.

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <malloc.h>
#include <pthread.h>

struct job {
  /* Link field for linked list.  */
  struct job* next;
  char *message;
  /* Other fields describing work to be done... */
};

/* A linked list of pending jobs.  */
struct job* job_queue;

void process_job (struct job* tmp){
  char print_me[20];
  printf("Thread %ld completed job %s \n", pthread_self(), tmp->message);
}

/* Process queued jobs until the queue is empty.  */

void* thread_function (void* arg)
{
  while (job_queue != NULL) {
    /* Get the next available job.  */
    struct job* next_job = job_queue;
    /* Remove this job from the list.  */
    job_queue = job_queue->next;
    /* Carry out the work.  */
    process_job (next_job);
    /* Clean up.  */
    free (next_job);
  }
  return NULL;
}

int main(void){
  struct job *one   = (struct job *) malloc(sizeof(struct job));
  struct job *two   = (struct job *) malloc(sizeof(struct job));
  struct job *three = (struct job *) malloc(sizeof(struct job));

  one->message   = "1";
  two->message   = "2";
  three->message = "3";

  job_queue = (struct job *) malloc(sizeof(struct job));
  job_queue->message = "4";
  job_queue->next = three;

  three->next = two;
  two->next = one;
  one->next = NULL;


  pthread_t first;
  pthread_t second;

  pthread_create(&first, NULL, thread_function, NULL);
  pthread_create(&second, NULL, thread_function, NULL);

  pthread_join(first, NULL);
  pthread_join(second, NULL);

  return 0;
}
```


### Mutex

La soluzione al problema della race condition della coda dei lavori è consentire a un solo thread alla volta di accedere alla coda dei lavori. Una volta che un thread inizia a guardare la coda, nessun altro thread dovrebbe essere in grado di accedervi finché il primo thread non ha deciso se elaborare un lavoro e, in tal caso, lo ha rimosso dall'elenco. L'implementazione richiede il supporto del sistema operativo. GNU/Linux fornisce i **mutex**, abbreviazione di blocchi MUTual EXclusion. Un mutex è un blocco speciale che solo un thread può bloccare alla volta. Se un thread blocca un mutex e poi un secondo thread tenta di bloccare lo stesso mutex, il secondo thread viene bloccato o messo in attesa. Solo quando il primo thread sblocca il mutex, il secondo thread viene sbloccato, ovvero può riprendere l'esecuzione. GNU/Linux garantisce che non si verifichino condizioni di gara tra thread che tentano di bloccare un mutex; solo un thread otterrà il blocco e tutti gli altri thread verranno bloccati. Pensa a un mutex come alla serratura di una porta del bagno. Chi arriva per primo entra nel bagno e chiude a chiave la porta. Se qualcun altro tenta di entrare nel bagno mentre è occupato, quella persona troverà la porta chiusa a chiave e sarà costretta ad aspettare fuori finché l'occupante non esce. Per creare un mutex, crea una variabile di tipo **pthread_mutex_t** e passa un puntatore a **pthread_mutex_init()**. Il secondo argomento di pthread_mutex_init è un puntatore a un oggetto attributo mutex, che specifica gli attributi del mutex.

```c
int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr);
```

Come con pthread_create, se il puntatore dell'attributo è nullo, vengono assunti gli attributi predefiniti. La variabile mutex dovrebbe essere inizializzata solo una volta. Questo frammento di codice dimostra la dichiarazione e l'inizializzazione di una variabile mutex.

```c
pthread_mutex_t mutex;
pthread_mutex_init (&mutex, NULL);
```

Un altro modo più semplice per creare un mutex con attributi predefiniti è inizializzarlo con il valore speciale `PTHREAD_MUTEX_INITIALIZER`. Non è necessaria alcuna chiamata aggiuntiva a pthread_mutex_init. Ciò è particolarmente comodo per le variabili globali
(e, in C++, i membri dati statici). Il frammento di codice precedente avrebbe potuto essere scritto in modo equivalente così:

```c
pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;
```

Un thread può tentare di bloccare un mutex chiamando **pthread_mutex_lock()** su di esso. 

* **Se il mutex è in stato sbloccato, diventa bloccato e la funzione ritorna immediatamente**
* **Se il mutex è in stato bloccato da un altro thread, pthread_mutex_lock blocca l'esecuzione e restituisce solo alla fine quando il mutex viene sbloccato dall'altro thread**.

Più di un thread può essere bloccato su un mutex bloccato contemporaneamente. Quando il mutex viene sbloccato, solo uno dei thread bloccati (scelto in modo imprevedibile) viene sbloccato e gli viene consentito di bloccare il mutex; gli altri thread rimangono bloccati.
Una chiamata a **pthread_mutex_unlock()** sblocca un mutex. Questa funzione dovrebbe essere sempre chiamata dallo stesso thread che ha bloccato il mutex.
L'esempio seguente mostra un'altra versione dell'esempio di coda di lavoro. Ora la coda è protetta da un mutex. Prima di accedere alla coda (sia per lettura che per scrittura), ogni thread blocca prima un mutex. Solo quando l'intera sequenza di controllo della coda e
rimozione di un lavoro è completa, il mutex viene sbloccato. Ciò impedisce la race condition descritta in precedenza.

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <malloc.h>
#include <pthread.h>

struct job {
  /* Link field for linked list.  */
  struct job* next;
  char *message;
  /* Other fields describing work to be done... */
};

/* A linked list of pending jobs.  */
struct job* job_queue;

void process_job (struct job* tmp){
  char print_me[20];
  printf("Thread %ld completed job %s \n", pthread_self(), tmp->message);
}

/* A mutex protecting job_queue.  */
pthread_mutex_t job_queue_mutex = PTHREAD_MUTEX_INITIALIZER;

/* Process queued jobs until the queue is empty.  */

void* thread_function (void* arg)
{
  while (1) {
    struct job* next_job;

    /* Lock the mutex on the job queue.  */
    pthread_mutex_lock (&job_queue_mutex);
    /* Now it's safe to check if the queue is empty.  */
    if (job_queue == NULL)
      next_job = NULL;
    else {
      /* Get the next available job.  */
      next_job = job_queue;
      /* Remove this job from the list.  */
      job_queue = job_queue->next;
    }
    /* Unlock the mutex on the job queue, since we're done with the
       queue for now.  */
    pthread_mutex_unlock (&job_queue_mutex);

    /* Was the queue empty?  If so, end the thread.  */
    if (next_job == NULL)
      break;

    /* Carry out the work.  */
    process_job (next_job);
    /* Clean up.  */
    free (next_job);
  }
  return NULL;
}


int main(void){
  struct job *one   = (struct job *) malloc(sizeof(struct job));
  struct job *two   = (struct job *) malloc(sizeof(struct job));
  struct job *three = (struct job *) malloc(sizeof(struct job));

  one->message   = "1";
  two->message   = "2";
  three->message = "3";

  job_queue = (struct job *) malloc(sizeof(struct job));
  job_queue->message = "4";
  job_queue->next = three;

  three->next = two;
  two->next = one;
  one->next = NULL;


  pthread_t first;
  pthread_t second;

  pthread_create(&first, NULL, thread_function, NULL);
  pthread_create(&second, NULL, thread_function, NULL);

  pthread_join(first, NULL);
  pthread_join(second, NULL);

  return 0;
}
```

Tutti gli accessi a job_queue (il puntatore dati condiviso) avvengono tra la chiamata a pthread_mutex_lock e la chiamata a pthread_mutex_unlock. Un oggetto job, memorizzato in next_job, è accessibile al di fuori di questa regione solo dopo che l'oggetto è stato rimosso dalla coda ed è quindi inaccessibile ad altri thread. Nota che se la coda è vuota (ovvero, job_queue è null), non usciamo immediatamente dal ciclo perché ciò lascerebbe il mutex bloccato in modo permanente e impedirebbe a qualsiasi altro thread di accedere di nuovo alla coda job. Invece, ricordiamo questo fatto impostando next_job su null ed usciamo solo dopo aver sbloccato il mutex. L'uso del mutex per bloccare job_queue non è automatico; spetta a te aggiungere codice per bloccare il mutex prima di accedere a quella variabile e quindi sbloccarlo in seguito. Ad esempio, una funzione per aggiungere un job alla coda job potrebbe apparire così:


```c
 void enqueue_job (struct job* new_job)
 {
   pthread_mutex_lock (&job_queue_mutex);
   new_job->next = job_queue;
   job_queue = new_job;
   pthread_mutex_unlock (&job_queue_mutex);
}
```

### Mutex Deadlocks

I mutex forniscono un meccanismo per consentire a un thread di bloccare l'esecuzione di un altro. Ciò apre la possibilità di **una nuova classe di bug**, chiamati **deadlock**. **Un deadlock si verifica quando uno o più thread sono bloccati in attesa di qualcosa che non si verificherà mai. Un semplice tipo di deadlock può verificarsi quando lo stesso thread tenta di bloccare un mutex due volte di seguito. Il comportamento in questo caso dipende dal tipo di mutex utilizzato. Esistono tre tipi di mutex:

* Il blocco di un mutex veloce (il tipo predefinito) causerà il verificarsi di un deadlock. Un tentativo di bloccare il mutex si blocca finché il mutex non viene sbloccato. Ma poiché il thread che ha bloccato il mutex è bloccato sullo stesso mutex, il blocco non può
mai essere rilasciato.
* Il blocco di un mutex ricorsivo non causa un deadlock. Un mutex ricorsivo può essere bloccato in modo sicuro più volte dallo stesso thread. Il mutex ricorda quante volte pthread_mutex_lock è stato chiamato su di esso dal thread che detiene il blocco; quel thread deve effettuare lo stesso numero di chiamate a pthread_mutex_unlock prima che il mutex venga effettivamente sbloccato e un altro thread possa bloccarlo.
* GNU/Linux rileverà e contrassegnerà un doppio blocco su un mutex di controllo degli errori che altrimenti causerebbe un deadlock. La seconda chiamata consecutiva a pthread_mutex_lock restituisce il codice di errore `EDEADLK`.

Per impostazione predefinita, un mutex GNU/Linux è del tipo veloce. Per creare un mutex di uno degli altri due tipi, crea prima un oggetto attributo mutex dichiarando una variabile **pthread_mutexattr_t** e chiamando **pthread_mutexattr_init()**.
Poi setta il tipo di mutex chiamando  **pthread_mutexattr_setkind_np()**.

```c
int pthread_mutexattr_setkind_np(pthread_mutexattr_t *attr, int kind);
```

Il primo argomento è un puntatore all'oggetto attributo mutex, e il secondo è `PTHREAD_MUTEX_RECURSIVE_NP` per un mutex ricorsivo, o `PTHREAD_MUTEX_ERRORCHECK_NP` per un mutex di controllo degli errori. Passa un puntatore a questo oggetto attributo a
**pthread_mutex_init()** per creare un mutex di questo tipo, quindi distruggi l'oggetto attributo con **pthread_mutexattr_destroy()**. Questa sequenza di codice illustra la creazione di un mutex di controllo degli errori, ad esempio:

```c
 pthread_mutexattr_t attr;
 pthread_mutex_t mutex;
 pthread_mutexattr_init (&attr);
 pthread_mutexattr_setkind_np (&attr, PTHREAD_MUTEX_ERRORCHECK_NP);
 pthread_mutex_init (&mutex, &attr);
 pthread_mutexattr_destroy (&attr);
```

Come suggerito dal suffisso "np", i tipi di mutex ricorsivi e di controllo degli errori sono specifici di GNU/Linux e non sono portabili. Pertanto, in genere non è consigliabile utilizzarli nei programmi. (Tuttavia, i mutex di controllo degli errori possono essere utili durante il debug.)

### Test Mutex non bloccanti

A volte, è utile verificare se un mutex è bloccato senza effettivamente bloccarlo. Ad esempio, un thread potrebbe dover bloccare un mutex ma potrebbe avere altro lavoro da fare invece di bloccare se il mutex è già bloccato. Poiché **pthread_mutex_lock()** non
tornerà finché il mutex non sarà sbloccato, è necessaria un'altra funzione. GNU/Linux fornisce **pthread_mutex_trylock()** per questo scopo. Se chiami pthread_mutex_trylock su un mutex sbloccato, bloccherai il mutex come se avessi chiamato pthread_mutex_lock e pthread_mutex_trylock restituirà zero. Tuttavia, se il mutex è già bloccato da un altro thread, pthread_mutex_trylock non bloccherà. Invece, tornerà immediatamente con il codice di errore `EBUSY`. Il blocco del mutex mantenuto dall'altro thread non è interessato. Puoi provare di nuovo più tardi a bloccare il mutex.

### Semafori

Nell'esempio precedente, in cui diversi thread elaborano i lavori da una coda, la funzione thread principale dei thread esegue il lavoro successivo finché non ci sono più lavori e quindi esce dal thread. Questo schema funziona se tutti i lavori vengono messi in coda in anticipo o se i nuovi lavori vengono messi in coda almeno con la stessa rapidità con cui i thread li elaborano. Tuttavia, se i thread lavorano troppo velocemente, la coda dei lavori si svuoterà e i thread usciranno. Se in seguito vengono messi in coda nuovi lavori, non ci saranno più thread che li elaborino. Ciò che potremmo invece desiderare è un meccanismo per bloccare i thread quando la coda si svuota finché non diventano disponibili nuovi lavori. Un semaforo fornisce un metodo conveniente per farlo. **Un semaforo è un contatore** che può essere **utilizzato per sincronizzare più thread**. Come con un mutex, GNU/Linux garantisce che il controllo o la modifica del valore di un semaforo può essere eseguito in modo sicuro, senza creare una condizione di competizione. **Ogni semaforo ha un valore contatore**, che è **un intero non negativo**. Un semaforo supporta due operazioni di base:

* Un'operazione di attesa decrementa il valore del semaforo di 1. Se il valore è già zero, l'operazione si blocca finché il valore del semaforo non diventa positivo (a causa dell'azione di un altro thread). Quando il valore del semaforo diventa positivo, viene decrementato di 1 e l'operazione di attesa ritorna.
* Un'operazione di post incrementa il valore del semaforo di 1. Se il semaforo era precedentemente zero e altri thread sono bloccati in un'operazione di attesa su quel semaforo, uno di quei thread viene sbloccato e la sua operazione di attesa viene completata (il che riporta il valore del semaforo a zero)

Nota che GNU/Linux fornisce due implementazioni di semafori leggermente diverse. Quella che descriviamo qui è l'implementazione standard del semaforo POSIX. Usa questi semafori quando comunichi tra thread.
L'altra implementazione, usata per la comunicazione tra processi,  Se usi i semafori, includi **<semaphore.h>**.
Un semaforo è rappresentato da una variabile **sem_t**. Prima di usarla, devi inizializzarla usando la funzione **sem_init()**, passando un puntatore alla variabile sem_t. Il secondo parametro dovrebbe essere zero (Un valore diverso da zero indicherebbe un semaforo che può essere condiviso tra i processi, il che non è supportato da GNU/Linux per questo tipo di semaforo) e il terzo parametro è il valore iniziale del semaforo. 

```c
int sem_init(sem_t *sem, int pshared, unsigned int value);
```

Se non hai più bisogno di un semaforo, è bene deallocarlo con **sem_destroy()**.


Per attendere un semaforo, usa **sem_wait()**. 

```c
int sem_wait(sem_t *sem);
```

Per inviare a un semaforo, usa **sem_post()**.

```c
int sem_post(sem_t *sem);
```

Viene fornita anche una funzione di attesa non bloccante, **sem_trywait()**. È simile a pthread_mutex_trylock: se l'attesa si fosse bloccata perché il valore del semaforo era zero, la funzione restituisce immediatamente, con il valore di errore `EAGAIN`, invece di
bloccare.

```c
int sem_trywait(sem_t *sem);
```

GNU/Linux fornisce anche una funzione per recuperare il valore corrente di un semaforo, **sem_getvalue()**, che inserisce il valore nella variabile int puntata dal suo secondo argomento. 

```c
int sem_getvalue(sem_t *sem, int *sval);
```

Tuttavia, non dovresti usare il valore del semaforo che ottieni da questa funzione per prendere una decisione se inviare o attendere il semaforo. Ciò potrebbe portare
a una race condition: un altro thread potrebbe modificare il valore del semaforo tra la chiamata a sem_getvalue e la chiamata a un'altra funzione del semaforo. Utilizza invece le funzioni atomiche di post e attesa.
Tornando al nostro esempio di coda di lavoro, possiamo usare un semaforo per contare il numero di lavori in attesa nella coda. L'esempio seguente controlla la coda con un semaforo. La funzione enqueue_job aggiunge un nuovo job alla coda.

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <malloc.h>
#include <pthread.h>
#include <semaphore.h>
#include <unistd.h> // sleep

struct job {
  /* Link field for linked list.  */
  struct job* next;
  char *message;
  /* Other fields describing work to be done... */
};

/* A linked list of pending jobs.  */
struct job* job_queue;

void process_job (struct job* tmp){
  char print_me[20];
  printf("Thread %ld completed job %s \n", pthread_self(), tmp->message);
}

/* A mutex protecting job_queue.  */
pthread_mutex_t job_queue_mutex = PTHREAD_MUTEX_INITIALIZER;

/* A semaphore counting the number of jobs in the queue.  */
sem_t job_queue_count;

/* Perform one-time initialization of the job queue.  */

void initialize_job_queue ()
{
  /* The queue is initially empty.  */
  job_queue = NULL;
  /* Initialize the semaphore which counts jobs in the queue.  Its
     initial value should be zero.  */
  sem_init (&job_queue_count, 0, 0);
}

/* Process queued jobs until the queue is empty.  */

void* thread_function (void* arg)
{
  while (1) {
    struct job* next_job;

    /* Wait on the job queue semaphore.  If its value is positive,
       indicating that the queue is not empty, decrement the count by
       one.  If the queue is empty, block until a new job is enqueued.  */
    sem_wait (&job_queue_count);

    /* Lock the mutex on the job queue.  */
    pthread_mutex_lock (&job_queue_mutex);
    /* Because of the semaphore, we know the queue is not empty.  Get
       the next available job.  */
    next_job = job_queue;
    /* Remove this job from the list.  */
    job_queue = job_queue->next;
    /* Unlock the mutex on the job queue, since we're done with the
       queue for now.  */
    pthread_mutex_unlock (&job_queue_mutex);

    /* Carry out the work.  */
    process_job (next_job);
    /* Clean up.  */
    free (next_job);
  }
  return NULL;
}

/* Add a new job to the front of the job queue.  */

void enqueue_job (char *message)
{
  struct job* new_job;

  /* Allocate a new job object.  */
  new_job = (struct job*) malloc (sizeof (struct job));
  /* Set the other fields of the job struct here...  */
  new_job->message = message;

  /* Lock the mutex on the job queue before accessing it.  */
  pthread_mutex_lock (&job_queue_mutex);
  /* Place the new job at the head of the queue.  */
  new_job->next = job_queue;
  job_queue = new_job;

  /* Post to the semaphore to indicate another job is available.  If
     threads are blocked, waiting on the semaphore, one will become
     unblocked so it can process the job.  */
  sem_post (&job_queue_count);

  /* Unlock the job queue mutex.  */
  pthread_mutex_unlock (&job_queue_mutex);
}


int main(void){

  enqueue_job("1");
  enqueue_job("2");
  enqueue_job("3");
  enqueue_job("4");

  pthread_t first;
  pthread_t second;

  pthread_create(&first, NULL, thread_function, NULL);
  pthread_create(&second, NULL, thread_function, NULL);

  sleep(60);


  enqueue_job("5");
  enqueue_job("6");
  enqueue_job("7");
  enqueue_job("8");

  pthread_join(first, NULL);
  pthread_join(second, NULL);

  return 0;
}
```

Prima di prendere un lavoro dalla parte anteriore della coda, ogni thread attenderà prima sul semaforo. Se il valore del semaforo è zero, indicando che la coda è vuota, il thread si bloccherà semplicemente finché il valore del semaforo non diventerà positivo, indicando che un lavoro è stato aggiunto alla coda. La funzione enqueue_job aggiunge un lavoro alla coda. Proprio come thread_function, deve bloccare il mutex della coda prima di modificare la coda. Dopo aver aggiunto un lavoro alla coda, invia un post al semaforo, indicando che un nuovo lavoro è disponibile. In questa implementazione i thread che elaborano i lavori non escono mai; se nessun lavoro è disponibile per un po', tutti i thread si bloccano semplicemente in sem_wait.

### Variabili di condizione

Abbiamo mostrato come usare un mutex per proteggere una variabile dall'accesso simultaneo da due thread e come usare i semafori per implementare un contatore condiviso. Una **variabile di condizione** è un terzo dispositivo di sincronizzazione fornito da GNU/Linux; con essa, puoi implementare condizioni più complesse in base alle quali i thread vengono eseguiti. Supponiamo di scrivere una funzione thread che esegue un ciclo all'infinito, eseguendo un po' di lavoro a ogni iterazione. Il ciclo thread, tuttavia, deve essere controllato da un flag: il ciclo viene eseguito solo quando il flag è impostato; quando il flag non è impostato, il ciclo si interrompe.
Durante ogni iterazione del ciclo, la funzione thread verifica che il flag sia impostato. Poiché il flag è accessibile da più thread, è protetto da un mutex. Questa implementazione potrebbe essere corretta, ma non è efficiente. La funzione thread impiegherà molta CPU
ogni volta che il flag non è impostato, controllando e ricontrollando il flag, ogni volta bloccando e sbloccando il mutex. Ciò che si desidera realmente è un modo per mettere il thread in modalità sleep quando il flag non è impostato, finché non cambiano alcune circostanze che potrebbero causare l'impostazione del flag.

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <pthread.h>

extern void do_work ();

int thread_flag;
pthread_mutex_t thread_flag_mutex;

void initialize_flag ()
{
  pthread_mutex_init (&thread_flag_mutex, NULL);
  thread_flag = 0;
}

/* Calls do_work repeatedly while the thread flag is set; otherwise
   spins.  */

void* thread_function (void* thread_arg)
{
  while (1) {
    int flag_is_set;

    /* Protect the flag with a mutex lock.  */
    pthread_mutex_lock (&thread_flag_mutex);
    flag_is_set = thread_flag;
    pthread_mutex_unlock (&thread_flag_mutex);

    if (flag_is_set)
      do_work ();
    /* Else don't do anything.  Just loop again.  */
  }
  return NULL;
}

/* Sets the value of the thread flag to FLAG_VALUE.  */

void set_thread_flag (int flag_value)
{
  /* Protect the flag with a mutex lock.  */
  pthread_mutex_lock (&thread_flag_mutex);
  thread_flag = flag_value;
  pthread_mutex_unlock (&thread_flag_mutex);
}
```

Una variabile di condizione consente di implementare una condizione in base alla quale un thread viene eseguito e, inversamente, la condizione in base alla quale il thread viene bloccato. Finché ogni thread che potenzialmente modifica il senso della condizione utilizza la variabile di condizione correttamente, Linux garantisce che i thread bloccati sulla condizione verranno sbloccati quando la condizione cambia. Come con un semaforo, un thread può attendere una variabile di condizione. Se il thread A attende una variabile di condizione, viene bloccato finché un altro thread, il thread B, segnala la stessa variabile di condizione. A differenza di un semaforo, una variabile di condizione non ha un contatore o una memoria; il thread A deve attendere la variabile di condizione prima che il thread B la segnali. Se il thread B segnala la variabile di condizione prima che il thread A la attenda, il segnale viene perso e il thread A si blocca finché un altro thread non segnala di nuovo la variabile di condizione. Ecco come utilizzeresti una variabile di condizione per rendere più efficiente l'esempio precedente:

* Il ciclo in **thread_function** controlla il flag. Se il flag non è impostato, il thread attende la variabile di condizione.
* La funzione **set_thread_flag** segnala la variabile di condizione dopo aver modificato il valore del flag. In questo modo, se thread_function è bloccato sulla variabile di condizione, verrà sbloccato e controllerà di nuovo la condizione.

C'è un problema con questo: c'è una condizione di competizione tra il controllo del valore del flag e la segnalazione o l'attesa della variabile di condizione. Supponiamo che thread_function abbia controllato il flag e abbia scoperto che non era impostato. In quel momento, lo scheduler di Linux ha messo in pausa quel thread e ha ripreso quello principale. Per una coincidenza, il thread principale è in set_thread_flag. Imposta il flag e quindi segnala la variabile di condizione. Poiché nessun thread è in attesa della variabile di condizione in quel momento (ricorda che thread_function è stato messo in pausa prima di poter attendere la variabile di condizione), il segnale viene perso. Ora, quando Linux riprogramma l'altro thread, inizia ad attendere la variabile di condizione e potrebbe finire bloccato per sempre. Per risolvere questo problema, abbiamo bisogno di un modo per bloccare il flag e la variabile di condizione insieme con un singolo mutex. Fortunatamente, GNU/Linux fornisce esattamente questo meccanismo. Ogni variabile di condizione deve essere utilizzata insieme a un mutex, per impedire questo tipo di race condition. Utilizzando questo schema, la funzione thread segue questi passaggi:

1. Il ciclo in thread_function blocca il mutex e legge il valore del flag.
2. Se il flag è impostato, sblocca il mutex ed esegue la funzione di lavoro.
3. Se il flag non è impostato, sblocca atomicamente il mutex e attende la variabile di condizione.

La caratteristica critica qui è nel passaggio 3, in cui GNU/Linux consente di sbloccare il mutex e attendere la variabile di condizione atomicamente, senza la possibilità che un altro thread intervenga. Ciò elimina la possibilità che un altro thread possa
modificare il valore del flag e segnalare la variabile di condizione tra il test del valore del flag e l'attesa della variabile di condizione di thread_function

Una variabile di condizione è rappresentata da un'istanza di **pthread_cond_t**. Ricorda che **ogni variabile di condizione deve essere accompagnata da un mutex**. Queste sono le funzioni che manipolano le variabili di condizione:

* **pthread_cond_init()** inizializza una variabile di condizione. Il primo argomento è un puntatore a un'istanza di pthread_cond_t. Il secondo argomento, un puntatore a un oggetto attributo di variabile di condizione, viene ignorato in GNU/Linux.
   Il mutex deve essere inizializzato separatamente
   ```c
   int pthread_cond_init(pthread_cond_t *restrict cond, const pthread_condattr_t *restrict attr);
   ```
* **pthread_cond_signal()** segnala una variabile di condizione. Un singolo thread bloccato sulla variabile di condizione verrà sbloccato. Se nessun altro thread è bloccato sulla variabile di condizione, il segnale viene ignorato. L'argomento è un puntatore all'istanza di
  pthread_cond_t. Una chiamata simile, **pthread_cond_broadcast()**, sblocca tutti i thread bloccati sulla variabile di condizione, invece di uno solo.

  ```c
  int pthread_cond_signal(pthread_cond_t *cond);
  ```

  ```c
  int pthread_cond_broadcast(pthread_cond_t *cond);
  ```
* **pthread_cond_wait()** blocca il thread chiamante finché la variabile di condizione non viene segnalata. L'argomento è un puntatore all'istanza pthread_cond_t. Il secondo argomento è un puntatore all'istanza del mutex pthread_mutex_t. Quando viene chiamata pthread_cond_wait, il mutex deve essere già bloccato dal thread chiamante. Quella funzione sblocca atomicamente il mutex e blocca la variabile di condizione. Quando la variabile di condizione viene segnalata e il thread chiamante si sblocca, pthread_cond_wait riacquisisce automaticamente un blocco sul mutex.
  ```c
  int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex);
  ```
  
Ogni volta che il programma esegue un'azione che potrebbe cambiare il senso della condizione che stai proteggendo con la variabile di condizione, dovrebbe eseguire questi passaggi. (Nel
nostro esempio, la condizione è lo stato del flag del thread, quindi questi passaggi devono essere eseguiti ogni volta che il flag viene modificato.)

1. Bloccare il mutex che accompagna la variabile di condizione.
2. Eseguire l'azione che potrebbe modificare il senso della condizione (nel nostro esempio, impostare il flag).
3. Segnalare o trasmettere la variabile di condizione, a seconda del comportamento desiderato.
4. Sbloccare il mutex che accompagna la variabile di condizione.

Il codice di sotto mostra di nuovo l'esempio precedente, che ora utilizza una variabile di condizione per proteggere il flag del thread. Notare che in thread_function, un blocco sul mutex viene mantenuto prima di controllare il valore di thread_flag. Tale blocco viene automaticamente rilasciato da pthread_cond_wait prima del blocco e viene automaticamente riacquisito in seguito. Notare inoltre che set_thread_flag blocca il mutex prima di impostare il valore di thread_flag e di segnalare il mutex

```c

/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <pthread.h>

extern void do_work ();

int thread_flag;
pthread_cond_t thread_flag_cv;
pthread_mutex_t thread_flag_mutex;

void initialize_flag ()
{
  /* Initialize the mutex and condition variable.  */
  pthread_mutex_init (&thread_flag_mutex, NULL);
  pthread_cond_init (&thread_flag_cv, NULL);
  /* Initialize the flag value.  */
  thread_flag = 0;
}

/* Calls do_work repeatedly while the thread flag is set; blocks if
   the flag is clear.  */

void* thread_function (void* thread_arg)
{
  /* Loop infinitely.  */
  while (1) {
    /* Lock the mutex before accessing the flag value.  */
    pthread_mutex_lock (&thread_flag_mutex);
    while (!thread_flag) 
      /* The flag is clear.  Wait for a signal on the condition
	 variable, indicating the flag value has changed.  When the
	 signal arrives and this thread unblocks, loop and check the
	 flag again.  */
      pthread_cond_wait (&thread_flag_cv, &thread_flag_mutex);
    /* When we've gotten here, we know the flag must be set.  Unlock
       the mutex.  */
    pthread_mutex_unlock (&thread_flag_mutex);
    /* Do some work.  */
    do_work ();
  }
  return NULL;
}

/* Sets the value of the thread flag to FLAG_VALUE.  */

void set_thread_flag (int flag_value)
{
  /* Lock the mutex before accessing the flag value.  */
  pthread_mutex_lock (&thread_flag_mutex);
  /* Set the flag value, and then signal in case thread_function is
     blocked, waiting for the flag to become set.  However,
     thread_function can't actually check the flag until the mutex is
     unlocked.  */
  thread_flag = flag_value;
  pthread_cond_signal (&thread_flag_cv);
  /* Unlock the mutex.  */
  pthread_mutex_unlock (&thread_flag_mutex);
}
```

La condizione protetta da una variabile di condizione può essere arbitrariamente complessa. Tuttavia, prima di eseguire qualsiasi operazione che possa modificare il senso della condizione, dovrebbe essere richiesto un blocco mutex e la variabile di condizione dovrebbe essere segnalata in seguito. Una variabile di condizione può anche essere utilizzata senza una condizione, semplicemente come meccanismo per bloccare un thread finché un altro thread non lo "sveglia". Anche un semaforo può essere utilizzato a tale scopo. La differenza principale è che un semaforo "ricorda" la chiamata di sveglia anche se nessun thread è stato bloccato su di esso in quel momento, mentre una variabile di condizione scarta la chiamata di sveglia a meno che un thread non sia effettivamente bloccato su di essa in quel momento. Inoltre, un semaforo fornisce solo una singola sveglia per post; con pthread_cond_broadcast, un numero arbitrario e sconosciuto di thread bloccati può essere risvegliato contemporaneamente.

### Deadlocks con due o più Thread

I deadlock possono verificarsi quando due (o più) thread sono bloccati, in attesa che si verifichi una condizione che solo l'altro può causare. Ad esempio, se il thread A è bloccato su una variabile di condizione in attesa che il thread B lo segnali, e il thread B è bloccato su una variabile di condizione in attesa che il thread A lo segnali, si è verificato un deadlock perché nessuno dei due thread segnalerà mai l'altro. Dovresti fare attenzione a evitare la possibilità di tali situazioni perché sono piuttosto difficili da rilevare. Un errore comune che può causare un deadlock riguarda un problema in cui più thread stanno tentando di bloccare lo stesso set di oggetti. Ad esempio, considera un programma in cui due thread diversi, che eseguono due funzioni di thread diverse, devono bloccare gli stessi due mutex. Supponiamo che il thread A blocchi il mutex 1 e poi il mutex 2, e che il thread B blocchi il mutex 2 prima del mutex 1. In uno scenario di pianificazione sufficientemente sfortunato, Linux potrebbe pianificare il thread A abbastanza a lungo da bloccare il mutex 1, e quindi pianificare il thread B, che blocca prontamente il mutex 2. Ora nessuno dei due thread può procedere perché ognuno è bloccato su un mutex che l'altro thread tiene bloccato. Questo è un esempio di un problema di deadlock più generale, che può coinvolgere non solo oggetti di sincronizzazione come i mutex, ma anche altre risorse, come blocchi su file o dispositivi. Il problema si verifica quando più thread tentano di bloccare lo stesso set di risorse in ordini diversi. **La soluzione è assicurarsi che tutti i thread che bloccano più risorse le blocchino nello stesso ordine**.

### Implementazione dei Thread in GNU/Linux

L'implementazione dei thread POSIX su GNU/Linux differisce dall'implementa zione dei thread su molti altri sistemi simili a UNIX in un modo importante: su GNU/Linux, **i thread sono implementati come processi**. Ogni volta che chiami pthread_create per creare un nuovo thread, Linux crea un nuovo processo che esegue quel thread. Tuttavia, questo processo non è lo stesso di un processo che creeresti con fork; in particolare, condivide lo stesso spazio di indirizzamento e le stesse risorse del processo originale anziché ricevere copie. Il programma mostrato sotto lo dimostra. Il programma crea un thread; sia il thread originale che quello nuovo chiamano la funzione getpid e stampano i rispettivi ID di processo e quindi ruotano all'infinito.

```c
/***********************************************************************
* Code listing from "Advanced Linux Programming," by CodeSourcery LLC  *
* Copyright (C) 2001 by New Riders Publishing                          *
* See COPYRIGHT for license information.                               *
***********************************************************************/

#include <pthread.h>
#include <stdio.h>
#include <unistd.h>

void* thread_function (void* arg)
{
  fprintf (stderr, "child thread pid is %d\n", (int) getpid ());
  /* Spin forever.  */
  while (1);
  return NULL;
}

int main ()
{
  pthread_t thread;
  fprintf (stderr, "main thread pid is %d\n", (int) getpid ());
  pthread_create (&thread, NULL, &thread_function, NULL);
  /* Spin forever.  */
  while (1);
  return 0;
}
```

Esegui il programma in background, quindi richiama `ps x` per visualizzare i processi in esecuzione. Non dimenticare di terminare il programma thread-pid in seguito: consuma molta CPU senza fare nulla. Ecco come potrebbe apparire l'output:

```bash
 % gcc -o thread-pid thread-pid.c -lpthread

 % ./thread-pid &
 [1] 14608
 main thread pid is 14608
 child thread pid is 14610

% ps x
 PID TTY      STAT   TIME COMMAND
 14042 pts/9    S      0:00 bash
 14608 pts/9    R      0:01 ./thread-pid
 14609 pts/9    S      0:00 ./thread-pid
 14610 pts/9    R      0:01 ./thread-pid
 14611 pts/9    R      0:00 ps x

 % kill 14608
 [1]+  Terminated              ./thread-pid
```

> [!NOTE]
> Notifica del controllo del job nella shell
> Le righe che iniziano con [1] provengono dalla shell. Quando esegui un programma in background, la shell gli assegna un numero di job, in questo caso 1, e stampa il pid del programma. Se un job in background termina, la shell segnala tale fatto la volta successiva che invochi un comando

Nota che ci sono tre processi che eseguono il programma thread-pid. Il primo di questi, con pid 14608, è il thread principale nel programma; il terzo, con pid 14610, è il thread che abbiamo creato per eseguire thread_function. E il secondo thread, con pid 14609? Questo è il "thread del gestore", che fa parte dell'implementazione interna dei thread GNU/Linux. Il thread del gestore viene creato la prima volta che un programma chiama pthread_create per creare un nuovo thread.

### Signal Handling

Supponiamo che un programma multithread riceva un segnale. In quale thread viene invocato il gestore del segnale? Il comportamento dell'interazione tra segnali e thread varia da un sistema UNIX a un altro. In GNU/Linux, il comportamento è dettato dal fatto che i thread sono implementati come processi. Poiché ogni thread è un processo separato e poiché un segnale viene inviato a un processo particolare, non vi è ambiguità su quale thread riceva il segnale. In genere, i segnali inviati dall'esterno del programma vengono inviati al processo corrispondente al thread principale del programma. Ad esempio, se un programma si biforca e il processo figlio esegue un programma multithread, il processo padre conterrà l'ID processo del thread principale del programma del processo figlio e utilizzerà tale ID processo per inviare segnali al suo figlio. Questa è in genere una buona convenzione da seguire quando si inviano segnali a un programma multithread. Si noti che questo aspetto dell'implementazione di pthreads di GNU/Linux è in contrasto
con lo standard di thread POSIX. Non fare affidamento su questo comportamento in programmi che sono
pensati per essere portabili. All'interno di un programma multithread, è possibile che un thread invii un segnale specificamente a un altro thread. Utilizzare la funzione **pthread_kill()** per farlo. Il suo primo parametro è un ID thread e il suo secondo parametro è un numero di segnale

```c
pthread_kill(pthread_t thread, int sig);
```

### La chiamata di sistema Clone()

Sebbene i thread GNU/Linux creati nello stesso programma siano implementati come processi separati, condividono il loro spazio di memoria virtuale e altre risorse. Un processo figlio creato con fork, tuttavia, ottiene copie di questi elementi. Come viene creato il primo tipo di processo? La chiamata di sistema clone di Linux è una forma generalizzata di fork e pthread_create che consente al chiamante di specificare quali risorse sono condivise tra il processo chiamante e il processo appena creato. Inoltre, clone richiede di specificare la regione di memoria per lo stack di esecuzione che il nuovo processo utilizzerà. Sebbene menzioniamo clone qui per soddisfare la curiosità del lettore, quella chiamata di sistema non dovrebbe essere normalmente utilizzata nei programmi. Utilizzare fork per creare nuovi processi o pthread_create per creare thread.

### Processi vs Thread

Per alcuni programmi che traggono vantaggio dalla concorrenza, la decisione se utilizzare processi o thread può essere difficile. Ecco alcune linee guida per aiutarti a decidere quale modello di concorrenza si adatta meglio al tuo programma:

*Tutti i thread in un programma devono eseguire lo stesso eseguibile. Un processo figlio, d'altra parte, può eseguire un eseguibile diverso chiamando una funzione exec.
* Un thread errante può danneggiare altri thread nello stesso processo perché i thread condividono lo stesso spazio di memoria virtuale e altre risorse. Ad esempio, una scrittura di memoria selvaggia tramite un puntatore non inizializzato in un thread può danneggiare
la memoria visibile a un altro thread. Un processo errante, d'altra parte, non può farlo perché ogni processo ha una copia dello spazio di memoria del programma.
* La copia della memoria per un nuovo processo aggiunge un ulteriore sovraccarico di prestazioni rispetto alla creazione di un nuovo thread. Tuttavia, la copia viene eseguita solo quando la memoria viene modificata, quindi la penalità è minima se il processo figlio legge solo
la memoria.
* I thread dovrebbero essere utilizzati per i programmi che necessitano di un parallelismo a grana fine. Ad esempio, se un problema può essere suddiviso in più attività quasi identiche, i thread potrebbero essere una buona scelta. I processi dovrebbero essere utilizzati per i programmi che necessitano di un parallelismo più grossolano.
* La condivisione dei dati tra thread è banale perché i thread condividono la stessa memoria. (Tuttavia, è necessario prestare molta attenzione per evitare race condition, come descritto in precedenza.) La condivisione dei dati tra processi richiede l'uso di meccanismi IPC. Ciò può essere più macchinoso, ma rende i processi multipli meno inclini a soffrire di bug di concorrenza
